{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Active Learning Tutorial",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/NLPproj/Text_Sum/blob/master/Copy_of_Active_Learning_Tutorial.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "qylS2W3h-3d6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Active Learning Tutorial**\n",
        "\n",
        "These days we are exposed to an abundance of unlabeled data either from the Internet or from some other source such as academia or business worlds. Due to the fact that unlabeled data is relatively easy to acquire and is expensive to label, companies usually employ an expert or several employees whose purpose is to label data [1]. Consider the following situation, a data-driven medical company has a lot of MRI scans and they need to employ an expert that will help them interpret these scans. The company has limited resources and they cant interpret or label all of their data; this is the point where they decide to use active-learning (AL). The promise of AL is that by iteratively increasing the size of our carefully selected labeled data, it is possible to achieve similar (or greater [2]) performance to using a fully supervised data-set with a fraction of the cost or time that it takes to label all the data. AL is considered to be a semi-supervised method, between unsupervised and fully supervised in terms of the amount of labeled data, i.e., for unsupervised data we use 0% labeled samples and for fully supervised we use 100% labeled samples. Therefore, the decision of how much data to use or alternatively how much performance is required from the model relies on a resource management decision, in other words it can be a business decision. \n",
        "\n",
        "There are three scenarios for AL: \n",
        "1. Membership query synthesis, i.e., a generated sample is sent to an oracle for labeling.\n",
        "2. Stream-Based selective sampling, i.e, each sample is considered separately - in our case for lable-querying or rejection. Similarly to online-learning, the data is not saved, there are no assumptions on data distribution, and therefore it is adaptive to change. \n",
        "3. Pool-Based sampling, i.e., sampled are chosen from a pool of unlabeled data for the purpose of labeling [3]. \n",
        "In this tutorial we use the third scenario.\n",
        "\n",
        "The following pseudo algorithm represents the learning process, as written in the code, for pool-based sampling:\n",
        "1. Divide the data to a 'pool' and a test-set\n",
        "2. Select 'k' samples from the pool for the initial train-set and label them, the remaining data will be the validation-set\n",
        "3. Normalize all the sets\n",
        "4. Train the Model using the train-set, with balanced weights.\n",
        "5. Use the trained model with the validation-set, get probabilities per sample.\n",
        "6. Use the trained model with the test-set, get performance measures.\n",
        "7. Select 'k' most-informative samples based on per-sample-probabilities, i.e., those that the model was most uncertain about regarding their labelling.\n",
        "8. Move these 'k' samples from the validation set to the train-set and query their labels.\n",
        "9. Inverse normalization for all the data-sets\n",
        "10. Stop according to the stop criterion, otherwise go to 3. \n",
        "\n",
        "There are a few things to note before going forward: \n",
        "1. The fully-supervised performance of a chosen algorithm is usually the upper bound, therefore it is advisable to try several algorithms.\n",
        "2. Normalization for all sets must be inversed and normalized again after we remove samples from the validation set, because our sample distribution changed in both the new validation and new train-sets.\n",
        "2. The sample selection function relies on test-sample probabilities derived from the trained model, therefore we can only use algorithms that provide access to sample probabilities.\n",
        "3. 'k' is a hyper parameter\n",
        "\n",
        "Our most important tool in AL method is the sample selection function, this is the only point where we influence the learning process and it crucial to use the right method. This area is a hot research topic and there are many studies that propose competing selection functions. \n",
        "In this tutorial I propose four known selection functions:\n",
        "1. Random selection - we select 'k' random samples from the validation set.\n",
        "2. Entropy selection - we select 'k' samples with the highest entropy, i.e., with high uncertainty.\n",
        "3. Margin selection - we select 'k' samples with the lowest difference between the two highest class probabilities, i.e., a higher figure will be given for samples whose model was very certain about a single class and lower to samples whose class probabilities are very similar. \n",
        "\n",
        "The code provided [here](https://github.com/orico/ActiveLearningFrameworkTutorial) utilizes a modular architecture in terms of selecting various learning algorithms and selection functions and can be used as a base for other model-function comparisons.\n",
        "\n",
        "We compare several learning algorithms, such as support vector machine (SVM) with a linear kernel, random forest (RF) and logistic regression (LOG). Each algorithm was executed with all of the selection functions using all 'k' = [10,25,50,125,250], accumulating a total of 80 experiments. Due to the random nature of some of the algorithms and the selection functions, it is advisable to run repeated experiments in the code in order to calculate a statistical significant result. However, running times are long and I have chosen to run the experiment only once for each combination of (model,function,k).\n",
        "\n",
        "The following is an explanation of the code and its class architecture.\n"
      ]
    },
    {
      "metadata": {
        "id": "x19OpFguwPXR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We start with all the needed dependencies."
      ]
    },
    {
      "metadata": {
        "id": "6MWwUTInv-oj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!/usr/bin/python\n",
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from scipy import stats\n",
        "from pylab import rcParams\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.datasets import fetch_mldata\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, \\\n",
        "    GradientBoostingClassifier\n",
        "\n",
        "max_queried = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WrFIsF1wvzCg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We start by downloading our data and splitting it to train and test, according to known MNIST definitions 60K/10K split. later the train-set will be split to train and validation.\n"
      ]
    },
    {
      "metadata": {
        "id": "T6lenkus5Lbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "f86040e8-49d6-402a-a00e-17bb128f44d1"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "#os.chdir('/content/scikit_learn_data/mldata')\n",
        "!cp -a /content/MNIST_data/.  /content/scikit_learn_data/mldata\n",
        "!ls -l"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 11340\r\n",
            "drwxr-xr-x 2 root root    4096 Aug 10 03:39 MNIST_data\r\n",
            "-rw-r--r-- 1 root root 1648877 Aug 10 01:33 t10k-images-idx3-ubyte.gz\r\n",
            "-rw-r--r-- 1 root root    4542 Aug 10 01:33 t10k-labels-idx1-ubyte.gz\r\n",
            "-rw-r--r-- 1 root root 9912422 Aug 10 01:33 train-images-idx3-ubyte.gz\r\n",
            "-rw-r--r-- 1 root root   28881 Aug 10 01:33 train-labels-idx1-ubyte.gz\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7ojzg4Gjwpgh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainset_size = 60000  # ie., testset_size = 10000\n",
        "from sklearn.datasets import fetch_mldata\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "#from sklearn.datasets import load_svmlight_file\n",
        "#X, y = load_svmlight_file(\"C:/Users/Ramesh/scikit_learn_data/mldata/mnist-original.mat\")\n",
        "def download():\n",
        "   \n",
        "    mnist = fetch_mldata(\"MNIST original\")\n",
        "#    mnist = input_data.read_data_sets(\"MNIST_data/\")                     \n",
        "    X = mnist.data.astype('float64')\n",
        "    y = mnist.target\n",
        "    print ('MNIST:', X.shape, y.shape)\n",
        "    return (X, y)\n",
        "\n",
        "\n",
        "def split(train_size):\n",
        "    X_train_full = X[:train_size]\n",
        "    y_train_full = y[:train_size]\n",
        "    X_test = X[train_size:]\n",
        "    y_test = y[train_size:]\n",
        "    return (X_train_full, y_train_full, X_test, y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yrb6IW2ExGST",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We create a modular class representation, 'BaseModel' is a base model for the class architecture, you can implement new models and use them interchangeably or in addition to all other models.\n",
        "our current implementations include SVM, logistic regression, random forest and gradient boosting."
      ]
    },
    {
      "metadata": {
        "id": "s2coy8C7xGqS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class SvmModel(BaseModel):\n",
        "\n",
        "    model_type = 'Support Vector Machine with linear Kernel'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training svm...')\n",
        "        self.classifier = SVC(C=1, kernel='linear', probability=True,\n",
        "                              class_weight=c_weight)\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "\n",
        "class LogModel(BaseModel):\n",
        "\n",
        "    model_type = 'Multinominal Logistic Regression' \n",
        "    \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training multinomial logistic regression')\n",
        "        train_samples = X_train.shape[0]\n",
        "        self.classifier = LogisticRegression(\n",
        "            C=50. / train_samples,\n",
        "            multi_class='multinomial',\n",
        "            penalty='l1',\n",
        "            solver='saga',\n",
        "            tol=0.1,\n",
        "            class_weight=c_weight,\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "class RfModel(BaseModel):\n",
        "\n",
        "    model_type = 'Random Forest'\n",
        "    \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training random forest...')\n",
        "        self.classifier = RandomForestClassifier(n_estimators=500, class_weight=c_weight)\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X51UCCeEzqb9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our 'TrainModel' class accepts one of the previously in defined learning algorithms, trains using the training set and gets performance measurements from the test set."
      ]
    },
    {
      "metadata": {
        "id": "NEcquMhTzqlC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = model_object()        \n",
        "\n",
        "    def print_model_type(self):\n",
        "        print (self.model_object.model_type)\n",
        "\n",
        "    # we train normally and get probabilities for the validation set. i.e., we use the probabilities to select the most uncertain samples\n",
        "\n",
        "    def train(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('Train set:', X_train.shape, 'y:', y_train.shape)\n",
        "        print ('Val   set:', X_val.shape)\n",
        "        print ('Test  set:', X_test.shape)\n",
        "        t0 = time.time()\n",
        "        (X_train, X_val, X_test, self.val_y_predicted,\n",
        "         self.test_y_predicted) = \\\n",
        "            self.model_object.fit_predict(X_train, y_train, X_val, X_test, c_weight)\n",
        "        self.run_time = time.time() - t0\n",
        "        return (X_train, X_val, X_test)  # we return them in case we use PCA, with all the other algorithms, this is not needed.\n",
        "\n",
        "    # we want accuracy only for the test set\n",
        "\n",
        "    def get_test_accuracy(self, i, y_test):\n",
        "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
        "        self.accuracies.append(classif_rate)               \n",
        "        print('--------------------------------')\n",
        "        print('Iteration:',i)\n",
        "        print('--------------------------------')\n",
        "        print('y-test set:',y_test.shape)\n",
        "        print('Example run in %.3f s' % self.run_time,'\\n')\n",
        "        print(\"Accuracy rate for %f \" % (classif_rate))    \n",
        "        print(\"Classification report for classifier %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
        "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
        "        print('--------------------------------')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vYar8S_jyYQ9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We create a modular selection function class representation, 'BaseSelectionFunction' is a base class for various sample selection methods. Using this architecture, you can implement new selection methods and use them in addition or instead of previous methods, for experimental purposes. Our current implementations include random-selection, entropy-selection, margin sampling-selection and minimum standard deviation-selection."
      ]
    },
    {
      "metadata": {
        "id": "ni-E8tN7yYX2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BaseSelectionFunction(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def select(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class RandomSelection(BaseSelectionFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        random_state = check_random_state(0)\n",
        "        selection = np.random.choice(probas_val.shape[0], initial_labeled_samples, replace=False)\n",
        "\n",
        "#     print('uniques chosen:',np.unique(selection).shape[0],'<= should be equal to:',initial_labeled_samples)\n",
        "\n",
        "        return selection\n",
        "\n",
        "\n",
        "class EntropySelection(BaseSelectionFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
        "        selection = (np.argsort(e)[::-1])[:initial_labeled_samples]\n",
        "        return selection\n",
        "      \n",
        "      \n",
        "class MarginSamplingSelection(BaseSelectionFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        rev = np.sort(probas_val, axis=1)[:, ::-1]\n",
        "        values = rev[:, 0] - rev[:, 1]\n",
        "        selection = np.argsort(values)[:initial_labeled_samples]\n",
        "        return selection\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ym7QEvD0yI9Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have a class that is used to normalize using a MinMax Scaler in the range of [0,1]."
      ]
    },
    {
      "metadata": {
        "id": "5aRcKj4D0SQJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Normalize(object):\n",
        "    \n",
        "    def normalize(self, X_train, X_val, X_test):\n",
        "        self.scaler = MinMaxScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_val   = self.scaler.transform(X_val)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_val, X_test) \n",
        "    \n",
        "    def inverse(self, X_train, X_val, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_val   = self.scaler.inverse_transform(X_val)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_val, X_test) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pl_AfuOx0fkM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Initially we would like to get a random sampling from the unlabeled data-pool, this is done using random.choice without replacement."
      ]
    },
    {
      "metadata": {
        "id": "l1GJB6Kb0e54",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_k_random_samples(initial_labeled_samples, X_train_full,\n",
        "                         y_train_full):\n",
        "    random_state = check_random_state(0)\n",
        "    permutation = np.random.choice(trainset_size,\n",
        "                                   initial_labeled_samples,\n",
        "                                   replace=False)\n",
        "    print ()\n",
        "    print ('initial random chosen samples', permutation.shape),\n",
        "#            permutation)\n",
        "    X_train = X_train_full[permutation]\n",
        "    y_train = y_train_full[permutation]\n",
        "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "    bin_count = np.bincount(y_train.astype('int64'))\n",
        "    unique = np.unique(y_train.astype('int64'))\n",
        "    print (\n",
        "        'initial train set:',\n",
        "        X_train.shape,\n",
        "        y_train.shape,\n",
        "        'unique(labels):',\n",
        "        bin_count,\n",
        "        unique,\n",
        "        )\n",
        "    return (permutation, X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SeRHks3K0wQO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is the main class that initiates the active-learning process according to the algorithm described in the introduction. In short, we select 'k' random samples, train a model, select the most informative samples, remove from the validation set, query their labels and retrain using those samples until reaching the stop criteria."
      ]
    },
    {
      "metadata": {
        "id": "eRtOTPPvyJGx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TheAlgorithm(object):\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    def __init__(self, initial_labeled_samples, model_object, selection_function):\n",
        "        self.initial_labeled_samples = initial_labeled_samples\n",
        "        self.model_object = model_object\n",
        "        self.sample_selection_function = selection_function\n",
        "\n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test):\n",
        "\n",
        "        # initialize process by applying base learner to labeled training data set to obtain Classifier\n",
        "\n",
        "        (permutation, X_train, y_train) = \\\n",
        "            get_k_random_samples(self.initial_labeled_samples,\n",
        "                                 X_train_full, y_train_full)\n",
        "        self.queried = self.initial_labeled_samples\n",
        "        self.samplecount = [self.initial_labeled_samples]\n",
        "\n",
        "        # permutation, X_train, y_train = get_equally_k_random_samples(self.initial_labeled_samples,classes)\n",
        "\n",
        "        # assign the val set the rest of the 'unlabelled' training data\n",
        "\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "        print ('val set:', X_val.shape, y_val.shape, permutation.shape)\n",
        "        print ()\n",
        "\n",
        "        # normalize data\n",
        "\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)   \n",
        "        \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        # fpfn = self.clf_model.test_y_predicted.ravel() != y_val.ravel()\n",
        "        # print(fpfn)\n",
        "        # self.fpfncount = []\n",
        "        # self.fpfncount.append(fpfn.sum() / y_test.shape[0] * 100)\n",
        "\n",
        "        while self.queried < max_queried:\n",
        "\n",
        "            active_iteration += 1\n",
        "\n",
        "            # get validation probabilities\n",
        "\n",
        "            probas_val = \\\n",
        "                self.clf_model.model_object.classifier.predict_proba(X_val)\n",
        "            print ('val predicted:',\n",
        "                   self.clf_model.val_y_predicted.shape,\n",
        "                   self.clf_model.val_y_predicted)\n",
        "            print ('probabilities:', probas_val.shape, '\\n',\n",
        "                   np.argmax(probas_val, axis=1))\n",
        "\n",
        "            # select samples using a selection function\n",
        "\n",
        "            uncertain_samples = \\\n",
        "                self.sample_selection_function.select(probas_val, self.initial_labeled_samples)\n",
        "\n",
        "            # normalization needs to be inversed and recalculated based on the new train and test set.\n",
        " \n",
        "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "\n",
        "            # get the uncertain samples from the validation set\n",
        "\n",
        "            print ('trainset before', X_train.shape, y_train.shape)\n",
        "            X_train = np.concatenate((X_train, X_val[uncertain_samples]))\n",
        "            y_train = np.concatenate((y_train, y_val[uncertain_samples]))\n",
        "            print ('trainset after', X_train.shape, y_train.shape)\n",
        "            self.samplecount.append(X_train.shape[0])\n",
        "\n",
        "            bin_count = np.bincount(y_train.astype('int64'))\n",
        "            unique = np.unique(y_train.astype('int64'))\n",
        "            print (\n",
        "                'updated train set:',\n",
        "                X_train.shape,\n",
        "                y_train.shape,\n",
        "                'unique(labels):',\n",
        "                bin_count,\n",
        "                unique,\n",
        "                )\n",
        "\n",
        "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
        "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
        "            print ('val set:', X_val.shape, y_val.shape)\n",
        "            print ()\n",
        "\n",
        "            # normalize again after creating the 'new' train/test sets\n",
        "            normalizer = Normalize()\n",
        "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            self.queried += self.initial_labeled_samples\n",
        "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "        print ('final active learning accuracies',\n",
        "               self.clf_model.accuracies)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K7OZblsL00L2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We download the data, split to train validation and test, we run the experiment by iterating over all of our training algorithms X all of our selection functions X all possible k's in the range of [10,25,50,125,250]. The accuracy results are kept in a dictionary and pickle-saved to a unique file as soon as the model finishes training - this is crucial when using google colaboratory as it tends to disconnect from time to time. We also limit our training to a maximum of 500 queried samples."
      ]
    },
    {
      "metadata": {
        "id": "2XzrAvJz00dk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1170
        },
        "outputId": "65b14c40-8b74-46b8-bef8-f3264a0facb5"
      },
      "cell_type": "code",
      "source": [
        "(X, y) = download()\n",
        "(X_train_full, y_train_full, X_test, y_test) = split(trainset_size)\n",
        "print ('train:', X_train_full.shape, y_train_full.shape)\n",
        "print ('test :', X_test.shape, y_test.shape)\n",
        "classes = len(np.unique(y))\n",
        "print ('unique classes', classes)\n",
        "\n",
        "def pickle_save(fname, data):\n",
        "  filehandler = open(fname,\"wb\")\n",
        "  pickle.dump(data,filehandler)\n",
        "  filehandler.close() \n",
        "  print('saved', fname, os.getcwd(), os.listdir())\n",
        "\n",
        "def pickle_load(fname):\n",
        "  print(os.getcwd(), os.listdir())\n",
        "  file = open(fname,'rb')\n",
        "  data = pickle.load(file)\n",
        "  file.close()\n",
        "  print(data)\n",
        "  return data\n",
        "  \n",
        "def experiment(d, models, selection_functions, Ks, repeats, contfrom):\n",
        "    algos_temp = []\n",
        "    print ('stopping at:', max_queried)\n",
        "    count = 0\n",
        "    for model_object in models:\n",
        "      if model_object.__name__ not in d:\n",
        "          d[model_object.__name__] = {}\n",
        "      \n",
        "      for selection_function in selection_functions:\n",
        "        if selection_function.__name__ not in d[model_object.__name__]:\n",
        "            d[model_object.__name__][selection_function.__name__] = {}\n",
        "        \n",
        "        for k in Ks:\n",
        "            d[model_object.__name__][selection_function.__name__][str(k)] = []           \n",
        "            \n",
        "            for i in range(0, repeats):\n",
        "                count+=1\n",
        "                if count >= contfrom:\n",
        "                    print ('Count = %s, using model = %s, selection_function = %s, k = %s, iteration = %s.' % (count, model_object.__name__, selection_function.__name__, k, i))\n",
        "                    alg = TheAlgorithm(k, \n",
        "                                       model_object, \n",
        "                                       selection_function\n",
        "                                       )\n",
        "                    alg.run(X_train_full, y_train_full, X_test, y_test)\n",
        "                    d[model_object.__name__][selection_function.__name__][str(k)].append(alg.clf_model.accuracies)\n",
        "                    fname = 'Active-learning-experiment-' + str(count) + '.pkl'\n",
        "                    pickle_save(fname, d)\n",
        "                    if count % 5 == 0:\n",
        "                        print(json.dumps(d, indent=2, sort_keys=True))\n",
        "                    print ()\n",
        "                    print ('---------------------------- FINISHED ---------------------------')\n",
        "                    print ()\n",
        "    return d\n",
        "\n",
        "\n",
        "max_queried = 500 \n",
        "\n",
        "repeats = 1\n",
        "\n",
        "models = [SvmModel, RfModel, LogModel] \n",
        "\n",
        "selection_functions = [RandomSelection, MarginSamplingSelection, EntropySelection] \n",
        "\n",
        "Ks = [250,125,50,25,10] \n",
        "\n",
        "d = {}\n",
        "stopped_at = -1 \n",
        "\n",
        "# print('directory dump including pickle files:', os.getcwd(), np.sort(os.listdir()))  \n",
        "# d = pickle_load('Active-learning-experiment-' + str(stopped_at) + '.pkl')  \n",
        "# print(json.dumps(d, indent=2, sort_keys=True))\n",
        "\n",
        "d = experiment(d, models, selection_functions, Ks, repeats, stopped_at+1)\n",
        "print (d)\n",
        "results = json.loads(json.dumps(d, indent=2, sort_keys=True))\n",
        "print(results)\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-5551164af177>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'train:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'test :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-a2ebccf35bc9>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_mldata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MNIST original\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#    mnist = input_data.read_data_sets(\"MNIST_data/\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/datasets/mldata.py\u001b[0m in \u001b[0;36mfetch_mldata\u001b[0;34m(dataname, target_name, data_name, transpose_data, data_home)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0murlname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLDATA_BASE_URL\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mmldata_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 642\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Dataset 'mnist-original' not found on mldata.org."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "HT9kYxtP381F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Independently, we trained several models using a train-test split of 60K-10K, the results indicate that the upper-bound for RF, SVM and LOG are 97., 94. and 92.47, respectively.\n",
        "\n",
        "The following graphs show that the random forest classifier paired with the margin-selection method and k=10 is the best configuration."
      ]
    },
    {
      "metadata": {
        "id": "oXoHDRLArYjX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1037
        },
        "outputId": "91f371fa-abc9-4f30-e297-873906e84191"
      },
      "cell_type": "code",
      "source": [
        "def performance_plot(fully_supervised_accuracy, dic, models, selection_functions, Ks, repeats):  \n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot([0,500],[fully_supervised_accuracy, fully_supervised_accuracy],label = 'algorithm-upper-bound')\n",
        "    for model_object in models:\n",
        "      for selection_function in selection_functions:\n",
        "        for idx, k in enumerate(Ks):\n",
        "            x = np.arange(float(Ks[idx]), 500 + float(Ks[idx]), float(Ks[idx]))            \n",
        "            Sum = np.array(dic[model_object][selection_function][k][0])\n",
        "            for i in range(1, repeats):\n",
        "                Sum = Sum + np.array(dic[model_object][selection_function][k][i])\n",
        "            mean = Sum / repeats\n",
        "            ax.plot(x, mean ,label = model_object + '-' + selection_function + '-' + str(k))\n",
        "    ax.legend()\n",
        "    ax.set_xlim([50,500])\n",
        "    ax.set_ylim([40,100])\n",
        "    ax.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "models_str = ['SvmModel', 'RfModel', 'LogModel']\n",
        "selection_functions_str = ['RandomSelection', 'MarginSamplingSelection', 'EntropySelection']\n",
        "Ks_str = ['250','125','50','25','10'] \n",
        "repeats = 1\n",
        "random_forest_upper_bound = 97.\n",
        "svm_upper_bound = 94.\n",
        "log_upper_bound = 92.47\n",
        "total_experiments = len(models_str) * len(selection_functions_str) * len(Ks_str) * repeats\n",
        "\n",
        "print('So which is the better model? under the stopping condition and hyper parameters - random forest is the winner!')\n",
        "performance_plot(random_forest_upper_bound, d, ['RfModel'] , selection_functions_str    , Ks_str, 1)\n",
        "performance_plot(svm_upper_bound, d, ['SvmModel'] , selection_functions_str    , Ks_str, 1)\n",
        "performance_plot(log_upper_bound, d, ['LogModel'] , selection_functions_str    , Ks_str, 1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "So which is the better model? under the stopping condition and hyper parameters - random forest is the winner!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFOCAYAAACrPEW7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fce083d1b70>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFOCAYAAACrPEW7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzsnXeYXVW5/z+779Omz2QmlSSThNCC\nNEMXwYKooCh6EcvPfgUVG3KtKHIRwa7XioKiUlVApEgTVIoQSgiQXiaTKWfaqbvv9fvjnDkzk04S\nIRPW53nWs8ous9Y+Z/b3vKu8SxFCCCQSiUQikez1qC91BSQSiUQikewcUrQlEolEIpkkSNGWSCQS\niWSSIEVbIpFIJJJJghRtiUQikUgmCVK0JRKJRCKZJOyUaK9YsYJTTjmFa665BoCenh7e/e53c/bZ\nZ/PJT34S3/cBuOWWWzjzzDN5+9vfzg033PCfq7VEIpFIJC9Ddija5XKZiy++mKOPPrpW9oMf/ICz\nzz6b3//+98yaNYsbb7yRcrnMj3/8Y6666ip++9vfcvXVVzMyMvIfrbxEIpFIJC8ndijapmnyi1/8\ngra2tlrZI488wsknnwzASSedxEMPPcRTTz3FwQcfTCaTwbZtDjvsMJYsWfKfq7lEIpFIJC8z9B2e\noOvo+sTTHMfBNE0AmpubyWazDAwM0NTUVDunqamJbDa7h6srkUgkEsnLl92eiLYtL6g74x1VelCV\nSCQSiWTn2aGlvTWSySSu62LbNn19fbS1tdHW1sbAwEDtnP7+fg499NDt3kdRFLLZwq5UYa+itTUz\n6duxL7QB9o127AttANmOvYl9oQ2wb7SjtTWzW9fvkqV9zDHHcOeddwJw1113cfzxx7No0SKWLl1K\nPp+nVCqxZMkSjjjiiN2qnEQikUgkkjF2aGk/88wzXHbZZXR3d6PrOnfeeSdXXHEFF154Iddddx1T\np07ljDPOwDAMPvOZz/CBD3wARVE499xzyWR27xeFRCKRSCSSMZSXemvOyd7VAftOl81kbwPsG+3Y\nF9oAsh17E/tCG2DfaMdL0j0ukUgkEonkxUeKtkQikUgkkwQp2hKJRCKRTBKkaEskEolEMkmQoi2R\nSCQSySRBirZEIpFIJJMEKdoSiUQikUwSpGhLJBKJRDJJkKItkUgkEskkQYq2RCKRSCSTBCnaEolE\nIpFMEqRoSyQSiUQySZCiLZFIJBLJJEGKtkQikUgkkwQp2hKJRCKRTBKkaEskEolEMkmQoi2RSCQS\nySRBirZEIpFIJJMEKdoSiUQikUwSpGhLJBKJRDJJkKItkUgkEskkQYq2RCKRSCSTBCnaEolEIpFM\nEqRoSyQSiUQySdBfyj/+gW/cRRSJl7IKewRNUyZ9O/aFNsC+0Y59oQ0g27E3sS+0AfaNdlz11dft\n1vXS0pZIJBKJZJKgCCFe0p8t2Wzhpfzze4TW1sykb8e+0AbYN9qxL7QBZDv2JvaFNsC+0Y7W1sxu\nXS8tbYlEIpFIJglStCUSiUQimSRI0ZZIJBKJZJIgRVsikUgkkkmCFG2JRCKRSCYJUrQlEolEIpkk\nSNGWSCQSiWSSIEVbIpFIJJJJghRtiUQikUgmCVK0JRKJRCKZJEjRlkgkEolkkiBFWyKRSCSSSYIU\nbYlEIpFIJglStCUSiUQimSTou3JRHMd89atfZeXKlRiGwUUXXUQymeSCCy4giiJaW1u5/PLLMU1z\nT9dXIpFIJJKXLbsk2vfccw+FQoFrr72WDRs2cMkll9DU1MTZZ5/Nqaeeyne+8x1uvPFGzj777D1d\nX4lEIpFIXrbsUvf4unXrOOSQQwCYOXMmmzZt4pFHHuHkk08G4KSTTuKhhx7ac7WUSCQSiUSya6I9\nf/58/vGPfxBFEWvWrKGrq4vu7u5ad3hzczPZbHaPVlQikUgkkr0dIQRhEOG5AeWiRyHnMjJUZrC/\nSH9Pfrfvv0vd4yeeeCJLlizhXe96FwsWLGDOnDmsWLFiQqV3ltbWzK5UYa9jX2jHvtAG2DfasS+0\nAWQ79iYmaxuEEIRhTOBHFPIupq4TxzFRJIhjQRyNpmPiSBBFcaW8eiyOx5WNPx5NvEflPEEURURh\nTBjGhEFMFFXSURhV43gr8dixON6+/h347Wm79Tx2SbQBPvWpT9XSp5xyClOmTMF1XWzbpq+vj7a2\ntp26TzZb2NUq7DW0tmYmfTv2hTbAvtGOfaENINuxN/GfakMcC3wvxHUCfC8kDCYKXCVfFbTRdDAm\ndkEwXiCjiSI47ry9CVVT0HUVVVPRNBVNU7CTRiWtV/KmEWJZHpbpYpoupuFi6A665uz2398l0X7+\n+ee5+uqrufTSS3nggQc44IADqK+v58477+T000/nrrvu4vjjj9/tykkkEonkxSEMIlwnwHUqIuy5\nwYS86wR4m+fdcI/9fU1T0HQN3VDRdRXT0jEMDU2v5HVdI5kyCYIIRVVQVQVVU1CVaqwqqKqKqiqV\n47WysXJ1K+WKqqAooKouisijxDmohjgcIQ5zgEBRNBRFRVE02CxWFBVQiMISUZBHxMEeey6bs0ui\nPX/+fIQQvO1tb8OyLK644go0TePzn/881113HVOnTuWMM87Y03WVSCQSyQ6IohjPDfHcAM8J8dyQ\nnvUj9PcVcN2K6HpOUBPe0Xy4kxatqipYCZ1k2qSpJYWdMLASOpalo48XWUOrxmq1bEyQNV3DGFeu\n6RVR3RE76jEQQhCFReLQQcQ+Ig4QcUBcjceHOPaJ/ByBN0ToDRPF3pY3VDR0sx5F0RAiQogYIUJE\nHIOIamWIqPJs9CS61YJuZtCMOjSjDt2sxJpZh2bs/hDFLom2qqp885vf3KL817/+9W5XSCKRSF7u\nCFHpdvbcsGbR1oTYDStC644rdwK8ajd1GOx8d7Jhati2TkNzkkTSwEoY2LaBndCrYmxgJ8bydsLA\nMDUUZccC+58mCkoEbj+BmyVwsgRuP77bj4i2Ir7bQVF0dKsJ3Wqsxk0Y1bRm1FWt6B0jhHhRnssu\nj2lLJBLJnuJtb3sTv/nNdSSTyV26/uGH/0VPzybe8pa3cd99d3PSSafQ07OJL33p81x55W+3e23g\nR+RHHPIjbjV2yFXThZyLiEWlu1VRat2yilKNVWrlmx8bTVeuZez4ZvcCquPCFSFet+E5nlnxACcc\n8d6dbr9paVi2QUNTEsvWsarCO5puaU0ThFHNKrYTBme94w3cdts9u/S8XyziOCDyc4TeMKGfwxnM\nkR/qJnCzxGFps7MVdKsZIzMHTU+jqDqKaqCqJopq1II6Ll2xhjN7RGxfrB8yUrQlEsmkZ/HiY2rp\na665mpNOOqWWF0JQLvnkhyvCnBtxKFTj/IiDU9r6+KOdMGhpS2PZBr4XEscCIcTEuBqiKEYE1GYt\nC1Epj6vxziyo0XQV29Yr1m3SYL/OZqyEgWXrlXLbwLT1qhgbVUGuBFXdvjX4Ukymi8IycVgGIRCM\nPgDB2MMQUD0Sh2VCf4TIGyH0c4T+CKE/shVhrqCbjVh10zASrRh2G4bdimG3oKj7vqTt+y2USCR7\nFaVSka997Us4joPrunzqU5+rHVu1aiWXXPJV0ukM++9/ACMjw3zxixdx/fV/4J577gLg+ONP5Jxz\n3scll1yErhvk8yMsXnwcy5evIGFmWLlyBR/54H9z4tFnMZQt8oF3f5KB4fU01U/nlYe8nYeevBbL\nTDOc34gfljnmyNN4btW/cL0SX/6fK2if2kxdQwLTqrwe3/jGU/jLX+4G4EtfuoC3vvUsnnhiCdmh\nfvr6ehkcHOBjH/skixcfwxlnnMqrXvVqnnv+WVpbW/nqVy8hCHwuueRrFAp5oiji4+d9htmzO3nP\ne97GkUcdTUN9I+973wdQtZjIG+Hxx/pZt6nEvQ99j77+IY5dfChnv+M01q7r5jvf/wOKopBI2Hz2\nk+9j2VMbueWvf+fLn/8IoHDWuz/N9dd8l8998XIOW3QgTy19jly+yHcuuxDbTnPp5T8hOzDE/vPn\nIUSM7/RXLFJFr1mmiqK/IKsxjgNCN4vv9BM4/ZVuaqefOCzu+pdEUdHNBsxEG5rZgF4Nre3TKTop\nVG1yush+Icuht4UUbYnkZcr1967i38/379F7Hrl/G2e9unO75wwODvLGN57BCSe8iscf/ze/+93V\ntWO//vXPed/7PsSJJ57El798IZZlsXrlWm699Wa+/pUf4pR8vn7p+dTb8+jpGsE00hy6/1v5+x3/\nIFfo5bADjsTQLA7tfAfd64cYzvVx+uvOo72jjR/+8jMcecJUunKNtLdP4byPf4uLL/4KRnqEq397\nNRdf/GWGCus4aMp+O9XWbDbLd7/7Y1avXsU3vvEVFi8+hoGBLKec8nrOP/9zfPGLn+Phh//J6tWr\nWLz4GN74xjezeuVSfvDDb/G/F32CIChxyDyNQxbq9D7//ZrIjfQMsHrtWr5/0Slo6nQ+8427OX5R\nwI+ufIx3vnkhnfs18pd7VnHt737GAfNbCJwehrpuAyCOfYY23EroDoK3kgs+NJ8/3Pwsf7zuJ7S3\npSnn1/Plc49i1bph/nRLgd7nf7plwxQVVUugavZY0CfmRRzguxWRDr0hYKIYaUY9dl0nulEHigKM\nBkBRUBj/o0BB1W10sxHdrEczG7bZZZ2qz1D2X/rld0IIvMijFDiUwhLlwKEUlCr5oEw5LFMKxsJo\nvhw6XHvWj3frb0vRlkgkLyqZTAN/+9td/Obqq/A8D0O38L2Qh+5bzbKlyzlw9pu4dsWjRMV2Vqx8\nnl9m/4Iet3LHTcsASBpT+deDS8iPuEybMhdFgcbmJJqd4qgTZnPz/Tpnvvcwyu4IyzbM4n3nVtwr\n33DbFKbPyZBKWxz6ikNRVZXm5hZmzdoPgMbGZkqlnbcODz/8SADmzu0km80S+iPYts3saSr5voeY\nM93iuSf/wtPLVpPPl7jlpp8A4PkRQxtuIY5cpjeP4JccdLMBIz0b3WokNZhlwfw80xacBcDs2V14\n5ivpyf6LV77qAwAcc+I6rvnDn1ncfjxm0qd51lsAgareS9PM09Ht5znq2LfSNHMGM2YncT2XobLC\nIYumUN9+IodNiTDNh0m3HFGZAR2HlVnRkU8cubUQ+sMgtj2xTdFsrNQMjEQbRqIN067Eqma/oO/E\nthBCIDyXMJcnyucZ6TFwij5oGoquo2gaiqZV8rWgo+ijZTrKDoYO/MifIK7FoEx5VHBHxXZUlMNK\nXA4couqM8R2hKiopPUnKSNGWbN3tZyJFWyJ5mXLWqzt3aBWPEsfxBGcXo44wtnCKEUQ8s6SbMIjR\nNZXBgSLlko9TCnDKPuWSz5JldxBFAYcvfB+DI10sefZWPDdk2ROb8P2Qvk0FGupVLFsnkTLpmF6H\nT5KjTphNImmwqVDHkUfOZckTfZx88iEcf8LR/PWvA6xZE3D4MbPQNIW2jjp6eopo2sRX3Gj3pKZp\ntbLxaSEEf/rTjdxzz100NDTyjW9cNuH6IPAJ3AF8pw/hBWTXXEvgDhCHJTYt+wFxFDC47iYA3OKG\nyv2VgP/3zldywMK51SVADehWI5r+ENMPOpdM/RQuv/xSNmxYypFHvpKDD16Ebj5BqvGgyvVGmkRd\nJ4pq1Mr0RIxh1ZPIzEE3/02q6WAAoliQbl6EpqfJNB9AurkTK70C1XKIYxVFUanvOLHaGoWmGW/Y\n7udeGZsPxgm5Qxy5KIqGYbft8iSu2HUJ83mifI4wlyPK5wnzuUo+nycaVyZ8/wXff0IbAKGpCFUh\nVhViFSJVIVJEJagQK6Pl1M5RFIWECpaq0FA9R9V1VN1AqwbdMNF1E8Ow0A0L07AxTbsaJ7DNBIZh\noVZ/YKDtvuRK0ZZIXgYIISgVPAazJYYHShRybk2EwzCqeqfa0pNVVE3vyDXjjlAUSKRMGhqTGHbI\nfh2zWXTUDO7++0NkGkxi1eQt57yCdUOdvPKUBo455li+/vU7mTmnibef8xouvPAOFh1Vcf/Y9b3V\nnPvxj7F02aOo2pZW1O7W9YwzzuRNp72W0BukMPAYIg7oWvYrAm+Q5599nOHDY5zcAM915Xjt0QZd\nPR6tLfUkGw/GD25hwDuA/fc/mK6BH/LG004n3dbFcxuLnPTm97F27RoeeeBfvPOdr0ZR9eoaYJUL\nLvhi7e8vWfIYK1Ysx3VdFEVh/fp1TJs2ndmz5/LMM09z0EGH8MQTS1iwYCGpVIrBwQGgMh+gXC5v\ns10zZ87ib3+7E4ClS5/C3wkxVBQFRTOrY8h12z039ryq8G4mxlsRZeHtYFmWqqJkMojWZqJ0giBl\n4ScMhAllxyEMfKLQJwoCojAgjgKIItQY1Bi0WFTSohpX81o1r8egCTBiBTWgek6MEgmUPTDuHFbD\n1j6N2Scft1v3lqItkexDCCEoF32GBkoMZUsMDZQYHigzPFjC93bcnTfe+YVp6eipMecXFWcYYw4z\ndF1DM0a9VY050xh1mNE6JYMfhCRTJpY9NrnpoKMTfOMbX6V3aBlnnnkWS7//MJqm0NyW5v3v/xCX\nXXYxN974B2bPnkOxWKSjYypvfvNb+PjHP0wcC970ptNpb+/YZhvmz1/Ahz70Hr7+9S19SYwnjjyi\nsIhX2shIz/04uRWM9HSx8elnJni0evUx07jgot8yfWoTc2dPJVG/P4m6Phpb8/zoDwP09vbxifO/\nRst+R1Ff/yP+8eh6fvmbO2hubmHxMSdx2BEel1xyER/72AeJ45jzz//sDj+H+fMXcOmlX6OrawOn\nn/5WMpkM55//Wb7znctQFIVMJsMXvvBVEokktp3gox99PwcfvIj29qnbvOfixcdy2223cN55H6az\ncx6trTt2NR37/mbWcFWQ8zmiXNUqrgqz8Nzt3kuoCiKVJGxMEySbcJMGZVulZCsUrJgRI2bICBkx\nA1xTqY6FR0CxGrbE0mxSRjMpPUHKSJE0KnElnyRpJEmNBr2ST+oJNFXb6v2AiuOUOEZEEXEY4jo+\nruPhOD6e6+G6fnWNvI/v+vieT+CH1Tgg9AKCICT0A6IgJApC4jCs/IAg5tgdPvXto4g9MZ1tN5js\nPn1B+ibem9gX2rEzbRBC4JSDccJcqgp1Gd+b6FpSVRXqmxI0taRoaknR2JKivjGBYU70WKVp6h5d\na7orn8UzzyzFtm06O+dx9VU/IwzyvO1NRxM4vQgRoxkpVD2FpqfRjDSankI1KvnxM4pFHBIFBcIg\nT+TniYI8YTWOggKhn9vqcqKaow27GcNqRreaaeuYRdFJoGpW7bwrr/wZDQ0NnHnmOyZcf9ppJ++V\na5/HfxZx4FeFdpwA1yzi8VZxntjZvq9soSiESRM/aeIkdMq2QtFSyFsxI2ZE2VarwqziWqNCvCWG\namwhrqlxIalX4mmtzQQlpZpPoG9jiZcQAj+Mcb0Qx49wvHBciHD8Str1IspeiOtXy72wdszxIlwv\nZFcEUlMVEpZO0tKxLY2EqZOwdBKWxhfev3gX7jiGtLQlkr0cp+wzPFDezHou4ToTxVlRoL4xwbRZ\nDRWBbq2IdH1TAm0r3ch7C0IIQn+YoNyLl3uSyy+7FkOLMQ04772Hk+u5d6fuo6gGqp6qjMFuY31v\n5UQN3ajDzEypOOOwm2uxZtRv8cNlb5mxvD2EEMSlEmFuhHBkpGIF50aq+Ry9ThFncKhiEe9IiAEv\noeMkNMoNNgUbSlXhLdsqjq1SSlTSrqkgxrkf1RRtgtA2GUmmjxPjLazf6nmmZtTuEUZxRUi9cUJa\nCil5IWuGNPoHSzh+AdfbTIzHibPrR0S7MEyiKFSE1tRprrNJWFpVbHUSZiVtj4qxOe7Y6HlmJW3o\nY5Z8EMeUgohyFFMOd27y2nbrKC3t3eflYt1NBiZzOzy3YjkHXsT6NUM1cXbKWzr/qG9M0NiSrFnO\nza0pGpqSaPp/Vpyj0CEKCuPW9hpj6c3ErrU1Q39/njgsEwWFSgiLY+mgkg7cAUQ8cXxVM+owk+0Y\niXbMRAdmcgqKahIFReKwSBSUiMIScVCsbtJQieOwNM7TVV3VB3Q9mplBr5apevIF9Si8lN8pEUVE\nhTzhyJgIR7kc/sgw3vAgYW6EOJdDFEoo0bYFQQCOpVK2FcqJMet31BIeLSvbGo6loGgayWqXc8pI\nTLB2N7d+R4Ot2sSRVhHT8datP2a1lrewbidavo4XEUa7tqtXwtKwx1m0461b2xy1ejc/NlFwTWOs\nt0kIQTGM6Hd8vCgmjAWhEASxIIxjolq6YtV7YVQR5zDCiSKcWODGMZt/Kr94w2G71L5RpKUtkbzI\n+F5YsZoHSgxny7V0ubjlxKBMvc2suXU0tSZprHZvNzQnMYxtj8ntKaLQISj34JU34Ts9+OUeIn9k\nm+dv7qCjRxUEbh7YzktY0dCtRsxEey0YyXY0fevuTCvlO7ft795MHPgV8R0eojjUjzM0gD8yKsJ5\nyBdRi2W0souyHbMqUqkIcINKKWFSsjVKiaolnFApJTREOoneUIelJytjvnpFiOuNJB2jli4WmrBQ\nYxMikyjQcGvCG+GWK4Kb8yJ6a0Ic4HiDOH4fjhfivwCf5+MxDZWEpZOyDVrqExNE1ba0muWbsDSm\ntGYIvGCC5ZuwdCxTQ93JH2JxLAj8iMAPq3HESN5jpeuT9QMGgpChOGIEgb+Lo0VKGKMGlWAEY2l1\nF5/ReKRoSyT/IQI/ZHiwXOvSHhooMzxQopjfcuZsus5ixpwmmlpSzJrdjGGrNDYnMcwX5180jjz8\ncjd+uacWQn94wjmqnsTOzEW3GsfW9cZBNV2N42qZCFHRMVNTq+PPmXFhLK9q9l6x+cSeQAhB7LoV\nIR7spTjUhzs0iD8yRJTLQaGAWiijlzxMb+tbWo5+2r6uULRVSi1GTYT9lEWYSkAmhVKXQa2vR09l\nMNUEBhaasEnGJqnIREQ6cWASeSqOH4OjMpxzcLyQkXHjt64f4nrDuzRuq2sqSUvDtnQaUtZmXcnj\nBHdr1q2pkbArXczaDtZRQ2XnMqfkk0xa9PflCfwIr+hT8CMCL8B3AnzXJ/BCfC8k8IKKIAcRQVBZ\nGeGHAk/X8E2N0NaIbI0gbeCnDcKkDuN3GVNAK4ckigFGKUANYpQYiAVaFKKFIVoUoEcheuijhwF6\nGGB5DpZXxggD9DhAiwM0EaDHYSUdB3Deq3bhaY977rt1tUQiIQyiijiPTgjLVgS6kNtyNm0qbTJ9\nv8baePNoF/eoy0x4cbpjo6CEV+rCK67HK27Ad3oZ79VK1RLYmbmYyQ7M5FTMZEd1x6PJ0a28JxFx\njJ8bIT/YQ3Gwj/JwFn94qGYVK4USetHFKnvo4WaewYDEuLxjKhQSKk6jRZCyCVIJolSKKJUiSKQJ\n7QyBXUekphCBTuTrhL6B76m4XlwR294Qd0NFeOMJo5teNWwfVVFqAluxbCdarZtbt6MirBsqvlKx\nPkMVFFUlFoJICKK4GkcxYRgSRRFRFCGimFB4uHFEVA5xCyHFMMSIAvQgQPMDIsfHd0McN8b1BW6g\n4IbghSpOrOELHR8dUBAKoFTG0cfS1VgBVAWhKESWSpQ0CC2byFaJbJ3Q3kyYR59HEFI3NEx6ZIS6\n4WHqhwapHx4g4TvoSoyuga6BUV1BoRoGimGgmiaKYYClo9TpqAkdTA2sJIqhgKlWFFanssZMFQhV\nWtoSyYuGEILhgTID/cVxs7VL5Ee2FOdEypgwIazStZ3Eso2t3HnX6iLiAEXRQNnxrO/Qz+EVN+AV\nN+CW1hO6A2MHFQ0rNR0rPXOcQG85IWtfIg58/JERCsN9lIazlHODeLlhwnyOuFCAYgm15GKUfSwn\nQBv3rh19D9fupVTGi4czOk7CxE1YeJaNYyVxjBRlLUVBTVOIM5Q9E6+sEYZV67JcDdktagj41VBB\ngeokKI2GjEVH85ZjsnY1bRsqCQ1sFSw1ZkqjjZsrYhGiRwFEIbEfIIKAOCji+iGlKKYYC/KuQt7V\n6Fd1CppBwTApGjaevrvf3XFPTqsGmx0t/959hCAtIuqET30UU69CvaZQr6u0WjpNpokyo41YbUQo\n0xFqBGpITFjZkztyiWOPOPKIIxcRjaXj2ENEL+4PUynaEsl28NyQjeuG2bBmkK41Q5Q2G3e2EwZT\nZ9TTWLWcR0XaTrzwF5yII7zSBnryfRTyucqLIfbGXhLj0ptP3ELRUMYFVL2WjiOPKMiNnaoa2Jk5\nWOmZWOlZWMlpL/ruSDfddD133vlXTNPE81w+/OFzOfLIV044xwkjBtyAQc9n0A0wNZWpSYupSYtE\ndXbukiWPcf75H+OmG26h0bbxczlygz188H8u5IRDDuR1B+1PVMgTF4pQLKOXXUwnwBg3trjRc/ld\n7yY+P2vOhL8faOBYGvf5BTZ6Pq9cOJ+SZlHUExS1JM88v5zerjWoiXqIVeIopKnzJDLJgzbXWyxT\nI2Fq1Fk6iVYd21CwVYFFhEWIrcRYSszwYDd33P9n3vyOj5EkIh17ZEKHdOBS55bQAq8itOUA4ftV\n0a3Ewq+kHxoe4q6BflRNxxWCo+YuZN7c/XETSVw7iWcncO1K2k0kufeSCznmkl9s87PSfY90fpiW\nYoFUMY/tuqxdu5K5+y2kb3iYVV2rOewVryFCJ0AnEDphrFZ+dygKQlOItUosNJVYU0BX0E0FxVQJ\nI4/Hbv4lgVdGQXDMOz5My4yZXPuVc8k0taCoGijwmo98ltap7dzzq5/Qu3o5iqLwmvd8hOmdC1AV\nBU1RqjGkDZ0GQ6POEKRxUKLqZMWgRBSOToKshIFCARG/kD24FVTNQtFsdLMBVbVQNKuyJFA1iRWd\nEI1QUQiEUvkqCHBEjBvHHP4C/tJWP4/dvF4i2acQQjCULbFhzRAbVg/S252vediyEwbzDmxjSkdd\nxXJuTZFM7d5uQ6Gfw82vwsmvwi2s3VKMR1HUymYNqoVupSovDdUAEVV9R1fisXxIHAcIEaEoGon6\nBRWRTs3ETHagKC/dErCenk3ceuuf+eUvf0OsqCxdvZoffvtS3jttHgNuRaAHXJ+wXMIql7CKBazS\nMHY5xwYnj+WWSHsOCdelO5ulSde59r8/yOuaWgBYVipieh7K8jUkh8aWfkUKOLbKSEqlbJqUDYOS\nbrGp7DOUH+amBYdQVpKUSFPdwfWeAAAgAElEQVQmgx8lMTSD8qbH8Yt91M98e60Luc3UaB32mDPv\nUI458TRsVRAWh/j+ty/k86cdTioOMN0SermAXsohigWioQJRIU9UKCDCyph2KZUhO2Ua/VOm0902\njfXtLRRsi2dmTNvqs9N9D8tzsF0Hy3MwogjfTuBaCTw7QVlReeSyz3H4l36AbicIinnu/tk3GXjX\nx1A3s5StOCJJjAp0Ch8LMGOwIzBCUL0YnJjAiXDKBqVyHU7JxhHw0NI/0tBwMroylf1nHkh5sHJP\nTVdpTBsk0xaptEkqbZFMm6TSZq0smbYwLa3Wk3PllT/j9JOO413vei//+tc/uP32v/DZN36Tvxg6\nV//4ZxP2WF+79jn+mR/k2l/+gjWrlvGtK77N2d/6n7HVCH41rq5ScOKA7S1wU7UkmlkHehKhJohU\nk1DR8FEIBHgCXBHjxDHlOKQcRZQiHy/ycQMXNyzhRkN4oYcTucTb8dM+ytuPetsOz9keUrQlL3t8\nL6R7/TDrVw+xYc0QpcLYr+62jgwz5zQxc24zre0Z1K2Mib0QRq1pJ78KN7+KwB3rF9WtZhJ1nUyZ\nfiDFslb59a5aVYGeXP+qQgi8ICJX8nG8kKLj0ztUYCg7yLrly8hmB/n5D64kEZRJ+EWOTaa48kNv\n56PzFzDX9/lb9yYaVY0lhRz7p9L8u1REBY6pb+Du3Agq8LmZs+kPfeY1ZPink2f2tFmUdYM7nh2i\nYVoHKxJprj/kcNZ397Lh+aUI1SDROosZR72TwB1h3Z2/QNENklNm4KZaGFz0GoZWLKHnX7ehaBqZ\nmXOYe8a7CR5dRdCTR12YRg98dL+E5pRRnAEUdwD+8UcoFjDjiHQcsfGuP6EpcMNzT4OASMScteAg\nWuvquezpJ5jTuZB1w8OIdB0Lzz4PPz/Ms1d9H1XXaZ06gwyCUw2fJ594jAfvvR1UjeZZczj8rPfz\n6N/+SLmYJ9/fizPYx36nnkXvo/fjDQ1w7HlfpK2uDgKPAzIWLU0NJDqaeNPlP6HOMulZ08WNV36f\n0PdBKJx60nsx1AxKKAjuH6A/18O/n/kToGDoFkcf+k5MI8GyVffR1fs0mqZx4jFvZTjfzUihh6Xr\nbuB1rzmdv//jdr70xW/w78ce4KY/XoemaSxYsJDzz/ksV175M0qlIhs2rKe7eyOf+MRnOProYyuT\n9sKKP/N3nHkqQviUc8ux1AGGBrrI9T5AHDkMbbydsiFqvs9v/tO/OGi2RvfSy7GAkaEeup6/geS4\nni0BRIpJoBh4WgIHlbKAUiwoxDG5KGQkChgJfErRALHYtZ3uFBRs3cbWLOqsDG1aC7ZuY2kWtm5h\na1btuK1blfJxDnp2lcn1JpBI9gBCCIYHy2xYPciGNUP0dOVq1rRl63Qe0MasOU3MmNNEIrn7+/ZG\nQREnvxInt2KCNa0oOnZdJ4m6Tuy6TgyrCYD61gz+izCB64+r/sIT/Uu3PCAEsQCBQAiqQYzFVGdK\nb6XcyDUxY7XJlEIfDV6eVOSRDHySQUhbFNMG7A90iYhbb/4Vh6QyHJzOcFymjjsdB6NYJEwZPO4U\nOPPQeZSeK5Gf3sjJ+x/Bn+59hGWzp3HSce/k1utu4p7TTsf1BN6qlfirnuXBw84ibmym++mvMPXY\n1+MMD+Id8WrW33MBr/3C5SRtmwf+75tM17voXv8Ehx1+BIccdTyP//0O1vf7HDC4ipvvuYG3nf4u\nNEXlnrtvoe6+WwnLJbKlAlohz0giRTbTDJlm+hpbGUplCI9/HQDl/k1kn3iEh8/8AKVN60m/4jga\n5h1I7yP38fvejcx94zkM3vtXZr32TBZOncXT3/8KU4pZ+p74J6e//lTef/Y5XP+H3/BwYYDD58/m\nR5d+kat+/XuSySQXXPApDvMHobWedaVhPvmN7/Hrq3/G6iX/4usfvoibb7kG48GHWHDQyXTNO47f\nfOqDTJuyP1Oa5zNr6qHomsHDT13PrKlH0NE6n+6+57j9rhs45rCzUJTKj9MHn7ySd//XucycNYtH\nHr+bIFzN8Se9hsd+sIY/3nwjPT2buOaaq7jof7/Mv0+7gx/+6AqWPP4wlhVCtJZfXvlDfvydL2Kb\n8NVLfsr9d/yI8shqNnT18tmPvZYlT2W47prLmZZ8ELbRo3TdtY9z1MEt5HruJ448fvh/vyE75LBg\nThNve9NCegdHyLS1ssIPKQmBSOr8pS+P2pKkGAuKsaBc/S5ujfFCm7YytOyk0E4ss0noFoZqvCTz\nPqRoS14WBH5Usaar3d7jl121tqeZOaeZmXObaOuo231rWggCtx8ntwIntwK/3F07pltNNaG20rNQ\n1T0zMQ0q60/HO6kYXdIz6tBivKMLxwtZr2bJGd6WwrzFK09Ut0QWgKjE1cXDKjFaHGPEAi0SLOjL\ncvyqsS7pUK10SQ/VqTi2jmvreLbFEYdPY24Q09Wf488r1nNHXObA157EmgMO5LBFh9N46Td5x2W/\n4sHzPsx7PvkZ5s1bwPLeCzj99DM58shXsvzhJRzVWE9ULpPUPF550EJyj9xGR0MT6eYm9lvzDAOD\nWV7Rs5YBt8ybf/6tSn0GB1Bu+DVRqcSrWlqZvfo5GpwyNw70MfXOG/GGB3j4pqtQdA0RRczzcugN\nSVZ5Gh9ps9EzSaJ0BtdO8pvH6njw3rvoXv4E5XKJMPB516e+wIyZbeQScPvVP2HdvX/GKRXomN3J\ncW1pHkkked/RhzAjqfPdGVNYnPC4rnstBx11BD1r1tOcaadUcPjrn/5O0mrk/ttW4TgBwm3ht7+4\nHdctYxpJbrzqcTatdcGr5+F71zCSjfGCfhqtQeZNP5n9ph1J3+BK1mx4glVdD3DB+Vdw96PdbBgo\n0pN7GEURtM9s4oOfWszN92mcduZU/u83a7jr/p8jiAl8n845U1n1fJHZM2x6Vl1NHLn812kp1j95\nKVHo0L30cgbXD+AV17H0kV/R1gDuwD24wPyZCs8t+zeBGzBvpolb3IBtu+RKDn2+gyfAEwJXCDwh\n8AU8cNvzlIRg+sFtXFdwaH/1bERnM822zj/+sIzVj/ZTxCRQ6nGsmViaBfrT1DUvomPaNGzN2o74\nvrRCuyeRoi3ZJxFCMDLk1KzpTV0jxFFFdNraSsyda9LaXk9rewYrYQIxijKIXxoCRQWUyg5HqjnW\nRa1Z2xwLFnGIW1xfEer8CiJ/dOKXgpWeRaJ+Pom6+Rh28w7rvXZTjnVdw1WvUeNdNY4Jb8W7VDRB\nlL1gJ10kKjHoPorRgGIkMWwfww7RrADV8MDwEJpHqLpEyrgJOkLQmI+Ylg2Y2u8zrT+grjw2hufr\nKn2tGR5/xWyCWdNpXziP+mQjU5INzLEypM00hqpX/EL7PpZV6SqMooizzz6TNy5+NbfeditiXS9H\nz5rD0O1/Jcj2M3zzn9moG5See47+7M9Z+esrKa5dRc+6dQAUyiWOaGziO13rmWHZnNDQSP9AljiO\nIJVBsW2SBx2CXpfBfP5ZrFQKs2s9bWecycwDD6HcvZHEH37L7E98moU/+R7/+7XPEniDhO4ggTfI\n3/+1jDA/yGNdN/P7mx4F4BPvPw5lZAWnndDB6141j+GREhd/7z6OT/0dq/9BfnrNYxw7p5FTjpvD\nI09s4olnVnDQ0C8wlICW7p/iAG5hNSMbbyZwNhDmbkOpb8CIhtCVftoyd5Owejmo888IAd2bVqHr\nGmUnJJO2ec3xj6E+uJFi2ecNr1+G/mA/xZLHGWesw49iTNMgYgoxr+Piy26i4P4R03Q490OLaczo\nKCJEEwHdSy8jjlx6l/8cQ4/5/IfnTRC1R59cR+QNE5c34lcF1okFMYIVfshqP2QoinnCC8hGEbeW\nXNxY8GzZRzVNwkDFtC0KcROuliCvrOJRZxoPXH0nqqLw+nPOYHbnXO678Q6S2nQ+8ZVzSRqJitC+\nckxo/5S/keHhIVKHW9h2hjMOPROAu0o3cs4R7yCZTO3cd38fQIq2ZJ8hCCJWPtfH0iUbWb96aMI6\n6SkdJvPnD1GXXA1xVVBjyG96YX+j4razIuKVseaKkHulrrFub80i2XBgVag7UfXEDu46xtI1g3zv\nhqd36lxdU2vLfepTBmYiwLADVDNAMXyE7lbEV3HwcfAp40Rl3HjLqTlRNYyS1BM06XVMyyt09Ps0\n9xRIdw+hlcdE3LVs1s+aQX/HTJxZc5g+r5MDW+p5dcpC+D71Rkx2fQ9hdoiosI5CoUBUKHDnY4+w\nbOMGPrL/QcTFArnhYfz+PhK/uZpV69fQ//STvLd9KgOrVxMODVF86gnKll3zmW12TEUbzJI88GC0\nZIJktp/5p51O45U/pbtc4jXf/RF3P/xPxECWo89+Dz997ztp+vBHSCZTrPj0x3nPm9/MyH13sjK/\ngdlWPQ89fiu+04Oau541q59l1VNXUZ+xuPG253n1sbPwnGHi0GH2VJMvfvx4hFCIhUIYRvi+oFQE\nTUlz1KI5/O5PK3jL6w5jaDgmsaCV/mw9//z3M8SxTm9fM3GssKm3DVXT8LwE+eIUmhodnlut096x\nH08v7yfGoql9Lj3ZJYxE9diWwrNrhnnj6w5g2fIeIlUQaD6R4hMLjyAeJI4KxKHHkice5+a7VnLh\nuYvRNRU/iCgX8rSYOTpnZnjq8RUce9wsnlo+wFDeZeFhU4mE4HHXp749w++e6mPawqmseqoHO5Om\nbsYcHr9zLbP1TmJX8Pff3sHZn/kAgvuom3UGU8prqM/cxxtO/CQPXn8+bz3wkzTXNXLhnz/Ne9/7\nQR577JHKxipHvIM1a1bRm1rFuSd8mHNP+HDte/TUU0+S2zDEFVd8H7XqaKVYLPKVL13IZZd9F0VT\nePLJJbzqVSczb94svv3t73LGGWeyfPnztLS07LRgi+qa8lF3pOPjF1Yeb7U82sr1tfLRMiH40esO\n3an6bgsp2pJJjecGrF81yJoVA3StGSIMK5afaWnMWdDMfrNjGtKr8YvPI0SIInSSTYswElMqfcII\nhIipTF8ZlxYCRFyZgV1bo1ldchVX1mhGfg4hKrOAdbORRP0rSNTPx0rPrCy72gU6pzXw7lMXUip5\nWKZSFV+PSHEIVRdflHGFQzkqUQqK5IMiBb9ANtjKzr2Cyqa+VZJ6ggY7Q8bsoM7MUGdmyJhpMmaG\nOjNNBhu7ZxB13Ua8lStxVq+asO9xOV1HT2cnfR0z6euYgZnOMLc4xKLsJhqefYTokbsJigVW5fOI\n7ezVfIQQrC0U+PID92IbBrGq8v+OOprm+ftzgGWwbmiIAz70UbRMHdYPv8O0j55H50GHkLr4K3Sc\neRazDjuC5JcuoOkNpwGQeOJx6o87npP7eli3bi3WlCmg68SRC0E37z/nDXzivHNQRMT8OQ00cQcn\nLCrzg1/9nfvuvZ2Z0+qI4xAhmnjrqSfwjR88iYJBQ2YqSeNkVm14glyhl7/eOXF3ptVrhrDMFBpH\nYtoqbe2Hc//NlzFl9gxmH3Qqv7/tZjKNXRx0zNHc/+ebuT2bJ1QV/tka40ZlNuke96g9sDjFw9c+\nxs1PPUmiPU05LPOT4jqSp8zis9++BUWB1KwGbm8U9JbL6ErIsuERBhyX0A3oK0YMBCoiNhHz5mNu\njPn0dx/FsixEFHP4619FeNBxLG49jj/+/Hr+sWwFqqLxsc+cz8zpMzH0f3DaUV/h0PaNXH75/7Lp\n8Q2YpsXnLvoCdXX1tGSn8vcf340Qgo9/5JMcNusI/rL/gfziy9/jv//7Ezxpppjf1sknzvs0X//C\n/6AoKoccciiLFh3KY489QhQL3LDikzsUorIyYJyg/fb6a+nq2cQHP/YhBJBIZ3jvBV+j/cDDeNf7\n341mmrTPmovbeQjPWyZK+0ze/r5zQFE49pyPctWK7sr9xgljGG8potGLuM2GqoBeXYZmqAqaqpBU\nVPQ90DUvNwzZA+wLnp8mUxvKRY+1KwdZuyJL9/qR2iSyhqYEByyaSku7TSa5gdLgEgKnB6iMJadb\nDifVdCjaC7B8d0RleVVQtbhf+D+kEIK8X2BjcRMbC5vYWNxE1s0yVM5RCrcixJuR0pNV4U1vVYjH\n8ukJ2xjGvo/f34/z/LM4K1fidW0gGMhCPNbdPdLQXBHo9hn0dcwk0jRa+7qZ0reRmWuXU5ef6OZU\n0XW0TB1aJoOWyZBqbSI0ErV87VhdHXomg2LtngtTIQSuU6ac68ctZQncLFEwjBIPoyp5VGXL4YKy\nY1EqJSmWErW4WErieSYV9yWg6ALFEihmRGyGYIX4qkegufi6g6s6OGoJX3cIdR+hvTAvV+MnQ42O\nv1qbjcGOjsnuyhhtvJlFGcWCusYk/QPFWj7YhmUYVS3JWvk4wZsgjNuwLje/90shlLqqVARTVdAV\ndULeqJUrO1U+Pq9X77e18po4V/Pb84Pe2prZrXZK0d4DTCbB2xZ7exvyIw5rVwywZsUAvRvHHIW0\ntqeZPb+V2fOaSafLxOVnyHb/GxF5gEKifj7pliOwM3Ne8gkoURzR7wzUxHljYRPdxR4KQXHCeQnD\npt6oI22mSRtpknoa20hhaylMLYmlJ9GUStrWdUxVRRcRuuuglcpoTgGtUEQpVPxdh4UCJceh4Pi4\npSJKqYTtlEiUi4w+kVhRGGqeUrOiB1o6SJcLtI0M0F7O0xG61Js6eqYiuBNEuBqr9kQRfqHfKSEE\nvhfilAPccoBT9nHKAaWSR7FYJA6GUMQwppYjYRVIJ0okEls6xQhDlVJ5TJgLjkXeMxjxFVwtINJ9\nQsMn1H0iwyOs5kfLt+ZqcrzQWrpFYjOhtTQLU7MxNRtDtTA0C101MVQLTTXRFANVMdBUA1CJBLWu\n1ppYbkUYX0i3bUUoY6IX8Y2+uVDqqloTrh0L4M4IqDqhvLU5RX7EqZw/es1OCOXexO6Ktuwel+yV\njC7LWrs8y5oVAwz0jQlbx/R6Zi9oYfa8Zkw9i5NbjpNdQXHjEACqnibTfhTp5sPQzfqXpP5u6NJd\n7J1gQfeUegniiRtFNNtNLGo4iKmpDhS1iayXptsxcIIIJ4LsNueWjfq/3BoJ0G0ymk57Oc+U/hHa\n+jZSlx9mdPQv0rSaFZ2fMpWwrYO6pM20hMGhmRRTmxswk4ld/qETxCE5J8+mkSy5QplSyaFYdGtC\n7DkhvhMRuILIhdhTEL6KIiCRcKlLl8hkymTSJTKZEq0tDqo6UY3Knk53Ls2wbzAc6oxEKsMCCkpM\npAtiI0Kf4mDoEYZmY6gmuprEUhtIqSaaWhVSxah6j9NRqHiRE2iAghAqmqHj+RGRgGCcYLpCMOhX\nxje3LZSCnfUJvrNoCuOEsWJJWuMsys0tQF1VyCRNAi/conx7lulWhXWze7/YQtlalyTr7f6e1JMZ\nKdqSvQYhBNneAmuWD7B2RZaRocrEI1VVmDGniTnzW5g1tw4l6sLJLSG/YQVxVDlHUQ0SDQvpmHk4\ngTprl8eUd6XOI16uKs49bCxuoru4iawzOOE8XdHoSLczPT2VaekOpqen0pFqp9eFpwcLLBku4lb3\nEU6Xhmku5DGC6u5BgT8xXY01IYhTKeJUmjCRwvA9Erkh0oP9pPt7sMrjll5ZNsXO/RGz52J2zicz\nZzaLUgkyhl578QZxiBu6eJFHfziCl+vDDV3cyMMLPUq+Q7nkU3ZCXCfC9WICXxD5KlGgEIcqRDrE\nOkpsoAoDFBWhKqBS2eRB1RCqjlAV1ESM0RCimSGaFaHqAkWHspKiIDLEaIRoRKgEsUYU60RoxKjE\nqAhNgRSw2TykUbfWtc+IcV5FY7a7U+gY44XBHyeUak20bEVFV/UtBHDzrtLtCeUEy3S0bFx+a/fY\nFaHc23vSJDuPFG3JS0ocC3o35lizPMvalQO19dO6oTJnQQuz57cyfZZF5K7Gyd3P4Oq1ICovVE1P\nk24+nET9fOzMbBRVp/E/+HKK4ojecn/Ncu4uVkS6tNkksJSeZEFjZ02cp2em0p5sQ1M1hBB0lVye\nGixww7peimGlLUmnxAErn2HOqmV0iACjdUp1/DeDUp+BTDNk0pCqI06nEJaFMzBIccN6Shu78LrW\nEoYRkaaR0y0GOxfitTbjNmVw6tM4SZMgjglETBiPEK5aQhRBHCnEQoVYBTQUdECr+jJXEYoKig1K\nAqE2ju2SlGDi9lV7kqrVqiIwVLVmAVo7FMCti9wEAR3tbh03QWhH92hvq2NwoLj9OkskLxJStCUv\nOlEYs3H9MGuWZ1m3ahC3HABgWjrzD5zCnAUtTNuvERH0UMj+k4GVzzJqHhn2lMpSqoYFmImO/9g4\ntRM64yznStxT7CUUE7vmWhLNdNbPoS3VzpREB02JKdh6Gj8WlRDFbCzHrCnmyfshy4aLjPiVLnI7\n9Jm/chlzVj5De3YTmcMOp/hf/8UfYhM3hFgoxCiMTpAiAvJAvgSUKuWN+1XCwTto0NZ6Zzc3SQER\nC5RqUIVAiWNUEaIqAg2Brgp0BXRVYGpgqFRjUQlajKbEaCLCUD0iZwSiAhoxOhFq1VY2jQSW1YBt\nN2BZzdiJZhJ2I7qmv2Rdr9tib6mHRAJStCUvEoEfsWFNZWnW+lWDBH5F/BIpgwNeMZU581uYOrMB\nVYkpDS9jaM2f8aszvw27lVTzK0jWL0C3GvdovYQQDLkjtW7tjcUeNhY2MegOTThPUzQa7TbSZiuW\n3oKqNhOIBoqhyjovZl1NFHPVsHUMEdKZW8fcweeZ5nRj1CUx3tCO3rw/qIK8swQtWEgiVtGCEN0L\n0NwA3Q1QoxAtjtDCEFUXqJaKmlBREhqqDhoxmhjtPI7QRFzrTNZEhEqMrgg0VWAqEYYWYagRhuKj\nKSG6EqDquzBeKBhb6B1MPKRqCYxUG0ZiCqbdhpFoxbDbKjsiSSSSF4ycPb4H2BfGi/5TbfDcgKWP\ndfP0/2fvvcPjKM/1/8+07atdbVG3JVnuGBscdxuMARNKIBAMpuWkHdqhJYdw4OcTEhI48KOEAClA\nEof4UEJJTOfQDO4FG4MN7kWyellJ29vMznz/WHkl2TKWC2BA93XNNTPvzLxlZ2fued73eZ97XT2p\nZNbCdLosDBnuo3KEn8KSbNhQLR0mGlhHtH09uhZnr+e30z8Js6Oi3xb1Z7VD0zWaYq1d5LzXQayJ\nhNY72IhdtmM3+UnoLjQ8SKIHUXTvFw1NQcMhJLATx0QKBQ0FDRkNReixjYaCiklQKaADuWsqkqHq\nGGENI6Jm12ENI6yid6oQ7MF+IuC3IBRbEIqsCEUWBHPWRM79LkKXPS4IXeu9yUL3dq+fUEAQZQRB\n6VrLCKLUR5rce3ufNZ9xTkFhAZ0h+rx3/ZHm7A/2SnMuXPg6Pp8fyEZYu+CCs/nud7/HT35y9UHz\n2L17Jw8+eB9/+MOf+zy+bNk7bNiwieuv/2mv9PnzH+edd97MlZtKJbniih8xc+asQ25Hf+vSH7z3\n3rs899zTKIpCPB7n0kuv4LLLLjrgc3HOOafx+uuLDqmM999/l1mzTmfHjm0sXbq4X7/zwep8zz2/\n5vHHn2DIkKFA9t4+9tgfkCSRQYPKue2226mp2cqNN95IRUVWRrWqaig/+9l/HVHZXzQGvMcHcEwi\nHkuzcW0dn65vRE1nMFtkTpw6mKEj/XgLHAiCkFWCitUSbVtLPLgFMBAlC86CaTh9E5DN7sMvX41n\nreYe3tvNsVYyPbq3BQT8Ni8j84dSYnFhE0zUJ/LYlvCQEiQsUppCoR07nTiEBuzEcRDHIaZxiipm\nSUQQFURRQZAUBNGU29dTBunaVlI7a9E7Y2hJEUOwkDQUjEQaMRJFUvv2KNYlhZSvHK1gMELZEOSy\nciwuOxabgsXatdgUFOWLcbY7XChmJ4KwP1H0lOaUZZm6ulruvfeuwyJtgKKiYhYtepu5cy8Hsi97\ni8VyRHXvLy666BIuvHAuAOFwiB/+8DKmTJmK2fzFlL8v0uk0f/zjQzz55HPYbHaCwSA333wDc+Z8\n96iW89RTC5g163SGDRvBsGEjjiivjz76kNWrV1BVNaxX+n33/Q+PPPIYBQWF/OIXt7JmzUoKCz2c\ncMJ47rrrviMq86uMAdIewFFFJJTk4zV1bNnYREbTsdlNTJhezugTSjCZu/9uqWgtnQ3v5MQ0FEsh\nTv9EbJ7jD0lEwzAM2pOdOXJu29rKrvZaOlPBXucpokKZo4gSi4tCxYJfEvAZSYR0kIZ0hA2pUqqN\nMkDAIUQZJ+5gjC2C3eJGtnhRLGUoZi+y2YsoZZW/DF1HC3aiBgKorW2kW5uJbd1OorEJI5lAMrTc\nPOiu4IwA6IgkFQcZdwGC24PJ78deUoSrsgznoGKKq0oJfI0dn6LRKOl0ClVVkWWZQYMGc9NNP+fG\nG6/hkUceA+Bvf/szTmceS5a8x/jxE1i7dg2iKHLWWefwxhuvIYoiDz/8KACTJk1l0aJ3cqS9aNHb\nTJo0NVfeokXv8NxzT3dLRv7057S2tnD77behKApDhw7PnbtkyXs8++xTSJLMiBGjuOGGn/W7XXl5\nLrxeH4FAAEVRuPPOXwKgaRq/+MWvKS0tY+7c8znppFP45JMNOBxO7r//IQKBtj7r0le9589/nFAo\nSH19PY2NDVx55bW8/vorNDc3cv/9D5OX5yKZTJBKpbHZ7LjdbubPfxKTyUQgUM8999yJpqmIosit\nt95OUVFRrrzq6t387nf3IQgCNpuNefPuwOl08vTTC1i8eBGCIHLNNdezdetmdu7czrx5tzBnzlwW\nLnyeu+6674D17UuasydGjBjJiSd+i+uvv6pX+vz5T2K3OwBwu/MJhUIUFnr6fT++rhgg7QEcFQQ7\n4ny0upbtn7ag6waOPDMnThnMyLFFyHK3RaimOgg2LiIR3AKA1TUCp38yZkf5QbvA1YxKU7wl5yC2\n14JOZXpbrFbJxmB7KUUmK6WySBEpnJkwghECLQRdTl47jVI2MoVmPfsiKDJpTPMqHO+vxGTKxgfO\nRCKogQBaXRvRQE2WoEzEeZsAACAASURBVANtpNva0DraIbP/GLAIpGQbEdlLUnFgOPNR/D6sxUXk\nDS7FP6QYl8d+QDWxLyoITNsLzxJZt/ao5umcMBH/RZd85jnDhg1n1KjjuOii85g6dTpTpkxn5sxZ\nBAJtRCIRnE4ny5cv5d57H2TJkvfwen08+uh8rr32x4TDYf70p7/yH//x7+zevROA/Px8zGYz9fV1\nFBUVs2XLZi6++FKam5uIx+P8+c9/5IkeEpfr169j9eoVnHbaGVx88aU89dTf2blzO/F4nAUL5vPY\nY09gMpm4/fbb2Ljx4363vba2hs7ODgoKCtm5czs/+tGVjB8/gddee5mFC1/ghht+RmNjA2eeeQ7X\nX/9Trrrqh+zatYN33nmzz7r0VW+AcDjMgw/+nscf/yNvvvkaDz74e/7yl0dZsWIpF198Geed9z0u\nvfQCJk+eyuTJ0zjttNmAk7/85VEuueRyJk6czKpVy1mw4K/ceusvcvV/6KH7ueWWeQwaNJiFC19g\n4cLnOfXU2SxevIjHH/87jY0NPPXU37ntttt5+ukF3H33/bk6fVZ9W1tbeOCBR1i9eiUvv/yv/Uj7\nQLHD9xJ2IBBg7drVXHnlNbS3N1JTU82tt/6McDjMj398JRMnTunz+q8rBkh7AEeE9tYo61fVsmtr\nK4YBLo+V8VMGM+y4QiSpeww4oyUINy8lElgLho7JVkp+2RmY7YP2yzNrPUfYHWqgJtJAY7SJ1ngz\n4VQ7Rq9JtgKi6EKRy7LjzpIXSfQiirasO5gG2zQwk8p2aUsGTkXCYTKzNabQqRoo6RTjCXOikCa/\nM4S2KUAg0JYl5/ZAr9jbPZGWLCTkfJJWBwnZSUJxkJEUTK483COq8FcWU+y3k++1IR/j3dhfBm6/\n/TfU1FTzwQereOaZ/+Wll/7J9Okns2bNSsaMGYfZbMLvLwBg9OjjAPB6fbmuWI/HQzTa3Rsxa9bp\nvPvuWwwbNoLx4yfkPnzq6mopKxuMzWYD4MQTv8X27Vupqalm1qzTu9ImsHr1Sqqrd9PS0sx//uf1\nAMRiUZqbm7FaD3z/XnjhWd5/fxHxeIx0WuVXv7oLRVHweLw89NADzJ//OJFImBEjRgFgt9sZOjTb\nDVxQUEA0Gu2zLgeqd8/fw+fz5drp8XgIhbIOkFdffR3nnXcBa9as5M03X+fppxfwyisv8+mnG6mt\n3cOCBfPRdR23u7dT5+bNm7j33rsAUFWVUaNGs337NkaPHoMoipSVDeK2227v83f4rPqOHXtCr/Ye\nCjo7O7j11p9x88234XK5cTpN/OhHV3LqqbNpbGzghhuu5rnnXkJRjp7E7bGOAdIewGGhpTHM+pV7\nqNmZDSLiLbDzrWnlVA7397IgDT1DJLCWcPNS9EwSyeQmv+R0TK6RbA/Fqetooy3RTlu8hWCqhVi6\njZQWQDdi+5QoI4k+JMmLLObjkBy4RZk8MY2DOE4hhkNqRLEmiBou4oKTGDZiach0JKC9A3O4A3M4\nhDkSZEY0hCsaQk5k51hngECP0nTZRMqcR1QpJCE5SCgOkoqThOxAM1mxpsLYk+041BCFJQ5Kp43H\nO+FEBPmr80j5L7rkoFbx54G90pwVFZVUVFRy4YVzufzyOfz4x1fxyisvEgoFmTnz1Nz5kiT1ud3T\nh3bmzFncfPON1NfXce65F9DQUAdkne96nqdpalZIwzByjoVZkRhQlGyX+IMP/qFXfZcteweATz/d\nyGOPZY/96ldZcts7ph0IBLjppmty47Lz5z/O5MlTOP/8Obz//rusXLl8v/rvbUNfdTlQvfvze6RS\nSYqLSzj//Dmcf/4cbrjhajZu3IgsK9x55734fL59bwkAFouF3//+8V49PYsXL8rF9v8s9Le+hmHQ\n2NjA3Xf/GoDrr/8ZI0eO6jPPWCzKzTffyFVX/QeTJmWt6cLCQk477QwASkvL8Hq9tLW1UlJSetA6\nfl3w1XnDDOBLh2EYNNYGWb+qlvqarFhEYWke35pazuAqT6+H3TAMEqGtBBveRUt3IkgWnMWn0qwU\n81bTHrZtXktCC5DJdLDvPCFJsOKU/ThFG27JjF+S8Yk6TjFBnhwlz2xgsgjIZg+yuRTF7EEy5ZP4\ndAvingZCezahdlnLmVDvse3uQmQMp5ukq4i4aCeYsRITbCRkBwnFiSaakBQJj89GvtuML9aKvGsj\n5oZVmDNxFI8H14yTyZt+MYr3szWyB9Abr732Mh9/vJ5f/OLXCIJALBZF13VGjz6ORx75LeFwmFtu\nmXdIeXq9PpxOJ1u3bmHevF/lSHvQoHLq62uJx2PYbHY++mg9P/jBT2hpaWbr1s2MHDkq1407eHAF\nNTXVdHZ2kJ/vYf78xznvvAtyZYwZM/aAXt0+n48zzzyHJ574C9dddxPBYJDS0jIMw2D58iVkMgcO\nwzZ4cPl+dTlQvdetW/OZv8PatWt48sknePDBPyDLMqlUikgkQklJCaNHj2HZssVccMEcPvxwLe3t\n7Zxxxpm5a4cOHcbq1SuZOnU67777Fm53PiNGjOLvf5+PpmmEwyHuv/8e7rnngf2I/FDqW1JS2i/v\n+D/84SHmzr2MKVOm5dJeeeUVqqvrueyy79PeHqCjoyPXI/NNwQBpD+CgMAyD2t0drF+5h+aGMACl\n5W6+Na2cksHu/cZgU7EGAvX/RybeiIFAnZDHkkicxsCr5MJddcElKvglC8WSQLFkUChLOBRbFyF7\nUMweZLMX2ZLdFqX9vXKTNTU0P/tbkjt3dCeKInK+B7lyGKrVRVy2E9attKdMdKoW0pI1NwdKEMDl\nseHx2Sn32/H47eT7bChttUSWLSX65loMTQNJwnHCibhOOhnb6DEIorhfXQZwcJx99rns2VPDVVf9\nAKvVhqZp/PSnt2A2WxgzZhw7dmzr5SDVX5xyymnU1FTnNJkBrFYr1113EzfffEMvycjCwkJuv/02\nli59P2cdWywWbrrpZn7+85swmRSGDRuRm87VH8ydezk/+MElnHXWd/jud7/H7353P0VFJcyZM5f7\n7vsfPvhgdZ/XXXTRpfvV5UD1PhhpT5w4me3bt3LttT/GYrGiqioXX3wpZWVl/OQnV3H33b/m3Xff\nQhAE5s37Va9rb7rp59x33//w9NMLMJnM3HHHXeTlufj2t8/m+uuvwjAMrr76OgCGDx/BlVf+G9de\ne+MR1Rfgtdde4s0332Dnzu3cffdvKC+v4JZb5vHmm69TV1fLq6++BMDs2WdyySUXcsMNP2X58iWo\nqsrPf37bN6prHAbmaR8VfF3naeu6QfX2NtavrCXQmh2LKh/qZfzUwRSVZoU4dEOnLR7ITqkKVeOO\nbmeQkB0H3pbWWJJI0akbgIIkebCJTirkNMebogy2e7BafD3IOUvQ/ZXO1EJBAi/+i/CK5WAYCMPG\noI6cRGNEpDUqEQ6l2Pff7cgz4/Flidnjt+P123F7bTlnOS0UIrxyOaHlS1FbWgBQCotwnXQyeVOn\nI7s+fwGSr8P/CQba8WXD0LTs7IaODpwmiCsOFL8f0WT6sqt22DiW74WuG6S1DGlVJ6VqxNIp4ukk\n0VSShJokriZJaCmuPmP2EZUzYGkPYD9kMjo7Nrfy0epagu3ZMd+ho/yMmVRC0hZme2QTizbVUB9t\noCnegW5kmGhRmGoxYRIE2jSdNWmFGqMSw1SIU/IwzCozKV9kmNuNYvEiyrbD9pLWVZX2t9+i8/VX\nIZ0iYfOwxT2BTqMEtmQVIcwWKCpz4fXvJWgHHp8Ns2X/r3JD14l9spHQ0iVEN34MmQyCouCcOg3X\nSTOxDhv+pct6DmAA+yITj6N1tKO2t/ex7kALdrLfVysg53tQCgpQCgowFRR2r/0FiF/Q/PYvChld\nJ63qqJpOWs2Q1vQcsaa1DKqqk1Q1UqpKXE2R0JIk1RSJTIq0liKpp0jrKulMGtVIo+lpNFQyhkoG\nlYygYQgqhqBhiBqClAFJAzHDgV4ZVzNA2gM4StC0DFs3NvPxmjoioSSCAI4KjURZLStYystbor06\nt0VgvFlhqsWMTRTJILBLHM77jEMzSTglkYl+F5MLXOSbj6wLS9MyNNeHaF3xAcrq/8OcCKGKZnb5\np9CcP4LCUjdDy/MZNqoQ2SRic5gOPoWsPUBo+TLCK5ahdWTDlpoHDcJ10kyck6ci2fueijKAAXze\n2BsDQGvvQO1oR2sPoHZ09CJnPZHo+2JRRM7Pxzp0GLLXi+Lx4vS6CO6pJ93aitraQmLbVhLbtu53\nqeRy5Qi8m9SzxC51eYYfKfYSaVrTUdUMKU1H7UGkPde9yFbNICkSwUicpJoilUmTyqRI6WnULlJV\n95IqaTJo6IKGsJdEuwhVEHsQ69612EeHcx+x+Q8EUZcRDRkRExJ2JF1BFhQUwYQiKphEEybRjFk6\n8l6OwyLtWCzGrbfeSigUQlVVrrvuOvx+P3fccQcAI0aM4Ne//vURV24Anz8yeob6jmbeXtZA9boI\nekpCFzJ0FtQRKN6Nak5CGswClMkiBZJMsdXNYKsHtx4lkw4CIkHbWF6LDSOalnGZZE4t8XCC14ly\nmOO+mYxOW1OEhj2d1O8JEtm9h6qWNXgTjegIBErGIc04g/HDiyksdeWigx2s+8zQNKIbPiK0dAnx\nzZvAMBAtFlwzT8F10kzM5f0PmTqAARwJdDVNqq6eVF1tFym3o7W3Z9ednaD37bwmWizIXh+K14vs\n8aJ4PNl9jxfZ60F25+/nb+H3OzH3eC70dDrrrNlF4qmW7KK1tZLYuYPEju3719dqR3N5UJ0eUs58\n4vZ8EjY3EYuLhGhCzRik1Mw+Vm339l5iznymN7oBSgrRnEAwxxEscYSubdGcgIyKYNahH6HrD8S5\noiEhCQqyYEIW7JgEE4powiyZMElmLJIJs2zGKpuxKhZsshmbyYrdZMZmsmCVLZglE2bJ0nWNgigc\n/D1naFr2vh4hDou0X3zxRSorK7n55ptpaWnhBz/4AX6/n3nz5jF27FhuvvlmlixZwsyZM4+4ggM4\nekhqSRpjzdSGGqjZ00BnXRqj3YEl5kJAICMadBTvIl1cg8+qMdRkp8RWyqC8MvzOcsy2QgTJSrh5\nKdHAh2QwSJoreDt1PI1hBzZZ5OxBHiYXuA6ZrHXdoL01Sv2eThr3BGmsC6KpOnImxZCOjxkZ2oqA\ngVAxnLIrrmBkxeBDyj/d3ERo2RLCK1eQiWRfXpaqoVmresLEr1234ACOLRiaRqqxgVRNDcmaapI1\n1aQa6vcPziMIyG43lsohSB4PgsuD4M5Hz8tHd7hQnW5UyURS00mpXUS4lxjbddLNIdJaJ6qqk9K6\nCRRBIBZPd1m1va1XVTOT0QcBgyAfRHcGlxojXw2Tr0Z6LGFczfWYmuuwAz1jkyVFExHZiibIaIKE\nJkjokpxbDEnBkGWQFQxFQjfpaCYdTVFRFY2UnCIhp0hICdKSQUYS0CTQJAFNEsjIIjZTHnn2AiRD\nxrKXVGULVsWMWTZjkcxdZGrGIndvm6We2yYk8fOJm6Cr6WzPSHs2xoPW3p4NzNTRnt3vzA5XlLz8\nryMq57BIOz8/n23btgHZ6Dxut5uGhgbGjh0LwKxZs1i1atUAaX9JMAyDUDqcixhWF66nsa0Ntc2M\nI+THEfYiZQqwAAY6Ql4Qd1GCquESFf4xuBxnolj8uXCdAHomTTSwjlDLcoxMkoyczwp9PJtjBZhE\ngVNL8plR5MYi9e+BMAyDzkCchj2dNOwJ0lAbJJ3ScsfzPRaqtGpcm5dBMo5SUIj/4kuwjzuh35aw\nnkoRXb+O0NIlOctBdDhwz/42rhknYy795sztHMAXB0PXSTc3Edm5m9juXaT31KA31SNo3f9vXZSI\n5BXQ4fDTavHSqTgJSnaCgoVkBtKqjt5pQM4wi3YtDUdUN5MiYpIlTIqI1SzjtptQ9qbJIooiYe5a\nm2Qxd74kiyQViYxoYElEMEU6UMIdSMF2hM4Ato42rNEoqAkMTe1zLP3I0YposSDabEh2B5LDgWi3\nZ7ft9q59AcluRrIrSA4bot2BZLEj9PO99FnQk0nU9i4Cbg9ktwMBtI7sdiZ0AHU/QUDO9+SGK44U\nh0Xa55xzDgsXLmT27NmEw2EeffRRfvOb3+SOZye8t/UrryNVPDlW8GW1Q9MzNIabqQnWUxOsZ0+w\njurOOmKJFPaIB0fIhzPkpyBZnrtGtiYpLFUZPcLHyOOH4/aV7qdgtRd6Jk1b3SqaaxajpaMgmdmk\nTGZFogJBkDi13Mc5Q4vIO8iYtWEYdLbHqd4RoGZndolF07njbo+N48aVUDHMiy/VQvM/niK+pxbJ\naqXsB9+n5NxzEPs5tcMaCdDyzru0LVlKJpZ1pHONG0vh7NPxTpnU73y+TAw8F8cOdN3AbDMTiaeJ\nxNKEu5bsfopkSwtCYx3mtgYcHU3kR9sw6d2xB3QE2kxumvJ8NJm9NFu8tJnc6EKWSEyyiFmRMZsk\n7IqIR5ExKSJmk4RJkTArXWtTdrvn/t7j2TRxv7Se+4osHrWhn7iaoDXaTmssQEs0QEusjdZogJZY\ngLZoO4amIWUM5IyBnAE5Y2DKCHhNTnxyHvmKnXzJjku04hQtOEQFJSOQSaUwVBU9nSaTSqOn0xhq\nOreficfRIhHUtlZSdbX9rq9ksyE7HcgOJ4rTkd12OpEdDpS87Fp2OpHtdtRwmFRrK6nWNpKtbaTa\n2ki1tqFF+h52E2QZs8+Ho3ww5gI/Zr8fS4Efc0EBZr8fk9eDeBSDLh1WTi+//DIlJSXMnz+frVu3\nct111+F0dj+chzKL7Fh13z8UfFHTEBJagoZoc86Cro820hRrQdM1MMCccOIM+SgKjcEc8SAYWSKW\nJJ3CUp2ySheVw8vJ93tzD68GBAKx/dqg6yrRwDrCLSvRtRiCaKLeNJ534hWkMXOC18lppV48ZoVU\nOEkbyf3qGw0ns1b0nk4aaoNEw90hQe0OE8OPK6RksJvScjd5bivptlYCz/8vuz/6EASBvBkn47vg\nQmSXi/ZgEvooYy8yiQSRD1YTW7mc2K5d2Xa73XjOOY28GSdh6grAcLB8jgUcy9NaDgWf1Y4vS5pT\ny+hEEyrRhEosoRKJq+zavZOXn32M7/7wdqLx7LFoUiWa0IglVBp3rCIVbsY/6hycmTjFyXaKUu1s\nr17Dlo4GPJKEAaiGwdlePyZ/OQ15BcQ8JaT9pVBYgt1pxW9VqLSZcFhk7FYFR9di6hHm9liR5tQN\nnc5kiPZkO4FER9fSTiDZQXuig/qPq3EfV0CiKUJoSxtFp2alMu2KjVJHCT6rB6/Vg8/qwWfx4rN6\ncJtdfXZN7ytxeuaZZ/OdC+aydu0a/vznPyKKElOnTueH197U6z+lqyp6PEYmGiMTi6LHomRiMTLR\n7FqPZdN7pqXr6jDS6f3q8FkQFAXF68M2uBzF60Px+bIOfl4fsteH7HL1GbMh3bXQ2dth8EuR5ly/\nfj0zZswAYOTIkaRSKbQeXT8tLS0UFHyzotR8Xgilwvxrx6vsCdcRSHb0OmZSTZREC8kL+RCDPvR0\nt3dGvkegrMJFxbAyigd5kOT+jTFnyfpDwi0rcmTtLJjBO/FKPg5qDLJbOL+igGLb/p4g8Viaxtpg\nrss71OPParHKDBnhp7TcTWl5Pm6PNffhoCcTBBb+k86338TQNCxDh1FwyeVYKio+s66GYZDctZPQ\nsqVE1q7JPoyiiP2EE3HNOBn78WOPSrfYAI4ujoY0p2EYpFWdUCyNz1/E08+/xJRTziOaUPl044do\nhsSH29oIPvdxjqCjCZVken+Bl1S4mbZgkrc+qMuliYJAvklnhNZOod5MNNXA5fULMaW6w+u2qhHO\nKB3EtydNx1pRCcWFXPc/v+Ifv73nKyHNGVcTBJLtaHqGd/YszpJyooNAsoOOZCe6sb8jnCRIeK35\nRFa2cN4Z38U71IPvDC9eiwefNR9rP2Ms7IueEqd78fDDD/Db3/4ev7+A66+/ipkzT8XvH5c7LioK\nosuN7Do0CV89ne4i9WiOzLOkHyMTiyE5nSg9SFlyOo8p59TDIu3y8nI2bNjAt7/9bRoaGrDb7ZSW\nlrJu3TomTJjA22+/zfe///2jXddvJJpC1XzYugGbKFMpW8mPOrAGfWhBL7GwE7rEH00WgbKRLgZX\nFTGoMh+box/ulT2gZ1TCrWu6yDqKIJrIK5yBzTeZF2pDbArGqHRa+bdhJZi7hEBSSbWLpLNj0h1t\n3S80k1mifKiX0nI3ZeX5ePz2/f74hq4TWb2Ktn+9QCYURM734LvoYpwTJ3/mQ5KJRAivWklo+RLS\njY0AKD4/eSedTOW5ZxLWj/3u728y9pXmLC0bxFXX/pRrrr2SW37xANGEyosv/C+SYmXThlUUDhpJ\n7c5PyBhQMGQS9dtWoRtQOuUqEu3VpCzlvPrG/7EhXAVA84Y3EfKqqG+LkqzuIN6ykc7dy5AlGW9R\nBVPO+D6CGua9hb/HZDJRNngIpgIH/33pODa8+xKvv/kKpJI4EZhdUMTyYCcN6SQ2eymW40ZiqajE\nXFGJZ+n75Pv9DOlBNl6f/5iS5nTmOfnl7+5mad0aPtm2lVf/+gKpdArV0Cg5bzgmt4VkJsVLu94g\n2Rqj4fVtSKKM1Wrl9J+cS6m3lE/eWseWDzZikhSuvfZGtm/bynuNHWxYsJI5c+byz4X/e0TSnH2h\noaEepzOPwsJsZLypU6fz4YcfMGnSuINceXCIJlM2wEx+/sFPPgZxWKQ9d+5c5s2bxxVXXIGmadxx\nxx34/X5++ctfous648aNY9q0aQfPaAD7Qc+kSUarSYZ3k4zswhzv5OLoUNoDHtrb80lnJNKAIELx\noDwGD/EyqNKDr9BxSF+DeiaFmmglnWxBTbTQtHkHaiqcI2tnwRQM0co/djWxJRhjiNPKpeUFtOx1\nHNvTSVtzt2KPLIuUVeTnLGl/kaNXOMl9kdi1k7ZnnyFZvRtBUfCc+108Z56NaO77Y8PQdeJbtxBe\ntoToR+sxNA1BlnFOmpwNgDJiJIIoYvY64WvQtfxFYOV7u9i9tfWo5lk5ws+YKYOJxtO0hFPUN4WJ\nJVUi8TSxhJbrms5Yijn73LNwFo7C7BuOo3AMNbvr+c3fliMpVvYsX0LJhB/SHkqSdkD++CupXfFH\nQqEQ4878KZveeZhBeXHkvHw6zMW01IU560QnZSUlPLyxnbO/M4dwZxtXXDGRq698hBf/0S0ZOWVw\nktWr13LR+d/h3AmTefKJv9ARaCL+P7fwz13b+e/yISj5Xh7vCNAy7gRKXHaibR0MufnWXm0VVi3v\ntX8sSHOe970LmX7GLObMPZeCkSXIlTYco72IikTdS1twTyikaFgBRnWS0Oo2Zv/7hewQ13DV8T/g\n0V//lj/c+RhDK4aycOELRDaHOeHUUbyy/mkWzP/H5ybNCfD++4tYtmwJJpOJn/70Fjo62nupkOXn\n59PQcGROeF8XHBZp2+12Hn744f3Sn3nmmSOu0DcNhmGgJppIdJF0KlYHXd1SWsbKhxsmE2jLenHn\nuS0MGuJhUKWH0sFuTOaD3z7DMNDSnaiJFtKJLEGriVa0dO/5gqJkIq9wOs6CqUiyDU3XeXpHI9vC\ncfwZAfeHrTz1yq6cUIAoChQPclFaniXqwuK8fnXBq52dBP71PJHVqwBwTpqM78IDi26onZ2EVywj\nvHwZaiDr3GgqKcF10kzypkxDcn71HZ2OVRiAbhgYetfa2Ls20A261l3pena9fW0d89ce3EHIMeJ7\n5FWeQrpjB201y9BaPmTEmImU5bVTNXw0r2528tPLZvCnxlf58Y/OZsxxo7k38iYXnH8WEydO5hf1\nL3HBtFIMw+Cjj9o5+VvfIdy0Ad2RZOrkyfhcVtS4TEtTQ04y0tB1jq+sYsOrL7P10w18x+mi7p13\nGJSIsyYWo9Vhp1OAPxgakmwi5nSQGDESu1VCDO+rOpfFly3NmdZVPmr9hD1aA43b1rFs2Ub043WG\nlJ1IeGcHoQ2tdK5o4jeP3c09f/4Nlg81MhsC6LpOqbuIi4efzwLp94zzH8eubTt56IH7gC9WmnPq\n1Ol861sTOeGE8bz77ls89ND9fP/7P+r9X/xSg20fWxiIiPYlQFMjOUs6GdmNrsVzx0y2EizOIRhy\nBe++3k6gLUblcB9TZ1Xhyu//eFFGixNqXkqs/WMMvbfjhSjbMDsqMVkLUayFmKwFFA8aQmtrjLbm\nCLV7alicThC0y5jbk5g2thMwwF/kzJF0UVl3QJP+QE+n6Xz7TTreeA0jncY8uBz/JZdhGz5iv3ON\nTCYbVnTZEmIbN2TjiptM5M04CddJM7EMqTqmxpiOdRiGQSK118rViCbS2W2nCduYwl6OWdEei6od\nWJmqJ2RJxGGXcVhNOKwyE7ocrAp8DkRd73a6smXXdouMJOhYu+bGZzIZLr98Dldf8V1eeeVFTHEz\n5519Jt8a4cdqlin2OXDZTYjCoUtzah3tqB0BGh/7I4mtWwns2Y0iCGixKHJxKa6JU/BazFjfe4dB\n11zHqMf+cMxKc5pMJmJqnI5omCe3PM/i6ncJBjvZ+mkjgWA9mbTGaOd4ym1ljBw7jMrzynEodm64\n4WryIzZsZht33/XAMSfNOXr0mNzxGTNm8uijv8fn89PR0Z5Lb2trPWC9v2kYIO0vALqukorWZkk6\nvBs12d0lKSlO7J4TsORVYXFWIsk2wsEErz23kVBngmHHF2Euy2Pd7nZEAQRBQOixFvfZFwydVGQX\nidAWMFQkuQCT1Y9idmcXSz6SZEUUBQQNiELz1jBNL62iuTGEltEJDXWRdpuxNccZi0zJqVX4i/Iw\nW+RcHTqiKQRBQGT/OvWsGxjEN3xM+0v/ItPejuxw4J97GXnTZiBJUtcLK/uSSLe2El6+lNCK5TlJ\nTXNFZTYAyqTJSNbDc3L5OiGj6726mQ9EuL3TNfR+mioWk4TDqlDqs+e8m+1WBWfX2tHHYlL6nkp0\nIO/xV1996XOTAYPxSAAAIABJREFU5tyy6VOuP+V0Ni9bQmf1bvQVK6irqaYNCafPxy6TwuXnfQ+t\nsZ7wsBEUnn8hb/3v30CSjklpzq3N22lMN/PqslfxnjSI1voGZLsJX1MbSS2F3+bj3CFnUt2wFSkl\ncKIxnicfe4ILHjznKyPN+dBDDzBr1mmMG3ciH320jiFDqiguLiEWi9HU1IjfX8DKlcv55S/v7N+f\n4WuOAdL+HGAYBmqyrYukd5GK1mIYWe96QZCxOKu6SHoIisXf64XX0Rbjtec3EIukOXHqYCwlTh75\n1yeHUYuh++yrQFvXchDsyBJmO1AHsKnlMMrfB+5vw14nz1U6rFra67CAgWAYCLgQfOcgFAiIkoQo\nibBeQPxo7YE/WOjel2URXTf6/qARBEQhW9q+H0AH/CDiwB9IvfbpZ34Hqb8ggNVmpq091icpx3sE\noPksCALYLVmiLci3dZGv3Cfp9iRnWfr85UaPpjRnJhEn3dhAy5MLOD4SoS4SofXv80kEOzEE8E6a\nzJXf+hZ/Wr8OKRZh7KzTmXr5v1HZ3HTMSXO+v2QRvrICOpKd/GXrk1hP8XPjz67N3styN54hBUj1\nGcr8ZVwx8d9Y1bGUcCjEmRWn8q8P2wimg19Jac5zzz2f+++/G1mWEQSBW2/9BQA///lt3HHHfwNw\n6qmzGTy4/LOy+cZgQJrzKMDvd9Lc1EIysptkONvlnVG726VYCrHkDcHiHILFUY4g9v2t1NIY5vXn\nN5JKakydVcUJkweR0XU2VXeSTGdf1nvHEI0eY4xqsoNYx2bUdBADAZOjAoujCgSle/yR7usScZXa\n6g46AnHAwO2xUTHcx8aOKJ0plXyTzCi3HQFhv/J6jmf22u+Rv66qJOsbSAfaMBCQXC6U4lIEszmX\nXyaRRA12ooZCGLqOgYBgtSE68xDtdgyE7nLp3d5922/0KF8QQMsYn1nfvvI7liFLQs7KPZDFu+9x\nm0Xu6un48nA055sbup4NqNHQQLqhPrturM/NHgAQzBZsI0ZgGzka26hRmErLjorm+ec1bz6UirA7\nVMOuYDW7QtXUR5t6TbMqthdS5aqgyl1JlasSj2V/7fr+4psw9/+rgi9lnvYAsjD0DOHWFQR27SQe\nrs+li7INW/4YLM4qrHlDkJSD36S66g7eXPgpGU1n1tkjGDm2GABJFBlbdQAnrVQHocb3iGc2QyHY\n3KNxl5yGbO57KkMyofLhyj3Uf9iIVTc4sTiPqadWkVfk4MW6AJrdYKLbzmVVRciH8bIzNI3g+4to\nf+Ul9EQCU3EJ/rmXYh9zPJANAxhZ9wGhZUtJ7tqZbZ8zj7zpM3DNOBlTP62rz8LhPtT9/Sjo6yMm\n93HAZ3/cHDj/3nm4XVbUlJojZLMifWPG8A3DQOtoJ9VQT7qhkVRjPemGBtJNjRiq2utcwWzBOnIU\ntpGjsI0ajaW8AuEoRp46mjAMg9ZEIEvQwRp2happS3SP2cqCREXe4C6SrmCIqwK7cnRUtQbw9cKx\n+Q//CsAwDNprXyHe+QmCIGF2lHeRdBWKteiQXrI7t7Sy6NUtCAJ8+4IxVA7f3+HCMAyMTBJNDZNJ\nh0lGdhMJrAVDx2QrJb/0DMyOQX3mn9F0Pllfz5q19cQVAbHKhXuIm3aLxBOBDmLN2S7zUW47l1YV\nI4uHThCxTzfS9uw/SDc3Idps+C+5HPcps0CSSFbvzgZA+WA1ejIJgoBtzPG4TpqJY9wJx8SLNtdl\nzZdPjl8Ha+JgMAyDTChEqnF/y1lP9o5YJygKpuISTKWlmEvKsuvSUmSP95j9mMnoGeqiDV0EnbWm\no2q3B7pVtnCcd2TOki53lqFIA/EFBnBwfPlvy68ogo2LiHd+gslWyujJV9MR7N9Y477Y9FEDS9/a\ngWKSOOvC4/DkdxAJ1JBJh8moYbR0mIwaIaOGMfTeloZkcuMuOQ2be/R+Ly/dMNgWjLGqJkB9KEHK\nLGJM6h6fa9FUhKhKvlmhzG5mVKGL8U77IRN2urmZtuf/kfXyFgRcp5yK77sXgCgSXLqY8LIlpOqy\nnryyx0P+GWeSN/2kA07xGsDXD5lotJucGxtINzSQaqhHj+0zjUqSMBUWYS4txVRahqkkS86Kv+Co\ndHN/nkhqSarDtTmSrgntId3jeXWbXUwoPCFH0sX2wn7JOQ5gAPtigLQPA5HWNURaVyKbvfirLkVS\nrMChWUaGYbB+VS0fLK3GYlM467w8jPhztHXs7ygmyjZksw/Z5ERS8pCUPGRzPjbXiP3Gx9MZnfXt\nYZbWdxDcK/tnlXAYAoPybBQ7LPgtJgqsJnwWJSeheajWXSYep+O1V+hc9A5kMlhHjsI/91L0eJzW\n554h+uG6bHemJOEY/y1cJ8/ENnrMMf/yHcCRwdA0Ert2Et/0KS0NtURranMzAXIQBJSCAqzDR2DO\nWc9lmAoLj4lel/4glIqwK1TN7q6u7n3Ho0vsRQxxVzDUVUmVuwKP5asZfWsAxx6+Gk/IMYR452Y6\nG95ClB0UVF2OJB/6uJNhGKxctIuN6+opKFSZOqWOdGc1IGD3nojFUYFkykNW8pAU5wEd13oilFZZ\n1RLig9YgSd0A3cDWHGekbOK0qRXke47O+Jih64SWL6X9xX+RiUSQfT6855yHFonQ9NgfUVuynuZK\nYSGuGTPJmzYd2eU6KmUP4NiDYRhEG/bQ+clHJDZvgl17ENLdFmbKaSFRWUDKn0fK7ybtd6H53Igm\nE5IgIQkSophE0quRmmuRRDGbJmTXkigh7d3eZ18UxN7Hxa5zBBGxx7lHatEahkFLrJVdoRp2BqvZ\nFaohsM94dGXe4C6HsQqGuMqxDYxHD+BzwgBpHwKSkRoCe15EEE0UVF2GbD60QPUAmYzO4je2Ub29\nnvEnNlBcUIeWNLA4K3GXnoHJWnhI+dXHkqxoDvJJRwQdENMZ8upjDMmInDxzCEWlR48w49u30faP\np0nV1SKYzeRNm0EmHqPlqQWQySAoCs4pU3GdfArWYcOP2fHGAfQPhmEQ1xIEUyE6k0GCqRDBVJhI\nsA15dx2O6hYK6sM4Y9keHQHoyJOorbBSW2yiwa+QNu0lzHB2SQONByjwc4KAkCXvHqQu9SL1rrQ+\njhuGQUO8iUiqO5KXVbYyxjuSKlclQ9wVA+PRA/hCMUDa/UQ60UJb9XOAgX/IxZhsh+7prKkZ3nnp\nUwTtE06dWYssachmL/mls7HkDes3yWm6ztZgnBUtneyJZp12lJiKa0+UoqTOtJlVDBnhO2qkqbYH\naHvheaLrPgDAVDaITDRCuCvKk3nQoGwAlMlTkez2o1LmAD5f6IZOJB0jmMqScWcqRCgVpjMZyqUF\nUyFUXUPMGBS1q5Q3pRncnGZYu5Zz10ubJZqH+khUlsCISpwFpYwxu5hhdlFa6KUtECajZ8gYOhlD\nRzcyZIwMb7/6BivfW4qkyKRTKb5z+YUMHzsye56ePSd7TabH9Rn0fY7XbtnNyw88w2X3XoPFZSVj\n6Giayj//v79RNWM0o88av19e+t5tQyedUQk3tbLrlU8Y+e+T0LvKyk4M7GrjpjBSh8Hl//5DqlyV\nFNkLEAWR+fMf52/vPJKby51KJbniih8xc+asw74vn6c054HQlzTnwfD+++8ya9bp7NixjaVLF+8n\ngXooiEaj3HXXL4lGs0F2/uu//puKikrmzDmXgoLCnIbBr35119dCn/1IMUDa/YCWDtG26xmMTApv\n+QVYnEMOOY9kIs2qtxdRXvwpDnsCQbLgKjoNp28CQh8asz1hGAYtiTQ7w3F2huNURxKoXRGJ7ME0\ntuowefEME2dUcNyJJUhHKUCGnkrR8eYbdL75BoaqIlqt6IkE6fo6BLMF18mn4Dp5JubyigGr+hhC\nRs8QSoe7LORQjoD3Lp3JEKF0uE/pRQAMg9KkmemtIqWNGfLrg0hql3+EKCJVVeI4bix5Y8Zhqag4\noJ+Cz+bEsO5vgTY1NbL63eX87a9P9ZLmvHT2JYfc1vXRdXxQvBhPnYW50y4DYO3aNbzn9DCpaDw/\nGX9wMtm9eycPLrmP3828K5emd31kGIbOGmUJGzZs4qTSqftd21NSMhwO8cMfXsaUKVO/EtKcR4Kn\nnlrArFmnM2zYCIYN2z8U8aHgueee5vjjx3H55T9g5crlzJ//OHfe+f8D8MADj+TimQ8giwHSPgh0\nLUHbrmfIqBHcJadj9xx/yHlEOtuo+eR5qga3YxgCdu9E3CUzP3M8PKJq7ArH2RHKEnVE7dYBzpck\n5EAcaWcQczLD2AlljJ86GLPl6HTRGYZB5IPVtD33LJlwKBuxBNATCSxVQ3GddDLOCZMQLV/Oi+mb\njHRG7U3CyRDBdHbd2ZUWSUd7WYo9IQoiLlMe5c5BuC0u3OY83GYX+Rkzrtp2lF11ZLbtQGvvjjug\nFBZhP+44bKPHYBs5EtFyZOFk95XmHDRoMDfd9HNuvPEaHnnkMQD+9rc/43TmsWTJe4wfP4G1a9cg\niiJnnXUOb7zxGqIo8vDDjwIwadJUFi16h7lzLwdg0aK3mTSpm2D7koxsbW3pUw5zyZL3ePbZp5Ak\nmREjRnHDDT/rd7vy8lx4vb5jSprT7XYzf/6TmEwmAoF67rnnTjRNRRRFbr319l6R56qrd/O7392H\nIAjYbDbmzbsDp9PJ008vYPHiRQiCyDXXXM/WrZvZuXM78+bdwpw5c1m48Pkjkua84oof5qxpt9tN\nOBzq92/+TcQAaX8GDF2jbfdzqMk2nP7JOAv2/9I+GNqbthGsW4jLqRJPFVM59nzMtr5DIwaSada1\nhdkRitGU6Bb5sMsS4zxOSkSJwMfNNG/LOsEMG13ApJMryXMfvZjc8R3baXliPmprd+hSwWrFNW0G\nrpNmYi4tPWplDaA3DMMglA7T1FxPdUsToVQ3Ee8l6FgPcZl9IYsybrOLoe5K3GZX92Jxkd+17TQ5\nEAURQ9MIbP0XyeAmjLSKoXU5j1WBNNSBbMpHUBRExQSSiEoHIZYS2rX0gOVDNsBPfunszzxn2LDh\njBp1HBdddB5Tp05nypTpzJw5i0CgjUgkgtPpZPnypdx774MsWfIeXq+PRx+dz7XX/phwOMyf/vRX\n/uM//p3du7MBevLz8zGbzdTX11FUVMyWLZu5+OJLaW5uOqBk5OrVK/qUw1ywYD6PPfYEJpOJ22+/\njY0bP+73/TsWpDkvvvgyzjvve1x66QVMnjyVyZOncdppswEnf/nLo1xyyeVMnDiZVauWs2DBX3Mh\nQwEeeuh+brllHoMGDWbhwhdYuPB5Tj11NosXL+Lxx//+uUlzmnvI8b7wwrPMnv3t3P4DD9xDU1Mj\nY8eewDXXXN/ve/F1xgBpHwCGoROoWUgqVpuNNFZ6xiF1ARuGQUv1MpLBJUgShJKTOW7y7D41phti\nSZY0dbKpM4oByILA0DwrQ/PsDHXZcOmwbsUeNn3ciGFA8SAX006toqA476i1N7hhI9V/+jNqc1Mu\nzVI1lPzTZmM/cTyiMuBoczSR0TM0x1upjzTSEG2iIdpEfbSxVwCOnrBIZtxmF4OcpTkSdpm7ydht\ncWGXbf36jwaXLibw/LOI421IVXZAQFCUrsWUnXb1OY923H77b6ipqeaDD1bxzDP/y0sv/ZPp009m\nzZqVjBkzDrPZhN9fAHRLUXq9vlxXrMfj6SXzOGvW6bz77lsMGzaC8eMn5H6HA0lG9iWHWV29m5aW\nZv7zP7PkEItFaW5uxmo98PDVly3NubedHo+HUChroV599XWcd94FrFmzkjfffJ2nn17AK6+8zKef\nbqS2dg8LFsxH1/VeetUAmzdv4t57s0MEX6Q051786U+PoCgK3/nO+QD85CdXM2XKNJzOPObN+zmL\nFy/i4osvOOD13xQMkHYfMAyDzvq3SIS2YnaU4y0//5AIW9dVGre+iJ7aSjqtkJZmc/zUCfuVsSuc\nYGlzBzvDCQBKbGZOLspnVL4dRRRR1Qwb19bzxupa1HQGt8fKlFlVVAw9OpGgMokE4VUr6Pi/18l0\ndulriyLOiZPwnv89TF0vzQEcGWJqnIZoI/XRJhoiWXJujrWgGZle5/ksHqrclQwrGIwlY+9Fzlb5\n6AxFxDZ9SuuTCxBtNuzmE7DnjcE6ctQXqqBmGAbpdJqKikoqKiq58MK5XH75HH7846t45ZUXCYWC\nzJx5au78ntKOhyrNeSDJyL7kMBUl2yV+rEpz9iV12dfvkUolKS4u4fzz53D++XO44Yar2bhxI7Ks\ncOed9x5z0pwjR47ir399jGCws9dHwVlnfSe3PWXKdHbv3nXQenwTMEDafSDcsoJoYC2KpQD/kLn9\nmie9F1o6SOOWZ0AP0Bl0YvGdx5jjq3LHdcNgU2eUpU2dNMRTAFTlWZlZ5KEqz4ogCOi6wdaNTXyw\nrJpYJI3FpjDllCGMGld8xE5mhmGQ3LWT4NIlRD5YDVqX+pgskzfjJPwXX4poMh1RGd9U6IZOINHe\nRc5dJB1tojPVO7iIIsqUOkoodRRT5syuSx3FOWL+vMKYpluaaXr8TwiSROlN/4l1SNXBL/oc8Npr\nL39u0pxbt25h3rxf5Uj7QJKRLS3N+8lhHovSnP2RuuyJtWvX8OSTT/Dgg3/4ykhzbtjwMZs3b+KB\nBx7O9URGo1F++cvbuPfe36EoCh9/vJ5TTjntM9v+TcEAae+DaPsGQk3vISku/FWXIUr9t3CSkWpa\ndr6AQJK6hmJKh59HxfDsvGtV1/koEGFZcyftKRUBGJPv4OTifMrs3WXUVXew6v1dtLfGkGSR8VMH\nc+KUwZjMR3arMpEI4VUrCS1f0ksZCUEgb8ZJjLrmJ3QmjnG5q2MIqUyaxq4u7b0WdEOsiXQm3es8\nl8nJaO8IyvaStKMYv9WHdJAZA0cbmXicxt8/jB6PU/TjK780woajK83ZE6eccho1NdW9hqAOJBlZ\nWFh4zElz9qzL4UpdfhWlOV988QVaW5u58cZrgKxD391338+UKdO5+uofYjabGTZsBLNmDZA2DEhz\n9kIivJO2Xc8iSiYKh/8IxdK/B9bnc7B787t01r+DYcDWHcMYO+1MSga70XSDtW0hFjd1EFEzSILA\niV4nJxfn47N0W7TtbVFWvb+but0dAAwfU8jkkytx5B1+t6ih6yS2bSW0dDHRj9ZjaNrefiwAbMeN\nwT/3MswlJV8bkYqj3Q7DMAimQtRHs2PPe8eg2xLtvTy0RUGkyFZAqaOEMmdxjqSdJseX3wZdp/H3\nDxH7ZCP5Z5yJ/+JDn1p1OBj4Tx07+Dq0Ab4e7RiQ5jxKSMcbCVS/gCCI+IZc0m/C1nWV6k/+QbD5\nI1JpE59uOZ6Tzz4ZT4GD9YEwixra6UxrmESBk4rymV7oJs/U/bPHIik+WFbNtk+aMQwoLXczdVYV\n/qLDv7FasJPQ8mWEly9DDWRjmUsuF3oigZFOoxQWZiUzjx83ML+6BzRdoynW2jX+3Ji1nqNN+3ls\n22QrQ92VWWJ2llDmKKbIXohyCMMoXyQCC/9J7JON2MYcj2/OxV92dQYwgAEcAY7Nt8wXDDXVQeuu\nf2DoGr7Ki7A4BvfruowWp3XnU6iJZjqDTrbtOpEzvjeJRkHnqU21tCbSSILAtEI3pxTn41C6f241\nrfH/2Dvv8LbK649/tG1Lsi3L8t5OHNtx4jh7TxJGCJAQZthQoPxCS6EUaBkFyijQAmUUKNCWtmGH\nvRIgZDuTDCeOHa942/LQtua9vz/kKDGxEztxsJPo8zx+JEv3vvd9r6R77nvec853x6YadmyuwesR\n0EWHMWlWJikZUcdlSEWfD/vuXZjXrvYrbokiEqWSsOF5uJua8LYYkYaGor/kMnRz5p4ywgwnC5vb\n3unaPhS93WBvOqLgiCFUz1BdJkmdM+hETTw6VeQpc7NjKdxA+9dfooiNI/7mW4OCLUGCnOKc2Vdu\nwOexYyxfhuC1o0s6j7DI7F7tJwo+jBXv4elopKY2ljpjPsPnZ/N2Yys1dicSYEx0OLMTotCpDqVL\nCYLAvl2NbFlbhcPuJlStYMqcIWSPjOs2HexYuI3NWNauwbx+XUBNSZWWjnrUKFwVFYckM6fPQH/R\nxcjD+y9N7FRAEAWaHS2Horc7Xdxmt6XLdkqpghRtEkma+ICLO0EdR0g/RW0PBM7KCpr+/U+koaEk\n3v5rZGHBErNBgpzqnNFGW/C5MVa8jdfVRnjsVLSGscfeCf86p7HqM9z2ahoao2kwj8U6zsD/av2u\n6OE6DXMT9cSEKrvsU13hDzJrb3EgV0gZMyWVggnJKJR9+xgEjwf7j9sxr12No3gvANLQUCJmzUE7\nfgL2nTto//wzRK+X0KFZGK5YQkhKap+OcSri9LrYZ2xmT21ZIECs3taI5yc65JGqCPL02V0iuA2h\n+tNK39hrMlH30t8QvV4SbrsdZVz8QHcpSJAg/cAZa7RF0UdL1Qe4HfWoo/KJiO99kX/jgdU4zbsw\nmTUUtYyhYqgG0eliSHgY85L0XaLBAVqarGxcVUFtlT8XOntkHOOnpaPWqrprvkdcdXWY167GUrgB\nobNIQWjWMCKmTUddMAbbti00vPISPrMZeVQUhksuRzN23Cnjyu0roihSa2uguLWEvW0lVJgP4Dss\n91kmkRGnjjksctv/qFGe3jNOweOm/uW/4TOZiL7kMtQjRg50l4IECdJPnJFGWxRF2qq/wGkpIyR8\nCFEp5/fasFXv34poXYPTqWRV83iahulI16mZHasjM7xrLXGbxcnmNZWUFPlLgian65g0KxN9TO8j\nikVB8KdqrfkBZ7m/bKNMq0V39rlETJuOMi6ejvIyap/5M66qSiRKJfoLF6Kbdw5SVd9uCk4FrG4b\n+9r2U9xWyt62Eqxu/82LBAnJ2kRGxA9DL4smURNPnDoG+SANDjtZiKJI83/+jbOiAu3ESegOy8MN\nEiTIqc+ZdUXrxNzwA/a2HSjDEohOW4xEcuycWWOHm01bd5AbugJEKd+3T8IwOpMFMRGMz4ihpeVQ\neT63y8uPm6rZubkWn1dAb1AzaXYmyelRfe6rfddOmv75OkgkhOWNIGLadDT5BUjkcjxtbTT841Ws\nmzYCoB0/kejFl6CI0vf5OIMVn+Cj0lLtN9KtJdRY6wKpVlqlhglxY8iJyiI7aihapea0SAk5EUwr\nv8GyYT0h6RnEXnv9oPWyfPjhe3zzzZcolUpcLic33/x/jBs3oc/tbN++lTvuuI3ly78I5FT7fD4W\nLjyPCy9c1CvJyGPJYS5fvpydO/ewdOkdXV5/441XWbny66A05wlKcx7s8xNPPMyrr/6TjIwhgL9Q\nzGuvvYRUKmPSpClcd91NJ3SM04UzzmhbW7ZiaVqLXBWFIeMKpLKeq3/5RJF9JjuFTe3Y9lRzbsJa\nZFKBSmEmS+ZODqRuHbww+nwCxTsb2LKuCqfDg1qjZPz0dLLy4pBKj+/iGTZ8uL8YxrBhKPT+8oOC\n203b55/S9uXniG43qtQ0Yi6/ktChWcdo7dSgzdlOcat/Jl3SXkaH168ZLpVIGRKZTm7UMHL0w0jU\nxJ1W69Anir1oN8b330UWEUnC/93uF/sYhDQ01PPZZx/z+utvdZHmPB6jDRAXF893360IqHxt376V\nkJ9JgS4ozXni0pw//riNwsL1gcIyB3n++Wf4y19ewGCIYenSm5kxYzYGQ/4JHet04Iwy2g7TPtpr\nvkIqD8OQeSUyRfdrmx5BYEOTicJmM2anB0OJkbNSNhES4kYePp2ZmdO7bC+KIpX7Wyj8oQJTqwOF\nUsb4aWmMHJeMQnlila+kCiXhk6cEjmPbthXj++/gbW1FFh5O9JVXEz55yimdyuP2eSgzVbC3rYTi\n1lIaHc2B9/QhUYyNLSA3KossXeYpHc19MnE3HipRmvB/tyP/iRjEYCIozRmU5jycYcOyKSgYw9Kl\nNwdeq6urRasNJzbW379Jk6awbdtmxo8PGu0zxmi7bNW0Vi1HIpVjyLwShap7V/V+s51PDhhpc3lQ\n+UQy97STl7iTiAgbqvCRxGTM6LJ9c4OFL9/fzYHyViQSyC1IYNzUNMLU/TvLcVYfwPjOMjpKS0Am\nQ3fOeUTNX/CzCj30F6Io0uRoZm9rCXvbSikzVeAR/DXQlVIFefpscvTDyI3KwhAaPWhdvIMFn8NB\n3YvPIXR0EHdj70uUflVjZHdbz6pLx8OIKA3nJh+9MFFQmjMozXk4Yd2kIra1tXZRIdPpdNTV1fX6\nszidOSOMtsdpxFjxDqIoYMi4HFVYwhHbWNxevui8iEmBCWGh2NbVER+9l/jYFpTqVGLSF3QxII21\nZj7+34+IIqRm6pk4K4Oo6P6NTPZaLbR+tBzz2tUgiqhHFWC45DKUsX2vzTyQODwdlLSXUdxWwt7W\n0i4iGgnqOHL1w8iJyiIzMn3QVhYbjIiCQMNrr+BpbER39jmE/+SCOFgJSnMGpTn7wsAW2z4xBEHA\nbnVjNTuxWZwYZgXLmB4Vr8dKc9kyBJ+TqJQLCQ0f0uV9QRTZ1GxmRV0rLp9AsjqEacoQtnxRgl5X\ny5CMms7170uRHCbyIAgCa1aUIopw2fXjiIrtX2Mter2Yvv+O1s8+RujoQJmQgOGyK1EPz+vX45ws\nBFGgxlrH3s616SpLdaDaWJg8lDEx+eREZZGjzyJSFTHAvT11aVn+AY6izhKlF/etROm5yYZjzopP\nBkFpzq7nIijNmXNEe9HRBtraWgP/G43NPfZ7MOBx+2iqt2AxdWC1OLGZXVjNTqwWJ3arq8tNx5RZ\nQ3tuqBec1kZb8Dkxli3D5zETET8bjb7rekid3cnHVc3UOVyEyKRcmBpDZHMHP3y0F12EifwRZUhl\nIRgyrkAm7+qG3rO9ntZmO9kj4hiWF9evEcv23btofncZnsZGpGFhGK5YQuSMWYO+9KjZZWVfZyrW\nvrb92Dx2wJ+OlRaeQo4+i9yoYaSGJwUDyPoBy8bOEqVxp1aJ0qA0Z1fOdGnO7oiPT8But9PQUI/B\nEMOGDevd2RRYAAAgAElEQVR48MFHj7rPz4koipjaOqiuaKWmoo36ahM+35E3N2qtktiEcDQRIWjD\nQ9BGnHga7uC2AieA4HNhrHgXj7MJTfRYwmMPuQ2dPh8ra9sobDYhAqP0Ws5J0lOyuY7v11UREeFm\n4vgSECE6/RIUIV1TqBx2N5vXVqJUyZkwM6Pf+uxubMD47tvYd+/ylx6dNYfoCxci0/RdKernwCt4\nqTAfYG9rCcVtpdTaDkl+RqoimBQ/jlz9MLJ1QwhThB2lpSB9xV+i9E1/idKlp1aJ0qA0Z1fOdGnO\nzz//mK+//pKyslIef/wRUlPTeOCBR/jtb+/lj3/8AwCzZ88lpZuqji6nB1NbB+Y2B6b2DsztHVja\nO5DKpKg1StQaFWEaJWqNkjCNKvCoVMn6HCvj8fioP2CiuqKV6oo2LCZn4D29QU1yRhS6aDXacBXa\niBDUWhUyWf/fSJ+W0pxejxVj+TI8HU2ERuYQnXZxwP20t93GJweasXp8RIcouDA1hrSwEH74qoTS\nPU1E6uRMm7ILwdNCVPJ8NNFjjmj/u8+LKS1qYtq8oeSNTjzh3GCfw07rZ59i+v5b8PkIzc4h5vIr\nUSUlH3ebfaW3Y2jpaA0EkJW2l+Hq1I+WS2QMicwIzKbj1bEDEkB2OuRpH2sMXpOJA3/6Iz6zmcRf\n/wZ13uCseHY6fBZweozjVB+DIAjUVLbjsLqprzVhbvcbameH94htpTIJoiAedR1crpASplaiVMmR\nK2QoFFLkChlyhRS53P+oUMiQK/yu/YYaU5fZtEIpIylNR2qmnuSMKDR9qG4ZlOb8Ce6OZozly/B5\nLGiix6BLOjdgsPeb7fyvrAGZRMJZiVFMj9Phdfn47J2dNNSaiUnQMGXiftz2FjTR47o12PU1JkqL\nmoiO1ZA76siAtr4gCgLmtWto/ehDfDYrCoMBw6WXox41etBETDu9LvabygPFTYwdh9aZYsMM5ERl\nkasfxtDIDJRHyXkP0j8cUaJ0kBrsIEH6A4upg+KdDezb3YjD5g68LpVK0EaGEJsQToQujIioUCKj\nQonQhaEJVyGK0OFw47C5sdtc/kerC7vtsNfsbjocHXjcvqP04BBRBjWpmVGkZOiJTQw/KbPo3nBa\nGW2ntRJj5XuIPhcR8bMJj50SMH5Wj5f3KpqQSuAX2Ukka0IwtTn48v3dmNs7yMw2MHZsIzbjflSa\nNHRJ845oXxAE1q7YD8C0eUOPu2AKgKNkH8Z3/oerpgaJSkX0osVEzp034AUxRFGk3t4YmE1XmCrx\ndtbzDpGpyI8eHkjH0of2vcJbkONHFEWa3vqXv0TppMnBEqVBTkt8XoGKUiPFOxuoO+DPMlGqZOSN\nTmDE6CQkMtBGhBxVFVEiAbVGhVqjwsDRZ7aiKOLzCXg9Al6PD0/no9frf/R5BaJjNWjCB0eNiNPG\naNvbdtNa/QkA+tSFqKNGBN4TRJH3Khqxe33MT44mWRNCfbWJr5cX4XJ6KZiUwogRDloPrEeu1BGd\n3n1p06Jt9bQZ7WSPjCMu8fginj0tRowfvIdt6xYAwidPIXrR4gEthmFz29lfXUJh5U6K20q7yFYm\naxP9FciissiISEUmPbFiMUGOn/YVX2PduMFfovSa6waNNyZIkP6gzWineGcDJUWNuJx+t3d8cgS5\n+fFkDDMgV8hOiptfIpH4XeJyGYQqjr3DAHPKG21RFLE0rcfc8D0SmQpD+mWEaNO6bLO6oZ1ySwc5\nkWomx0ZSWtTIqi9LAJh57jAyh0JT6TtIpEqiMy5DJj8yaMpuc7FlXSWqEDkTjyP4THC5aPvqc9q/\n+RrR4yEkIxPD5UsIzei/QLbe4vQ6KTNVUtJeRkl7GXW2hsB7GoWacbGjydX763mHK09s/SVI/2Av\n2kXLB+8hixzcJUqDBOkLLqeX8pJm9u1qpKnOP1kIDVMwakIyOfnxREYFA1h/yilttEVRoL3mK2yt\n25ApwjFkXokyNKbLNpXWDr6tayVCIWdRWgxb11Wxdf0BlCo5Zy8cTnyigsaS1xFFL9Hplx2x/0EK\nV1XgdvmYfvZQQsN6f8EURRHrpo20fPg+3vZ2ZJGRGBZfinb8xJ8tRcfj81BpqaakvYzS9jKqLDWB\nnGm5VE6Wbgijk3JJDUkjSZMQTMcaZLgbG2h49e9IZDIS/+9Xg7pEaZAgx8LnE6iuaGP/niaq9rcE\ngrtSMqLIyY8ndYh+wNaLTwVOWaMt+Ny0VH2I07IfRWgchswrkCu6zgodXh/vlTciARanxbDx61L2\n72lGGxHC/EtHEKlT0Vz2H3weCxHxswiL6L7wfX21idI9TRjiNOTk9z74zFlZQfM7y3CWlyGRy4k6\nfwFR58xHepLFDARRoNpaS2lbOSXtZZSbKwNlQqUSKanaJIbphpClG0JGRCoKmeKUjy49XfE57NS9\n+HxnidKbCUn/+T0zQYKcKKIo0lRvoXRPE+XFzYGob50+jKy8WIbmxqKNGBxrxoOdU9Jo+zw2jOVv\n4+5oIESbSXT6YqSyriH3oijyQUUTZo+X2foIdn1eSmOtmdjEcM69OI+QUAVtNZ/jstcQFjmc8Nip\n3R/L5698BjBtXlavgs+8JhMtyz/A0lkFSTNmLIZLLkPRh5zPviCKIg32poC7u8xUEVDGAkjUxJOl\ny2SYbghDIjMIDYpunBJ0LVF6LuGTJg90l/qN00Wa87vvVrBs2Ydd2rrmmsv5299eYfTosX0ez0Hu\nvfdOnnzyrz2+35385ty5/RuY+OWXn1FRUc4VV1zFG2+8yu9+94c+7d/c3MTjjz1Ce5sVq8WOJiyG\n8SMuRqMNZeTYJLLyYomO1QRiMx577I/MnDmHKVOm9foYZWX7USqVpKSk8tBD9/H73z90Qgpr7733\nNitXfoUo+usJLFp0yRESrOeccx7nn3/RgEmHHpfRfv/99/n0008D/xcVFfH222/zxz/+EYBhw4bx\n8MMP90sHf4rH2UJz+TJ8bhPqqFFEpczvNmhsfZOJfWY7GRIZTSsqsJicDMkxMGt+NnK5DKtxM/bW\nH1GExhOVekGPQT1F2+pob3GQkx9PbEL4UfsmeDyYvl1B6+efIbqcqJKTMVy+hLBh2f0y9sNp6Wij\npH0/pe3+2bTVfaimb3SontEx+QzTZZKlG4JWOTiLswQ5Oi0fvo+jaDdheSOJvrhnPeRTjdNJmtPr\n9VJauo+sLP9v/NtvV5CQkHjC7R7NYPckvzljxmyUyv6PddDrowMGWxBEzO0OLCYnLqcXl9OD2+nt\nfN755/K//vUP/yImMouJw/ORK6QUVX5GYpaTCxfNPmrkd19Yvfp7srNzSUlJ5eGHnzihturqavny\ny894/fW3EEWRK65YxLx55wJdJVgP0p10aPrP4Ak7LqN9ySWXcMkl/ovI5s2b+eqrr3jsscf4/e9/\nz8iRI7nrrrtYvXo1M2bMOEZLfcNpq6al4h0En5OIuBmEx03v1tjW2px8U9tCpMWDZHcTFqeX0ZNT\nGD8tHYlEgtNSQXvtN0jlagwZlyKVdh8xaLe62LKuClWInAkz0nvslyiK2H7cjvG9d/AYm5FptOgv\nvZyIadP7bd3a7LKyv3MmXdJeTquzLfBeuFLLuNiCgMtbHxpc8zzVsWxcT/s3X51yJUp7w+kkzTlp\n0hRWrvwmYLQ3bdrI8OH+zBWv18tjj/0Ro7GZjo4ObrjhZqZMmcbSpTeT0anEdtVV1wX6kZ9fwM6d\nP/Lii68xf/4cvvjiO5YuvZlx4yawfftWTCYTf/7zs6jV6m7lNwH27y/lr3/9M3K5HKlUyqOPPond\nbufXv36YmJh4du/excKFF1NeXsbevUUsXHgJF198KYsXL+Dcc89n27YtKBQK/vSnpxBFEafDzbpV\nO3jh5ce4/ML7eO0/9zEkZSK1TXsRBC9zJt6CKIqs3fYWPp+HhJgcyqoLufS8B3G7O9BGSpk9P5v0\nrGiUqkOSxq+++hK7du1AEHwsWnRpFy+Bz+fjqaceo76+Dq/Xy0033cqYMeMoLd3H0qXP4PMJ5OXl\nc8458/nkk+WsXv09Op2OBx+8j7feehebzcoTTzyCx+OXIL333geQSCQ89tgfSUhIpKxsP1lZw44Q\nP4mPT+Dll19H3lkuOiQkBLu9e4GTnqRDB63RPpyXXnqJJ554gquuuoqRI/2FHmbNmsXGjRv71Wjb\n2/fQeuBjEEWiUi48oo74QZxeH29XNCCzuInY3oJXhFnnDSN7ZDwAHlcbLVUfgESCIf1S5MqeU7c2\nrCrH4/Yx45ysHoPPXHW17HnhPcw7d4FMRuTcs9EvuOCEy0o6PB3sN1VQ2mmoG+xNgfdC5aHkG/LI\n0mWSrRtCbFhMMP3nNMJaup+mf/+zs0TpHcjCTk4E7Xvfl7FlX/OxN+wD47JjuHT2kKNuczpJc06c\nOJkXX3yO2277FSUlxaSmpgUEMqxWC+PHT+Tcc8+nrq6WBx64N+D6zcjI5KKLFvPCC88ye/ZZXHbZ\nEl5++fluj6FWq3n++b/z97+/wJo13/cov6lShWAytfGb39xNVlY2r7/+CitWfMWUKdMpLi7mkUf+\njMVi4eqrL+X99z/F7Xbzhz/8jkWLLkEURCI0MSy9+RH+/d9XePKRv+NxSmk3NyHaKuhwePzR3RKR\nnNwsrr/hBt56+zliM5xYrG2MGTeC2267g69XfErT+zu48TfTmFAUyX333UWtcQfjx09k7txzSEpK\nZufOH2lqauSll/6B2+3mhhuuYvr0mYHxrlz5NXp9NPfd9yAmk4lf//pW/v3vd3juuWd49NGH0esT\nefTRB1Gr1UyYMImZM+eQm3tISOn111/h/PMvZM6ceaxa9S1vvvkaN954CyUlxTz88OPodFEsXHhe\n4Lt2EKlUGlAp27y5kIiIyIBRXrXqO9auXY1SqeSOO+4eUOnQEzLau3btIj4+HplMRnj4IdexXq/H\naDT2qo1jlXQTRZHmA2torfocqUxF5qhrCNdn9bjtazsqMdncZBSbcftELrt+HMPy/CdeFHzsLXwN\nweckdfglRCfm9njcyrIWyvY2k5ASyfQ5WUi6Wctu27yF6iefRvT5iBxdQPqN1xGWlNSrcf8Ul9dN\nSUs5Rc0l7G7aR0V7dUA1RylTkB+XQ15MNnmxw0iPTO4399LhnGh5vcHCqToO0efDtGs3xc+/iCgI\n5PzuLnQjTkwR6GiEhimRyfr3Zi80TNnl/Pf0Wfztb89SXl7O2rVree+9//LFFx9x1llzKC7+kYKC\nAtTqUHJzM1Eq5UyZMh6DQUtCQjzjxhVgMGiJj49FLheIjAxDrVaxYMF8NmxYRW5uLlOmTCI8PBSr\nVYXN1kJGRjqpqbEATJs2mfr6Kurra1i48AIMBi2zZ09n+/bNmEyNNDc3ce+9/rVrq9WKw+Ev7hH2\nk3EBqNUqYmOjyMnJprq6lA0bfuDCC8/n22+/JTIyjPT0BN55Zz+33/4LpFIpdrsVg0GLUiln8mT/\nmBoaali8+CIMBi3z559DWVkJBoMWiUQS2HbmzKkYDFoyMlIwmUwYDFruv/9errvuKtauXctXX33F\nO+/8h48++oiMjGSeeeYZnE4nzc3NLFiwgKgoNcnJKegidDgsXrTaSGr2O2lsaKW5sZXX/7oWm9VF\nTYkSY2UpUreehrZyMtKyUIRpmXXuMIprNNz7xHmsOvtZfnPvlYSHh7OjeCiJKRpadpZz1rxpDMmK\nZXH4ApYvfxuDQcusWZNZtep71q9fz5o1a7j55mt59tlnqajYx759e7jzztsAkEpBFJ2EhCiIiAjl\nxx83sW3bNvbtKwL8imERESpqa6vJzs4OfH+AwD4GgxaZTEp0tIayshL+8Id7iY7WMnfuTP7znzeJ\nilKTmppKdrbfYxoXF4tKJXb7/dyxYwevvPI3XnvtNQwGLeedN485c2Ywbtw4vvjiC15++VluueUW\nVCp5YH+NJqTb78jJ4ISM9gcffMDChQuPeL0v5cyPFrEsigLtdSuwGTcjU2gxZFyBS+hZUWtTs5mt\n9e0kl5hxW92MnpxCVKw6sL3DtA+nrRF1VD6iMqfHdnw+gc/f2wnApFkZtLQe6SJxlJZQ9+xfQCYj\n+567ETKysQP2XkZg+wQfB6w1lLT5Z9KV5gOBymNSiZSM8FSydEMYphtCWkTKIY1pH7S22nt1jL5w\nukSPn2rjEEUR14EqLIUbsW4uxGfx56oaLr0Cb/KQkzqWBRNTWDAxpd/bPdjnnj6Lg9Kc4eExzJ9/\nMeeccxFLlizm6qtv5NNPP6KmpoEpU2ZgNFpxu71YLE6MRisulwer1RV43t7u/x3Y7S7mzp3MXXf9\nitLS8oA0p93uwmRy4HJ5A/0wmWyoVCpcLg9ms7/dtjYbbrcXm81NVlZ2t9KcDoebVavWd5HmPNj+\n5MkzWb78E7Zv38qSJTfy+edfYTI5ePvtD2hqauH551/FYrFw001XB8Zks7k7x+HFbO7AaLRiNnfg\ndvv7KoriEeO32ZzYbAfPhROVKoKzzjqfs846n9tvv4U1awp5883XuOiCy0lLzuPDD5exc2sNprr1\nGBttvPTkKjxeF26nj01rKvB4XX5d7agw5AopeQXxJKXEU1Jupayig9zcVCoqvCSm6ZBIJZhMDnw+\ngfb2DlwuCQ6HG4ulg44ONzabq/Nc2vH5hMP6GEJ+/gTy8ycwZEgOH374MZmZQzj33AVcffX1Xc6z\n0+nBbO7A64Urr7y2i8vcbHYBki7fr8P3MRqt+HwCLS02fD6RlhYroqiipcWEIEBbmx1RlAT29XoF\nWlttPPfcvVRXH2DcuAlce+2N7N9fyiOP3M9TTz2HXK7BaLQSH58eOO7IkeP585+fQi5X09DQFGiv\noqKaiIiIXv1eT9Swn9B0bdOmTRQUFBAVFYXJZAq83tTURExM9/nOvUUQPLRUvo/NuBlFSAyxWTeg\nDOtZ+afB4eKLaiNR1XZocpCUpmPc1K7r0LYWv+ydNmZSd00E2L21lvZWB7kFCcTEHxl85qw+QP0L\nzyEKAgm3LUU/YdyxxyMK1Fjr+a56DS/vfJO71z7EX7a9zOeVKygzVRKvjmVOynRuy7+Bp6c9zJ1j\nbuP8jHkM1WUcMthBThvcxmZaP/uEqgfuo/pPD2P6dgWiIBAxazYjn3oC3byzB7qLJ43PP/+Ep556\nLHBzf7g0Z1VVBRs2rGfmzLP61Obh0pwjRhyqx364ZCTAjz9uZ9iw3IAcJtCtNCf4o8ONxkPLBwel\nOV988TUMhkPXt8mTp7J27WrS0zMDGtIAJpOJ+PgEpFIpq1d/j8fjOaLfiYmJgX4UFm7o1Vi3bNnE\n3XffgcXsoLaqja3ry2moM7J9nZHK8jq2rm7hqw93smnzBtparLicHpQqGcNGxDF2cgohYQoWXTOa\nq345AU14CJdcP5bQMCUKbTs5+fHU1O3v09psQkIS+/YVdxmDIAhcc83lVFZWBLZrbm4iISGR3Nw8\n1q9fiyAIuFwunn32qS7t5ebmsW7dagDa29t49dWXAEhLS2fnTv9k6oknHqGqqhKJRILP17V2eE5O\nbuAz3bFjW7d63Qf53e/+wIsvvsa1196Iz+fjiSce4bHHniI+/lBq73PPPcPOnT8C8OOPW8nIyOwi\nHer1etmwYR3jxk3s9Tk7EY7bGjQ1NaFWqwPRihkZGWzdupWxY8eyYsUKrr766uPulM9jx1jxDm5H\nHSpNGob0S5EeJU1JEEXerWhE1tKBusyMJlzFWRfkdEnP8jhbcVorUKlTeiygAmCzONmyroqQUDkT\nph8ZfOZuaqLuub8gOJ3E3XRLj4INoihi7GgJBI7tby8P6EsDxIRFM0w3lGG6IQzVZaBRnDrSikGO\nD5/VinXrZiyFG3GW+9djJQoF2vET0E6YhHp4HhK5HK1Bi/MU8hb0ldNNmjMkJITc3Dxmzpzzk/7M\n5t5772Tv3iLmzZ1PZISePz/+VzocHpobreh1HSxceCmPPPIHVq36ntzc4YH18MPxeUVammw01Vto\nbmojRh2CzJvA1VcuQS5X4hO8DEmZhNcZyui8ORTu/i+xsfFcuWQJb/3vZX576Y3srdYwe342DocD\nxcsyYhPCcTgcXY5TUrKPjz76AJBw44238MMP3/fqvJ933gLuu+/OQNCcVCpFKpXy0EN/4i9/eTKw\nXXx8AnfeeQ+hoaEUFIzhlluuB0QWLuyaGTF79lls376FW2+9AZ/Pxw033Az4pUOffPJJPB4fw4eP\nIC0tnfz8Ap577unAWjTATTfdyhNPPMpnn32MXK7gvvsewOs9Ug3sp2zbtoWGhnqeeurxwGu33fYr\nFiy4iKeffhy5XI5EIuGee+4H6JV06MnguKU5i4qKeO6553j99dcBKCsr48EHH0QQBPLz87nvvvt6\n1c5P3QkeZyvG8mV43e2E6UagT7kAyTHqXe9tt/F2UQ2JW1qQeAUuuqrgiPSs9roVWJsL0acuQh2V\n10NLsPKTPZQVG5l57jBy8uO7vOc1mah58jE8LUZirryKyNn+2cBBN6DJZQ64u0vby2l3HfI+RKoi\nGNbp7s7SZaILiezV+fm5ONXcyj0x2MYhuFzYd+7AUrgB+54i8PlAIiEsJxfthEloRo9BFhraZZ/B\nNobj5UwchyiKmNs7aG220dJso7XJRkuzHbvV1e32JmsjIi4y0nKoqv+Rhub9XL74lyiVMtpbHbQa\n7ZhaHQhC18u0NiIEvUFNVIwavUGD3qAmIiq0x1iXY41h8eIFvPXWu12MX29pbGzgwIEqJkyYRFHR\nLt5441WeffalPrfTG06H79SASXPm5eUFDDbAkCFDWLZs2Ql1xmWvxVjxDoLXQXjsVCLiZ/UqKnpd\nfTv63W2Ibh9T5w09wmALggd7606k8jDCInvOma6taqes2EhMgpbskV3v9H12O7XPPoOnxYj+gouI\nnH0WPsFHUes+qg5UsrOhmCbHoeA7tSKMAsMIhkX507BiQqODEd5nCKIg4Cjei3XTRqzbtiG6/IVu\nVCmphE+cjHb8BOSRg+umLcghRFHEZnFhanNgbu9ApVRgtXYgCiKCiP+x8+/gc6/X5zeyzTa8HqFL\ne2qNkpTMKPQxGnRRYbjdXr9EpNVFQ6PAx1++yraiLxBFmJh/GTs21QT2lSukGOK06GPU6GP8xjnK\noEEVMniWzNRqDe+++z/+9a9/IIpwxx2/HegundYMmk/eYdpHa9VyRNFHVPL8brWsu6Pe7sS8vRGN\nxUPW8FiGFxxZZtTRvhfB1+GX6uxhfdjnE1i70i+7OX1eVhcDK7hc1P3tWdx1tUTOnoN83my+rFzJ\nurpCzG7/XZ9SpmS4Pruz8thQEjVxwRreZxCiKOKqPtAZULYJn9nvZZFHRxN+1ly0EyahSjgx/fXT\nGVEUcTm9fo1juxtH51+H3UOH3U2Hw41aqyJtaDRJqTpk8hP/bbmcHtpbHZjbOjC1OTB1PprbO/B5\nhWM38BMkEtBFq4mO0aCP0RAd6ze0R9cqyGHJTbMB8Hp9ODr1nl0uL5FRYYRHhvwsN/sffPDZce+r\n1WqPCN4LcvIYFEbbatxMe+3XSKQKDOmXExrR+zSX7zYdQFNnRx0VyvRzsrr9gh8MQNPoe74R2LWl\nFlOrg+GjEzDEHXJfiF4v9X9/iY7yMszTR7FupJQdG5/AJ/oIkYUwM2kKs7MmESnog7KVZyAeoxHL\npo1YCzfibvSrpUnVaiJmzCJ84mRChgwJelh6wNhoZduGAzQ3WOiwe45wAXfH3h0NKFUyUjL0pGdF\nk5IRhVJ17MuYIAi0NtuprzHRWGumsc6Cw+Y+YjuFUoZOH0akPoxIXSgRUWFEGzRYrU6kUglSqQTJ\nwUeJJPCaVCZBGxHil3c8TuRyGeGRoYRHhh574yBnLANqtA+mdFmbC5HK1cRkXoEyrPezkQN1Zixb\nG5HIJSy4OA+F4sgfjNvRiNtRR0j4UOSq7l2SNouTreurCAlVdAk+EwWBmn+9xjZHKbsXJtAUWg/N\n9cSrY5mRNJlxsaMJkatOi3WWUxlRFHHVVOPYU4Rd9OD0gkShRKJUIFEokAaeK5EqFEiUSv/rSqV/\nO4UCaef7km4CgX6Kz2Y7FFBW5vfOSBQKNGPHET5xMuq8EUjkg+J++ITocLgxtfpnoO2tjs7nDiRS\nCdkj4sgeGdcnxbuDtDTZ2Lquisr9LQBowlUY4rSEqhWEqZWEqpX+xzAlYWoFoWoloWEKWo12Kktb\nqCxtoay4mbLiZmQyCUlpOtKzDKQN1Qf643H7aKq30FhrpqHWTFO9BY/7UJSxWqMkNTOKiKgwIqPC\niIwKJTIqjDCN8oibrODvO8hgYkCvLJW7lmFt3olcFU1M5hXIVb0vv+lyelj58R6kgkjGrHR0+u6j\nrwNpXkdxt2/4vhyvR2Da3KGoQvwlTY2OVlZ8+ybbE5twZoQjRWCUYQQzkiYzNDIjOHsaYASnE0fx\nHuy7d2HfvQtve3v/NCyTIZEfZsSVCr+hVyiRKJUgCHSUl3UfUHaSKpf9HJjbHVSWtviNc5vfQB9U\nYjqckDAFXrePwh8q2LK2kiE5MQwfnXjMuvwArUYbW9cdoKLEH/sRmxjO+GlpJKbqevV7SkiOJCE5\nksmzM2lttlHRacAPlLdxoLwNydcQlxjhz9dtsnWZuev0YcQlRRCfHEF8UgTaiJ/H7RwkSH8zoEa7\nvWknKnUK0RmXIZP33iUkiiLffb4Pj9WNI03LrNHJ3W4n+FzY23cjU0YQEt59acWayjbK9xmJTQxn\naF4Mxa2lrK5bT5GxGFEDYW4p8xKmMj1t+qCL+D7TcDc1Yt+1E/uuXXTsL0HsTOOQajRoJ05CPSIf\nw5AU2ptNCB43otuD6PEc9tzt/9/tfxQ97sOee7o8F91uBI8bwe7A5/W/R2c+qCo5Be3ESWjHT0Sh\nO7XrvNutLraur6J4ZwMH80gkEgiPDCU2McLvKo4KC7iMQ0IVuJwe9u1uZM/2ekqKmigpasIQpyVv\ndC2uLmoAACAASURBVAJDcmKQ/8Tj1d5iZ+v6KsqK/cY6Jl7LuGlpJKdHHZfhlEgkRMdqiY7VMn5a\neuCGo7K0hYZaM1KphOg4DfFJEcQnRRKXFH5cHoEgQQYjA2q0Q9SxGIZc1WNwWE/8WFjNgbJWnDol\nwyenoOxBMN3etgtR8KDRj0HSTVCYz+sPPhPkHhSj2/nT5r/Q7PC77OJaPRQ0yDjr6nsIiTo5kppB\njo7g8dBRWoJ9t99Qe5oP1V9XpaSiHjkS9Yh8QtIzAoIa4QYtLv3JcWWKgoDo9SI9CUpKPzcup4cf\nC6vZvbUOr1cgMiqUgkmpxMZrCdeFIuvhNwWgClGQPy6ZkWOTqK1qp2hbHQfKW1n1ZQkbvi8nJz+e\n4QUJSJHw7Wd72b/HX6AkOlbD+GnppGRGsXz5+/zpyf6V5hw1YTTODg8gcullC7jwwkVMnh2U5jxe\n+kOa86mnHsPpdOJyOUlPz+Tuu3+PQtG9QNNgkOZsamrk97+/m4KCMYHP22az8ac/PYjN5i8C9Lvf\n/YG0tHQWL15ATExsIM3uoYf+1KXozsliQI22Lm5knw12bVU7m9dUIobIaB8RxaS47mc6oij6XeMS\nKRp9Qbfb/LBpB8XaLVgy69nb5EUulTNansrQL3aQ6A4l+d57UAYN9s+Kp62t0+W9E0fxXkSXP79V\nogpBUzCm01CPRB75889wJVKp30V+CuPx+CjaVsf2jdW4XV7UWiVTp6YzbERsn+vZSyQSktOjSE6P\nwmp2smdHPcU7G9ixqYYdm2qQSEAUQR+jZtzUdNKG6pFIJCdVmjMkVMGWLZuC0pz9yOHSnH3h9ddf\n4bzzLmB2Zz2Lp59+nE2bNjB1av8JSfWnNCf4K62NGTMOQTiUPfDuu/9jxIh8liy5lg0b1vHGG6/y\n6KP+ojHPPPO348ptPxEG1GhHGoZj777mQLfYLE5WfroXJBKa83TkxUYSoex+CC57NR6nkbDI4cgO\nqzbmE3zsbtnLdwfWUeGqhFjQKSOZnjSJfIsG80uvIFUqSbz7LpSxfa/KFKRviD4fzooK7Lt3Ytu1\nE3ftoRxVRVwc6hH5aEbmEzo067QI7hoofD6Bkt2NbF1Xhd3mRhUiZ9KsDPJGJx7hzj4etBEhTJyR\nwbgpaZTva2bPjgZkUgnDRyeSMaxrjYKgNOepIc15kIaGeu6//x7eeOM/XHbZRVx44SLWr1+L2+3m\n+edfRhBE7r//d7hcLiZNmsJnn33M++9/itVq7SJteffdvw88H4zSnACPP/40P/zwPRUV5YHXrrrq\nusANbWRkJBaL+ajfiZPNgF4FQ7UJ2F3d65X+FJ9PYMXHe3E6PCjyDbgjlEyJ63mN2WbsTPMy+F1U\nVreN9fWbWVu3EZPLf9LVZj0zk6dw9uhJuCsrqX3lKSRSKQm330HIz1SS7kzEZ7ViL9rtn1EX7Ubo\nrAstkcsJG56HemQ+6hH5KE+wfn0Qv8epfJ+RzWsqMbd3IFdIGT0phVETkvmi9hs+3PK/fj1eQcwI\nFuWdT1ZeXI9R10FpzsElzXnxxZcCkJqaxo033sILLzzLV199jkajOaIvPp+PlJQ0rrzyGh566D62\nbt1Cc3MjaWkZ3HHHb1m+/P1ATfklS67lvvvu4ssvPzslpDkBwrqRVD68nvz777/D3LmHdAGeeeYJ\nGhrqGTlyFLfeuvRnCW4cUKPdlwFu+K6cpnoLyVnRbNArSNWEkKju3gXm89hwmItRhBho8ElYs/cd\ntjftxCv6UMmUjNaOxrJeQ1p0IueOGYW7vp66559F9HpJuO12wrKG9dcQg3TiNjZj3VSIffcunBXl\nHIx6kuui0I4bh3pEPmE5uUgP+4EEOTEa68ys/7aM5gYrUqmE4aMTGDM5FbVm4M/xAw/4BR82b97I\nsmVv8fHHHzBlynQ2bdpAXl4+KpUysD6Ymzsc8Ltphw71/zajoqKw2Q7d8M+adRbffvsNQ4cOY/To\nsYFrS01NNUlJKQEXZkHBGEpL91FVVcmsWWd1vjaWwsINVFZW0NTUyJ13LgX8QiaNjY2EhvbsiVCp\nQsjIGMKuXTtYu3Y1M2fOYe3aHwDQasMpLt7Dp58uRyKRdpmh5eT4jcyBA5XMmTMXgClTZrB3754j\njpGf71/ei4mJwWz2t3HLLf/HBRcsZNOmDXz99Rf873//5s03/4tOp+fvf38Bl8tJS4sxMINNSUkh\nIiIShUKJTheFwRCDw+HoMhMeO9a/PJGXN4Jt27YGzntP/TEYYrHbbVRVVVFQ4M/OmTp1OsuWvRVo\n5/33P2XLlkIKCzdw003X8MgjT1Bauo89e3azdKm/prgoCrS0tATaLyraxc6dPwZumFwuv1emuvoA\n2dnZGI1WHnjgkR4/k5KSYm691f8Zjh49ln/9y1+5MzExGb0+GoDoaAN2u+0Io300Xn75bygUCs4/\n/yIAbrzxFiZOnIxWG87vf/9bfvjhu8B36mRySvgbS/c0UbS9Dl10GO6Remi3MSW25zXNduM2ipwu\ndnaYqG3wV+qJDTMwPWkyY6ML+PTfu/G4Opg+byje1hZqn30awWEn9vqb0Izqfv07yPEh+ny0f/MV\nrZ9+7I/2lkoJHTIU9YiRqEfmo0xMCqbe9DNWs5PCHyooK/YHgGVmG5gwI50IXde1t0VDzmfRkPN/\n9v4dlOZMS0snLS2diy++jCVLFnPDDTfz6acfYTabmDFjdmD7w0U0Dn9+uGzCjBmzuOuuX1FbWxOQ\n5gQ619UPbef1elCpVIiiGAhOFUX/+qVC4XeJdyfNCX5jcrg050FmzTqL779fyfbtW/nFL34ZMNor\nV36NxWLhpZdeD0hzHkShkHcem4DrtaefQXdjdrmcxMcncNFFi7noosXcfvst7N27hzfffI0lS65l\n4sTJLFv2Hzo6HL0+hwfPgygefUJ15P5iQJzp8P1cLichISFMmzaTadNmkpc3km+//YbMzCGcf/6F\nR0hzHkQuV3DNNTccEVjX+5gLSWBcHo838Dn/VIxFFEWeeuqxLtKcPfH6669gMrV3camfe+6h387E\niVOoqCj/WYz2oK+z2Wq0sfrrEhRKGTMuyGGn2Y5OKSdXd6Qbo83ZzidlX/JkyVd84XBR12FiZPRw\nbh/1Cx6Y8FtmJk2hZLsRc3sHeWMSiQgRqH32GXwmE4ZLLydiytQBGOHpi7P6ANWPPULL8g+QhoUR\ne92NZD77Asn3/J6o885HlZQcNNj9iNvlZdPqCt7+x2bKipuJiddy0VUFzLto+BEGeyAJSnMe4kSk\nOQ8qV7lcLqxWK3Fx8ZjNJhITk3C73RQWru+VutVBDspP7tmzi7S0IxUOe+J0kebsiZ07d7B37x7u\nvfeBwI2DzWbjzjuXBj7THTu2k56eeYwz1T8M6pm22+Xlm4/24PUIzLtoOCVeDx5BZFJsJNLOi70o\nipS2l7O6bgO7jHsQEQmVwLTIZObmLEEfGhVoz2LqYPuGA4SqFYwZE0fdc8/gaWpCd+58dPP6N13i\nTEbwuGn7/DPavv4SfD7CJ0/BcOkVyLpZIwty4giCSMnuRjavqcRhd6PWKpk4I4Ohw2MH5U3RmSjN\nOX/+BcTExPDPf/6jyzaXXHIFDz5471GlOX/KuHETKC3dxy9/eQMhIaF4PB4uvfQK4uMTuPjiy7jv\nvt+SmJjIxRdfxrPPPsXs2XN7c/rOeGlOo7GZhx++n7a2VpxOJ/v27eWuu+7lo4/ep7m5kV/96lYA\nwsMjePzxp5k4cQq33HIdKpWKoUOHMWvWnGMcoX84bmnO/qKn8oCiKPLNR3uwtOxnaK6WvIkzeaao\nGrdP5J5RaSB62Ny4ndW1G2h0+O+Gk7WJjFbKyPS1kpx9C8qwrj/8rz8sonJ/C3POySR05f/oKNlH\n+LTpxF5z/Qld3E6HMof9NYaO8jKa/vkG7sYG5FF6Yq+5DnXeiH7oYe840z6LugPtbPiunJZmG3KF\nlFETUhg1PhmFcuDr4J8OnwWc3HFUVJRjs1kZOXIUK1d+zfbt27jnnr6nVx2LoDTn4GHApDlPNjs3\n11Bd3sTc2XuRSX3U7t1NincYiohUPi3/nE0NW3H6XMgkMsbFFjAjaTJJqnAail9AqU46wmAfKG+l\ncn8L8Qla1Os+wl6yD83oMcRefd2gnI2cagguFy0ffYDpu29BFImYNQfDxYuRhgTFD/obu9VFU72F\n0qKmQP3urLxYJszIQKMd+CCzIL0nLEzN008/3ik+IuW++x4c6C71maA058/LoDTa9dUmCn+oIDXV\njEzqQxYSS4mlgXrXWqosPwAQqQznrJSZTEkcT7jSf+diqv8OAE1010pEXq+PdSv3I0GkwL4F+47t\nhOXkEveLWwOVtIIcP/a9e2h66594W1pQxMYSe+0NwQj8fsLj8WFstNJcb6Gp3kpzgwWb5VBxg7ik\ncKbMGUJM/LFrfwcZfMTFxfH3v78x0N0ISnOeQgw6o223uljxyR4kEgmZuSY22d1stzVj8fijIJPl\nckar5AwLVaELC0Ej81cAEgUfttYdSGWhqHVdUxV2bKrBYnIySV6Ka1shqrR0Ev7vdqQ9lNML0jt8\nDjvG997Fsm4NSKXozp2PfsGFp0WZz4HC6/Wxa2sNpfuaaa630Nps4/AFrFC1grQhemISwv21tZMj\ngp6iIEHOIAaV0fb5BFZ8soc2sQX5RCMvtZTiBaQSAaUimyuyZjNGH4O1eRNW42ZM9d9hadqANmYC\nUnkYgteONmZil9KoFlMH2zdWM8S+l7CGzSji4kj89W+CbtsTxLbjR5r++298JhOq5GRir72RkLS0\nge7WKU17q52VH++l1eiPdJbJJMQkhBPb+RcTrw2qUwUJcoYzaIy2V/Dy7qpv+VG7nY4EE3hBJ5Uw\nTp9LYccYktThjIvxpwhFJswiPGYS1pbNWJs3YW74IdCORt9VgnP9t2XEtO0jtXkzcl0USb+5G7k2\n6Eo8XrwWC8a3/4t1y2Ykcjn6ixYRdc55wRKjJ4Ao+qO/167cj9cjUDAhhYzsaPQxmqMKdwQJEuTM\nY8CvtCaXmXV1hayu3ohD6gAN5OqGMUrWQZK3lX2a6UicXqbERXaZYUjlIUTETUdrmICtZRvW5kJU\n2jQUIfrANlVlLdh3bGdE80akGg2Jv/ktCr2+u24EOQaiKGLdtJHmd5Yh2GyEZGQSe90NqPpBHOFM\nxu3ysuabUvbvbUapkjHvolwmTss85SNkgwQJcnIY0Nv4v274Bw9seIKvqr7D5fYQ05zBb7Jv55bh\ni0n2tSFTp7KhzUe4QkaervswealMRXjsZBJH3El02qLA616Pj53LV5PXtBqJUkHir+5ElZDwcw3t\ntMLT1kb9C8/R+PpriG43hsuvJPnePwQN9gnS3GDh/X9uZf/eZmIStFxy/Vgys8+MeusffvgeN998\nHUuX3swvfnENW7ZsOq52tm/fyvTp42lpMQZe8/l8XHDB2bzxxqu9aqOioixQUrM7li9fzosvPnfE\n62+88SpXXnnxEW1NnTo2UNzjeLn33juP+v7333/LLbdcz9KlN3PDDVexcuXXJ3S87vjyy8948cXn\naG1t4amnHuvz/s3NTfz2t78KfMaPP/5wtwVmDvLYY39k/fq1fTpGWdl+qqsPAPDQQ/fhcjn73M+D\nNDTUM3fudJYuvZmlS2/m/vvvAfyFVO6++9f88pc3cuedt5/ZgiGFNdtJUMcTVpmAsjqacy4YQWZi\nDJam9QDs9iTjEUQuTjMgl/ZtHW/nF4UM3f81EgkkLv01oRkZJ2MIpzWiIGBeu4aWD95F6OggLCeX\nmGuuQ/kzaMaezoiiyK4ttRT+UIEgiBRMTGHctLQzxhV+MqU5wW/Ig9Kc/ceZJM2ZkpJ6hK76e+8t\no6BgDFdeeQ2ffLKc//7339x2269O+FjHy4Aa7cfPuofC5Q1UVLUwclxSYJZhbytCRMqmjjhyItWM\niOpbJa3WkkpUX72FTPQQc8OtqHsofB+kZ9zNzTT9+006SvYhDQ0l9prrCZ82PRgEdYJ0ONys+mIf\nB8rbCA1TMGdBDsnpUcfe8TQiKM0ZlOYcrNKc3bFt25ZA/vyUKdP53e/u6NV+J4sBNdotRT4q9rUQ\nlxTBxJn+mbC7oxmPs4lqMQmJLIQLUmP6ZCjcra00vvBXlD4XkrMWoZs08WR1/7REFARM366g5ePl\niG436lEFxCy5BoWuZ4GWIL2j7kA7331WjN3mJilNx5zzswkbQMUt4/vvYN26pV/b1I4dh+GSy4+6\nTVCaMyjNOVilOdvaWrn//t/R0tLCokWXMG/eubS2thIZqQt811pbWxhIBtRor/y8mFC1gnkX5QZc\ng/a23QCUCqmcmxJNhLL3XfTZbFQ99RQKpxVj5mQmX7bgpPT7dMVVV0vTv97EWVmBTKsl5rob0Ywb\nH5xd9wMVJUa++WgPUqmEiTMzGDXhzBZLCUpzBqU5B5s0Z0REBDfddCtnn30eNpuNX/ziWkaPHtel\n7QGu+g0MgujxeRcOD+j7iqKIuXU3XlEO6kzGGnqfmiU4ndQ+91dobaImcjgFN115Rl8U+4Lg8VD9\nznvUvPcB+HxoJ0wk5vIlyPqgNRukZ9pb7Xz/xT7kCikLLssnLilioLsEgOGSy485Kz4ZBKU5g9Kc\ng1Wac/78CwCIjIwkOzuH6uoqoqOjaWtrQaPR0NJi7JWIzMlkQCNfckbEk5ASGfjfYqlG6rNQJSZz\nYXpCQMnrWAgeD/Uvv4CrqoIGbSZh5y0kyhBUlDoWrro6mt99m8q776Tm7XeRh4eTcPsdxP/i1qDB\n7ifcLi9fL9+Dx+1j1nnZg8ZgDyRBac5DBKU5B4805/btW3nhBX8AYEdHB/v3l5KcnML48RP5/vtv\nAfjhh++YMGFSj+39HAzoTHvk2KQu/5fWbiEWCNfnER3SuyhIURBofOMfOPbuoUWdTHXmLC6fmtb/\nnT1NEJwdWDdvxrxuDc6KcgBkGi2JCy8kZNbZyI5D5SdI94iiyKov92FqdTByXBJDcoJR9xCU5jyc\noDTn4JHmHDlyFF999Tm33HI9guDj6quvw2CIYfHiy3n00Qe47bab0Gi0PPjgo706LyeLAZXm9PkE\n2tr8d8ClJgtixd+RSiSk59+FXHrsL68oijT/9y3Mq1fREZlIYdQszlo08mfPdR3scnGiKOIsL8O8\nbg3WLZsRXS6QSAgbnkfEtOlo8guIidcN6jH0lsH0WezYVM3GVRXEJ0ew4PL8Xqd0DaYxnAjBcRyb\noDRn3zgdvlOntDTnwYuYyyewqWoXMyQuJJFjemWwAVo/+Qjz6lUQE89m9XQSMgxkDBvY9YbBhNdi\nwbJxPZZ1a3E31AMgj44m4pzzCJ8yFUVUsDrcyaLuQDuFP1Sg1iiZd2HuGZODHaRvBKU5g/SVAQ9E\nA1hZ10q8rxykEBOT36t92r9dSdvnnyI3xLA59iwEl5ypc4ec8cFnoiBgL9qNZd0abDt3gM+HRC5H\nO34C4VOnE5adE5Qj7QUOu5vvv9hHXEI4BRNTkMl7f85sFicrPtmLRCJh3kXDBzStK8jgJijNGaSv\nDLjRrrZ1sKWphWvldciUkSjDjl1NyFK4AeM7/0MWEUHr1Mto322lYGIyOr36Z+jx4MRjNGJevwbL\n+vV4OwNplEnJREydTvjESci6ybkM0j3i/7d33+FRlWkfx7+TTCa9kQYJhIQSCBApAgqGjiisAuLq\nsiyirxQRw+IqLgisi11AWRQUAcG+CwjYEARpitKLJCGEkNASSE9InyQzc94/RgZCAqlkSu7PdXl5\nZcqZ554Tcs8585znpyjs2nyK5HO5JJ/NITE+g0EjOhIQWP3VDHqdgW3fnERbXE6/e9vLxDMhRIMy\na9Mu1xvYdC6DYNUl1Ohw9Y6o9ki5MPp30j5ejZ2LC55PPsOOLam4eThyZ9/WjTRqy2EoL6Pw2DHy\n9v5MyR+zN+2cnfEcMAjPfv1xbB3S5M881MXxAxdJPpdLq1BvPLydOXnsMps+O8YdvVrSu18oDpqb\nf33z685EMi4XENY5gM49ZK17IUTDMmvT3pKURoa2jCHOl6AcXJt1ueXjS84kkLr8fVT29gROf5Zd\nx0ow6BX6Dm53yz+ktqY0+SJ5e38m/8ABDH9cyuIc1gHPyP643dkTO0c5HVtXqSl5HPrlHK5uGoY8\nGI6zi4Z2Hf3Zs/U00YdTOJeQxcDhYbQMqbz0aHx0KnHHL+Pj50r/+8PkA5MQosGZtWlvTUrHT63H\nszwZB+fmODjdfBJZaXIyl977D4rBQOAzfyfN4E3yucu0CvWmTQffRhy1eeiLiyg4eJC8X3+h9MJ5\nAOw9PfG+fwSekf3R1OESGVGRtqScHd8Zr5kdOrITzi7Gyw4Dg7149MmeHPntAr8fvMj3a6PpeEdz\n+g5ui6OTAwCZaQX8sv0MGkc1943pgoND0/kQKYRoPGadkaRXFB70yQEMuHrf/Ci7LDODlCVvYygp\nofn/TcSxYxd+25mInb2KyHvb2+wRjb6wkIIjh0j9aAVnn3+WjC8/ozT5Iq5duxEYNYM2C97B78+P\nSsNuAIqisOuHeArzS+kZGVJh0R8AtYM9dw9sw8OP34mvvxvx0WmsXXWYs6cz0ZaUs+3rk+h1BoY+\nGI6nt7OZqrAeEs15axLNWTMNGc0JsH79/5g8eQKTJk1g06avAON+Hjv2IVNk5+bN39TrNerLrEfa\nEX4euGt/oxRwuUnT1uVd4dLiRejz8vAb+zc87u7LgT1nKcwvpUffYLya2c5iIIbyMrSJiRSdjKX4\nVBylFy8Y1xQEHPwD8Izsh0ffSNReXtVsSdRW9JEULiRmE9Taix59bj4/wq+5O2Me78GJQ8kc+fU8\n274+iYurhuKiMnre05rW7eQyuupINGf1JJqzZhoymvPSpRS2bPmejz76DEVR+OtfxzBs2HAAHnlk\nLA8//JeGGHK9mbVpD2vpRFHMRRzdWqPWVJ6Zqy8uIuU/71CemUmzB0biPfRecrOLOHEoGTcPx1v+\ncbUGisFAafJFiuPiKD51kpIzCShXP4na2+Mc1gGX8E64dOqCU2iozZ5RMLeM1HwO7D6Ls4sDQx8M\nN62jfDP29nb06NOa0DBf9mw9TVpKPsFtmtFTVuKrEYnmlGhOS4zmbNEikA8++Ai12tgWnZycKozf\nUpi1aXtqz1AEuHpHVLrPUFrK5aXvUpaSjOfAwfiMeghFUfj1p0QMBoXIoe2s8nvD8qxMiuPiKIo7\nSXF8HIbrkoo0LVvh2qkzLp064dy+g0woawSlWh3bv4nDYFAYOjK8VtdUe/u4Mvpv3UlNzsO/hbvV\nfajatyuJs/EZ1T+wFtp09Kfv4La3fIxEc0o0pyVGc9rZ2ZlWhDt06ACenl4EBBi/ety9eyd79/6M\nRqPh2WdfaJCzKXVl1qadm3ocVHa4eFVc0F3R6Uhd8QElZxJw79Ub/3HjUalUJMVnkHI+l+A2zQhp\nbx2Tz/RFRRTHxxmPpuNOUn5dAIHauxlu9/TDpVMnXDp2Qu0p1/Q2JkVR2LP1NAV5Wnr0Da5yRnh1\nVCpVpe+/RfUkmlOiOS0tmvPa68fw/vtLWLjQOI+hT597uPPOXnTr1oMdO7axZMki033mYNamXVKY\nirNnB+zU1ybuKAYDaZ+spij6BC6du9B84hRUdnaUl+mum3xmuSufGcrL0SYlUhx3kqK4k8aZ3n98\n8rRzdsa1W/c/jqY74xDQ3GLraArifr/M2dOZtGjpSa8meGq77+C21R4V3w4SzSnRnJYazXnmTAIL\nFrzKwoVLTEfZ1x/FR0YOYPnypTUcx+1R59nj3333HSNHjmTMmDHs2bOH1NRUHnvsMcaNG8eMGTMo\nKyur0Xaun4CmKAqZ69dScGA/Tm3aEPh0FKo/vl848tsFigrK6H5XMJ7eljP5TDEYKDx7jpxtW0n5\nz9skzXiGlLcXkLNlM6XJF3FuH4bPqIdo9eI82i5ZRlDUDLwGD0XTvIU0bDPKSi/gtx2JODmrGToy\nvBZ/EER9STTnNRLNaTnRnHq9njfffIXXX19IixbXFkZasuRt03tz/PgR03wEc6nTkXZubi7vv/8+\nGzdupLi4mKVLl7Jt2zbGjRvH8OHDWbx4MRs2bGDcuHG33I692glnz2uTQHK2bObKju1oAgMJ+vtz\n2P0xAzQ3q4jowym4ezrRvU9wXYZ8WxRGnyDj809Ny4YCaIJa/jF5rDMuYR1MNQjLUVaqY/u3cej1\nCvf9KRw3D9lHjUmiOa+RaE7LieY8evQwqamXWbjwDdNt06b9nQcfHM2iRW+gVqtRqVTMmjWvRu/L\n7VKnaM4tW7Zw6NAh5s+fb7pt8ODB/Pjjj2g0Go4fP86aNWtYuvTWpxHysuIpU4xf6F/5eTcZn3+K\nupkPrWbPxaGZ8ftFRVH4fu0JLl24wv0PdyHUAr7LVnQ6sjZ+Re5P21Cp1fj2i8S+TRgu4Z2s9nIs\nW4i8g1vXoSgKuVnFHNp7jnMJWXTt3cosp4er0xT2hTWRaM5bk2jO2jFLNGdKSgparZapU6eSn5/P\n9OnTKSkpMV0j6OPjQ2ZmZjVbAU9f42USWb/tI+OLz3Dw9CDitfk4B107NXHy+CUuXbhC+3B/evUx\n/1raJampnF70H4qSknAOCiRs5nO4tan5qSRLVt9fJktxfR2FBaWcS8gkKSGTcwlZFOQbF18ICvbi\ngYfvqFV6V2OyxX1hzW5XHeXl/jz//AJTNOebb755217rVtu1t7fD19cNV9fahy45OiosWbKAL75Y\nA8DcuXNv6363ld+puqrzRLQrV66wbNkyLl++zIQJE26Y0FDzg/fze/Zz6b0l2Dk60mL6cxRq3Cn8\n45NUWamOH7+Jxd5eRa/+oWRlmfeaufz9+0j/4jOUUi0e9/TDf9x4ShwdcQOb+PRn7TUAeHm5EHM8\nheRzuaSczyE7o8h0n5OLA+06+dMqxJu2Hf3IyS26xZbMx1b2hdRRPQcHd957b2WF227Ha1VXtja0\n1wAAIABJREFUw7p131JcbKC4uC6vreKttyrOpr5d75ct/E6Z5Ujbx8eH7t27o1arCQ4OxtXVFXt7\ne7Ra42zB9PR0/P39q91OQcIZLn+w1HjZTNQMnEJCKtx/5LcLFBUaV5oy59KQBq2WjP9+Tv6+37Bz\nciJg8lQ87rrbbOMRlenK9ezZepqzCVnodcZZsPb2KlqGeNMyxJtWod74+LuZ/UyNEELUR52admRk\nJLNnz2by5Mnk5eVRXFxMZGQk27ZtY9SoUWzfvp1+/fpVu524V15HKSsjcFoULjfM8MvJLCLmyB+T\nz+423+Qz7cULpK5YTnl6Go4hobSY8jSaGnwgEY1Hrzew/Zs4LiRl4+vvRtAfTbpFS0/UVrgAjxBC\n3EydmnZAQAD33Xcfjz5qXEln3rx5REREMGvWLNatW0dgYCCjR4+udju6ggICnngStz8uzL9KURT2\n/nTGuPLZve3M8odXURSu7PyJrA3rUXQ6vO8bju9DD5suQROWQVEUdm+J50JSNq1CvXlsah9yc4vN\nPSwhhLgt6tyBxo4dy9ixYyvc9vHHH9dqG+HzXkQf0qHS7YmnMrh88Qqt2/kQ0q7xZ4vrCwpI+/gj\niqJPYO/uQfOJk3HtUnmpVWFeV5e1PXMyg4AgD+57qAtqtRxZCyFsl1mnzjbr1bPSbWWlOvbtSsJe\nbUfk0HaNPqbi+FOcf/lfxhXZwjvTev4r0rAt1OFfzxN77BLN/Fz50yMROGikYVsLiea8NYnmrJmG\njuZMT09j4sTHKuzvwsJCXnhhBk8/PZHnnpteYTlac7C4c72Hfz1PcWEZvfqF4OHVeJPPFL2e7O+/\nJeeH78HODt+HH8H7vuGoZKUsi3TicDJHf7uAh5cTD/zlDhydHMw9JFFDEs1ZPYnmrJmGjOYE40pr\nd97ZC4PBYLpt/fr/0r37nYwbN4Fvv93EF198yrRpf6/3a9WVRTXt7IxCYo6k4OHlRLe7WjXa65Zn\nZ5P20QpKziSg9vWlxeSpOLdt/KN8UTPx0ans25mEi5uGB8d2xbUWyVzC/CSaU6I5LTGaE+CNNxax\nZ88uzp5NMt129OhhXnzxJQDuuac///zns7f8nbjdLKZpK4rC3u1nUBSIvLd9o303WXDsKOmfrMFQ\nXIRbz94ETHgce5faLzAgGse5hEz2bD2No5OaB//StVHPxtia3Es/UXwlrkG36eLVCe+gWy+bKdGc\nEs1pidGcAC5V/O3Pzs7Gy8vb9LuWnZ1V6TGNyWKa9pmT6aSm5BHa3pfWbX1u++sZysrI/Gotebt3\nodJoCJjwf3j06y/X8VqwlPO5bP82Dnu1HX969A6a+cmHK2sl0ZwSzWmp0Zy3UodVvxucRTTtUq2O\nfbuTUKvt6Dvk9q8FXXr5MqkrPqDsUgqaoJa0eOppHM0Yai6ql345n60bYwAY/nAXAgI9zDwi6+cd\ndG+1R8W3g0RzSjSnpUZzVsXX15ecnCzc3NzIysqsUYjM7WQRs6wO/3qOkqJyevRtfVtPdyqKQt4v\nP3PxtfmUXUrBc+Bggue+JA3bwuVkFfHD+mj0OgP3juxEy5Bm5h6SqAeJ5rxGojktJ5rzZnr3vptd\nu3YAsGfPTu66q89NH9sYzH6knZVeSOzRS3h6O9Ot9+2bfKYvLibj808oOHwIOxcXmk+cgvudlS85\nE5ZDrzdw8vhlDu89T1mpjkEjOtCmg3k/5Yr6k2jOaySa03KiOTMzM3j55Xnk5GSj1WqJj4/j+edn\n8+c/j+XVV//FtGmTcHNz56WXXq3R+3K71Cmas6EoisKqJb+QlpLPnx6NILjN7fkuu+RsEmkrP6Q8\nKxOndu1pMfkpHHwabtEWW1nE3pJquHg2h307E8nNLkbjaM89Q9rR8Y4W1T7P0uqoC1uoAaSOmpBo\nztqxhd8pswSGNJTooymkpeQTGuZ7Wxq2YjCQu20rWd9sAoOBZg88iM+Do1HV4NOsMI8rOcXs25nE\nhaRsVCro1K0FvfuH4uzS8NefCmFuLi6uLFr0hima8+qlRdbE1dWNdeu+5JNPVqEo8OyzM809JJtm\n1qa94/s41Go77hnS8NdEG0pLubz8fYpjo7H38qLFpKcqhZIIy1Gq1XF03wVijqRgMCgEBntxz5B2\n+AZUvuxECFvRvHlzli9fbe5hsGHD93V+rru7e6XJe+L2MWvTLios464Bobh7NuzqRYbSUi4tXUJJ\n/ClcukTQfOJk1O4y29gSGQwKp2PSOPjzWUqKy3H3dKLPoLa06eArl98JIcQNzNq0W4Z407VXw04+\nu75hu3W/kxZPPS3JXBbEYDBQVFBGYb6W/Dwt0YdTyEovRO1gR+/+oXTt1VLiNIUQ4ibM2s2enB7Z\noJMKDGVlXF72HiXxp3Dt3kMatpmUasu5fDGPwnwthQWlxv/nl1KQX0pxYSk3Tn0M6xzAXQPb4OYu\ny5EKIcSt2ExHMzbsdyk+dRLXbt0JfGqaNGwzKMjT8u2XxynIL61wu0oFru6OBAR54ubhiLuHI27u\nTgQEeeDXvH6zKYUQoqmwia5mKC/j8vvvURx3Eteu3Qic+ow0bDMoKizl+7UnKMgvpXP3QAKDvXDz\ncMTN3REXN0fTqklCbNy4nm3btqDRaCgt1TJlyjN1Svk6duwIzz47jU2bfjBdU63X63nooRGMGjWG\niROfqnYbZ88msnjxQpYtW1nl/Zs2beLEiZNERVUMili9egU//fRjhWu5O3XqzLRpM6rcTlFRISdP\nxtK79901La/GavN+Xh8AUhu7d+9g0KChHDiwj9TUyzz00J/rPN709DTeeOMV9Hod9vZqXnrpFXx8\nfBkw4C4iIrqaHvfuu8tRFIXXX59PWloqTk4aZs6cS1BQyzq/trWz+s5mbNhLKT4Zi+sdXWkhDdss\nSorL+H7tCfJyS+jRJ5i7BrQx95CEhbKlaM5HHhnLww//pUaPPX06nkOHDjR4027o97Mq5eXlrFv3\nXwYNGsrdd/et9/ZWrVrOyJEPMWTIvWzcuJ51675k2rQZuLm5VfrwZAwvcWf58tc4ffoEK1a8zyuv\n1D+G01pZdXczNuxlFMfGGBv201HYOUiucmMr1ZazeW00uVnF3NGzJb3713wJRNH02FI058385S+j\n6ddvIDExJ3Bzc2fRoiUsXryQ4uIiWrUKJjY2GrXagfz8K7z88pumKMqysjImTZpK7953VxmX+dxz\nUcyf/zpBQS3JyEhn9uznefHFlyq9n1cb37lzZ/nPfxai0ahxcHBkzpz5FcZ54sRxVqx4H7Vajb9/\nALNmzcPBwYElS94mLi4We3t7XnjhRb7+eiNJSYm8/fZbdOrUmbNnk4iKepb16//Hzp3bAejXbwDj\nxz/B66/Px9fXj9OnT5GensZLL71Ghw4dK7zu88/PNmV/e3l5k5AQf9P38siRQ9x//58A6Nu3L7Nn\nv1infWIrrLZpG8rLSf1gGcWx0bhG3CEN20zKSnVsXhdNVkYhnboH0ndIW7lUy0psTc4kJqew+gfW\nQkQzN4a3uvXSn7YUzXkzly9f4v77/0RU1LNMmfIESUlnGDfuMc6eTWLUqDHExkbj4eHBrFlz2bp1\nMxqNhmXLVpKVlUlU1FOsXbsJqByXef/9I9i5czsTJjzJr7/+wtCh9930/VSr1SxZsogXXphDjx6d\nWbFiDZs2rWfYsOGmcS5Zsoh3312Oh4cnH3zwLrt378DbuxkZGemsXPkJv/9+jJ07f2LcuMeIi4tl\n5szZbNnyvanGrVu/Z9UqY6rXlCmPm5LTysrKWLx4Gd98s4Eff/yhUtN2djZmTOj1er7++iueeGKS\n6Xnz588lPT2VAQMGM3bseHJyrkVj2tnZoVKpKC8vx6GJ/r23yqZtKC8ndfkyimKicekSQYtp0rDN\nobxMz5avYshILSCsSwD9h7WXhi1qxFaiOb/6ai27d+80/fzII39lwIBBuLq60q6dcU1zf3//CmO9\n6mpdp0+fMkVb+vr6odE4mGI8b4zLnDx5Ks89N50JE55k3769zJo176bv53vvfUhc3EkWLHgNjUZN\nUVEJ4eGdTK+fk5NNSkoyc+a8AIBWq8XT04vMzAzT98rduvWgW7cepKZerjT+M2dO07lzBOo/vo6M\niOhKYmICUDG+s6q4UTA27FdffYkePXrSs2dvAJ55ZgbDho1ApVLxzDOT6datR6XnWUI8pjlZXdNW\ndDpSP3yfougTuHTuQuAz07FzkCUuG5tOp+fHTbGkpuTRtqMfg0Z0kIZtZYa38qv2qPh2sKVozpt9\np11VDOSN1OqrBxqqCveXl5dXGtvVuExPTy/8/f05deokBoOCn5//Td/P9PQ0nJycWLp0Bf7+HqbL\na682YLXaAV9fv0rfIf/vf1+YXvfWbj7uG/fTje+dn58/b7zxMq1aBZsCQQBGj742ua1nz14kJSXi\n6+tHTk626TUURWmyR9lgIdGcNaXodFz+8H2KTvxubNhRf5eGbQZ6vYHtX58k5XwuIe18GPJgeC2y\nbkVTZ2vRnDVVVYwkVIySTE9Pw87ODnd342WQVcVl3nffCBYvXsCgQcZUsZu9n97e3rRr194Ul7lj\nxzaOHDlkel0PD+MqkVfjMzdsWEti4pkK40lIiOeddxagUtlVGntYWAdiY2PQ6XTodDri4k4SFtah\nytpvfO+2b9+Kg4NDhdn9Fy+eZ/78uSiKgk6nIybmBKGhbejV62527zZGY+7evZsePZp2OqPVHGmb\nGvbvx3EJ70zgM9KwzcFgMLDju1NcSMqhVag3947uhL29NGxRc7YUzXnj6XEPD0/eeGNRlY/t0KEj\nH364tFLDHzJkGMePH2X69KfQ6cp54YU5pvtujMsEuOee/ixY8LopCvRW7+eMGTNZuPB11q//ApVK\nzfz5r1FUVGTa/uzZL/HGGy/j4GA86h45cgwajYa9e39m2jTj98zPPz8bX19fdLpy5s2bRd++kYAx\nanPkyIeYPn0KBoPCgw+Oonnz6pP4ADZt+oqyslKiooxH2SEhbZg5czb+/gFMnvw4KpWKyMj+dOrU\nhQ4dwjly5CBPPz0RV1dnXnhhXo1ew1aZNZoTqNGKaIpOR+qK5RQeP4pLeCcCo2Zg52g5q2fZSlxc\ndTUoisKuzfEknEwnsJUnIx69AwcLW3K0qewLayB11M/N4jKPHTvCli3fM2/eyzXeluwLy2HV0Zw1\noeh0pK76kMLjR3HuGG5xDbspyL9SwrmELBJPZZCRWkBAoAfD/xxhcQ1bCFu3evUKDh7cz+uvLzT3\nUISZWHTTNjXso0dw7hhO0PRnpWE3ktzsIs6ezuLs6Uyy0q/NfA1u24yhD4ajcbToXx0hrF5VcZkT\nJz5Vo1XehO2y2L+8il5P6kcrjA07rIM07NtMURQy0wo4l2Bs1LnZxQDY2aloFepNmw5+hLT3xcVV\n5hEIIYS5WGTTVvR60j5aQeGRw8aGPeM5adi3iaIonDqRyolDKVzJMTZqe7Udoe19Ce3gS0g7Hxyd\nmu7lFUIIYUksrmkrej1pq1dScPgQzu3DCPr7P6Rh3yZFhaXs2XKai2dzcNDY066TP23CfAlu44OD\nRr6vFkIIS2NRTdvYsFdRcOigsWHPeA67Rlr4v6lJis/gl20JaEt0tAr15uHH7qS0TGfuYQkhhLgF\ni2naisFA2pqPKDh0AKe27Qia8Q+raNjJ53LIvFxAibYcjcYehz/+0ziqcdDYW9w1zKVaHb/+dIaE\nk+mo1Xb0u7c9nXsE4uHpbPWXUgjrIdGcDcvaojnBeI37smX/YevW3abL2nbu3M7atV+gUtlx5529\neOqpZ9iy5Xs++uhDAgOD0GjUdO16J48/PrFer23NLKJpKwYDaR9/RMHB/caG/ezz2Dk5m3tY1bp0\nIZfN66Jv+Rg7OxUOGnscndR0jGhO196tUJvpUqmU87ns3hJPYX4p/i3cGfxAON4+LtU/UYgGJNGc\nEs25detmcnKyK3zg0Wq1LF++lM8+W4uzswtTpjxhCjcZPPheoqKetYnrtOvL7E1bMRhI/3g1Bfv3\n4dSmLUHPPo+9s+U3bIBT0akA3DOkHeXlesrLdJSV6Skv1f/xs56yMh3lZXqKCko5tPc8cSdS6TOo\nLW07+jXaWt06nZ6DP58j+nAKKhX0jAyhR59gizsLIJoGieaUaM4BAwbh4uLKTz/9aLrNycmJzz5b\ni4uLKwCenp6m4BRxjVmbtqLXk/7JavL3/4ZTmzZW1bBLtTrOns7C09uZwcM7kpV164jDUq2OY/sv\nEH0khZ++jSPmqCeRQ9vh17x+q+NUJzOtgJ2bT5GbVYxnM2eGPhiOfwuP2/qawjqs35XI4fiM6h9Y\nC706+vPo4Ha3fIxEc0o059XGfKOrtyclJZKWlkrnzhFcupTC778f47nnpmNnpzBlShRhYR2rfH5T\nYNamnfj+h+Tv+w2n0DYEPTsTexfrOVWbeCoDvc5Axzua1+iI2dFJTZ9BbenULZD9u5M4l5DFhk+O\n0iGiOXcNCMXVrWYz5BVFIS+3hOyMIspKddf+K9NTVmo8qjfeZjzKz8spwWBQ6NIjiLsHtZFVzIRF\nkGhOiea8meTki7z88lz+/e/XUKvVdO4cgZeXN337RpKSksicOXP57LN1tdqmLTFr087YuQvHkFCC\n/vG8VTVsgPiYVFQqCOtSu2ADT29n7h/ThZTzuezbmcjpmDTOns6kR59g7ujVErW64h8IbUk56Zfz\nybicT3pqARmX8ynVVj/L285OhcbRHm8fF/oMbkur0Ga1GqewfY8OblftUfHtINGcRk09mrMqGRnp\nvPjiTP71r1dMH9Batw6hdesQALp3786VK1fQ6/WV3uOmwqxN2zOiC76Tn8b+JqdKLFVuVhEZlwto\n1aYZbu51u4a8ZYg3f/6/nsRHp3Lwl3Mc/Pkccb+n0vOe1ujKDaRfzif9cj55uSUVnufh5URwm2b4\nNXfHycUBjUaNxvHabHWNo/Fne3s7ybcWFmnz5m/5/fdjzJv3MiqVqkI053vvvUN+fn6FpKuauD6a\nc86cf5ua9vXRnC4urhw/fozHH59Ienoa8fFxdOwYXmU0p7d3M1avXsHIkQ+ZXuNqvGRdVRfNOXTo\nfVVGcw4cOKTKaM6RI8cAN38/r4/mHDnyfnbs2IaXlzdBQS2BitGcoaFt2LBhLd263Ul4eCe++OIT\nxo2bQEJCPN9//y1/+9vjVUZzrlmzEp3OeBARF3eSCROeZO/ePZVqrOl799ZbrzJz5uwKp9O//PJT\n/P0DuPfe+0lISMDLy6vJNmwwc9Pu8trLVjkTMD4mDYCOEbWPD7yenZ2KTt0CadvRn6P7LhBzJIXd\nW06b7tc42tMq1Bv/Fh4EBHrgH+iOs4ssIyqsm0RzSjTnp5+u5vDhg+TkZDNz5t/p0iWCBx4YzYkT\nx/noow9Njxs79m/ce+/9vPrqS3z77SZUKoXZs/9Vo9ewVVYRzWlJ9HoDn3+wH4Ne4fGovtir7Rrs\nMoS83GISYtNx93ImINAdr2YujXa0bCuXUthCHbZQA0gd9SXRnJXZQh02H81paZLP5lBSVE6XHkHY\nqxv2kilPbxd69Qtt0G0KIWyHRHOKOjXtgwcPMmPGDNq3N55WCgsLY9KkSfzzn/9Er9fj5+fHokWL\n0Ghs71Su6dT4HfU7NS6EELci0ZyiKnU+0u7duzfvvfee6ecXX3yRcePGMXz4cBYvXsyGDRsYN25c\ngwzSUpQUl3EhMRsfP1d8A9zMPRwhhBBNTIOd3z148CBDhhgnRgwaNIj9+/c31KYtRkJsOgaDQoca\nXpsthBBCNKQ6H2knJiYydepU8vLyiIqKoqSkxHQ63MfHh8zMzAYbpCVQFIX4mDTs7FSEdQ4w93CE\nEEI0QXVq2iEhIURFRTF8+HCSk5OZMGFChWv4ajMhvb4z6RrL5eQr5GQW0TGiOcGtfSrdby113Iot\n1AC2UYct1ABShyWxhRrAduqoqzo17YCAAEaMGAFAcHAwvr6+xMTEoNVqcXJyIj09HX//qle8uZG1\nTN/f/0sSAKEdfCuN2VYuQ7D2GsA26rCFGuDWdVhTNOfevT9ZfTTn9fvCEqI5X399PqdPn8LDwxOA\nceMm0LdvJNu3b2X9+v+hUqkYNeohHnhgdIXn2cK/DbNc8vXdd9+RmZnJxIkTyczMJDs7mzFjxrBt\n2zZGjRrF9u3b6devX70GZkl0Oj1nTmbg4qohuI0sBypEfUg0p0RzAjz1VBT33HOtT5SUlPDxx6tY\nteozHBzUTJo0gf79B5kauzCqU9MePHgwM2fOZOfOnZSXlzN//nzCw8OZNWsW69atIzAwkNGjR1e/\nIStx/kw2ZaU6OnVrVWG1JSFE7Uk0p0RzViUuLpbw8M64uRmvzImI6Ep09AkiI/vXaR/Yqjo1bTc3\nNz788MNKt3/88cf1HpAliv8jN1uuzRa2ZFPiZo5nxDToNrv7RzCm3QO3fIxEc0o0JxhP6a9b9yXe\n3t784x+zyM7OxsvLy3S/t3czsrOz6vT+2zJZEa0ahflaks/lEhDogbePdQWbCGGpJJqzaUdz3nff\nCDw9PWnfvgOff/4Ja9asoEuXrhUeY+YVti2WNO1qnI5NB+QoW9ieMe0eqPao+HaQaE6jphzN2bNn\nb9P9kZH9eeedtxg4cAjZ2dmm27OyMuncOaIG42ha5AvaW1AUhdMxaajVdrTtWLPZ8EKIW9u8+VsW\nLnzd9Af/+mjO8+fPsm/fbwwcOLRW27w+mjMi4g7T7ddHcwIcP36MDh06ERzcmvj4OIAqoznBODs8\nMzPDtK2r8ZLLlq28aR70rVQXzQlUGc0JVBnNOWiQcTGrm72f10dzAuzYsY0jRw6ZXvf6aE6ADRvW\nkph4psJ4EhLieeedBahUdlVGc8bGxqDT6dDpdMTFnSQsrEOVtd/43s2d+wKXLqUAcPz4UUJD29K5\ncxfi4+MoKCiguLiY6OgTpiN2cY0cad9CakoeebklhHUOwNFJ3iohGoJEc0o058MP/4V//3sOTk5O\nODs7M2fOv3F0dGLq1Cieey4KlUrFk09ONk1KE9dINOct7PohntMxaTw4tistQ7xv+jhbuXbQ2msA\n26jDFmoAqaO+JJqzMluoQ6I5b5PyMh1J8Rm4ezoR1Nqr+icIIcRtJtGcQpr2TSTFZ6IrN9ChS4CE\ngwghGp1Ec4qqyES0m4iPNuZmd4iQWeNCCCEsgxxp3yAns4gDP58lNSWPoNZeeHg5m3tIQgghBCBN\n26QwX8vhX89zOiYNRYEWrTzpf19Y9U8UQgghGkmTb9qlWh3HD1wk+kgKep0Bb18X7h7YhtZtfeS7\nbCGEEBalyTZtvc5A7LFLHN13gVKtDld3Db0iQ+kQ0Rw7O2nWQtxO1hTNuWnTJquP5ryeJURzpqen\n8cYbr6DX67C3V/PSS6/g4+PLgAF3mZZQBXj33eWVVpdr6mymaZeX6ynV6rC3V2Fvb4fdH/+/8WhZ\nURTOxGVw6JdzFORp0Tjac9eAUCJ6tsTBQX45hLjdJJpTojlXrVrOyJEPMWTIvabgkGnTZuDm5nbT\nD0/CyCaadqlWx/o1hynML610n52dytTA7exVKApoi8uxs1fRtVdLevRtjZOzQxVbFULcDhLNKdGc\nzz8/G41GA4CXlzcJCfF1ep+bIpto2od+OUdhfiktWnni7OKAXq9g0Buu+7+hwm3BnZvRq1+IzAwX\nTVrmV2spOHK4Qbfp3rMXfo+MveVjJJpTojmdnY1/e/V6PV9//RVPPDHJ9Lz58+eSnp7KgAGDGTt2\nfJ3ef1tm9U07IzWfk8cv4dnMmQf/0hV7tVx6LoSlk2jOph3NCcaG/eqrL9GjR09T6tczz8xg2LAR\nqFQqnnlmMt269aBjx05VPr+psuqmbTAo/LItAUWB/sPCpGELUQt+j4yt9qj4dpBoTqOmHM3p5+fP\nG2+8TKtWwTz55BTTY0ePvja5rWfPXiQlJUrTvoFVd7m445fJTCukfSf/WwZ6CCEsh0RzVtQUozm3\nb9+Kg4NDhdn9Fy+eZ/78uSiKgk6nIybmBKGhbWr8/jYVVnukXVxYysFfzqJxtKfv4LbmHo4QooYk\nmlOiOTdt+oqyslKiooxH2SEhbZg5czb+/gFMnvw4KpWKyMj+dOrUpUbba0qsNprzp+/iSIzLoN+w\n9nTpEdTAo6odW4mLs/YawDbqsIUaQOqoL4nmrMwW6miS0Zwp53NIjMvAr7k7nboFmns4QgjRKCSa\nU1hd09bp9Pyy7QwqFQy4P0xWLxNC2CSJ5hRVsbqJaL8fSCYvt4QuPYLwa16/0wxCCCGENbGqpp2X\nW8yx/RdwcdXQq1+ouYcjhBBCNCqradqKorB3+xn0eoW+Q9ri6GR1Z/aFEEKIerGapn32dCbJ53Jp\nGeJNu/DaXyMphBBCWDuraNplpTp+3ZGIvb2KfsPaS861EFZu48b1TJnyBFFRU5g8eQKHDx+s03aO\nHTtC//69ycrKNN2m1+sZOfI+Vq9eUaNtnD2baLpeuCqbNm1i2bIllW5fvXoFY8c+RFTUFNN/H3zw\n7k23U1RUyKFDB2o0ptqqzfuZmnqZiRMfq/Vr7N69A4ADB/b9ce14/Xz11VoGDLiL4uJi023bt29l\n0qQJTJ78OJs3f1Pv17BFVnGO+dDecxQXltHzntZ4NXOp/glCCIsl0ZwSzbl162ZycrIrLF5TUlLC\nxx+vYtWqz3BwUDNp0gT69x+Eh4dnvV/Pllh8085MKyD26CU8vZ3p3ifY3MMRQtSTRHNKNOeAAYNw\ncXHlp59+NN0WFxdLeHhn3NzcAGMASXT0CSIj+9dpH9gqi27ahfladv0Qj6JAv2HtUatvnrYjhKid\nfbuSOBufUf0Da6FNR/9qlxWWaE6J5nRxca30nmVnZ+Pl5WX62du7GdnZWXV6/22ZxTbttEt5bNt0\nkuKiMrr0CKJVaDNzD0kI0UAkmlOiOatj5hW2LZZFNu3TsWn8vPU0BoNC38FtuaNXS3O5Mvn9AAAI\nLUlEQVQPSQib03dwW7OE7Ug0p1FTj+a8ka+vL9nZ2aafs7Iy6dw5ogbjaFosava4waCwf3cSuzbH\nY6+2Y8Qjd9C1dyuZLS6EDZFozoqaYjRnVTp37kJ8fBwFBQUUFxcTHX3CdMQurrGYI+2yUh07vovj\nQlIOnt7ODP9zBN4+MlNcCFsj0ZwSzfnpp6s5fPggOTnZzJz5d7p0iWDatBlMnRrFc89FoVKpePLJ\nyaZJaeIai4jmzMstZuuGWHKzi2kZ4s2w0Z1wdHKo/skWwlbi4qy9BrCNOmyhBpA66kuiOSuzhTqs\nPpoz5Xwu2785SalWxx09W9JncJsKn5SFEEIYSTSnMGvTPvzbeX78OgaVSsXA4R0I71qzUytCCGHr\nJJpTVMWsTXvrphicXBy4/6HOtGjlVf0ThBBCiCbMrE3bv4U7w0Z3xt2zcZYcFEIIIayZWZv2hKf7\nUlRcas4hCCGEEFbDrDO+XFw15nx5IYQQwqrUq2lrtVqGDh3Kpk2bSE1N5bHHHmPcuHHMmDGDsrKy\nhhqjEEIIIahn016+fDmensbYtPfee49x48bx3//+l9atW7NhQ/3zVoUQQghxTZ2bdlJSEomJiQwc\nOBCAgwcPMmSIcYWeQYMGsX///gYZoBBCCCGM6ty0FyxYwOzZs00/l5SUoNEYv6P28fEhMzOz/qMT\nQgghhEmdZo9/8803dOvWjVatWlV5f21WRq3vkm6WwhbqsIUawDbqsIUaQOqwJLZQA9hOHXVVp6a9\nZ88ekpOT2bNnD2lpaWg0GlxcXNBqtTg5OZGeno6/f+1TcIQQQghxc/UODFm6dClBQUEcP36cnj17\nMmrUKF577TU6dOjAI4880lDjFEIIIZq8BrtOe/r06XzzzTeMGzeOK1euMHr06IbatBBCCCGwgGhO\nIYQQQtSMZGAKIYQQVkKathBCCGElGi0w5ODBg8yYMYP27dsDEBYWxqRJk/jnP/+JXq/Hz8+PRYsW\nma71tjQJCQlMmzaNJ554gvHjx5Oamlrl2L/77js+/fRT7OzsePTRRy1uMt6NdcyePZuTJ0/i5WWM\nRp04cSIDBw606DoWLlzI0aNH0el0PPXUU0RERFjlvrixjl27dlnVvigpKWH27NlkZ2dTWlrKtGnT\n6Nixo9Xti6rq2LZtm1Xti6u0Wi0PPPAA06ZNo0+fPla3L666vo5Dhw5Z1b6oTa+rUw1KIzlw4IAy\nffr0CrfNnj1b2bJli6IoivLOO+8oX375ZWMNp1aKioqU8ePHK/PmzVM+//xzRVGqHntRUZEybNgw\nJT8/XykpKVH+9Kc/Kbm5ueYcegVV1TFr1ixl165dlR5nqXXs379fmTRpkqIoipKTk6MMGDDAKvdF\nVXVY27744YcflJUrVyqKoigpKSnKsGHDrHJfVFWHte2LqxYvXqyMGTNG2bhxo1Xui6uur8Pa9kVN\ne11dazDr6XFrWfpUo9GwatWqCteeVzX2EydOEBERgbu7O05OTvTo0YNjx46Za9iVVFVHVSy5jl69\nevHuu+8C4OHhQUlJiVXui6rq0Ov1lR5nyXWMGDGCyZMnA5CamkpAQIBV7ouq6qiKpddRk6WlLb0G\nqFxHVayhjus15L5o1KadmJjI1KlT+etf/8pvv/1mNUufqtVqnJycKtxW1dizsrJo1qyZ6THNmjWz\nqJqqqgPgiy++YMKECfzjH/8gJyfHouuwt7fHxcUFgA0bNtC/f3+r3BdV1WFvb29V++KqsWPHMnPm\nTObMmWOV++Kq6+sA6/p3ATVbWtrSa4DKdYD17Yua9Lq61tBo32mHhIQQFRXF8OHDSU5OZsKECRWO\nLBQrvvLsZmO3hppGjRqFl5cX4eHhrFy5kmXLltG9e/cKj7HEOnbs2MGGDRtYs2YNw4YNM91ubfvi\n+jpiY2Otcl+sXbuWU6dO8cILL1QYn7Xti+vrmDNnjlXti7ouLW1JNUDVdVjb36i69rqa1tBoR9oB\nAQGMGDEClUpFcHAwvr6+5OXlodVqAaxu6dOry7bCtbH7+/uTlZVlekxGRobF19SnTx/Cw8MBGDx4\nMAkJCRZfx969e/nwww9ZtWoV7u7uVrsvbqzD2vZFbGwsqampAISHh6PX63F1dbW6fVFVHWFhYVa1\nL/bs2cPOnTt59NFH+eqrr/jggw+s8t9FVXUoimJV+6Kmva6uNTRa0/7uu+9YvXo1AJmZmWRnZzNm\nzBi2bdsGwPbt2+nXr19jDafe+vbtW2nsXbt2JSYmhvz8fIqKijh27Bg9e/Y080hvbfr06SQnJwPG\n713at29v0XUUFBSwcOFCVqxYYZpNao37oqo6rG1fHDlyhDVr1gCQlZVFcXGxVe6Lqup46aWXrGpf\nLFmyhI0bN7J+/XoeeeQRpk2bZpX7oqo6/ve//1nVvqhpr6trDY22IlphYSEzZ84kPz+f8vJyoqKi\nCA8PZ9asWZSWlhIYGMibb76Jg4NDYwynVmJjY1mwYAGXLl1CrVYTEBDA22+/zezZsyuN/ccff2T1\n6tWoVCrGjx/PyJEjzT18k6rqGD9+PCtXrsTZ2RkXFxfefPNNfHx8LLaOdevWsXTpUkJDQ023vfXW\nW8ybN8+q9kVVdYwZM4YvvvjCavaFVqtl7ty5pKamotVqiYqKokuXLlX+m7bUGqDqOlxcXFi0aJHV\n7IvrXc2DiIyMtLp9cb2rdQQGBlrVvqhNr6tLDbKMqRBCCGElZEU0IYQQwkpI0xZCCCGshDRtIYQQ\nwkpI0xZCCCGshDRtIYQQwkpI0xZCCCGshDRtIYQQwkpI0xZCCCGsxP8Doi7+sn3s50cAAAAASUVO\nRK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fce083d1be0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFOCAYAAACrPEW7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhEpI0hZCCCFU4v8BNV7iguxpY7QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fce07cedd30>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ny0_f1nyOi3H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "outputId": "9cb42b48-64d3-406b-a8c0-1e6ef9d94d86"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print('So which is the best sample selection function? margin sampling is the winner!')\n",
        "performance_plot(random_forest_upper_bound, d, ['RfModel'], selection_functions_str    , Ks_str, 1)\n",
        "print()\n",
        "print('So which is the best k? k=10 is the winner')\n",
        "performance_plot(random_forest_upper_bound, d, ['RfModel'] , ['MarginSamplingSelection'], Ks_str, 1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "So which is the best sample selection function? margin sampling is the winner!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFOCAYAAACrPEW7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKlIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fce07dba668>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "So which is the best k? k=10 is the winner\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFOCAYAAACrPEW7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fce0870d048>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "z82imfIIPoJd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I would like to thank Moshe Hadad for his valueable critique regarding PEP8 and Shay Zweig for his proof-reading and comments.\n",
        "\n",
        "Ori Cohen has done his PhD in computer science in the fields of machine learning, brain-computer-interface and neurobiology.\n",
        "\n",
        "[1] Shay Yehezkel, *High Dimensional Statistical Process Control and Application*, M.Sc Thesis.\n",
        "\n",
        "[2] Ilhan, Hamza Osman, and Mehmet Fatih Amasyali. \"[*Active Learning as a Way of Increasing Accuracy*](http://www.ijcte.org/papers/910-AC0013.pdf).\" International Journal of Computer Theory and Engineering 6, no. 6 (2014): 460.\n",
        "\n",
        "[3] Stefan Hosein [*Active Learning: Curious AI Algorithms*](https://www.datacamp.com/community/tutorials/active-learning)\n"
      ]
    },
    {
      "metadata": {
        "id": "HiRcnlZVUpRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787655
        },
        "collapsed": true,
        "outputId": "07204bd8-e187-4f70-b6d4-337e91dccf43"
      },
      "cell_type": "code",
      "source": [
        "#@title Executed code for the experiment with output.\n",
        "#!/usr/bin/python\n",
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "from scipy import stats\n",
        "from pylab import rcParams\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.datasets import fetch_mldata\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, \\\n",
        "    GradientBoostingClassifier\n",
        "\n",
        "trainset_size = 60000  # ie., testset_size = 10000\n",
        "max_queried = 500\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "def download():\n",
        "    mnist = fetch_mldata('MNIST original')\n",
        "    X = mnist.data.astype('float64')\n",
        "    y = mnist.target\n",
        "    print ('MNIST:', X.shape, y.shape)\n",
        "    return (X, y)\n",
        "\n",
        "\n",
        "def split(train_size):\n",
        "    X_train_full = X[:train_size]\n",
        "    y_train_full = y[:train_size]\n",
        "    X_test = X[train_size:]\n",
        "    y_test = y[train_size:]\n",
        "    return (X_train_full, y_train_full, X_test, y_test)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "class BaseModel(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit_predict(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class SvmModel(BaseModel):\n",
        "\n",
        "    model_type = 'Support Vector Machine with linear Kernel'\n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training svm...')\n",
        "        self.classifier = SVC(C=1, kernel='linear', probability=True,\n",
        "                              class_weight=c_weight)\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "\n",
        "class GmmModel(BaseModel):\n",
        "\n",
        "    model_type = 'Gaussian Mixture Model'\n",
        "    \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training gaussian mixture model...')\n",
        "        pca = PCA(n_components=75).fit(X_train)  # ,whiten=True).fit(X_train)\n",
        "        reduced_train_data = pca.transform(X_train)\n",
        "        reduced_test_data = pca.transform(X_test)\n",
        "        reduced_val_data = pca.transform(X_val)\n",
        "        print ('PCA: explained_variance_ratio_',\n",
        "               np.sum(pca.explained_variance_ratio_))\n",
        "        self.classifier = GaussianMixture(n_components=10, covariance_type='full')\n",
        "        self.classifier.fit(reduced_train_data)\n",
        "        self.test_y_predicted = \\\n",
        "            self.classifier.predict(reduced_test_data)\n",
        "        self.val_y_predicted = self.classifier.predict(reduced_val_data)\n",
        "        return (reduced_train_data, reduced_val_data,\n",
        "                reduced_test_data, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "\n",
        "class LogModel(BaseModel):\n",
        "\n",
        "    model_type = 'Multinominal Logistic Regression' \n",
        "    \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training multinomial logistic regression')\n",
        "        train_samples = X_train.shape[0]\n",
        "        self.classifier = LogisticRegression(\n",
        "            C=50. / train_samples,\n",
        "            multi_class='multinomial',\n",
        "            penalty='l1',\n",
        "            solver='saga',\n",
        "            tol=0.1,\n",
        "            class_weight=c_weight,\n",
        "            )\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "\n",
        "class GbcModel(BaseModel):\n",
        "\n",
        "    model_type = 'Gradient Boosting Classifier'\n",
        "    \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training gradient boosting...')\n",
        "        parm = {\n",
        "            'n_estimators': 1200,\n",
        "            'max_depth': 3,\n",
        "            'subsample': 0.5,\n",
        "            'learning_rate': 0.01,\n",
        "            'min_samples_leaf': 1,\n",
        "            'random_state': 3,\n",
        "            }\n",
        "        self.classifier = GradientBoostingClassifier(**parm)\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted,\n",
        "                self.test_y_predicted)\n",
        "\n",
        "\n",
        "class RfModel(BaseModel):\n",
        "\n",
        "    model_type = 'Random Forest'\n",
        "    \n",
        "    def fit_predict(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('training random forest...')\n",
        "        self.classifier = RandomForestClassifier(n_estimators=500, class_weight=c_weight)\n",
        "        self.classifier.fit(X_train, y_train)\n",
        "        self.test_y_predicted = self.classifier.predict(X_test)\n",
        "        self.val_y_predicted = self.classifier.predict(X_val)\n",
        "        return (X_train, X_val, X_test, self.val_y_predicted, self.test_y_predicted)\n",
        "\n",
        "\n",
        "# ====================================================================================================\n",
        "\n",
        "class TrainModel:\n",
        "\n",
        "    def __init__(self, model_object):        \n",
        "        self.accuracies = []\n",
        "        self.model_object = model_object()        \n",
        "\n",
        "    def print_model_type(self):\n",
        "        print (self.model_object.model_type)\n",
        "\n",
        "    # we train normally and get probabilities for the validation set. i.e., we use the probabilities to select the most uncertain samples\n",
        "\n",
        "    def train(self, X_train, y_train, X_val, X_test, c_weight):\n",
        "        print ('Train set:', X_train.shape, 'y:', y_train.shape)\n",
        "        print ('Val   set:', X_val.shape)\n",
        "        print ('Test  set:', X_test.shape)\n",
        "        t0 = time.time()\n",
        "        (X_train, X_val, X_test, self.val_y_predicted,\n",
        "         self.test_y_predicted) = \\\n",
        "            self.model_object.fit_predict(X_train, y_train, X_val, X_test, c_weight)\n",
        "        self.run_time = time.time() - t0\n",
        "        return (X_train, X_val, X_test)  # we return them in case we use PCA, with all the other algorithms, this is not needed.\n",
        "\n",
        "    # we want accuracy only for the test set\n",
        "\n",
        "    def get_test_accuracy(self, i, y_test):\n",
        "        classif_rate = np.mean(self.test_y_predicted.ravel() == y_test.ravel()) * 100\n",
        "        self.accuracies.append(classif_rate)               \n",
        "        print('--------------------------------')\n",
        "        print('Iteration:',i)\n",
        "        print('--------------------------------')\n",
        "        print('y-test set:',y_test.shape)\n",
        "        print('Example run in %.3f s' % self.run_time,'\\n')\n",
        "        print(\"Accuracy rate for %f \" % (classif_rate))    \n",
        "        print(\"Classification report for classifier %s:\\n%s\\n\" % (self.model_object.classifier, metrics.classification_report(y_test, self.test_y_predicted)))\n",
        "        print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, self.test_y_predicted))\n",
        "        print('--------------------------------')\n",
        "\n",
        "\n",
        "# ====================================================================================================\n",
        "\n",
        "def get_k_random_samples(initial_labeled_samples, X_train_full,\n",
        "                         y_train_full):\n",
        "    random_state = check_random_state(0)\n",
        "    permutation = np.random.choice(trainset_size,\n",
        "                                   initial_labeled_samples,\n",
        "                                   replace=False)\n",
        "    print ()\n",
        "    print ('initial random chosen samples', permutation.shape),\n",
        "#            permutation)\n",
        "    X_train = X_train_full[permutation]\n",
        "    y_train = y_train_full[permutation]\n",
        "    X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "    bin_count = np.bincount(y_train.astype('int64'))\n",
        "    unique = np.unique(y_train.astype('int64'))\n",
        "    print (\n",
        "        'initial train set:',\n",
        "        X_train.shape,\n",
        "        y_train.shape,\n",
        "        'unique(labels):',\n",
        "        bin_count,\n",
        "        unique,\n",
        "        )\n",
        "    return (permutation, X_train, y_train)\n",
        "\n",
        "\n",
        "# ====================================================================================================\n",
        "\n",
        "class BaseSelectionFunction(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def select(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class RandomSelection(BaseSelectionFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        random_state = check_random_state(0)\n",
        "        selection = np.random.choice(probas_val.shape[0], initial_labeled_samples, replace=False)\n",
        "\n",
        "#     print('uniques chosen:',np.unique(selection).shape[0],'<= should be equal to:',initial_labeled_samples)\n",
        "\n",
        "        return selection\n",
        "\n",
        "\n",
        "class MinStdSelection(BaseSelectionFunction):\n",
        "\n",
        "    # select the samples where the std is smallest - i.e., there is uncertainty regarding the relevant class\n",
        "    # and then train on these \"hard\" to classify samples.\n",
        "\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        std = np.std(probas_val * 100, axis=1)\n",
        "        selection = std.argsort()[:initial_labeled_samples]\n",
        "        selection = selection.astype('int64')\n",
        "\n",
        "#     print('std',std.shape,std)\n",
        "#     print()\n",
        "#     print('selection',selection, selection.shape, std[selection])\n",
        "\n",
        "        return selection\n",
        "\n",
        "\n",
        "class MarginSamplingSelection(BaseSelectionFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        rev = np.sort(probas_val, axis=1)[:, ::-1]\n",
        "        values = rev[:, 0] - rev[:, 1]\n",
        "        selection = np.argsort(values)[:initial_labeled_samples]\n",
        "        return selection\n",
        "\n",
        "\n",
        "class EntropySelection(BaseSelectionFunction):\n",
        "\n",
        "    @staticmethod\n",
        "    def select(probas_val, initial_labeled_samples):\n",
        "        e = (-probas_val * np.log2(probas_val)).sum(axis=1)\n",
        "        selection = (np.argsort(e)[::-1])[:initial_labeled_samples]\n",
        "        return selection\n",
        "\n",
        "\n",
        "# ====================================================================================================\n",
        "\n",
        "class Normalize(object):\n",
        "    \n",
        "    def normalize(self, X_train, X_val, X_test):\n",
        "        self.scaler = MinMaxScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_val   = self.scaler.transform(X_val)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_val, X_test) \n",
        "    \n",
        "    def inverse(self, X_train, X_val, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_val   = self.scaler.inverse_transform(X_val)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_val, X_test) \n",
        "\n",
        "      \n",
        "# ====================================================================================================\n",
        "\n",
        "class TheAlgorithm(object):\n",
        "\n",
        "    accuracies = []\n",
        "\n",
        "    def __init__(self, initial_labeled_samples, model_object, selection_function):\n",
        "        self.initial_labeled_samples = initial_labeled_samples\n",
        "        self.model_object = model_object\n",
        "        self.sample_selection_function = selection_function\n",
        "\n",
        "    def run(self, X_train_full, y_train_full, X_test, y_test):\n",
        "\n",
        "        # initialize process by applying base learner to labeled training data set to obtain Classifier\n",
        "\n",
        "        (permutation, X_train, y_train) = \\\n",
        "            get_k_random_samples(self.initial_labeled_samples,\n",
        "                                 X_train_full, y_train_full)\n",
        "        self.queried = self.initial_labeled_samples\n",
        "        self.samplecount = [self.initial_labeled_samples]\n",
        "\n",
        "        # permutation, X_train, y_train = get_equally_k_random_samples(self.initial_labeled_samples,classes)\n",
        "\n",
        "        # assign the val set the rest of the 'unlabelled' training data\n",
        "\n",
        "        X_val = np.array([])\n",
        "        y_val = np.array([])\n",
        "        X_val = np.copy(X_train_full)\n",
        "        X_val = np.delete(X_val, permutation, axis=0)\n",
        "        y_val = np.copy(y_train_full)\n",
        "        y_val = np.delete(y_val, permutation, axis=0)\n",
        "        print ('val set:', X_val.shape, y_val.shape, permutation.shape)\n",
        "        print ()\n",
        "\n",
        "        # normalize data\n",
        "\n",
        "        normalizer = Normalize()\n",
        "        X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)   \n",
        "        \n",
        "        self.clf_model = TrainModel(self.model_object)\n",
        "        (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "        active_iteration = 1\n",
        "        self.clf_model.get_test_accuracy(1, y_test)\n",
        "\n",
        "        # fpfn = self.clf_model.test_y_predicted.ravel() != y_val.ravel()\n",
        "        # print(fpfn)\n",
        "        # self.fpfncount = []\n",
        "        # self.fpfncount.append(fpfn.sum() / y_test.shape[0] * 100)\n",
        "\n",
        "        while self.queried < max_queried:\n",
        "\n",
        "            active_iteration += 1\n",
        "\n",
        "            # get validation probabilities\n",
        "\n",
        "            probas_val = \\\n",
        "                self.clf_model.model_object.classifier.predict_proba(X_val)\n",
        "            print ('val predicted:',\n",
        "                   self.clf_model.val_y_predicted.shape,\n",
        "                   self.clf_model.val_y_predicted)\n",
        "            print ('probabilities:', probas_val.shape, '\\n',\n",
        "                   np.argmax(probas_val, axis=1))\n",
        "\n",
        "            # select samples using a selection function\n",
        "\n",
        "            uncertain_samples = \\\n",
        "                self.sample_selection_function.select(probas_val, self.initial_labeled_samples)\n",
        "\n",
        "            # normalization needs to be inversed and recalculated based on the new train and test set.\n",
        " \n",
        "            X_train, X_val, X_test = normalizer.inverse(X_train, X_val, X_test)   \n",
        "\n",
        "            # get the uncertain samples from the validation set\n",
        "\n",
        "            print ('trainset before', X_train.shape, y_train.shape)\n",
        "            X_train = np.concatenate((X_train, X_val[uncertain_samples]))\n",
        "            y_train = np.concatenate((y_train, y_val[uncertain_samples]))\n",
        "            print ('trainset after', X_train.shape, y_train.shape)\n",
        "            self.samplecount.append(X_train.shape[0])\n",
        "\n",
        "            bin_count = np.bincount(y_train.astype('int64'))\n",
        "            unique = np.unique(y_train.astype('int64'))\n",
        "            print (\n",
        "                'updated train set:',\n",
        "                X_train.shape,\n",
        "                y_train.shape,\n",
        "                'unique(labels):',\n",
        "                bin_count,\n",
        "                unique,\n",
        "                )\n",
        "\n",
        "            X_val = np.delete(X_val, uncertain_samples, axis=0)\n",
        "            y_val = np.delete(y_val, uncertain_samples, axis=0)\n",
        "            print ('val set:', X_val.shape, y_val.shape)\n",
        "            print ()\n",
        "\n",
        "            # normalize again after creating the 'new' train/test sets\n",
        "            normalizer = Normalize()\n",
        "            X_train, X_val, X_test = normalizer.normalize(X_train, X_val, X_test)               \n",
        "\n",
        "            self.queried += self.initial_labeled_samples\n",
        "            (X_train, X_val, X_test) = self.clf_model.train(X_train, y_train, X_val, X_test, 'balanced')\n",
        "            self.clf_model.get_test_accuracy(active_iteration, y_test)\n",
        "\n",
        "        print ('final active learning accuracies',\n",
        "               self.clf_model.accuracies)\n",
        "\n",
        "\n",
        "# get MNIST\n",
        "\n",
        "(X, y) = download()\n",
        "(X_train_full, y_train_full, X_test, y_test) = split(trainset_size)\n",
        "print ('train:', X_train_full.shape, y_train_full.shape)\n",
        "print ('test :', X_test.shape, y_test.shape)\n",
        "classes = len(np.unique(y))\n",
        "print ('unique classes', classes)\n",
        "\n",
        "def pickle_save(fname, data):\n",
        "  filehandler = open(fname,\"wb\")\n",
        "  pickle.dump(data,filehandler)\n",
        "  filehandler.close() \n",
        "  print('saved', fname, os.getcwd(), os.listdir())\n",
        "\n",
        "def experiment(d, models, selection_functions, Ks, repeats, contfrom):\n",
        "    algos_temp = []\n",
        "    print ('stopping at:', max_queried)\n",
        "    count = 0\n",
        "    for model_object in models:\n",
        "      if model_object.__name__ not in d:\n",
        "          d[model_object.__name__] = {}\n",
        "      \n",
        "      for selection_function in selection_functions:\n",
        "        if selection_function.__name__ not in d[model_object.__name__]:\n",
        "            d[model_object.__name__][selection_function.__name__] = {}\n",
        "        \n",
        "        for k in Ks:\n",
        "            d[model_object.__name__][selection_function.__name__][k] = []           \n",
        "            \n",
        "            for i in range(0, repeats):\n",
        "                count+=1\n",
        "                if count >= contfrom:\n",
        "                    print ('Count = %s, using model = %s, selection_function = %s, k = %s, iteration = %s.' % (count, model_object.__name__, selection_function.__name__, k, i))\n",
        "                    alg = TheAlgorithm(k, \n",
        "                                       model_object, \n",
        "                                       selection_function\n",
        "                                       )\n",
        "                    alg.run(X_train_full, y_train_full, X_test, y_test)\n",
        "                    d[model_object.__name__][selection_function.__name__][k].append(alg.clf_model.accuracies)\n",
        "                    fname = 'Active-learning-experiment-' + str(count) + '.pkl'\n",
        "                    pickle_save(fname, d)\n",
        "                    if count % 5 == 0:\n",
        "                        print(json.dumps(d, indent=2, sort_keys=True))\n",
        "                    print ()\n",
        "                    print ('---------------------------- FINISHED ---------------------------')\n",
        "                    print ()\n",
        "    return d\n",
        "\n",
        "max_queried = 500\n",
        "# max_queried = 20\n",
        "\n",
        "repeats = 1\n",
        "\n",
        "models = [SvmModel, RfModel, LogModel]#, GbcModel]\n",
        "# models = [RfModel, SvmModel]\n",
        "\n",
        "selection_functions = [RandomSelection, MarginSamplingSelection, EntropySelection]#, MinStdSelection]\n",
        "# selection_functions = [MarginSamplingSelection]\n",
        "\n",
        "Ks = [250,125,50,25,10]\n",
        "# Ks = [10]\n",
        "\n",
        "d = {}\n",
        "stopped_at = -1\n",
        "\n",
        "# stopped_at = 73\n",
        "# d = pickle_load('Active-learning-experiment-'+ str(stopped_at) +'.pkl')  \n",
        "# print(json.dumps(d, indent=2, sort_keys=True))\n",
        "\n",
        "d = experiment(d, models, selection_functions, Ks, repeats, stopped_at+1)\n",
        "print(json.dumps(d, indent=2, sort_keys=True))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST: (70000, 784) (70000,)\n",
            "train: (60000, 784) (60000,)\n",
            "test : (10000, 784) (10000,)\n",
            "unique classes 10\n",
            "stopping at: 500\n",
            "Count = 1, using model = SvmModel, selection_function = RandomSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [19 32 26 20 25 27 21 27 29 24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.474 s \n",
            "\n",
            "Accuracy rate for 83.020000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.94      0.93       980\n",
            "        1.0       0.86      0.99      0.92      1135\n",
            "        2.0       0.86      0.82      0.84      1032\n",
            "        3.0       0.85      0.78      0.81      1010\n",
            "        4.0       0.80      0.80      0.80       982\n",
            "        5.0       0.75      0.79      0.77       892\n",
            "        6.0       0.89      0.89      0.89       958\n",
            "        7.0       0.75      0.82      0.79      1028\n",
            "        8.0       0.86      0.76      0.81       974\n",
            "        9.0       0.76      0.70      0.73      1009\n",
            "\n",
            "avg / total       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 925    0    0    4    0   24   18    3    5    1]\n",
            " [   0 1121    3    3    0    2    4    0    2    0]\n",
            " [  32   23  843   33   10   21   29   27   11    3]\n",
            " [   5   17   20  789    1   96    7   26   33   16]\n",
            " [   2   14    5    1  781    0   17   65   12   85]\n",
            " [  10   27    6   54   16  703   19    8   28   21]\n",
            " [  16    6   24    2   16   29  855    1    9    0]\n",
            " [   6   45   37    1   21    2    0  846    3   67]\n",
            " [   9   38   35   38   17   50    6   14  737   30]\n",
            " [   8   12    8    3  110   12    3  137   14  702]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [45 53 50 45 50 55 45 45 58 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.580 s \n",
            "\n",
            "Accuracy rate for 85.640000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.96      0.95       980\n",
            "        1.0       0.85      0.99      0.92      1135\n",
            "        2.0       0.83      0.86      0.84      1032\n",
            "        3.0       0.86      0.80      0.83      1010\n",
            "        4.0       0.85      0.83      0.84       982\n",
            "        5.0       0.82      0.82      0.82       892\n",
            "        6.0       0.91      0.90      0.91       958\n",
            "        7.0       0.82      0.81      0.81      1028\n",
            "        8.0       0.90      0.80      0.84       974\n",
            "        9.0       0.79      0.79      0.79      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    0    5    3    0   12   13    3    1    3]\n",
            " [   0 1123    4    3    0    1    3    0    1    0]\n",
            " [  17   16  883   38   12    5   30   13   11    7]\n",
            " [   9   13   21  808    2   83    5   20   33   16]\n",
            " [   1   23    7    0  818    0   10   27    7   89]\n",
            " [   8   33   11   40   13  729   16    4   16   22]\n",
            " [  13    6   29    1   20   20  863    3    3    0]\n",
            " [   0   44   58    1   30    2    0  828    5   60]\n",
            " [   9   36   30   45   10   33    7   15  777   12]\n",
            " [  11   20   11    5   54    4    0   96   13  795]]\n",
            "--------------------------------\n",
            "final active learning accuracies [83.02000000000001, 85.64]\n",
            "saved Active-learning-experiment-1.pkl /content ['datalab', '.forever', 'Active-learning-experiment-1.pkl', '.ipython', '.cache', '.config', 'scikit_learn_data', '.rnd', '.local']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 2, using model = SvmModel, selection_function = RandomSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [13 11 19  7 10 10 14 16 11 14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.370 s \n",
            "\n",
            "Accuracy rate for 73.760000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.85      0.86       980\n",
            "        1.0       0.86      0.97      0.91      1135\n",
            "        2.0       0.81      0.76      0.79      1032\n",
            "        3.0       0.83      0.63      0.72      1010\n",
            "        4.0       0.65      0.41      0.50       982\n",
            "        5.0       0.62      0.55      0.58       892\n",
            "        6.0       0.71      0.92      0.80       958\n",
            "        7.0       0.79      0.83      0.81      1028\n",
            "        8.0       0.70      0.61      0.65       974\n",
            "        9.0       0.55      0.80      0.65      1009\n",
            "\n",
            "avg / total       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 835    2   20    1    0   42   72    7    0    1]\n",
            " [   0 1096    1    0    1    2    4    1   30    0]\n",
            " [   8   50  786   12    1    6   55   45   61    8]\n",
            " [  15   26   34  638    6   89   55   43   87   17]\n",
            " [   1   10   52    0  400   30   26   22    0  441]\n",
            " [  41   24    2   85   20  489  101   20   67   43]\n",
            " [  15    6   19    0   19   10  884    0    3    2]\n",
            " [   1   26   15    1   26    8    1  850    5   95]\n",
            " [  33   23   20   31   47   98   43   32  592   55]\n",
            " [  13    8   17    4   91   16    2   50    2  806]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59875, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [26 22 31 21 28 22 23 28 22 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.915 s \n",
            "\n",
            "Accuracy rate for 83.520000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.93      0.91       980\n",
            "        1.0       0.88      0.96      0.92      1135\n",
            "        2.0       0.86      0.77      0.81      1032\n",
            "        3.0       0.77      0.81      0.79      1010\n",
            "        4.0       0.81      0.89      0.85       982\n",
            "        5.0       0.77      0.72      0.75       892\n",
            "        6.0       0.84      0.92      0.88       958\n",
            "        7.0       0.87      0.86      0.86      1028\n",
            "        8.0       0.82      0.70      0.75       974\n",
            "        9.0       0.84      0.77      0.80      1009\n",
            "\n",
            "avg / total       0.83      0.84      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 914    2   12    2    0   19   28    3    0    0]\n",
            " [   0 1094    0    4    0    4    1    0   32    0]\n",
            " [  17   50  792   27   14   14   50   25   38    5]\n",
            " [  11   13   39  818    0   33   21   17   49    9]\n",
            " [   4    4   14    1  874   11    9    6    4   55]\n",
            " [  26   17    0  132   16  646   31    7   12    5]\n",
            " [  24    5    8    3   17   23  878    0    0    0]\n",
            " [   1   29   23    9   27    4    0  881    7   47]\n",
            " [  18   18   22   61   26   79   24   24  677   25]\n",
            " [  15   10   16   12  107    6    4   54    7  778]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [38 39 41 38 40 35 32 42 31 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 17.917 s \n",
            "\n",
            "Accuracy rate for 85.600000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.97      0.94       980\n",
            "        1.0       0.90      0.97      0.93      1135\n",
            "        2.0       0.84      0.84      0.84      1032\n",
            "        3.0       0.80      0.86      0.83      1010\n",
            "        4.0       0.79      0.92      0.85       982\n",
            "        5.0       0.82      0.75      0.79       892\n",
            "        6.0       0.89      0.91      0.90       958\n",
            "        7.0       0.89      0.84      0.86      1028\n",
            "        8.0       0.86      0.70      0.77       974\n",
            "        9.0       0.86      0.77      0.81      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 950    1    7    3    0    9    8    2    0    0]\n",
            " [   0 1104    1    5    1    2    1    0   21    0]\n",
            " [  17   28  867   11   19   10   22   22   30    6]\n",
            " [   4    9   44  870    2   19   14   12   30    6]\n",
            " [   3    5   12    1  901    6    8    7    3   36]\n",
            " [  16   21    7  120   10  670   19    8   14    7]\n",
            " [  22    7   14    1   21   19  874    0    0    0]\n",
            " [   2   26   31    9   27    5    0  868    6   54]\n",
            " [  20   21   33   61   27   64   31   22  683   12]\n",
            " [  14    9   16   12  133   10    0   39    3  773]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59625,) [0. 0. 0. ... 7. 9. 9.]\n",
            "probabilities: (59625, 10) \n",
            " [0 0 0 ... 7 9 9]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [50 51 48 50 52 44 50 55 44 56] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 22.355 s \n",
            "\n",
            "Accuracy rate for 86.440000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.96      0.94       980\n",
            "        1.0       0.90      0.98      0.94      1135\n",
            "        2.0       0.84      0.85      0.85      1032\n",
            "        3.0       0.78      0.87      0.82      1010\n",
            "        4.0       0.83      0.90      0.86       982\n",
            "        5.0       0.84      0.74      0.79       892\n",
            "        6.0       0.90      0.93      0.91       958\n",
            "        7.0       0.91      0.84      0.87      1028\n",
            "        8.0       0.89      0.72      0.80       974\n",
            "        9.0       0.84      0.82      0.83      1009\n",
            "\n",
            "avg / total       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    1    5    4    0   14   13    1    0    0]\n",
            " [   0 1115    1    5    1    2    1    0   10    0]\n",
            " [  19   28  877   14   16    5   20   15   30    8]\n",
            " [   8   10   41  877    4   18    8   12   26    6]\n",
            " [   3    4   10    1  881    4   10    7    1   61]\n",
            " [  14   19   11  129   11  664   22   11    6    5]\n",
            " [   9    8    9    2   12   26  892    0    0    0]\n",
            " [   1   25   36    4   23    3    0  862    5   69]\n",
            " [  16   19   33   79   15   52   27   17  704   12]\n",
            " [   6    8   20   16   96    4    1   20    8  830]]\n",
            "--------------------------------\n",
            "final active learning accuracies [73.76, 83.52000000000001, 85.6, 86.44]\n",
            "saved Active-learning-experiment-2.pkl /content ['datalab', '.forever', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-1.pkl', '.ipython', '.cache', '.config', 'scikit_learn_data', '.rnd', '.local']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 3, using model = SvmModel, selection_function = RandomSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [8 6 3 0 6 6 7 3 8 3] [0 1 2 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 3.216 s \n",
            "\n",
            "Accuracy rate for 56.390000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.84      0.83       980\n",
            "        1.0       0.70      0.52      0.60      1135\n",
            "        2.0       0.74      0.51      0.60      1032\n",
            "        3.0       0.00      0.00      0.00      1010\n",
            "        4.0       0.47      0.80      0.59       982\n",
            "        5.0       0.28      0.60      0.39       892\n",
            "        6.0       0.77      0.87      0.82       958\n",
            "        7.0       0.94      0.60      0.73      1028\n",
            "        8.0       0.40      0.78      0.53       974\n",
            "        9.0       0.63      0.16      0.26      1009\n",
            "\n",
            "avg / total       0.58      0.56      0.54     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[819   0  45   0   2  95  11   1   7   0]\n",
            " [  0 594   0   0   1 470  32   0  38   0]\n",
            " [ 46  78 523   0  33  75  79   9 182   7]\n",
            " [ 37   1  98   0   9 319  36  10 499   1]\n",
            " [  1  10   8   0 783  71  17   0  33  59]\n",
            " [ 30   4  18   0  27 536  38   6 225   8]\n",
            " [ 15   3   1   0  15  71 838   0  14   1]\n",
            " [  8 140   9   0 113  59   3 621  61  14]\n",
            " [ 25   7   1   0  25 118  26   4 759   9]\n",
            " [ 21   8   3   0 650  74   3  12  72 166]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59950,) [0. 0. 0. ... 4. 5. 5.]\n",
            "probabilities: (59950, 9) \n",
            " [0 0 0 ... 3 4 4]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [14  8  8  4 10 11 10 10 14 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.167 s \n",
            "\n",
            "Accuracy rate for 72.930000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.93      0.90       980\n",
            "        1.0       0.83      0.70      0.76      1135\n",
            "        2.0       0.87      0.69      0.77      1032\n",
            "        3.0       0.84      0.40      0.54      1010\n",
            "        4.0       0.87      0.58      0.69       982\n",
            "        5.0       0.39      0.77      0.52       892\n",
            "        6.0       0.87      0.89      0.88       958\n",
            "        7.0       0.93      0.79      0.86      1028\n",
            "        8.0       0.68      0.75      0.71       974\n",
            "        9.0       0.61      0.82      0.70      1009\n",
            "\n",
            "avg / total       0.78      0.73      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[907   0   3  10   3  32  14   1   8   2]\n",
            " [  0 792   2   1   0 322   5   1  12   0]\n",
            " [ 40  67 710   2   6  49  39  17  88  14]\n",
            " [ 12   1  45 408   2 325  22   9 168  18]\n",
            " [  4  10   6   0 566  48  13   1   5 329]\n",
            " [ 16  10   3  36   7 689  26   8  24  73]\n",
            " [ 27   3   9   0  11  56 848   1   2   1]\n",
            " [  3  49  28  11   3  43   1 817  12  61]\n",
            " [ 17   9   2  12  19 129  12   6 729  39]\n",
            " [ 13  11   6   8  36  56   0  20  32 827]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 0. ... 9. 9. 5.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 8 ... 9 9 5]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [19 18 12 12 11 13 17 11 20 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.637 s \n",
            "\n",
            "Accuracy rate for 78.440000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.92      0.91       980\n",
            "        1.0       0.77      0.98      0.86      1135\n",
            "        2.0       0.89      0.67      0.77      1032\n",
            "        3.0       0.72      0.73      0.72      1010\n",
            "        4.0       0.91      0.57      0.70       982\n",
            "        5.0       0.68      0.69      0.68       892\n",
            "        6.0       0.85      0.94      0.89       958\n",
            "        7.0       0.93      0.74      0.82      1028\n",
            "        8.0       0.78      0.74      0.76       974\n",
            "        9.0       0.59      0.83      0.69      1009\n",
            "\n",
            "avg / total       0.80      0.78      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 904    2    0   21    3   20   16    1   10    3]\n",
            " [   0 1110    2    1    0   13    6    0    3    0]\n",
            " [  35  117  696   35    5   15   61   11   39   18]\n",
            " [   4   38   16  735    1  103   14    4   82   13]\n",
            " [   4    6   14   11  561   17   13    4    6  346]\n",
            " [  12   50    4   70    5  615   31    8   22   75]\n",
            " [  19    4    8    3    9   12  899    0    3    1]\n",
            " [   4   62   23   78    6   17    5  758   11   64]\n",
            " [  13   33   11   34   11   74   13    6  724   55]\n",
            " [  16   18    7   30   18   23    1   27   27  842]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [25 25 17 18 15 19 20 17 24 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.282 s \n",
            "\n",
            "Accuracy rate for 81.000000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.91      0.91       980\n",
            "        1.0       0.85      0.98      0.91      1135\n",
            "        2.0       0.88      0.75      0.81      1032\n",
            "        3.0       0.76      0.75      0.75      1010\n",
            "        4.0       0.91      0.64      0.75       982\n",
            "        5.0       0.67      0.74      0.70       892\n",
            "        6.0       0.86      0.90      0.88       958\n",
            "        7.0       0.90      0.83      0.86      1028\n",
            "        8.0       0.81      0.73      0.77       974\n",
            "        9.0       0.65      0.85      0.73      1009\n",
            "\n",
            "avg / total       0.82      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 887    1    1   20    3   29   26    1   10    2]\n",
            " [   0 1113    1    3    0   10    5    0    3    0]\n",
            " [  25   65  771   27    7   13   44   26   36   18]\n",
            " [   4   24   20  756    1  118    8    9   59   11]\n",
            " [   3    5   14    6  627   16   15    8    4  284]\n",
            " [   5   19    6   78    6  664   31    7   25   51]\n",
            " [  23    3   28    2   14   27  858    0    2    1]\n",
            " [   1   37   15   35    3   24    1  856    8   48]\n",
            " [  15   35   15   40    8   68   11   13  714   55]\n",
            " [  13    8    8   29   19   26    0   36   16  854]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [31 33 19 23 22 24 22 22 29 25] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.305 s \n",
            "\n",
            "Accuracy rate for 82.730000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.93      0.92       980\n",
            "        1.0       0.85      0.99      0.92      1135\n",
            "        2.0       0.90      0.75      0.82      1032\n",
            "        3.0       0.77      0.77      0.77      1010\n",
            "        4.0       0.87      0.77      0.82       982\n",
            "        5.0       0.69      0.74      0.71       892\n",
            "        6.0       0.89      0.89      0.89       958\n",
            "        7.0       0.89      0.84      0.86      1028\n",
            "        8.0       0.82      0.73      0.77       974\n",
            "        9.0       0.72      0.83      0.77      1009\n",
            "\n",
            "avg / total       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 908    1    1   15    0   32   13    1    8    1]\n",
            " [   0 1119    1    2    0    4    5    0    4    0]\n",
            " [  19   58  779   34   17   13   35   27   41    9]\n",
            " [   8   20   15  779    0  120    6   13   42    7]\n",
            " [   2    6    6    6  756    6    9    1    6  184]\n",
            " [   5   25    9   65   13  662   29   11   25   48]\n",
            " [  26    3   15    2   25   30  854    0    3    0]\n",
            " [   4   32   14   30   11   19    0  862   13   43]\n",
            " [  16   35   18   48   16   59   13   14  713   42]\n",
            " [  16   11    8   30   33   18    0   37   15  841]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [37 39 23 27 25 33 28 25 34 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 15.439 s \n",
            "\n",
            "Accuracy rate for 83.520000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.94      0.93       980\n",
            "        1.0       0.85      0.98      0.91      1135\n",
            "        2.0       0.89      0.77      0.83      1032\n",
            "        3.0       0.80      0.79      0.79      1010\n",
            "        4.0       0.87      0.75      0.80       982\n",
            "        5.0       0.70      0.82      0.76       892\n",
            "        6.0       0.89      0.88      0.89       958\n",
            "        7.0       0.91      0.83      0.87      1028\n",
            "        8.0       0.81      0.73      0.77       974\n",
            "        9.0       0.74      0.85      0.79      1009\n",
            "\n",
            "avg / total       0.84      0.84      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 917    1    1    9    0   27   13    2   10    0]\n",
            " [   0 1117    1    2    0    5    6    0    4    0]\n",
            " [  18   58  791   23   14   12   36   26   42   12]\n",
            " [   6   21   18  797    0   98    6   13   44    7]\n",
            " [   2    9    8   12  732   11   11    2   10  185]\n",
            " [   7   11    6   64   13  732   21    8   19   11]\n",
            " [  24    3   16    3   20   44  847    0    1    0]\n",
            " [   4   42   14   30   13   16    0  853    9   47]\n",
            " [  11   33   22   41   19   83   11    8  710   36]\n",
            " [  12   13    7   21   33   18    1   24   24  856]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59700,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [44 42 28 33 27 36 37 29 38 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 17.384 s \n",
            "\n",
            "Accuracy rate for 84.350000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.96      0.94       980\n",
            "        1.0       0.85      0.98      0.91      1135\n",
            "        2.0       0.91      0.78      0.84      1032\n",
            "        3.0       0.81      0.81      0.81      1010\n",
            "        4.0       0.88      0.74      0.80       982\n",
            "        5.0       0.74      0.82      0.77       892\n",
            "        6.0       0.89      0.90      0.90       958\n",
            "        7.0       0.92      0.83      0.87      1028\n",
            "        8.0       0.83      0.73      0.78       974\n",
            "        9.0       0.73      0.86      0.79      1009\n",
            "\n",
            "avg / total       0.85      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 939    1    0    9    0   14   10    1    6    0]\n",
            " [   0 1115    1    2    0    6    6    0    5    0]\n",
            " [  22   47  806   31   15   13   37   23   29    9]\n",
            " [   1   23   18  817    1   75    6    8   54    7]\n",
            " [   2    7    4    5  726    8    9    2    8  211]\n",
            " [   8   16    8   64    6  729   20    6   15   20]\n",
            " [  24    3    7    2   17   39  864    0    2    0]\n",
            " [   4   43   19   22   10   11    0  857    6   56]\n",
            " [  16   37   20   39   21   80   11   13  712   25]\n",
            " [  12   16    7   17   27   16    3   25   16  870]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [53 48 33 42 30 39 39 31 45 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.446 s \n",
            "\n",
            "Accuracy rate for 85.170000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.96      0.93       980\n",
            "        1.0       0.87      0.98      0.92      1135\n",
            "        2.0       0.93      0.82      0.87      1032\n",
            "        3.0       0.78      0.87      0.82      1010\n",
            "        4.0       0.89      0.73      0.80       982\n",
            "        5.0       0.78      0.81      0.79       892\n",
            "        6.0       0.91      0.90      0.90       958\n",
            "        7.0       0.93      0.82      0.87      1028\n",
            "        8.0       0.84      0.74      0.79       974\n",
            "        9.0       0.73      0.86      0.79      1009\n",
            "\n",
            "avg / total       0.86      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    1    0   15    0   10    6    1    9    1]\n",
            " [   0 1114    0    5    0    6    6    0    4    0]\n",
            " [  15   22  849   31   11    9   32   23   31    9]\n",
            " [   1   16    7  880    1   45    3    8   44    5]\n",
            " [   2   10    4    7  720    6    9    2    8  214]\n",
            " [   6   12    5   90    7  726   19    1   14   12]\n",
            " [  27    3   13    2   17   37  858    0    1    0]\n",
            " [   4   45   14   41   10    9    0  839    9   57]\n",
            " [  17   36   15   41   21   73   12   11  723   25]\n",
            " [  16   16    6   23   25   15    1   20   16  871]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [58 51 36 51 34 45 42 40 51 42] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 21.361 s \n",
            "\n",
            "Accuracy rate for 86.170000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.97      0.95       980\n",
            "        1.0       0.89      0.98      0.93      1135\n",
            "        2.0       0.90      0.83      0.87      1032\n",
            "        3.0       0.83      0.87      0.85      1010\n",
            "        4.0       0.87      0.77      0.82       982\n",
            "        5.0       0.77      0.83      0.80       892\n",
            "        6.0       0.92      0.89      0.90       958\n",
            "        7.0       0.93      0.86      0.89      1028\n",
            "        8.0       0.85      0.75      0.80       974\n",
            "        9.0       0.76      0.84      0.80      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 955    1    0    2    0   14    4    1    3    0]\n",
            " [   0 1111    1    4    0    8    6    0    5    0]\n",
            " [  20   23  858   23   12   15   35   14   28    4]\n",
            " [   3   18    7  883    2   43    4   10   36    4]\n",
            " [   2    6    7    5  761    7    7    2    5  180]\n",
            " [   9   11    9   67   13  740   13    4   17    9]\n",
            " [  19    3   24    2   17   38  854    0    1    0]\n",
            " [   2   34   18   19   12    2    0  880    9   52]\n",
            " [  13   35   17   38   19   86   10    7  727   22]\n",
            " [  14   13    9   21   42   10    0   32   20  848]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 7. 9. 9.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [65 58 40 57 40 48 46 43 57 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.582 s \n",
            "\n",
            "Accuracy rate for 86.660000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.98      0.95       980\n",
            "        1.0       0.89      0.98      0.93      1135\n",
            "        2.0       0.91      0.83      0.87      1032\n",
            "        3.0       0.83      0.88      0.85      1010\n",
            "        4.0       0.82      0.81      0.82       982\n",
            "        5.0       0.79      0.84      0.81       892\n",
            "        6.0       0.93      0.90      0.91       958\n",
            "        7.0       0.93      0.85      0.89      1028\n",
            "        8.0       0.87      0.75      0.81       974\n",
            "        9.0       0.77      0.83      0.80      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 960    1    0    1    1   11    4    1    1    0]\n",
            " [   0 1117    2    2    0    4    4    0    6    0]\n",
            " [  16   24  858   37   15   13   25   14   22    8]\n",
            " [   3   13   12  886    6   41    3   10   32    4]\n",
            " [   2    8    8    0  793    1    9    1    4  156]\n",
            " [  10   11    8   63   21  745    9    2   15    8]\n",
            " [  20    3   17    7   19   32  860    0    0    0]\n",
            " [   2   36   15   21   23    2    0  874    6   49]\n",
            " [   8   34   18   33   24   87    8    9  734   19]\n",
            " [  15   14    5   16   61   12    0   25   22  839]]\n",
            "--------------------------------\n",
            "final active learning accuracies [56.38999999999999, 72.92999999999999, 78.44, 81.0, 82.73, 83.52000000000001, 84.35000000000001, 85.17, 86.17, 86.66]\n",
            "saved Active-learning-experiment-3.pkl /content ['datalab', '.forever', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-1.pkl', '.ipython', '.cache', '.config', 'scikit_learn_data', '.rnd', 'Active-learning-experiment-3.pkl', '.local']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 4, using model = SvmModel, selection_function = RandomSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [3 4 0 1 2 2 3 3 3 4] [0 1 3 4 5 6 7 8 9]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n",
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 1.644 s \n",
            "\n",
            "Accuracy rate for 51.450000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.66      0.50      0.57       980\n",
            "        1.0       0.61      0.97      0.75      1135\n",
            "        2.0       0.00      0.00      0.00      1032\n",
            "        3.0       0.31      0.07      0.12      1010\n",
            "        4.0       0.32      0.19      0.24       982\n",
            "        5.0       0.46      0.61      0.52       892\n",
            "        6.0       0.47      0.74      0.57       958\n",
            "        7.0       0.58      0.79      0.67      1028\n",
            "        8.0       0.49      0.51      0.50       974\n",
            "        9.0       0.49      0.73      0.59      1009\n",
            "\n",
            "avg / total       0.44      0.51      0.45     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 492    2    0   46   43  212  113   23   38   11]\n",
            " [   0 1096    0    0    1    1   33    3    1    0]\n",
            " [  19  161    0   89  182    8  260  113  161   39]\n",
            " [  63  168    0   72    3  162   80  169  238   55]\n",
            " [   9   87    0    0  187   52  119   53   13  462]\n",
            " [  86   31    0   23    8  541  101   44   34   24]\n",
            " [  41   13    0    0  119   23  711    4   26   21]\n",
            " [   8  104    0    0    2   19    1  810    9   75]\n",
            " [  25   71    0    3    8  141   91   52  499   84]\n",
            " [   5   74    0    2   27   19   13  123    9  737]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59975,) [6. 0. 8. ... 9. 1. 1.]\n",
            "probabilities: (59975, 9) \n",
            " [0 7 7 ... 6 6 6]\n",
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [4 6 2 4 6 5 7 5 5 6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 3.232 s \n",
            "\n",
            "Accuracy rate for 67.880000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.71      0.79       980\n",
            "        1.0       0.67      0.97      0.79      1135\n",
            "        2.0       0.55      0.25      0.34      1032\n",
            "        3.0       0.52      0.67      0.58      1010\n",
            "        4.0       0.68      0.71      0.69       982\n",
            "        5.0       0.53      0.57      0.55       892\n",
            "        6.0       0.65      0.78      0.71       958\n",
            "        7.0       0.89      0.78      0.83      1028\n",
            "        8.0       0.74      0.60      0.66       974\n",
            "        9.0       0.74      0.72      0.73      1009\n",
            "\n",
            "avg / total       0.69      0.68      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 695    1   45   18   12  132   61    2   11    3]\n",
            " [   0 1106   14    4    0    1    9    1    0    0]\n",
            " [  12  150  254  291   48   39  150   20   53   15]\n",
            " [  11   73   78  672    2   57   14   16   67   20]\n",
            " [   0   41    3   30  695   17   47    1    6  142]\n",
            " [  26   24   16  172   20  504   62   17   44    7]\n",
            " [  26   11   10   39   73   52  747    0    0    0]\n",
            " [   5  106   14   12   31   11    1  804    9   35]\n",
            " [  10  102   18   51    6   99   51   14  585   38]\n",
            " [   5   43    9    3  136   36    1   32   18  726]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 8. ... 9. 1. 1.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 8 ... 9 5 8]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [ 4  8  4  5 10 11 10  7  8  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.661 s \n",
            "\n",
            "Accuracy rate for 72.250000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.68      0.77       980\n",
            "        1.0       0.74      0.96      0.83      1135\n",
            "        2.0       0.77      0.50      0.60      1032\n",
            "        3.0       0.60      0.61      0.61      1010\n",
            "        4.0       0.71      0.74      0.72       982\n",
            "        5.0       0.52      0.68      0.59       892\n",
            "        6.0       0.74      0.84      0.79       958\n",
            "        7.0       0.89      0.80      0.84      1028\n",
            "        8.0       0.74      0.68      0.71       974\n",
            "        9.0       0.75      0.70      0.73      1009\n",
            "\n",
            "avg / total       0.74      0.72      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 670    1   15   15    5  207   62    4    0    1]\n",
            " [   0 1091   15    1    0    5   12    1   10    0]\n",
            " [  17  123  512  163   37   21   74   23   49   13]\n",
            " [   9   38   68  621    2  131    5   19  103   14]\n",
            " [   0   29    4   26  728   13   44    2    5  131]\n",
            " [  23   17    6  139   15  603   40    8   35    6]\n",
            " [  25   16    4   16   48   39  807    0    2    1]\n",
            " [   2   83   14    8   27   19    1  821   11   42]\n",
            " [  12   55   20   39    8   96   46    9  665   24]\n",
            " [   3   31    8    2  161   35    2   38   22  707]]\n",
            "--------------------------------\n",
            "val predicted: (59925,) [0. 0. 6. ... 9. 5. 5.]\n",
            "probabilities: (59925, 10) \n",
            " [0 0 6 ... 9 5 5]\n",
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 7  9  5  8 12 14 12 11  9 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.112 s \n",
            "\n",
            "Accuracy rate for 77.820000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.82      0.85       980\n",
            "        1.0       0.81      0.98      0.88      1135\n",
            "        2.0       0.89      0.57      0.70      1032\n",
            "        3.0       0.66      0.80      0.72      1010\n",
            "        4.0       0.76      0.81      0.78       982\n",
            "        5.0       0.66      0.79      0.72       892\n",
            "        6.0       0.77      0.85      0.81       958\n",
            "        7.0       0.86      0.79      0.82      1028\n",
            "        8.0       0.83      0.59      0.69       974\n",
            "        9.0       0.76      0.76      0.76      1009\n",
            "\n",
            "avg / total       0.79      0.78      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 803    2    8    7    7  101   48    2    1    1]\n",
            " [   0 1108    1   17    0    1    8    0    0    0]\n",
            " [  16   84  592  120   37   20   62   52   37   12]\n",
            " [   8   15   15  808    1   98    3   20   29   13]\n",
            " [   0   20    3   22  794    4   50    1    4   84]\n",
            " [  22   18    1   43   22  708   42    7   17   12]\n",
            " [  39    6    9   14   32   44  814    0    0    0]\n",
            " [   3   56    3    8   36    4    0  810   11   97]\n",
            " [   9   39   28  171   10   77   32   16  574   18]\n",
            " [   5   25    2   15  111   19    2   38   21  771]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 6. ... 9. 9. 9.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 6 ... 9 9 8]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [ 9 14  7 10 14 17 13 13 12 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.493 s \n",
            "\n",
            "Accuracy rate for 79.190000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.86      0.84      0.85       980\n",
            "        1.0       0.83      0.98      0.90      1135\n",
            "        2.0       0.90      0.62      0.74      1032\n",
            "        3.0       0.71      0.80      0.76      1010\n",
            "        4.0       0.80      0.79      0.79       982\n",
            "        5.0       0.70      0.80      0.75       892\n",
            "        6.0       0.77      0.84      0.81       958\n",
            "        7.0       0.89      0.78      0.83      1028\n",
            "        8.0       0.82      0.63      0.71       974\n",
            "        9.0       0.71      0.81      0.76      1009\n",
            "\n",
            "avg / total       0.80      0.79      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 828    1    0    7   11   76   53    2    0    2]\n",
            " [   0 1115    1    2    0    1    8    1    7    0]\n",
            " [  11   73  642  108   22   19   50   48   46   13]\n",
            " [  20   18   16  812    1   62    3   14   37   27]\n",
            " [   0   19    6   10  772    2   41    0    3  129]\n",
            " [  27   21    2   40   11  715   45    6    9   16]\n",
            " [  48    3   11   14   30   44  806    0    2    0]\n",
            " [   1   43   16    9   26    6    0  798    6  123]\n",
            " [  16   40   18  131    7   81   34   10  609   28]\n",
            " [  14   12    2    7   91   18    1   22   20  822]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) [0. 0. 6. ... 9. 9. 9.]\n",
            "probabilities: (59875, 10) \n",
            " [0 0 6 ... 9 9 9]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [11 17 12 14 16 20 15 14 14 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.815 s \n",
            "\n",
            "Accuracy rate for 80.320000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.83      0.85       980\n",
            "        1.0       0.84      0.98      0.90      1135\n",
            "        2.0       0.85      0.68      0.75      1032\n",
            "        3.0       0.76      0.82      0.79      1010\n",
            "        4.0       0.80      0.77      0.78       982\n",
            "        5.0       0.71      0.82      0.76       892\n",
            "        6.0       0.80      0.85      0.83       958\n",
            "        7.0       0.89      0.78      0.83      1028\n",
            "        8.0       0.84      0.67      0.75       974\n",
            "        9.0       0.71      0.81      0.76      1009\n",
            "\n",
            "avg / total       0.81      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 814    2   10    6   11   79   53    2    1    2]\n",
            " [   0 1111    1    5    0    3    7    1    7    0]\n",
            " [  15   52  700   83   16   20   41   46   49   10]\n",
            " [  14   21   22  827    0   61    0   17   27   21]\n",
            " [   0   18   17    7  758    2   38    0    5  137]\n",
            " [  18   22    6   47   12  730   35    5    4   13]\n",
            " [  47    3   21    3   30   36  816    0    1    1]\n",
            " [   1   47   14    6   27    4    1  800    6  122]\n",
            " [  17   35   26  100    8   80   23    7  655   23]\n",
            " [  13   10    6    9   90   15    1   20   24  821]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59850,) [0. 0. 6. ... 9. 9. 9.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 6 ... 9 9 9]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [13 19 14 16 19 23 19 16 17 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.372 s \n",
            "\n",
            "Accuracy rate for 81.190000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.86      0.86      0.86       980\n",
            "        1.0       0.83      0.99      0.90      1135\n",
            "        2.0       0.88      0.75      0.81      1032\n",
            "        3.0       0.83      0.79      0.81      1010\n",
            "        4.0       0.83      0.75      0.79       982\n",
            "        5.0       0.70      0.82      0.75       892\n",
            "        6.0       0.81      0.90      0.85       958\n",
            "        7.0       0.89      0.77      0.83      1028\n",
            "        8.0       0.85      0.66      0.74       974\n",
            "        9.0       0.70      0.82      0.75      1009\n",
            "\n",
            "avg / total       0.82      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 840    2   10    5    7   73   40    0    1    2]\n",
            " [   0 1119    1    2    0    1    6    0    6    0]\n",
            " [  18   50  770   22   16   16   54   37   38   11]\n",
            " [  16   22   27  795    0   75    8   20   32   15]\n",
            " [   4   19   17    1  735    3   24    1    3  175]\n",
            " [  19   19    3   43    9  727   40    9   10   13]\n",
            " [  40    3    7    1   14   25  866    0    2    0]\n",
            " [   5   54   15    1   23    6    0  792    4  128]\n",
            " [  14   44   23   86    6  100   29    8  647   17]\n",
            " [  16   18    4    6   75   20    1   20   21  828]]\n",
            "--------------------------------\n",
            "val predicted: (59825,) [0. 0. 6. ... 9. 9. 9.]\n",
            "probabilities: (59825, 10) \n",
            " [0 0 6 ... 9 9 9]\n",
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [16 21 16 20 22 24 21 21 18 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.422 s \n",
            "\n",
            "Accuracy rate for 81.910000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.89      0.88       980\n",
            "        1.0       0.84      0.99      0.91      1135\n",
            "        2.0       0.86      0.76      0.81      1032\n",
            "        3.0       0.83      0.79      0.81      1010\n",
            "        4.0       0.82      0.82      0.82       982\n",
            "        5.0       0.72      0.82      0.77       892\n",
            "        6.0       0.84      0.90      0.87       958\n",
            "        7.0       0.86      0.77      0.81      1028\n",
            "        8.0       0.84      0.65      0.73       974\n",
            "        9.0       0.72      0.78      0.75      1009\n",
            "\n",
            "avg / total       0.82      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 875    1    7    5    6   55   28    0    1    2]\n",
            " [   0 1120    1    1    0    1    5    2    5    0]\n",
            " [  25   49  785   19   19   13   47   31   34   10]\n",
            " [  14   18   31  801    0   53    8   29   41   15]\n",
            " [   2   19   15    1  808    2   21    3    3  108]\n",
            " [  21   12    2   50    8  734   30    8   10   17]\n",
            " [  34    3   12    3   17   20  866    0    3    0]\n",
            " [   2   51   20    0   21    4    1  787    3  139]\n",
            " [  14   40   29   77    6  121   27   10  629   21]\n",
            " [  15   20    7   10   97   14    0   42   18  786]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [20 22 18 21 25 27 23 24 19 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.604 s \n",
            "\n",
            "Accuracy rate for 82.680000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.91      0.89       980\n",
            "        1.0       0.85      0.99      0.92      1135\n",
            "        2.0       0.89      0.77      0.82      1032\n",
            "        3.0       0.81      0.78      0.80      1010\n",
            "        4.0       0.79      0.85      0.82       982\n",
            "        5.0       0.74      0.81      0.77       892\n",
            "        6.0       0.86      0.88      0.87       958\n",
            "        7.0       0.88      0.81      0.84      1028\n",
            "        8.0       0.84      0.65      0.73       974\n",
            "        9.0       0.75      0.79      0.77      1009\n",
            "\n",
            "avg / total       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 889    1    7    6    5   44   23    0    1    4]\n",
            " [   0 1121    1    2    0    1    5    0    5    0]\n",
            " [  25   47  793   20   25   11   41   25   32   13]\n",
            " [  17   14   29  790    3   59    8   32   43   15]\n",
            " [   2   16    5    1  839    3    9    4    2  101]\n",
            " [  25    9    5   57   12  726   25    7   11   15]\n",
            " [  40    3    9    3   34   19  846    0    3    1]\n",
            " [   1   44   19    1   31    1    0  834    3   94]\n",
            " [  15   41   23   87    7  113   28    8  631   21]\n",
            " [  13   19    2    9  101    8    0   39   19  799]]\n",
            "--------------------------------\n",
            "val predicted: (59775,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59775, 10) \n",
            " [0 0 6 ... 9 9 9]\n",
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [23 26 20 22 27 30 26 26 22 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.665 s \n",
            "\n",
            "Accuracy rate for 82.890000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.94      0.89       980\n",
            "        1.0       0.86      0.98      0.92      1135\n",
            "        2.0       0.89      0.74      0.81      1032\n",
            "        3.0       0.82      0.78      0.80      1010\n",
            "        4.0       0.80      0.85      0.82       982\n",
            "        5.0       0.74      0.82      0.78       892\n",
            "        6.0       0.86      0.88      0.87       958\n",
            "        7.0       0.87      0.82      0.84      1028\n",
            "        8.0       0.84      0.66      0.74       974\n",
            "        9.0       0.76      0.80      0.78      1009\n",
            "\n",
            "avg / total       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 926    0    4    2    2   28   13    1    2    2]\n",
            " [   0 1117    2    2    0    2    4    0    8    0]\n",
            " [  36   47  767   20   24    9   53   29   39    8]\n",
            " [  20   13   28  785    4   66    8   37   40    9]\n",
            " [   2   16    6    0  832    7    7    2    1  109]\n",
            " [  23    5    5   65    8  731   26    7    6   16]\n",
            " [  51    3    5    2   31   22  841    0    3    0]\n",
            " [   1   41   20    0   29    3    2  840    5   87]\n",
            " [  24   34   24   75   13  108   21   13  643   19]\n",
            " [  14   17    4    8   92   11    0   42   14  807]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [26 29 27 22 30 31 26 31 23 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 15.041 s \n",
            "\n",
            "Accuracy rate for 82.890000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.81      0.96      0.88       980\n",
            "        1.0       0.88      0.98      0.93      1135\n",
            "        2.0       0.86      0.74      0.80      1032\n",
            "        3.0       0.83      0.75      0.79      1010\n",
            "        4.0       0.82      0.84      0.83       982\n",
            "        5.0       0.76      0.82      0.79       892\n",
            "        6.0       0.87      0.85      0.86       958\n",
            "        7.0       0.85      0.86      0.86      1028\n",
            "        8.0       0.84      0.66      0.74       974\n",
            "        9.0       0.76      0.80      0.78      1009\n",
            "\n",
            "avg / total       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    0    5    1    2   25    5    1    2    2]\n",
            " [   0 1117    3    0    0    2    5    1    7    0]\n",
            " [  40   38  767   14   28    6   50   36   43   10]\n",
            " [  31   13   35  762    2   62    8   31   47   19]\n",
            " [   3   15    3    1  829    5    7    5    0  114]\n",
            " [  39    5    5   54   10  727   21    6    9   16]\n",
            " [  77    3    6    2   28   21  818    0    3    0]\n",
            " [   4   34   13    1   11    2    0  887    2   74]\n",
            " [  11   33   53   73   12   97   23   15  641   16]\n",
            " [  13   13    1    7   92   10    0   58   11  804]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59725,) [0. 0. 0. ... 9. 7. 7.]\n",
            "probabilities: (59725, 10) \n",
            " [0 0 0 ... 9 7 7]\n",
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [29 32 29 24 33 34 29 33 25 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 16.316 s \n",
            "\n",
            "Accuracy rate for 83.050000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.96      0.88       980\n",
            "        1.0       0.89      0.98      0.94      1135\n",
            "        2.0       0.87      0.75      0.80      1032\n",
            "        3.0       0.85      0.75      0.80      1010\n",
            "        4.0       0.84      0.84      0.84       982\n",
            "        5.0       0.76      0.81      0.78       892\n",
            "        6.0       0.85      0.85      0.85       958\n",
            "        7.0       0.86      0.86      0.86      1028\n",
            "        8.0       0.83      0.66      0.73       974\n",
            "        9.0       0.75      0.82      0.78      1009\n",
            "\n",
            "avg / total       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 939    0    5    1    2   21    7    1    2    2]\n",
            " [   0 1117    3    0    0    2    5    1    7    0]\n",
            " [  40   31  771   15   23    5   55   38   41   13]\n",
            " [  30   12   37  760    1   65   10   27   52   16]\n",
            " [   2   11    2    1  827    5   19    7    0  108]\n",
            " [  38    4    5   48   13  725   22    6   12   19]\n",
            " [  76    3    9    0   30   21  816    0    3    0]\n",
            " [   3   30   12    1   13    1    1  883    4   80]\n",
            " [   9   32   46   66    8   99   30   11  643   30]\n",
            " [  14   13    1    4   70   14    0   57   12  824]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [32 35 31 29 35 36 30 36 27 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 17.119 s \n",
            "\n",
            "Accuracy rate for 83.920000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.96      0.89       980\n",
            "        1.0       0.89      0.98      0.94      1135\n",
            "        2.0       0.88      0.76      0.81      1032\n",
            "        3.0       0.85      0.79      0.82      1010\n",
            "        4.0       0.84      0.84      0.84       982\n",
            "        5.0       0.76      0.82      0.78       892\n",
            "        6.0       0.86      0.86      0.86       958\n",
            "        7.0       0.85      0.86      0.86      1028\n",
            "        8.0       0.86      0.68      0.76       974\n",
            "        9.0       0.77      0.83      0.80      1009\n",
            "\n",
            "avg / total       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    0    5    0    2   22    6    1    3    0]\n",
            " [   0 1116    0    3    0    2    5    1    8    0]\n",
            " [  42   28  783   14   16    6   53   41   38   11]\n",
            " [  16   10   28  797    3   73   10   27   34   12]\n",
            " [   2   10    4    2  827    4   20    5    1  107]\n",
            " [  37    5    3   49   12  727   19    9    9   22]\n",
            " [  62    3    9    0   40   19  822    0    3    0]\n",
            " [   3   30   14    4   13    1    0  885    2   76]\n",
            " [   8   34   45   58   12   94   26   13  659   25]\n",
            " [  14   14    1    8   57   13    0   56   11  835]]\n",
            "--------------------------------\n",
            "val predicted: (59675,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59675, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [34 39 34 34 36 37 32 39 29 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.016 s \n",
            "\n",
            "Accuracy rate for 84.690000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.83      0.96      0.89       980\n",
            "        1.0       0.89      0.99      0.94      1135\n",
            "        2.0       0.87      0.79      0.83      1032\n",
            "        3.0       0.84      0.83      0.84      1010\n",
            "        4.0       0.85      0.83      0.84       982\n",
            "        5.0       0.79      0.81      0.80       892\n",
            "        6.0       0.85      0.85      0.85       958\n",
            "        7.0       0.86      0.89      0.88      1028\n",
            "        8.0       0.89      0.66      0.75       974\n",
            "        9.0       0.80      0.83      0.81      1009\n",
            "\n",
            "avg / total       0.85      0.85      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    1    4    0    2   23    6    1    2    0]\n",
            " [   0 1119    0    4    0    1    5    1    5    0]\n",
            " [  41   18  818   14   17    5   54   33   26    6]\n",
            " [  18    8   30  842    2   45   10   24   23    8]\n",
            " [   2   14    4    4  817    2   20    4    1  114]\n",
            " [  37   11    3   50   11  726   18   10    7   19]\n",
            " [  66    4    8    1   43   18  815    0    3    0]\n",
            " [   4   26   19    1   10    0    2  913    6   47]\n",
            " [  10   40   46   81   11   87   26   13  640   20]\n",
            " [  14   15    3    8   52   12    0   57   10  838]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [36 41 36 39 37 40 35 44 31 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.340 s \n",
            "\n",
            "Accuracy rate for 84.770000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.96      0.89       980\n",
            "        1.0       0.90      0.99      0.94      1135\n",
            "        2.0       0.89      0.79      0.83      1032\n",
            "        3.0       0.80      0.86      0.83      1010\n",
            "        4.0       0.82      0.85      0.83       982\n",
            "        5.0       0.80      0.79      0.79       892\n",
            "        6.0       0.86      0.84      0.85       958\n",
            "        7.0       0.87      0.89      0.88      1028\n",
            "        8.0       0.89      0.68      0.77       974\n",
            "        9.0       0.81      0.81      0.81      1009\n",
            "\n",
            "avg / total       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    1    3    3    3   20    7    1    1    0]\n",
            " [   0 1118    0    4    0    1    4    1    7    0]\n",
            " [  40   20  812   20   21    6   49   34   26    4]\n",
            " [  15    5   24  867    1   37   11   21   23    6]\n",
            " [   2   10    3    4  830    2   22    3    2  104]\n",
            " [  38   13    4   76   13  701   18   10    5   14]\n",
            " [  66    4    8    1   52   17  807    0    3    0]\n",
            " [   3   27   18    3   11    0    2  919    4   41]\n",
            " [   7   31   42   89   14   77   17   13  666   18]\n",
            " [  14   13    1   19   65   14    0   55   12  816]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59625, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [40 48 37 41 39 41 37 46 34 37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.904 s \n",
            "\n",
            "Accuracy rate for 84.660000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.96      0.90       980\n",
            "        1.0       0.88      0.98      0.93      1135\n",
            "        2.0       0.88      0.78      0.83      1032\n",
            "        3.0       0.78      0.86      0.82      1010\n",
            "        4.0       0.84      0.85      0.84       982\n",
            "        5.0       0.80      0.79      0.79       892\n",
            "        6.0       0.86      0.85      0.86       958\n",
            "        7.0       0.87      0.89      0.88      1028\n",
            "        8.0       0.88      0.68      0.77       974\n",
            "        9.0       0.83      0.80      0.82      1009\n",
            "\n",
            "avg / total       0.85      0.85      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    0    4    3    2   23    7    1    2    1]\n",
            " [   0 1113    1    5    0    1    4    1   10    0]\n",
            " [  42   16  806   27   18    6   53   33   28    3]\n",
            " [  15    6   24  871    2   36    9   20   23    4]\n",
            " [   2   21    7   10  831    0   18    2    3   88]\n",
            " [  33   15    2   75   10  707   19   10    5   16]\n",
            " [  55    4   10    1   46   21  818    0    3    0]\n",
            " [   3   34   19    4   12    0    1  912    4   39]\n",
            " [   9   28   39   95   11   83   20   13  660   16]\n",
            " [  16   23    5   20   60   12    0   53    9  811]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59600,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [41 52 39 43 43 44 38 50 37 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 21.017 s \n",
            "\n",
            "Accuracy rate for 85.000000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.96      0.89       980\n",
            "        1.0       0.90      0.98      0.94      1135\n",
            "        2.0       0.88      0.79      0.83      1032\n",
            "        3.0       0.78      0.86      0.82      1010\n",
            "        4.0       0.84      0.88      0.86       982\n",
            "        5.0       0.80      0.79      0.79       892\n",
            "        6.0       0.86      0.85      0.86       958\n",
            "        7.0       0.87      0.89      0.88      1028\n",
            "        8.0       0.88      0.69      0.77       974\n",
            "        9.0       0.85      0.78      0.82      1009\n",
            "\n",
            "avg / total       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    0    2    3    1   22   11    1    2    1]\n",
            " [   0 1113    1    5    0    1    4    1   10    0]\n",
            " [  43   14  817   25   15    9   53   25   27    4]\n",
            " [  13    6   26  873    2   37    8   20   22    3]\n",
            " [   3   19    6    5  862    0   17    6    3   61]\n",
            " [  34   12    2   81   12  703   17   10    6   15]\n",
            " [  56    4    8    4   45   22  816    0    3    0]\n",
            " [   4   28   20    3   14    1    1  916    3   38]\n",
            " [  10   25   38   95   11   77   19    9  672   18]\n",
            " [  16   21    5   19   63   11    0   70   13  791]]\n",
            "--------------------------------\n",
            "val predicted: (59575,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59575, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [41 57 40 47 43 47 39 56 39 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 21.441 s \n",
            "\n",
            "Accuracy rate for 85.300000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.85      0.95      0.90       980\n",
            "        1.0       0.90      0.98      0.94      1135\n",
            "        2.0       0.89      0.79      0.84      1032\n",
            "        3.0       0.81      0.86      0.83      1010\n",
            "        4.0       0.84      0.88      0.86       982\n",
            "        5.0       0.77      0.82      0.80       892\n",
            "        6.0       0.87      0.85      0.86       958\n",
            "        7.0       0.87      0.89      0.88      1028\n",
            "        8.0       0.88      0.70      0.78       974\n",
            "        9.0       0.85      0.78      0.81      1009\n",
            "\n",
            "avg / total       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 934    1    2    1    1   28   10    1    2    0]\n",
            " [   0 1117    1    3    0    2    3    1    8    0]\n",
            " [  41   12  817   26   14    8   51   28   30    5]\n",
            " [  13    5   26  865    2   46    6   16   27    4]\n",
            " [   2   18    8    3  867    2   17    5    4   56]\n",
            " [  32   12    2   61    7  733   14    8    5   18]\n",
            " [  54    4    6    2   45   28  816    0    3    0]\n",
            " [   5   27   20    4   13    2    0  915    5   37]\n",
            " [  10   21   35   89   10   85   18   10  677   19]\n",
            " [  14   20    5   18   71   13    0   67   12  789]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 9. 7. 7.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 9 7 7]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [41 59 43 48 46 51 39 60 43 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 22.488 s \n",
            "\n",
            "Accuracy rate for 85.790000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.95      0.89       980\n",
            "        1.0       0.91      0.99      0.94      1135\n",
            "        2.0       0.88      0.81      0.84      1032\n",
            "        3.0       0.84      0.85      0.84      1010\n",
            "        4.0       0.84      0.88      0.86       982\n",
            "        5.0       0.79      0.84      0.81       892\n",
            "        6.0       0.88      0.85      0.86       958\n",
            "        7.0       0.87      0.89      0.88      1028\n",
            "        8.0       0.88      0.73      0.80       974\n",
            "        9.0       0.84      0.79      0.81      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 930    1    5    2    1   28   10    1    2    0]\n",
            " [   0 1119    1    3    0    2    3    1    6    0]\n",
            " [  37   14  838   15   13    6   42   26   31   10]\n",
            " [  16    5   32  854    1   40    4   20   34    4]\n",
            " [   2   21    4    2  867    2   19    4    0   61]\n",
            " [  34   11    2   57    6  745   15    5    6   11]\n",
            " [  54    4   13    1   45   26  812    0    3    0]\n",
            " [   4   27   22    4   12    2    1  912    4   40]\n",
            " [  14   12   31   76    9   75   16    9  709   23]\n",
            " [  14   20    4    8   77   19    0   66    8  793]]\n",
            "--------------------------------\n",
            "val predicted: (59525,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59525, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [42 60 48 51 51 57 41 61 44 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 22.964 s \n",
            "\n",
            "Accuracy rate for 86.080000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.85      0.95      0.89       980\n",
            "        1.0       0.90      0.99      0.94      1135\n",
            "        2.0       0.88      0.83      0.85      1032\n",
            "        3.0       0.84      0.85      0.84      1010\n",
            "        4.0       0.84      0.89      0.86       982\n",
            "        5.0       0.77      0.84      0.80       892\n",
            "        6.0       0.90      0.85      0.88       958\n",
            "        7.0       0.88      0.89      0.89      1028\n",
            "        8.0       0.89      0.72      0.80       974\n",
            "        9.0       0.86      0.79      0.82      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 928    1    6    1    1   31    9    1    2    0]\n",
            " [   0 1120    1    3    0    2    3    1    5    0]\n",
            " [  35   15  855   17   14    7   25   27   30    7]\n",
            " [  16    5   28  855    1   59    3   19   20    4]\n",
            " [   2   21    6    3  870    1   16    5    0   58]\n",
            " [  29   12    3   56    6  752   16    4    9    5]\n",
            " [  53    4    9    1   42   29  816    0    4    0]\n",
            " [   5   27   23    2    9    2    1  918    4   37]\n",
            " [  13   14   43   69   10   78   13   12  701   21]\n",
            " [  13   21    2   12   81   21    0   57    9  793]]\n",
            "--------------------------------\n",
            "final active learning accuracies [51.449999999999996, 67.88, 72.25, 77.82, 79.19, 80.32000000000001, 81.19, 81.91000000000001, 82.67999999999999, 82.89, 82.89, 83.05, 83.91999999999999, 84.69, 84.77, 84.66, 85.0, 85.3, 85.79, 86.08]\n",
            "saved Active-learning-experiment-4.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-1.pkl', '.ipython', '.cache', '.config', 'scikit_learn_data', '.rnd', 'Active-learning-experiment-3.pkl', '.local']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 5, using model = SvmModel, selection_function = RandomSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [1 0 2 2 1 2 0 1 0 1] [0 2 3 4 5 7 9]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n",
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.713 s \n",
            "\n",
            "Accuracy rate for 31.010000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.23      0.35       980\n",
            "        1.0       0.00      0.00      0.00      1135\n",
            "        2.0       0.24      0.94      0.38      1032\n",
            "        3.0       0.29      0.52      0.37      1010\n",
            "        4.0       0.55      0.29      0.38       982\n",
            "        5.0       0.25      0.26      0.26       892\n",
            "        6.0       0.00      0.00      0.00       958\n",
            "        7.0       0.54      0.21      0.31      1028\n",
            "        8.0       0.00      0.00      0.00       974\n",
            "        9.0       0.34      0.64      0.44      1009\n",
            "\n",
            "avg / total       0.30      0.31      0.25     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[224   0 147 253   4 350   0   1   0   1]\n",
            " [  0   0 850   4   0   0   0   1   0 280]\n",
            " [  5   0 973  21   0  20   0  11   0   2]\n",
            " [  8   0 324 527   0 115   0   9   0  27]\n",
            " [  2   0 265  69 280  42   0  54   0 270]\n",
            " [  4   0 220 267  67 232   0  13   0  89]\n",
            " [  9   0 809 123   3  14   0   0   0   0]\n",
            " [ 19   0 175  10  35  15   0 220   0 554]\n",
            " [  4   0 318 493  30  63   0  15   0  51]\n",
            " [ 11   0  44  70  92  65   0  82   0 645]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59990,) [3. 5. 3. ... 4. 7. 7.]\n",
            "probabilities: (59990, 7) \n",
            " [4 4 1 ... 2 1 2]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [1 0 6 2 3 2 1 2 2 1] [0 2 3 4 5 6 7 8 9]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 1.348 s \n",
            "\n",
            "Accuracy rate for 33.540000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.85      0.26      0.40       980\n",
            "        1.0       0.00      0.00      0.00      1135\n",
            "        2.0       0.20      0.96      0.33      1032\n",
            "        3.0       0.58      0.44      0.50      1010\n",
            "        4.0       0.52      0.52      0.52       982\n",
            "        5.0       0.33      0.24      0.28       892\n",
            "        6.0       0.59      0.08      0.14       958\n",
            "        7.0       0.72      0.11      0.20      1028\n",
            "        8.0       0.33      0.47      0.38       974\n",
            "        9.0       0.40      0.29      0.34      1009\n",
            "\n",
            "avg / total       0.45      0.34      0.30     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 254    0  237   97   34  246   16    0   96    0]\n",
            " [   0    0 1057    0    1    0    0    5   70    2]\n",
            " [   3    0  990    8   12    0    0    3   15    1]\n",
            " [   4    0  418  449    2   95    0    6   23   13]\n",
            " [   1    0  309    0  509    2    0   12  134   15]\n",
            " [   3    0  314   73   46  212   37    0  187   20]\n",
            " [   9    0  679   11   81   14   76    0   88    0]\n",
            " [  17    0  402    0   22    8    0  117   97  365]\n",
            " [   2    0  307  129   13   49    0    3  457   14]\n",
            " [   5    0  184   12  260    7    0   16  235  290]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59980,) [2. 5. 8. ... 8. 8. 8.]\n",
            "probabilities: (59980, 9) \n",
            " [1 4 2 ... 1 1 1]\n",
            "trainset before (20, 784) (20,)\n",
            "trainset after (30, 784) (30,)\n",
            "updated train set: (30, 784) (30,) unique(labels): [1 3 6 2 4 3 2 3 5 1] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59970, 784) (59970,)\n",
            "\n",
            "Train set: (30, 784) y: (30,)\n",
            "Val   set: (59970, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 1.950 s \n",
            "\n",
            "Accuracy rate for 48.670000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.85      0.20      0.32       980\n",
            "        1.0       0.79      0.92      0.85      1135\n",
            "        2.0       0.38      0.87      0.53      1032\n",
            "        3.0       0.69      0.34      0.45      1010\n",
            "        4.0       0.49      0.42      0.45       982\n",
            "        5.0       0.34      0.39      0.36       892\n",
            "        6.0       0.62      0.42      0.50       958\n",
            "        7.0       0.67      0.24      0.36      1028\n",
            "        8.0       0.34      0.71      0.46       974\n",
            "        9.0       0.41      0.27      0.33      1009\n",
            "\n",
            "avg / total       0.56      0.49      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 194    2  107   32   21  434   42    0  148    0]\n",
            " [   0 1046   56    0    2    0    2    0   27    2]\n",
            " [   2   27  902    6   13    3    4    4   70    1]\n",
            " [   3   20  272  343    3  173   69    5  111   11]\n",
            " [   0   40  171    0  414    0   22   52  272   11]\n",
            " [   3   60   69   27   11  352   87    0  272   11]\n",
            " [   8    9  374    3  145   11  402    0    6    0]\n",
            " [  12   56  214    0   13   11    0  251  126  345]\n",
            " [   2   31   87   80    7   46   17    6  691    7]\n",
            " [   3   25  115    9  216    7    2   59  301  272]]\n",
            "--------------------------------\n",
            "val predicted: (59970,) [5. 5. 8. ... 8. 8. 7.]\n",
            "probabilities: (59970, 10) \n",
            " [8 8 8 ... 8 8 8]\n",
            "trainset before (30, 784) (30,)\n",
            "trainset after (40, 784) (40,)\n",
            "updated train set: (40, 784) (40,) unique(labels): [2 4 6 4 5 6 2 3 6 2] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59960, 784) (59960,)\n",
            "\n",
            "Train set: (40, 784) y: (40,)\n",
            "Val   set: (59960, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 2.620 s \n",
            "\n",
            "Accuracy rate for 57.340000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.27      0.40       980\n",
            "        1.0       0.79      0.96      0.87      1135\n",
            "        2.0       0.55      0.84      0.66      1032\n",
            "        3.0       0.76      0.50      0.60      1010\n",
            "        4.0       0.53      0.74      0.62       982\n",
            "        5.0       0.32      0.58      0.41       892\n",
            "        6.0       0.75      0.39      0.52       958\n",
            "        7.0       0.74      0.16      0.26      1028\n",
            "        8.0       0.60      0.62      0.61       974\n",
            "        9.0       0.47      0.61      0.53      1009\n",
            "\n",
            "avg / total       0.63      0.57      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 266    0   38   12   14  578   30    0   42    0]\n",
            " [   0 1094   26    0    1    2    1    0    9    2]\n",
            " [   6   42  862    8   25   17    2    4   64    2]\n",
            " [  23   47  136  504    8  218   24    1   39   10]\n",
            " [   1   19   66    0  724    1   15   25   37   94]\n",
            " [   8   40   25   45   72  520   44    0  104   34]\n",
            " [   3   17  142    0  341   76  375    0    4    0]\n",
            " [  39   57  135    1   22   86    0  166   17  505]\n",
            " [  14   46   57   78   18  109    7    1  605   39]\n",
            " [   4   26   83   12  139   12    0   28   87  618]]\n",
            "--------------------------------\n",
            "val predicted: (59960,) [5. 5. 8. ... 9. 7. 7.]\n",
            "probabilities: (59960, 10) \n",
            " [5 5 8 ... 4 8 8]\n",
            "trainset before (40, 784) (40,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [2 4 7 5 6 7 4 3 9 3] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 3.235 s \n",
            "\n",
            "Accuracy rate for 61.680000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.27      0.42       980\n",
            "        1.0       0.85      0.92      0.88      1135\n",
            "        2.0       0.52      0.88      0.65      1032\n",
            "        3.0       0.82      0.50      0.62      1010\n",
            "        4.0       0.60      0.80      0.68       982\n",
            "        5.0       0.38      0.77      0.51       892\n",
            "        6.0       0.71      0.59      0.65       958\n",
            "        7.0       0.74      0.16      0.27      1028\n",
            "        8.0       0.72      0.69      0.71       974\n",
            "        9.0       0.53      0.56      0.55      1009\n",
            "\n",
            "avg / total       0.69      0.62      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 266    0   39    5   11  522  129    0    8    0]\n",
            " [   0 1042   68    1    2   10    1    0   11    0]\n",
            " [   1   15  907    7   16   28   14    4   39    1]\n",
            " [   0   24  121  502    1  287   16    4   49    6]\n",
            " [   0   13   73    0  782    5   26   24   32   27]\n",
            " [   1   29   21   12   56  688   29    0   28   28]\n",
            " [   1   14  201    0  124   41  570    0    7    0]\n",
            " [   2   39  196    1   64  111    1  168   26  420]\n",
            " [   2   44   44   77   19   78   13    2  676   19]\n",
            " [   2   11   73   10  231   24    1   26   64  567]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [5. 5. 6. ... 9. 4. 7.]\n",
            "probabilities: (59950, 10) \n",
            " [5 5 6 ... 4 8 8]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (60, 784) (60,)\n",
            "updated train set: (60, 784) (60,) unique(labels): [ 2  6  8  6  7  7  5  4 10  5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59940, 784) (59940,)\n",
            "\n",
            "Train set: (60, 784) y: (60,)\n",
            "Val   set: (59940, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 3.846 s \n",
            "\n",
            "Accuracy rate for 64.760000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.98      0.27      0.42       980\n",
            "        1.0       0.86      0.91      0.88      1135\n",
            "        2.0       0.53      0.87      0.66      1032\n",
            "        3.0       0.66      0.44      0.53      1010\n",
            "        4.0       0.71      0.76      0.74       982\n",
            "        5.0       0.37      0.66      0.48       892\n",
            "        6.0       0.72      0.67      0.69       958\n",
            "        7.0       0.85      0.48      0.62      1028\n",
            "        8.0       0.74      0.69      0.72       974\n",
            "        9.0       0.59      0.68      0.63      1009\n",
            "\n",
            "avg / total       0.71      0.65      0.64     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 265    0   42   20    9  459  142    0   11   32]\n",
            " [   0 1035   70    0    2   10    1    0   15    2]\n",
            " [   1   18  893   19   12   26   14    5   31   13]\n",
            " [   0   25  124  447    1  338   16    7   41   11]\n",
            " [   0   13   64    0  751    4   23   14   37   76]\n",
            " [   1   28   19   73   39  588   33    2   25   84]\n",
            " [   0   13  190    0   82   22  640    0    5    6]\n",
            " [   0   34  168   11   40   51    2  498    7  217]\n",
            " [   2   33   44   96   16   55   14    4  676   34]\n",
            " [   2    8   62   14  100   16    1   56   67  683]]\n",
            "--------------------------------\n",
            "val predicted: (59940,) [5. 5. 6. ... 9. 9. 7.]\n",
            "probabilities: (59940, 10) \n",
            " [5 5 6 ... 9 7 7]\n",
            "trainset before (60, 784) (60,)\n",
            "trainset after (70, 784) (70,)\n",
            "updated train set: (70, 784) (70,) unique(labels): [ 3  8  9  6  8  8  6  5 12  5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59930, 784) (59930,)\n",
            "\n",
            "Train set: (70, 784) y: (70,)\n",
            "Val   set: (59930, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.427 s \n",
            "\n",
            "Accuracy rate for 69.280000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.59      0.73       980\n",
            "        1.0       0.82      0.96      0.88      1135\n",
            "        2.0       0.60      0.83      0.69      1032\n",
            "        3.0       0.67      0.43      0.52      1010\n",
            "        4.0       0.70      0.78      0.74       982\n",
            "        5.0       0.45      0.68      0.54       892\n",
            "        6.0       0.74      0.66      0.70       958\n",
            "        7.0       0.83      0.57      0.68      1028\n",
            "        8.0       0.74      0.72      0.73       974\n",
            "        9.0       0.67      0.67      0.67      1009\n",
            "\n",
            "avg / total       0.72      0.69      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 575    2   23   20    6  223  113    2    8    8]\n",
            " [   0 1086   16    0    1    6    1    0   23    2]\n",
            " [   8   39  854   19   16   23   17   13   30   13]\n",
            " [   0   28  102  431    2  344   23   10   62    8]\n",
            " [   0   16   47    0  770    5   31   30   18   65]\n",
            " [   2   30   14   72   27  604   26    2   37   78]\n",
            " [   9   19  169    0   93   25  636    0    4    3]\n",
            " [   0   50  131    3   54   57    1  591   10  131]\n",
            " [   3   44   16   86   20   55   14    4  704   28]\n",
            " [   3   14   58   14  113   14    0   62   54  677]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59930,) [0. 5. 6. ... 9. 7. 7.]\n",
            "probabilities: (59930, 10) \n",
            " [5 5 6 ... 7 7 7]\n",
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [ 3  9  9  9  9  9  8  6 13  5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.915 s \n",
            "\n",
            "Accuracy rate for 71.970000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.58      0.72       980\n",
            "        1.0       0.84      0.96      0.90      1135\n",
            "        2.0       0.66      0.79      0.72      1032\n",
            "        3.0       0.64      0.62      0.63      1010\n",
            "        4.0       0.75      0.81      0.78       982\n",
            "        5.0       0.46      0.58      0.51       892\n",
            "        6.0       0.78      0.82      0.80       958\n",
            "        7.0       0.81      0.62      0.70      1028\n",
            "        8.0       0.72      0.71      0.72       974\n",
            "        9.0       0.69      0.66      0.67      1009\n",
            "\n",
            "avg / total       0.74      0.72      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 569    0   26   29    6  199  120    3   19    9]\n",
            " [   0 1090    8    0    0   10    0    0   26    1]\n",
            " [   8   41  819   34   15   20   18   32   36    9]\n",
            " [   0   19   52  629    2  221   15   12   50   10]\n",
            " [   0   15   47    0  795    8   23   14   21   59]\n",
            " [   1   23    8  163   28  515   27    2   47   78]\n",
            " [   6   17   83    1   31   22  789    0    7    2]\n",
            " [   0   46  123    2   52   59    1  635    8  102]\n",
            " [   3   31   12  111   17   50   17    8  695   30]\n",
            " [   3   10   59   11  117   14    4   79   51  661]]\n",
            "--------------------------------\n",
            "val predicted: (59920,) [0. 5. 6. ... 9. 7. 7.]\n",
            "probabilities: (59920, 10) \n",
            " [0 5 8 ... 7 7 7]\n",
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [ 3 11 10 10  9 10  9  9 14  5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.597 s \n",
            "\n",
            "Accuracy rate for 73.200000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.58      0.73       980\n",
            "        1.0       0.86      0.96      0.91      1135\n",
            "        2.0       0.72      0.76      0.74      1032\n",
            "        3.0       0.63      0.60      0.61      1010\n",
            "        4.0       0.78      0.80      0.79       982\n",
            "        5.0       0.48      0.63      0.54       892\n",
            "        6.0       0.78      0.86      0.82       958\n",
            "        7.0       0.77      0.73      0.75      1028\n",
            "        8.0       0.74      0.70      0.72       974\n",
            "        9.0       0.69      0.66      0.68      1009\n",
            "\n",
            "avg / total       0.75      0.73      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 569    0   20   28    2  193  139   13    9    7]\n",
            " [   0 1090    6    1    0   15    0    0   23    0]\n",
            " [   7   39  787   54   10   19   18   59   32    7]\n",
            " [   0   16   48  602    1  253   13   21   46   10]\n",
            " [   0   14   47    0  788    6   21   16   30   60]\n",
            " [   1   22    4  135   27  558   23    8   36   78]\n",
            " [   4   17   64    1   21   17  824    2    7    1]\n",
            " [   0   35   46    2   41   46    1  751    4  102]\n",
            " [   3   28   11  114   13   55   19   13  685   33]\n",
            " [   2    7   54   13  111   11    2   94   49  666]]\n",
            "--------------------------------\n",
            "val predicted: (59910,) [0. 5. 8. ... 9. 7. 7.]\n",
            "probabilities: (59910, 10) \n",
            " [0 5 6 ... 7 7 7]\n",
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 4 11 12 11 10 10 13  9 14  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.263 s \n",
            "\n",
            "Accuracy rate for 74.030000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.63      0.76       980\n",
            "        1.0       0.88      0.96      0.92      1135\n",
            "        2.0       0.73      0.77      0.75      1032\n",
            "        3.0       0.64      0.60      0.62      1010\n",
            "        4.0       0.78      0.80      0.79       982\n",
            "        5.0       0.48      0.61      0.54       892\n",
            "        6.0       0.77      0.88      0.82       958\n",
            "        7.0       0.78      0.73      0.76      1028\n",
            "        8.0       0.76      0.70      0.73       974\n",
            "        9.0       0.70      0.69      0.69      1009\n",
            "\n",
            "avg / total       0.75      0.74      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 613    0   35   21    3  178  104    9    8    9]\n",
            " [   0 1090    3    1    0   14    1    0   23    3]\n",
            " [   8   28  794   52   11   12   41   56   22    8]\n",
            " [   0   14   48  606    1  248   20   20   42   11]\n",
            " [   0   11   41    0  786    6   20   13   30   75]\n",
            " [   1   20    9  138   25  545   33    6   37   78]\n",
            " [   7    9   45    0   30   16  841    2    7    1]\n",
            " [   0   32   51    3   42   56    2  753    6   83]\n",
            " [   4   29    9  117   13   52   24   16  680   30]\n",
            " [   2    6   57   12   98   12    0   91   36  695]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 5. 8. ... 9. 9. 7.]\n",
            "probabilities: (59900, 10) \n",
            " [0 5 8 ... 9 7 7]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [ 5 12 13 12 12 11 13 11 14  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.649 s \n",
            "\n",
            "Accuracy rate for 75.080000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.64      0.77       980\n",
            "        1.0       0.88      0.96      0.92      1135\n",
            "        2.0       0.79      0.77      0.78      1032\n",
            "        3.0       0.69      0.62      0.65      1010\n",
            "        4.0       0.75      0.81      0.78       982\n",
            "        5.0       0.51      0.69      0.58       892\n",
            "        6.0       0.80      0.87      0.83       958\n",
            "        7.0       0.73      0.76      0.75      1028\n",
            "        8.0       0.80      0.69      0.74       974\n",
            "        9.0       0.70      0.66      0.68      1009\n",
            "\n",
            "avg / total       0.76      0.75      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 632    0   17   13    4  199   92   15    5    3]\n",
            " [   0 1094    3    1    1   15    0    0   20    1]\n",
            " [   7   27  795   55   13   19   37   51   23    5]\n",
            " [   0   15   48  626    2  237   13   19   39   11]\n",
            " [   0   12   17    0  794    3   22   23   25   86]\n",
            " [   0   20    7   92   26  615   27   10   25   70]\n",
            " [  11    8   30    0   42   24  835    2    5    1]\n",
            " [   3   31   45    3   61   15    2  783    1   84]\n",
            " [   2   33    8  104   19   74   21   15  669   29]\n",
            " [   3    7   39   11   99   12    0  153   20  665]]\n",
            "--------------------------------\n",
            "val predicted: (59890,) [0. 5. 8. ... 9. 7. 7.]\n",
            "probabilities: (59890, 10) \n",
            " [0 5 8 ... 9 7 7]\n",
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [ 5 12 15 13 15 12 14 11 14  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.363 s \n",
            "\n",
            "Accuracy rate for 76.010000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.63      0.76       980\n",
            "        1.0       0.90      0.96      0.93      1135\n",
            "        2.0       0.73      0.78      0.76      1032\n",
            "        3.0       0.75      0.68      0.71      1010\n",
            "        4.0       0.73      0.83      0.78       982\n",
            "        5.0       0.53      0.69      0.60       892\n",
            "        6.0       0.82      0.87      0.84       958\n",
            "        7.0       0.78      0.74      0.76      1028\n",
            "        8.0       0.83      0.70      0.76       974\n",
            "        9.0       0.67      0.69      0.68      1009\n",
            "\n",
            "avg / total       0.77      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 616    0   25    9    2  207   89   12    4   16]\n",
            " [   0 1089    3    4    6    8    2    1   20    2]\n",
            " [   8   18  803   53   11   18   32   54   25   10]\n",
            " [   0   10   53  684    6  180   12   15   38   12]\n",
            " [   1    7   37    0  816    4    9    7    6   95]\n",
            " [   0   19   13   78   27  618   20   10   34   73]\n",
            " [  11    7   45    1   41   18  830    0    4    1]\n",
            " [   3   26   49    3   69   17    2  760    2   97]\n",
            " [   2   31   17   65   26   79   20   14  685   35]\n",
            " [   3    5   48   11  116   12    0  103   11  700]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59880,) [0. 5. 8. ... 9. 9. 7.]\n",
            "probabilities: (59880, 10) \n",
            " [0 5 8 ... 9 9 7]\n",
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [ 5 13 16 14 15 13 17 11 16 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.960 s \n",
            "\n",
            "Accuracy rate for 76.550000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.62      0.75       980\n",
            "        1.0       0.91      0.96      0.93      1135\n",
            "        2.0       0.76      0.77      0.77      1032\n",
            "        3.0       0.75      0.69      0.72      1010\n",
            "        4.0       0.77      0.81      0.79       982\n",
            "        5.0       0.54      0.71      0.61       892\n",
            "        6.0       0.82      0.90      0.86       958\n",
            "        7.0       0.82      0.68      0.74      1028\n",
            "        8.0       0.84      0.72      0.78       974\n",
            "        9.0       0.62      0.78      0.69      1009\n",
            "\n",
            "avg / total       0.78      0.77      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 607    0   22    9    2  215   91   10    8   16]\n",
            " [   0 1091    6    7    5    8    1    0   14    3]\n",
            " [   9   17  795   63   10   14   31   41   38   14]\n",
            " [   0   11   54  695    6  192   11    9   21   11]\n",
            " [   1    6   26    0  792    3   15    7    5  127]\n",
            " [   0   14   12   73   26  630   21    6   29   81]\n",
            " [   8    7   33    1   25   16  860    0    6    2]\n",
            " [   2   27   44    2   50   13    1  696    1  192]\n",
            " [   3   24   20   69   25   64   19   12  702   36]\n",
            " [   3    6   30   13   86    7    1   66   10  787]]\n",
            "--------------------------------\n",
            "val predicted: (59870,) [0. 5. 8. ... 9. 9. 7.]\n",
            "probabilities: (59870, 10) \n",
            " [0 5 8 ... 9 7 7]\n",
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [ 5 15 16 14 18 14 17 13 17 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.594 s \n",
            "\n",
            "Accuracy rate for 77.430000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.62      0.75       980\n",
            "        1.0       0.91      0.96      0.93      1135\n",
            "        2.0       0.77      0.77      0.77      1032\n",
            "        3.0       0.76      0.69      0.72      1010\n",
            "        4.0       0.73      0.89      0.80       982\n",
            "        5.0       0.55      0.74      0.63       892\n",
            "        6.0       0.82      0.90      0.86       958\n",
            "        7.0       0.83      0.71      0.77      1028\n",
            "        8.0       0.84      0.71      0.77       974\n",
            "        9.0       0.68      0.74      0.71      1009\n",
            "\n",
            "avg / total       0.79      0.77      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 606    0   19   11    3  209   94    9   10   19]\n",
            " [   0 1092    5    4   10    8    1    0   14    1]\n",
            " [   8   17  792   62   11   15   31   41   40   15]\n",
            " [   0   10   56  694    4  190   10   12   21   13]\n",
            " [   1    5   23    0  870    1   12    3    2   65]\n",
            " [   0   14   10   60   41  661   19    6   23   58]\n",
            " [   8    7   39    1   21   15  861    0    6    0]\n",
            " [   1   28   40    2   64   13    1  734    1  144]\n",
            " [   3   23   25   65   29   78   19   12  688   32]\n",
            " [   3    5   25   11  137    8    0   63   12  745]]\n",
            "--------------------------------\n",
            "val predicted: (59860,) [0. 5. 8. ... 9. 9. 7.]\n",
            "probabilities: (59860, 10) \n",
            " [0 5 8 ... 9 9 7]\n",
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 5 15 18 15 18 16 19 13 19 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.209 s \n",
            "\n",
            "Accuracy rate for 77.750000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.59      0.74       980\n",
            "        1.0       0.90      0.94      0.92      1135\n",
            "        2.0       0.79      0.82      0.80      1032\n",
            "        3.0       0.80      0.70      0.74      1010\n",
            "        4.0       0.75      0.85      0.80       982\n",
            "        5.0       0.53      0.79      0.63       892\n",
            "        6.0       0.83      0.89      0.86       958\n",
            "        7.0       0.87      0.70      0.78      1028\n",
            "        8.0       0.81      0.70      0.75       974\n",
            "        9.0       0.70      0.77      0.73      1009\n",
            "\n",
            "avg / total       0.80      0.78      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 582    0   20    7    3  263   87    3    3   12]\n",
            " [   0 1070    6    3    7    8    0    0   41    0]\n",
            " [   6   27  847   36   10   15   28   21   35    7]\n",
            " [   0   12   51  702    4  176   11   10   29   15]\n",
            " [   0    6   22    0  835    3   13    1    4   98]\n",
            " [   0   13   13   62   26  704   21    6   20   27]\n",
            " [   5    8   33    1   26   25  857    0    2    1]\n",
            " [   1   29   43    1   66   19    0  721    6  142]\n",
            " [   3   20   20   59   25  105   19    7  684   32]\n",
            " [   3    4   19    9  107   14    1   60   19  773]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 5. 6. ... 9. 9. 7.]\n",
            "probabilities: (59850, 10) \n",
            " [0 5 8 ... 9 9 7]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [ 5 15 19 15 20 16 20 15 23 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.543 s \n",
            "\n",
            "Accuracy rate for 79.720000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.59      0.74       980\n",
            "        1.0       0.91      0.94      0.93      1135\n",
            "        2.0       0.81      0.81      0.81      1032\n",
            "        3.0       0.82      0.69      0.75      1010\n",
            "        4.0       0.75      0.86      0.80       982\n",
            "        5.0       0.55      0.79      0.65       892\n",
            "        6.0       0.83      0.89      0.86       958\n",
            "        7.0       0.87      0.84      0.85      1028\n",
            "        8.0       0.80      0.76      0.78       974\n",
            "        9.0       0.79      0.76      0.77      1009\n",
            "\n",
            "avg / total       0.81      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 580    0   19    8    9  259   78   10    5   12]\n",
            " [   0 1068    5    3    6   10    1    0   41    1]\n",
            " [   6   23  839   30   11   13   36   23   44    7]\n",
            " [   0   10   48  700    3  175   12   14   35   13]\n",
            " [   0    6   20    0  849    2    8    1    6   90]\n",
            " [   0   12   11   55   31  702   22    9   25   25]\n",
            " [   5    7   29    1   33   23  857    0    2    1]\n",
            " [   1   30   28    3   55    0    1  865    7   38]\n",
            " [   2   13   19   37   25   86   19   10  744   19]\n",
            " [   3    4   21   13  106   11    0   66   17  768]]\n",
            "--------------------------------\n",
            "val predicted: (59840,) [0. 5. 8. ... 9. 9. 7.]\n",
            "probabilities: (59840, 10) \n",
            " [0 5 8 ... 9 7 7]\n",
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [ 6 17 20 16 21 17 21 16 24 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.117 s \n",
            "\n",
            "Accuracy rate for 80.780000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.67      0.79       980\n",
            "        1.0       0.90      0.96      0.93      1135\n",
            "        2.0       0.81      0.80      0.80      1032\n",
            "        3.0       0.83      0.69      0.75      1010\n",
            "        4.0       0.76      0.86      0.81       982\n",
            "        5.0       0.59      0.79      0.68       892\n",
            "        6.0       0.83      0.90      0.86       958\n",
            "        7.0       0.87      0.84      0.85      1028\n",
            "        8.0       0.81      0.78      0.80       974\n",
            "        9.0       0.80      0.76      0.78      1009\n",
            "\n",
            "avg / total       0.82      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 660    0   17    9    7  183   81    8    5   10]\n",
            " [   0 1094    5    1    2    7    1    0   25    0]\n",
            " [   7   23  821   29   10   12   35   25   63    7]\n",
            " [   2   13   46  696    3  177   12   11   39   11]\n",
            " [   0    7   21    0  848    1    8    1    6   90]\n",
            " [   1   13   12   49   32  708   21    9   24   23]\n",
            " [   7    8   30    0   33   19  858    0    2    1]\n",
            " [   2   39   28    3   54    0    1  861    3   37]\n",
            " [   2   14   15   37   25   72   17   10  763   19]\n",
            " [   3   11   20   11  106   12    0   64   13  769]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59830,) [0. 0. 3. ... 9. 9. 7.]\n",
            "probabilities: (59830, 10) \n",
            " [0 5 8 ... 9 7 7]\n",
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [ 8 18 21 16 23 17 21 17 25 14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.618 s \n",
            "\n",
            "Accuracy rate for 81.620000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.80      0.87       980\n",
            "        1.0       0.89      0.95      0.92      1135\n",
            "        2.0       0.82      0.79      0.80      1032\n",
            "        3.0       0.85      0.68      0.76      1010\n",
            "        4.0       0.75      0.86      0.80       982\n",
            "        5.0       0.63      0.80      0.71       892\n",
            "        6.0       0.87      0.89      0.88       958\n",
            "        7.0       0.88      0.84      0.86      1028\n",
            "        8.0       0.79      0.78      0.79       974\n",
            "        9.0       0.78      0.75      0.77      1009\n",
            "\n",
            "avg / total       0.82      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 787    0   14    4    6  121   33    4    4    7]\n",
            " [   0 1077    5    1    4    6    1    0   41    0]\n",
            " [  12   28  813   24   11    8   33   24   70    9]\n",
            " [   3   13   49  690    4  180   11   11   39   10]\n",
            " [   1    6   15    0  849    0    9    1    7   94]\n",
            " [   6   12   13   48   27  712   16    9   21   28]\n",
            " [   5    8   29    0   39   19  853    0    4    1]\n",
            " [   5   37   25    3   55    0    0  861    5   37]\n",
            " [   5   17   12   36   21   68   20    8  763   24]\n",
            " [   7   11   20    9  119   10    1   60   15  757]]\n",
            "--------------------------------\n",
            "val predicted: (59820,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59820, 10) \n",
            " [0 5 0 ... 9 9 7]\n",
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [ 8 18 22 17 24 18 22 19 26 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.232 s \n",
            "\n",
            "Accuracy rate for 81.800000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.80      0.87       980\n",
            "        1.0       0.90      0.95      0.92      1135\n",
            "        2.0       0.81      0.78      0.80      1032\n",
            "        3.0       0.83      0.69      0.75      1010\n",
            "        4.0       0.75      0.88      0.81       982\n",
            "        5.0       0.64      0.78      0.70       892\n",
            "        6.0       0.87      0.89      0.88       958\n",
            "        7.0       0.89      0.85      0.87      1028\n",
            "        8.0       0.79      0.78      0.79       974\n",
            "        9.0       0.78      0.77      0.78      1009\n",
            "\n",
            "avg / total       0.82      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 781    0   15    5    6  123   34    4    4    8]\n",
            " [   0 1079    5    1    2    3    3    0   39    3]\n",
            " [  12   30  806   25   10    8   39   24   69    9]\n",
            " [   3   13   42  694    4  172    7   14   38   23]\n",
            " [   1    5   18    0  868    0    8    0    6   76]\n",
            " [   6   13   13   58   29  696   16    8   21   32]\n",
            " [   5    7   34    1   38   18  852    0    3    0]\n",
            " [   5   31   21    3   51    0    1  874    4   38]\n",
            " [   5   16   11   40   24   65   19   14  756   24]\n",
            " [   6    6   24   10  120    8    1   49   11  774]]\n",
            "--------------------------------\n",
            "val predicted: (59810,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59810, 10) \n",
            " [0 5 0 ... 9 9 7]\n",
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [ 9 19 24 17 26 19 23 20 27 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.577 s \n",
            "\n",
            "Accuracy rate for 82.030000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.81      0.87       980\n",
            "        1.0       0.90      0.95      0.92      1135\n",
            "        2.0       0.83      0.78      0.80      1032\n",
            "        3.0       0.85      0.68      0.76      1010\n",
            "        4.0       0.74      0.89      0.81       982\n",
            "        5.0       0.64      0.79      0.70       892\n",
            "        6.0       0.86      0.88      0.87       958\n",
            "        7.0       0.89      0.85      0.87      1028\n",
            "        8.0       0.80      0.80      0.80       974\n",
            "        9.0       0.79      0.76      0.78      1009\n",
            "\n",
            "avg / total       0.83      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 790    0   11    6    5  113   39    3    3   10]\n",
            " [   0 1079    6    1    2    4    2    0   38    3]\n",
            " [  11   27  806   27   16    9   39   24   65    8]\n",
            " [   3   12   42  689    4  181    9   14   39   17]\n",
            " [   1    5   13    0  871    2    9    0    5   76]\n",
            " [   5   14   11   54   27  704   21    8   22   26]\n",
            " [   6    7   29    0   52   19  843    0    2    0]\n",
            " [   4   31   21    3   52    0    1  873    4   39]\n",
            " [   7   17   11   19   20   63   21   14  777   25]\n",
            " [   6    6   21   10  122   13    1   48   11  771]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [10 19 24 17 26 22 25 21 28 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.404 s \n",
            "\n",
            "Accuracy rate for 81.820000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.80      0.87       980\n",
            "        1.0       0.90      0.95      0.93      1135\n",
            "        2.0       0.84      0.78      0.81      1032\n",
            "        3.0       0.86      0.68      0.76      1010\n",
            "        4.0       0.76      0.87      0.81       982\n",
            "        5.0       0.63      0.79      0.70       892\n",
            "        6.0       0.85      0.87      0.86       958\n",
            "        7.0       0.88      0.85      0.87      1028\n",
            "        8.0       0.80      0.79      0.79       974\n",
            "        9.0       0.77      0.78      0.78      1009\n",
            "\n",
            "avg / total       0.83      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 782    0    9    6    2  123   44    2    2   10]\n",
            " [   0 1078    6    1    3    3    4    0   38    2]\n",
            " [  11   27  804   29   16   10   36   26   65    8]\n",
            " [   3   12   42  691    4  169   11   14   45   19]\n",
            " [   1    5    9    0  857    1   11    0    5   93]\n",
            " [   8   12    9   51   20  706   25    9   26   26]\n",
            " [   5    7   31    0   51   24  837    0    2    1]\n",
            " [   4   29   21    3   44    0    1  876    4   46]\n",
            " [   7   17   11   14   22   81   17   14  767   24]\n",
            " [   7    6   17   11  113   11    1   49   10  784]]\n",
            "--------------------------------\n",
            "val predicted: (59790,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59790, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [11 21 24 19 29 22 27 21 28 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.688 s \n",
            "\n",
            "Accuracy rate for 82.720000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.79      0.86       980\n",
            "        1.0       0.90      0.97      0.93      1135\n",
            "        2.0       0.84      0.77      0.81      1032\n",
            "        3.0       0.86      0.76      0.81      1010\n",
            "        4.0       0.75      0.89      0.81       982\n",
            "        5.0       0.66      0.79      0.72       892\n",
            "        6.0       0.85      0.89      0.87       958\n",
            "        7.0       0.89      0.85      0.87      1028\n",
            "        8.0       0.82      0.78      0.80       974\n",
            "        9.0       0.78      0.76      0.77      1009\n",
            "\n",
            "avg / total       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 778    0   10    7    5  127   40    3    2    8]\n",
            " [   0 1099    4    1    2    3    3    0   19    4]\n",
            " [  11   32  798   37   17   10   37   25   57    8]\n",
            " [   2   12   37  765    4  101   10   14   43   22]\n",
            " [   1    6    9    0  871    2   11    0    5   77]\n",
            " [  10   17    9   51   19  702   25    8   25   26]\n",
            " [   5    7   30    0   46   20  848    0    1    1]\n",
            " [   4   30   23    2   42    0    1  877    4   45]\n",
            " [   7   18   11   16   24   81   17   13  763   24]\n",
            " [   6    6   17   11  127   11    1   49   10  771]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59780,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59780, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [12 21 27 19 29 23 28 22 29 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.998 s \n",
            "\n",
            "Accuracy rate for 82.940000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.85      0.89       980\n",
            "        1.0       0.90      0.97      0.93      1135\n",
            "        2.0       0.82      0.77      0.79      1032\n",
            "        3.0       0.87      0.74      0.80      1010\n",
            "        4.0       0.76      0.88      0.81       982\n",
            "        5.0       0.68      0.78      0.73       892\n",
            "        6.0       0.86      0.88      0.87       958\n",
            "        7.0       0.89      0.87      0.88      1028\n",
            "        8.0       0.81      0.79      0.80       974\n",
            "        9.0       0.78      0.76      0.77      1009\n",
            "\n",
            "avg / total       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 831    0    9    4    6   88   29    1    2   10]\n",
            " [   0 1096    4    1    2    2    4    0   20    6]\n",
            " [  14   34  794   33   16    9   37   26   64    5]\n",
            " [   2   14   43  748    4  110    7   15   48   19]\n",
            " [   1    6   23    0  860    2   12    0    5   73]\n",
            " [   6   14   10   48   19  694   27    9   34   31]\n",
            " [   7    7   34    1   42   20  846    0    1    0]\n",
            " [   3   31   21    2   33    0    1  891    4   42]\n",
            " [   7   15   10   17   22   81   16   12  770   24]\n",
            " [   9    6   24    9  129   10    1   49    8  764]]\n",
            "--------------------------------\n",
            "val predicted: (59770,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59770, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [14 22 27 20 29 25 28 24 30 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.565 s \n",
            "\n",
            "Accuracy rate for 83.030000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.88      0.91       980\n",
            "        1.0       0.89      0.97      0.93      1135\n",
            "        2.0       0.83      0.77      0.80      1032\n",
            "        3.0       0.88      0.74      0.80      1010\n",
            "        4.0       0.76      0.85      0.80       982\n",
            "        5.0       0.69      0.78      0.73       892\n",
            "        6.0       0.87      0.88      0.87       958\n",
            "        7.0       0.88      0.86      0.87      1028\n",
            "        8.0       0.81      0.78      0.79       974\n",
            "        9.0       0.77      0.77      0.77      1009\n",
            "\n",
            "avg / total       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 865    0    6    5    6   62   24    2    2    8]\n",
            " [   0 1097    4    1    3    5    3    0   19    3]\n",
            " [  20   32  792   29   15   11   36   27   63    7]\n",
            " [   5   15   45  747    4  114    6   15   44   15]\n",
            " [   0    6   17    0  839    4   14    0    5   97]\n",
            " [   8   17   12   43   19  694   27    9   35   28]\n",
            " [   9    6   33    1   40   21  843    0    1    4]\n",
            " [   3   34   21    2   37    0    1  888    4   38]\n",
            " [  10   18    9   16   19   84   16   15  761   26]\n",
            " [  10    6   16    9  123   10    1   50    7  777]]\n",
            "--------------------------------\n",
            "val predicted: (59760,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59760, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [15 23 31 21 29 25 29 25 31 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.963 s \n",
            "\n",
            "Accuracy rate for 83.720000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.90      0.92       980\n",
            "        1.0       0.90      0.97      0.93      1135\n",
            "        2.0       0.82      0.82      0.82      1032\n",
            "        3.0       0.88      0.74      0.80      1010\n",
            "        4.0       0.76      0.85      0.81       982\n",
            "        5.0       0.71      0.78      0.74       892\n",
            "        6.0       0.88      0.88      0.88       958\n",
            "        7.0       0.88      0.86      0.87      1028\n",
            "        8.0       0.82      0.78      0.80       974\n",
            "        9.0       0.77      0.77      0.77      1009\n",
            "\n",
            "avg / total       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 883    0    7    3    5   49   22    1    2    8]\n",
            " [   0 1098    4    1    2    5    3    0   18    4]\n",
            " [  14   21  848   24    7    9   25   30   49    5]\n",
            " [   6   14   50  745    4  112    6   15   42   16]\n",
            " [   0    6   22    0  838    3   10    0    5   98]\n",
            " [   8   17   15   41   18  696   26    7   35   29]\n",
            " [   7    6   31    0   43   21  844    0    1    5]\n",
            " [   5   33   23    2   37    0    1  887    3   37]\n",
            " [  10   18   14   16   20   82   16   14  758   26]\n",
            " [  13    6   16   10  122    9    1   50    7  775]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [15 26 31 23 29 25 29 28 32 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 14.292 s \n",
            "\n",
            "Accuracy rate for 83.810000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.90      0.92       980\n",
            "        1.0       0.89      0.98      0.93      1135\n",
            "        2.0       0.83      0.81      0.82      1032\n",
            "        3.0       0.88      0.74      0.80      1010\n",
            "        4.0       0.76      0.85      0.80       982\n",
            "        5.0       0.71      0.78      0.75       892\n",
            "        6.0       0.88      0.88      0.88       958\n",
            "        7.0       0.87      0.88      0.88      1028\n",
            "        8.0       0.82      0.77      0.80       974\n",
            "        9.0       0.79      0.77      0.78      1009\n",
            "\n",
            "avg / total       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 886    0    7    4    5   49   22    1    1    5]\n",
            " [   0 1109    4    1    0    1    3    1   15    1]\n",
            " [  15   26  837   25    8    8   25   33   49    6]\n",
            " [   6   18   46  747    4  112    6   18   39   14]\n",
            " [   0    8   23    0  830    3   11    4    5   98]\n",
            " [   8   15   13   44   19  696   26    7   37   27]\n",
            " [   7   10   30    0   44   19  843    1    1    3]\n",
            " [   4   30   17    2   32    0    1  908    5   29]\n",
            " [  11   25   14   17   18   80   16   16  753   24]\n",
            " [  13    6   14    9  127    7    1   50   10  772]]\n",
            "--------------------------------\n",
            "val predicted: (59740,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59740, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [17 28 31 24 30 26 29 30 33 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 14.665 s \n",
            "\n",
            "Accuracy rate for 83.720000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.91      0.92       980\n",
            "        1.0       0.89      0.98      0.93      1135\n",
            "        2.0       0.83      0.81      0.82      1032\n",
            "        3.0       0.87      0.74      0.80      1010\n",
            "        4.0       0.78      0.85      0.81       982\n",
            "        5.0       0.71      0.79      0.75       892\n",
            "        6.0       0.89      0.87      0.88       958\n",
            "        7.0       0.87      0.89      0.88      1028\n",
            "        8.0       0.82      0.76      0.79       974\n",
            "        9.0       0.79      0.77      0.78      1009\n",
            "\n",
            "avg / total       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 889    0    8    4    4   44   23    1    2    5]\n",
            " [   0 1109    4    1    0    1    3    1   15    1]\n",
            " [  13   26  833   25    9   11   24   35   49    7]\n",
            " [   7   18   44  747    4  111    5   18   41   15]\n",
            " [   0    8   22    0  834    4   11    3    6   94]\n",
            " [   5   15   12   46   14  706   25    6   37   26]\n",
            " [   8   11   34    0   44   23  832    1    1    4]\n",
            " [   4   30   17    2   30    0    1  910    5   29]\n",
            " [  11   25   14   23   16   92   15   18  738   22]\n",
            " [  12    6   16   10  121    8    1   51   10  774]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59730,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59730, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [17 28 33 24 33 27 30 30 35 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 15.567 s \n",
            "\n",
            "Accuracy rate for 83.950000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.90      0.92       980\n",
            "        1.0       0.89      0.98      0.93      1135\n",
            "        2.0       0.82      0.81      0.82      1032\n",
            "        3.0       0.87      0.74      0.80      1010\n",
            "        4.0       0.77      0.86      0.81       982\n",
            "        5.0       0.71      0.80      0.75       892\n",
            "        6.0       0.89      0.87      0.88       958\n",
            "        7.0       0.88      0.88      0.88      1028\n",
            "        8.0       0.83      0.78      0.81       974\n",
            "        9.0       0.79      0.75      0.77      1009\n",
            "\n",
            "avg / total       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 885    0    9    5    4   47   22    1    2    5]\n",
            " [   0 1108    4    1    1    2    3    1   14    1]\n",
            " [  14   25  838   24    9   13   27   25   51    6]\n",
            " [   7   18   53  746    4  109    5   13   40   15]\n",
            " [   0    8   14    0  847    3   12    2    5   91]\n",
            " [   5   14   16   49   15  710   22    7   28   26]\n",
            " [   8   10   30    1   45   25  834    0    1    4]\n",
            " [   4   27   23    2   30    1    1  905    5   30]\n",
            " [  11   25   15   15   14   78   15   17  762   22]\n",
            " [  12    6   17   10  131    6    1   55   11  760]]\n",
            "--------------------------------\n",
            "val predicted: (59720,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59720, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [18 28 34 25 34 29 31 30 37 24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 15.773 s \n",
            "\n",
            "Accuracy rate for 84.380000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.92      0.93       980\n",
            "        1.0       0.90      0.98      0.94      1135\n",
            "        2.0       0.84      0.81      0.82      1032\n",
            "        3.0       0.90      0.72      0.80      1010\n",
            "        4.0       0.76      0.86      0.81       982\n",
            "        5.0       0.72      0.84      0.77       892\n",
            "        6.0       0.88      0.87      0.87       958\n",
            "        7.0       0.88      0.88      0.88      1028\n",
            "        8.0       0.83      0.79      0.81       974\n",
            "        9.0       0.80      0.75      0.77      1009\n",
            "\n",
            "avg / total       0.85      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 897    0    3    4    4   41   23    1    2    5]\n",
            " [   0 1108    4    1    1    1    5    1   13    1]\n",
            " [  15   22  837   24   12   11   30   24   51    6]\n",
            " [   6   21   51  730    4  126    6   13   39   14]\n",
            " [   0    7   13    0  848    4   12    2    7   89]\n",
            " [   4   15   10   21   15  748   22    9   26   22]\n",
            " [   7   10   27    1   52   24  833    0    1    3]\n",
            " [   5   27   22    2   30    1    1  905    6   29]\n",
            " [   9   17   14   14   14   79   15   17  773   22]\n",
            " [  11    7   17   11  132    6    1   55   10  759]]\n",
            "--------------------------------\n",
            "val predicted: (59710,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59710, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [18 28 36 26 35 30 31 32 39 25] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 16.162 s \n",
            "\n",
            "Accuracy rate for 85.020000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.92      0.93       980\n",
            "        1.0       0.90      0.98      0.94      1135\n",
            "        2.0       0.84      0.82      0.83      1032\n",
            "        3.0       0.90      0.74      0.82      1010\n",
            "        4.0       0.77      0.89      0.82       982\n",
            "        5.0       0.73      0.84      0.78       892\n",
            "        6.0       0.88      0.87      0.87       958\n",
            "        7.0       0.89      0.88      0.88      1028\n",
            "        8.0       0.85      0.80      0.83       974\n",
            "        9.0       0.82      0.77      0.79      1009\n",
            "\n",
            "avg / total       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 897    0    5    2    4   42   22    1    4    3]\n",
            " [   0 1108    4    1    1    1    5    1   13    1]\n",
            " [  15   22  842   32   12   10   30   24   39    6]\n",
            " [   6   18   41  751    4  123    6   13   33   15]\n",
            " [   0    7   11    0  872    2   12    2    6   70]\n",
            " [   6   16   11   16   14  747   25    8   25   24]\n",
            " [   7   10   31    1   51   25  830    0    1    2]\n",
            " [   7   28   24    3   35    1    1  901    3   25]\n",
            " [   8   17   16   12   14   70   16   14  782   25]\n",
            " [  11    7   17   12  127    6    1   47    9  772]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [19 29 36 26 37 32 31 34 40 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 16.577 s \n",
            "\n",
            "Accuracy rate for 85.360000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.92      0.93       980\n",
            "        1.0       0.90      0.98      0.94      1135\n",
            "        2.0       0.84      0.81      0.83      1032\n",
            "        3.0       0.90      0.74      0.81      1010\n",
            "        4.0       0.78      0.89      0.83       982\n",
            "        5.0       0.73      0.83      0.78       892\n",
            "        6.0       0.88      0.86      0.87       958\n",
            "        7.0       0.89      0.88      0.89      1028\n",
            "        8.0       0.84      0.80      0.82       974\n",
            "        9.0       0.84      0.79      0.81      1009\n",
            "\n",
            "avg / total       0.86      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 903    0    6    2    3   36   21    1    4    4]\n",
            " [   0 1108    4    2    1    2    5    1   12    0]\n",
            " [  15   20  841   32   11    9   32   25   42    5]\n",
            " [   6   17   42  748    4  125    6   13   35   14]\n",
            " [   0    8   11    0  872    2   12    3    7   67]\n",
            " [   6   17   10   17   13  744   24    7   31   23]\n",
            " [   8    8   31    0   55   26  828    0    1    1]\n",
            " [   4   28   22    3   40    1    1  907    3   19]\n",
            " [   9   17   15   15   12   68   15   15  784   24]\n",
            " [  10    7   15   10  103    6    1   46   10  801]]\n",
            "--------------------------------\n",
            "val predicted: (59690,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59690, 10) \n",
            " [0 5 0 ... 9 9 7]\n",
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [19 31 37 27 37 32 31 38 40 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 17.115 s \n",
            "\n",
            "Accuracy rate for 85.650000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.92      0.93       980\n",
            "        1.0       0.90      0.98      0.94      1135\n",
            "        2.0       0.84      0.82      0.83      1032\n",
            "        3.0       0.91      0.75      0.82      1010\n",
            "        4.0       0.80      0.89      0.84       982\n",
            "        5.0       0.73      0.83      0.78       892\n",
            "        6.0       0.88      0.86      0.87       958\n",
            "        7.0       0.89      0.89      0.89      1028\n",
            "        8.0       0.85      0.80      0.82       974\n",
            "        9.0       0.83      0.81      0.82      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 904    0    6    2    3   34   21    1    4    5]\n",
            " [   0 1108    4    1    1    2    5    1   12    1]\n",
            " [  15   21  849   23   12    9   31   25   42    5]\n",
            " [   6   16   43  754    3  123    6   14   31   14]\n",
            " [   0    8   10    0  870    3   13    4    7   67]\n",
            " [   6   17    9   17   13  743   24    8   31   24]\n",
            " [   8   10   31    0   54   25  828    0    1    1]\n",
            " [   3   28   23    3   33    2    1  912    3   20]\n",
            " [   9   17   15   17   14   65   15   16  781   25]\n",
            " [   9    8   15   11   90    7    1   42   10  816]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59680,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59680, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [20 31 38 30 37 33 34 39 40 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 17.578 s \n",
            "\n",
            "Accuracy rate for 85.260000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.92      0.93       980\n",
            "        1.0       0.90      0.98      0.94      1135\n",
            "        2.0       0.84      0.79      0.81      1032\n",
            "        3.0       0.89      0.75      0.82      1010\n",
            "        4.0       0.80      0.89      0.84       982\n",
            "        5.0       0.72      0.84      0.78       892\n",
            "        6.0       0.85      0.86      0.86       958\n",
            "        7.0       0.89      0.89      0.89      1028\n",
            "        8.0       0.85      0.79      0.82       974\n",
            "        9.0       0.83      0.80      0.82      1009\n",
            "\n",
            "avg / total       0.86      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 905    0    2    2    2   41   21    1    3    3]\n",
            " [   0 1109    5    0    1    2    4    1   12    1]\n",
            " [  15   21  815   33    9   17   54   20   44    4]\n",
            " [   5   15   44  759    3  110    8   15   36   15]\n",
            " [   1    8    8    0  870    5   16    3    6   65]\n",
            " [   6   15    7   26   11  747   20    8   24   28]\n",
            " [   7   10   29    0   53   34  824    0    0    1]\n",
            " [   3   28   24    4   32    1    1  912    3   20]\n",
            " [  10   17   19   16   14   68   16   16  773   25]\n",
            " [   9    9   19   10   89    8    0   44    9  812]]\n",
            "--------------------------------\n",
            "val predicted: (59670,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59670, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [21 32 38 30 37 34 34 42 42 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.096 s \n",
            "\n",
            "Accuracy rate for 85.370000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.93      0.93       980\n",
            "        1.0       0.90      0.98      0.93      1135\n",
            "        2.0       0.84      0.79      0.81      1032\n",
            "        3.0       0.90      0.75      0.81      1010\n",
            "        4.0       0.80      0.88      0.84       982\n",
            "        5.0       0.73      0.86      0.79       892\n",
            "        6.0       0.85      0.86      0.86       958\n",
            "        7.0       0.90      0.89      0.89      1028\n",
            "        8.0       0.85      0.80      0.82       974\n",
            "        9.0       0.84      0.80      0.82      1009\n",
            "\n",
            "avg / total       0.86      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 908    0    2    3    2   38   20    1    2    4]\n",
            " [   0 1107    5    0    1    4    4    0   13    1]\n",
            " [  15   24  813   32    9   15   55   19   46    4]\n",
            " [   5   15   43  755    4  114    8   14   38   14]\n",
            " [   1    8   10    0  867    2   16    4    6   68]\n",
            " [   4   14    8   23    9  770   19    5   22   18]\n",
            " [   9   10   29    0   52   37  820    0    0    1]\n",
            " [   3   28   24    4   31    2    1  914    3   18]\n",
            " [  10   18   19   15   13   63   16   15  779   26]\n",
            " [   9    9   18   11   92    7    1   47   11  804]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59660, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [22 35 38 33 38 34 34 42 43 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.475 s \n",
            "\n",
            "Accuracy rate for 85.370000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.93      0.93       980\n",
            "        1.0       0.90      0.98      0.94      1135\n",
            "        2.0       0.84      0.79      0.81      1032\n",
            "        3.0       0.88      0.76      0.82      1010\n",
            "        4.0       0.80      0.88      0.84       982\n",
            "        5.0       0.74      0.86      0.79       892\n",
            "        6.0       0.85      0.85      0.85       958\n",
            "        7.0       0.90      0.89      0.89      1028\n",
            "        8.0       0.86      0.79      0.82       974\n",
            "        9.0       0.84      0.79      0.82      1009\n",
            "\n",
            "avg / total       0.86      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 907    0    2    6    3   36   19    1    2    4]\n",
            " [   0 1108    5    0    1    4    4    0   12    1]\n",
            " [  16   24  812   32    9   15   55   19   46    4]\n",
            " [   3   15   46  768    3  110    8   14   29   14]\n",
            " [   1    8   10    0  868    2   16    4    6   67]\n",
            " [   4   14    8   26   10  767   19    5   21   18]\n",
            " [   9   10   29    1   52   37  819    0    0    1]\n",
            " [   3   28   24    4   32    2    1  913    3   18]\n",
            " [  10   18   18   20   16   63   16   14  773   26]\n",
            " [   9    9   18   11   95    6    1   47   11  802]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [22 37 40 33 39 35 35 43 44 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.790 s \n",
            "\n",
            "Accuracy rate for 85.190000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.91      0.93       980\n",
            "        1.0       0.90      0.97      0.93      1135\n",
            "        2.0       0.84      0.79      0.81      1032\n",
            "        3.0       0.89      0.76      0.82      1010\n",
            "        4.0       0.79      0.89      0.84       982\n",
            "        5.0       0.74      0.85      0.79       892\n",
            "        6.0       0.83      0.85      0.84       958\n",
            "        7.0       0.90      0.88      0.89      1028\n",
            "        8.0       0.86      0.80      0.83       974\n",
            "        9.0       0.83      0.79      0.81      1009\n",
            "\n",
            "avg / total       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 892    0    2    5    2   36   34    1    2    6]\n",
            " [   0 1106    7    0    1    4    3    0   13    1]\n",
            " [  15   25  813   28    8   13   63   18   45    4]\n",
            " [   4   15   41  771    3  110   10   13   27   16]\n",
            " [   1    6   10    0  875    2   15    4    5   64]\n",
            " [   6   15    9   26    9  762   20    5   20   20]\n",
            " [   5   10   32    1   59   32  818    0    0    1]\n",
            " [   3   29   23    4   37    2    1  906    3   20]\n",
            " [  10   16   17   20   13   62   18   12  780   26]\n",
            " [  11    9   16   11  101    5    1   47   12  796]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59640, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [23 37 41 34 40 36 37 44 45 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.099 s \n",
            "\n",
            "Accuracy rate for 85.180000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.91      0.93       980\n",
            "        1.0       0.90      0.98      0.94      1135\n",
            "        2.0       0.83      0.78      0.81      1032\n",
            "        3.0       0.88      0.77      0.82      1010\n",
            "        4.0       0.79      0.89      0.83       982\n",
            "        5.0       0.75      0.85      0.79       892\n",
            "        6.0       0.83      0.85      0.84       958\n",
            "        7.0       0.90      0.88      0.89      1028\n",
            "        8.0       0.86      0.80      0.83       974\n",
            "        9.0       0.84      0.79      0.81      1009\n",
            "\n",
            "avg / total       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 896    0    2    5    2   36   32    1    2    4]\n",
            " [   0 1108    7    1    1    3    3    0   11    1]\n",
            " [  14   24  807   34    9   11   63   18   48    4]\n",
            " [   4   16   45  781    3  102    9   10   25   15]\n",
            " [   1    7   11    0  870    4   15    4    4   66]\n",
            " [   6   14    9   32   10  756   20    5   20   20]\n",
            " [   7   10   32    1   61   32  814    0    0    1]\n",
            " [   3   29   22    4   37    2    1  907    2   21]\n",
            " [  10   16   18   18   13   63   17   13  781   25]\n",
            " [  11    8   16   11  101    5    1   46   12  798]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59630,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59630, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [23 37 43 34 42 37 39 44 48 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.676 s \n",
            "\n",
            "Accuracy rate for 85.620000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.91      0.93       980\n",
            "        1.0       0.90      0.98      0.94      1135\n",
            "        2.0       0.83      0.80      0.81      1032\n",
            "        3.0       0.88      0.77      0.82      1010\n",
            "        4.0       0.79      0.89      0.84       982\n",
            "        5.0       0.75      0.86      0.80       892\n",
            "        6.0       0.85      0.85      0.85       958\n",
            "        7.0       0.91      0.89      0.90      1028\n",
            "        8.0       0.86      0.81      0.83       974\n",
            "        9.0       0.85      0.79      0.82      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 896    0    1    5    2   37   32    1    2    4]\n",
            " [   0 1108    6    1    1    3    3    0   12    1]\n",
            " [  13   24  822   32    9   10   50   18   51    3]\n",
            " [   4   16   49  777    3   99    7   11   30   14]\n",
            " [   1    6    9    0  877    5   13    3    6   62]\n",
            " [   5   14   10   32    9  767   17    5   15   18]\n",
            " [   7    9   34    1   58   30  817    0    1    1]\n",
            " [   3   29   22    4   34    1    1  910    3   21]\n",
            " [  10   16   18   21   17   62   16    9  792   13]\n",
            " [  11    9   17    9  101    7    0   47   12  796]]\n",
            "--------------------------------\n",
            "val predicted: (59620,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59620, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [25 37 45 34 43 38 41 45 48 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.883 s \n",
            "\n",
            "Accuracy rate for 85.470000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.91      0.93       980\n",
            "        1.0       0.91      0.97      0.94      1135\n",
            "        2.0       0.83      0.79      0.81      1032\n",
            "        3.0       0.88      0.75      0.81      1010\n",
            "        4.0       0.79      0.90      0.84       982\n",
            "        5.0       0.72      0.86      0.79       892\n",
            "        6.0       0.85      0.86      0.86       958\n",
            "        7.0       0.90      0.88      0.89      1028\n",
            "        8.0       0.86      0.81      0.83       974\n",
            "        9.0       0.86      0.79      0.82      1009\n",
            "\n",
            "avg / total       0.86      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 893    0    3    7    1   32   35    2    2    5]\n",
            " [   0 1106    5    1    1    9    2    0   10    1]\n",
            " [  14   27  815   30   12   13   50   18   49    4]\n",
            " [   4    8   47  757    3  123    8   14   33   13]\n",
            " [   0    5    8    0  885    6   14    2    6   56]\n",
            " [   6   12    8   28   11  770   17    6   14   20]\n",
            " [   8    8   34    1   51   28  827    0    0    1]\n",
            " [   3   26   28    4   34    1    0  909    3   20]\n",
            " [   9   14   17   21   16   70   17    8  788   14]\n",
            " [  12    5   15   10  101   11    0   46   12  797]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59610, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [27 39 47 34 44 39 41 47 48 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 20.392 s \n",
            "\n",
            "Accuracy rate for 85.620000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.93      0.92       980\n",
            "        1.0       0.92      0.97      0.94      1135\n",
            "        2.0       0.84      0.78      0.81      1032\n",
            "        3.0       0.88      0.75      0.81      1010\n",
            "        4.0       0.80      0.90      0.85       982\n",
            "        5.0       0.73      0.86      0.79       892\n",
            "        6.0       0.86      0.87      0.87       958\n",
            "        7.0       0.90      0.89      0.89      1028\n",
            "        8.0       0.86      0.80      0.83       974\n",
            "        9.0       0.86      0.79      0.82      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 916    0    2    6    0   24   27    1    2    2]\n",
            " [   0 1106    5    1    1    9    2    0   10    1]\n",
            " [  18   26  810   30   11   12   49   22   50    4]\n",
            " [   7    8   46  759    3  124    6   13   31   13]\n",
            " [   4    5    7    0  884    6   13    2    5   56]\n",
            " [   9   12    9   29   10  767   17    6   14   19]\n",
            " [  11    8   26    1   53   27  831    0    0    1]\n",
            " [   2   24   27    3   33    1    0  912    4   22]\n",
            " [  20   14   17   19   16   69   17    8  781   13]\n",
            " [  17    5   13   10   99   10    0   48   11  796]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [27 39 50 34 46 40 42 48 50 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 20.586 s \n",
            "\n",
            "Accuracy rate for 85.780000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.93      0.92       980\n",
            "        1.0       0.92      0.97      0.95      1135\n",
            "        2.0       0.85      0.80      0.82      1032\n",
            "        3.0       0.90      0.75      0.82      1010\n",
            "        4.0       0.79      0.90      0.84       982\n",
            "        5.0       0.73      0.86      0.79       892\n",
            "        6.0       0.87      0.86      0.87       958\n",
            "        7.0       0.90      0.89      0.90      1028\n",
            "        8.0       0.85      0.81      0.83       974\n",
            "        9.0       0.86      0.79      0.82      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 916    0    2    6    0   25   25    1    3    2]\n",
            " [   0 1106    3    1    3   10    1    0   10    1]\n",
            " [  18   19  822   25   11   12   51   22   48    4]\n",
            " [   8    9   45  756    4  123    5   13   36   11]\n",
            " [   3    4    7    0  884    6   12    2    7   57]\n",
            " [   8   12    9   29   10  770   14    7   14   19]\n",
            " [  11   10   29    0   53   29  825    0    0    1]\n",
            " [   2   19   26    2   34    1    0  917    5   22]\n",
            " [  20   14   16   14   16   70   16    6  786   16]\n",
            " [  17    5   13    9   98   10    0   49   12  796]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59590, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [29 42 51 36 46 40 42 48 51 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 21.032 s \n",
            "\n",
            "Accuracy rate for 86.010000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.93      0.92       980\n",
            "        1.0       0.93      0.98      0.95      1135\n",
            "        2.0       0.85      0.81      0.83      1032\n",
            "        3.0       0.90      0.77      0.83      1010\n",
            "        4.0       0.80      0.90      0.85       982\n",
            "        5.0       0.74      0.85      0.79       892\n",
            "        6.0       0.87      0.86      0.87       958\n",
            "        7.0       0.90      0.89      0.90      1028\n",
            "        8.0       0.85      0.80      0.83       974\n",
            "        9.0       0.85      0.79      0.82      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 916    0    2    6    0   25   25    1    3    2]\n",
            " [   0 1112    2    1    0   10    1    0    8    1]\n",
            " [  18   14  833   19   11   12   45   23   53    4]\n",
            " [   8    4   46  775    4  111    4   11   38    9]\n",
            " [   3    5    6    0  882    6   12    2    7   59]\n",
            " [   9   14    9   32    8  762   15    7   14   22]\n",
            " [  12   10   31    0   52   29  823    0    0    1]\n",
            " [   3   23   22    3   34    1    0  915    4   23]\n",
            " [  20   15   16   17   16   67   16    7  784   16]\n",
            " [  16    5   13   12   96   10    0   46   12  799]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59580,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59580, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [29 42 52 36 47 40 44 51 53 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 21.427 s \n",
            "\n",
            "Accuracy rate for 86.050000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.93      0.92       980\n",
            "        1.0       0.93      0.98      0.95      1135\n",
            "        2.0       0.85      0.81      0.83      1032\n",
            "        3.0       0.90      0.77      0.83      1010\n",
            "        4.0       0.81      0.89      0.85       982\n",
            "        5.0       0.74      0.85      0.79       892\n",
            "        6.0       0.88      0.86      0.87       958\n",
            "        7.0       0.88      0.90      0.89      1028\n",
            "        8.0       0.85      0.81      0.83       974\n",
            "        9.0       0.85      0.78      0.82      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 915    0    2    6    0   27   25    1    3    1]\n",
            " [   0 1112    2    1    0   10    1    0    8    1]\n",
            " [  18   13  833   20   10   14   45   22   53    4]\n",
            " [   8    3   40  779    3  107    4   17   38   11]\n",
            " [   3    5   11    0  874    6   12    4    4   63]\n",
            " [   9   15    7   31    8  762   15    8   14   23]\n",
            " [  11    9   29    0   52   29  827    0    0    1]\n",
            " [   2   24   31    3   23    1    0  924    5   15]\n",
            " [  20   16   14   17   15   62   16    9  788   17]\n",
            " [  13    5   11   12   90   13    0   63   11  791]]\n",
            "--------------------------------\n",
            "val predicted: (59570,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59570, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [31 42 53 39 48 41 44 52 53 37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 22.013 s \n",
            "\n",
            "Accuracy rate for 85.960000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.93      0.93       980\n",
            "        1.0       0.92      0.98      0.95      1135\n",
            "        2.0       0.84      0.80      0.82      1032\n",
            "        3.0       0.87      0.78      0.82      1010\n",
            "        4.0       0.81      0.89      0.85       982\n",
            "        5.0       0.75      0.85      0.80       892\n",
            "        6.0       0.88      0.87      0.87       958\n",
            "        7.0       0.88      0.90      0.89      1028\n",
            "        8.0       0.86      0.80      0.83       974\n",
            "        9.0       0.85      0.78      0.82      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 915    0    2    4    0   29   25    2    2    1]\n",
            " [   0 1112    2    2    0   10    1    0    8    0]\n",
            " [  18   15  826   30    9   12   44   21   53    4]\n",
            " [   7    4   47  785    2   98    3   18   35   11]\n",
            " [   3    5   12    1  872    6   12    4    4   63]\n",
            " [   8   14    8   35    8  761   15    7   13   23]\n",
            " [  12    8   25    0   52   29  830    1    0    1]\n",
            " [   2   24   30    5   22    2    0  924    4   15]\n",
            " [  19   17   17   25   15   57   16   10  781   17]\n",
            " [  12    5   12   19   90   10    0   62    9  790]]\n",
            "--------------------------------\n",
            "val predicted: (59560,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59560, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [31 42 54 39 49 46 44 52 55 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 22.345 s \n",
            "\n",
            "Accuracy rate for 85.960000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.93      0.93       980\n",
            "        1.0       0.93      0.98      0.95      1135\n",
            "        2.0       0.84      0.81      0.82      1032\n",
            "        3.0       0.87      0.78      0.82      1010\n",
            "        4.0       0.82      0.89      0.85       982\n",
            "        5.0       0.73      0.87      0.79       892\n",
            "        6.0       0.88      0.87      0.87       958\n",
            "        7.0       0.88      0.90      0.89      1028\n",
            "        8.0       0.87      0.79      0.83       974\n",
            "        9.0       0.85      0.78      0.82      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 910    0    1    4    0   37   23    3    1    1]\n",
            " [   0 1111    2    2    1   10    1    0    8    0]\n",
            " [  18   15  831   31    9   12   43   21   48    4]\n",
            " [   6    3   41  784    2  112    1   18   32   11]\n",
            " [   3    6   10    1  873    6   12    4    4   63]\n",
            " [   3   12   10   36    7  776   14    7    5   22]\n",
            " [  12   10   25    0   49   31  829    1    0    1]\n",
            " [   2   22   34    4   22    0    0  925    4   15]\n",
            " [  18   17   20   21   16   72   15   10  767   18]\n",
            " [  14    5   13   17   89   10    0   62    9  790]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [34 43 55 41 51 47 44 52 55 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 22.907 s \n",
            "\n",
            "Accuracy rate for 86.000000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.92      0.92       980\n",
            "        1.0       0.93      0.98      0.95      1135\n",
            "        2.0       0.85      0.81      0.83      1032\n",
            "        3.0       0.88      0.79      0.83      1010\n",
            "        4.0       0.82      0.89      0.85       982\n",
            "        5.0       0.72      0.87      0.79       892\n",
            "        6.0       0.88      0.86      0.87       958\n",
            "        7.0       0.88      0.90      0.89      1028\n",
            "        8.0       0.88      0.79      0.83       974\n",
            "        9.0       0.85      0.78      0.82      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 903    0    1    4    0   41   26    3    1    1]\n",
            " [   0 1111    2    2    1   10    1    0    8    0]\n",
            " [  17   15  832   34    9   13   43   20   45    4]\n",
            " [   6    4   36  793    2  111    1   19   27   11]\n",
            " [   3    6    7    1  875    6   13    4    4   63]\n",
            " [   5   10   11   32    9  777   14    7    5   22]\n",
            " [  12   10   29    1   49   30  825    1    0    1]\n",
            " [   2   22   33    5   23    0    0  924    4   15]\n",
            " [  18   17   19   16   17   76   14   10  769   18]\n",
            " [  14    5   13   16   88   11    0   62    9  791]]\n",
            "--------------------------------\n",
            "val predicted: (59540,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59540, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [34 45 56 43 52 47 45 53 57 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.085 s \n",
            "\n",
            "Accuracy rate for 86.240000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.92      0.92       980\n",
            "        1.0       0.92      0.98      0.95      1135\n",
            "        2.0       0.85      0.80      0.83      1032\n",
            "        3.0       0.88      0.80      0.84      1010\n",
            "        4.0       0.82      0.91      0.86       982\n",
            "        5.0       0.73      0.87      0.79       892\n",
            "        6.0       0.88      0.86      0.87       958\n",
            "        7.0       0.88      0.90      0.89      1028\n",
            "        8.0       0.88      0.79      0.83       974\n",
            "        9.0       0.87      0.79      0.83      1009\n",
            "\n",
            "avg / total       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 902    0    1    5    0   41   26    3    1    1]\n",
            " [   0 1110    2    2    1   10    1    0    9    0]\n",
            " [  18   16  828   32   11   13   44   20   46    4]\n",
            " [   6    5   34  805    2  101    1   18   27   11]\n",
            " [   3    6    6    1  891    6   13    3    4   49]\n",
            " [   5    9    8   33   12  778   14    8    5   20]\n",
            " [  12   10   28    1   51   30  824    1    0    1]\n",
            " [   2   23   35    4   23    0    0  922    4   15]\n",
            " [  18   17   17   18   16   75   14   10  770   19]\n",
            " [  14    5   13   15   85   12    0   63    8  794]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59530,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59530, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [36 46 57 43 53 47 47 54 57 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.180 s \n",
            "\n",
            "Accuracy rate for 86.600000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.92      0.92       980\n",
            "        1.0       0.93      0.98      0.95      1135\n",
            "        2.0       0.85      0.82      0.83      1032\n",
            "        3.0       0.88      0.80      0.84      1010\n",
            "        4.0       0.83      0.91      0.87       982\n",
            "        5.0       0.74      0.87      0.80       892\n",
            "        6.0       0.88      0.89      0.88       958\n",
            "        7.0       0.88      0.90      0.89      1028\n",
            "        8.0       0.89      0.79      0.83       974\n",
            "        9.0       0.87      0.78      0.83      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 898    0    5    6    0   40   27    2    1    1]\n",
            " [   0 1114    2    2    1    7    4    0    5    0]\n",
            " [  18   13  843   27   11   12   40   20   44    4]\n",
            " [   6    4   30  810    2  100    2   18   27   11]\n",
            " [   3    6    5    1  893    4   16    4    4   46]\n",
            " [   5   10   15   34   11  773   14    8    4   18]\n",
            " [  13    8   31    1   34   20  849    1    0    1]\n",
            " [   3   23   33    5   23    1    0  921    4   15]\n",
            " [  18   17   15   19   14   77   17   10  767   20]\n",
            " [  14    5   11   15   87   14    0   63    8  792]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59520, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [36 49 59 44 53 47 48 56 58 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.400 s \n",
            "\n",
            "Accuracy rate for 86.660000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.92      0.92       980\n",
            "        1.0       0.93      0.98      0.96      1135\n",
            "        2.0       0.85      0.81      0.83      1032\n",
            "        3.0       0.88      0.80      0.84      1010\n",
            "        4.0       0.83      0.91      0.87       982\n",
            "        5.0       0.74      0.87      0.80       892\n",
            "        6.0       0.88      0.89      0.88       958\n",
            "        7.0       0.88      0.90      0.89      1028\n",
            "        8.0       0.89      0.79      0.84       974\n",
            "        9.0       0.87      0.78      0.83      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 899    0    5    5    0   40   27    2    1    1]\n",
            " [   0 1115    2    2    1    7    4    0    4    0]\n",
            " [  18   16  839   29   11   12   39   21   43    4]\n",
            " [   6    3   29  813    2  100    2   17   26   12]\n",
            " [   3    6    6    1  892    4   16    3    4   47]\n",
            " [   5   12   15   34   11  772   14    8    4   17]\n",
            " [  13    8   31    1   34   21  848    1    0    1]\n",
            " [   3   18   31    5   23    1    0  930    3   14]\n",
            " [  18   16   16   20   15   76   17    8  768   20]\n",
            " [  14    4   11   15   86   13    0   68    8  790]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59510, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [37 50 59 47 53 48 50 56 58 42] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 24.023 s \n",
            "\n",
            "Accuracy rate for 86.810000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.92      0.92       980\n",
            "        1.0       0.93      0.98      0.96      1135\n",
            "        2.0       0.85      0.81      0.83      1032\n",
            "        3.0       0.88      0.82      0.85      1010\n",
            "        4.0       0.83      0.91      0.87       982\n",
            "        5.0       0.75      0.87      0.80       892\n",
            "        6.0       0.87      0.89      0.88       958\n",
            "        7.0       0.88      0.91      0.89      1028\n",
            "        8.0       0.89      0.79      0.84       974\n",
            "        9.0       0.87      0.78      0.82      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 899    0    5    6    0   40   26    1    1    2]\n",
            " [   0 1115    2    2    1    7    4    0    4    0]\n",
            " [  18   16  834   29   10   13   44   20   43    5]\n",
            " [   5    3   29  827    2   91    3   18   21   11]\n",
            " [   3    6    8    1  892    5   14    3    4   46]\n",
            " [   5   11   14   33   11  773   16    7    4   18]\n",
            " [  16    6   29    0   32   20  853    1    0    1]\n",
            " [   3   17   29    5   22    1    0  931    4   16]\n",
            " [  18   16   17   23   14   72   20    7  765   22]\n",
            " [  13    4   11   16   85   13    0   66    9  792]]\n",
            "--------------------------------\n",
            "final active learning accuracies [31.009999999999998, 33.54, 48.67, 57.34, 61.68, 64.75999999999999, 69.28, 71.97, 73.2, 74.03, 75.08, 76.01, 76.55, 77.42999999999999, 77.75, 79.72, 80.78, 81.62, 81.8, 82.03, 81.82000000000001, 82.72, 82.94, 83.03, 83.72, 83.81, 83.72, 83.95, 84.38, 85.02, 85.36, 85.65, 85.26, 85.37, 85.37, 85.19, 85.18, 85.61999999999999, 85.47, 85.61999999999999, 85.78, 86.00999999999999, 86.05000000000001, 85.96000000000001, 85.96000000000001, 86.0, 86.24000000000001, 86.6, 86.66, 86.81]\n",
            "saved Active-learning-experiment-5.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-1.pkl', '.ipython', '.cache', '.config', 'scikit_learn_data', '.rnd', 'Active-learning-experiment-3.pkl', '.local']\n",
            "{\n",
            "  \"SvmModel\": {\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.009999999999998,\n",
            "          33.54,\n",
            "          48.67,\n",
            "          57.34,\n",
            "          61.68,\n",
            "          64.75999999999999,\n",
            "          69.28,\n",
            "          71.97,\n",
            "          73.2,\n",
            "          74.03,\n",
            "          75.08,\n",
            "          76.01,\n",
            "          76.55,\n",
            "          77.42999999999999,\n",
            "          77.75,\n",
            "          79.72,\n",
            "          80.78,\n",
            "          81.62,\n",
            "          81.8,\n",
            "          82.03,\n",
            "          81.82000000000001,\n",
            "          82.72,\n",
            "          82.94,\n",
            "          83.03,\n",
            "          83.72,\n",
            "          83.81,\n",
            "          83.72,\n",
            "          83.95,\n",
            "          84.38,\n",
            "          85.02,\n",
            "          85.36,\n",
            "          85.65,\n",
            "          85.26,\n",
            "          85.37,\n",
            "          85.37,\n",
            "          85.19,\n",
            "          85.18,\n",
            "          85.61999999999999,\n",
            "          85.47,\n",
            "          85.61999999999999,\n",
            "          85.78,\n",
            "          86.00999999999999,\n",
            "          86.05000000000001,\n",
            "          85.96000000000001,\n",
            "          85.96000000000001,\n",
            "          86.0,\n",
            "          86.24000000000001,\n",
            "          86.6,\n",
            "          86.66,\n",
            "          86.81\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.449999999999996,\n",
            "          67.88,\n",
            "          72.25,\n",
            "          77.82,\n",
            "          79.19,\n",
            "          80.32000000000001,\n",
            "          81.19,\n",
            "          81.91000000000001,\n",
            "          82.67999999999999,\n",
            "          82.89,\n",
            "          82.89,\n",
            "          83.05,\n",
            "          83.91999999999999,\n",
            "          84.69,\n",
            "          84.77,\n",
            "          84.66,\n",
            "          85.0,\n",
            "          85.3,\n",
            "          85.79,\n",
            "          86.08\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          56.38999999999999,\n",
            "          72.92999999999999,\n",
            "          78.44,\n",
            "          81.0,\n",
            "          82.73,\n",
            "          83.52000000000001,\n",
            "          84.35000000000001,\n",
            "          85.17,\n",
            "          86.17,\n",
            "          86.66\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          73.76,\n",
            "          83.52000000000001,\n",
            "          85.6,\n",
            "          86.44\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.02000000000001,\n",
            "          85.64\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 6, using model = SvmModel, selection_function = MarginSamplingSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [26 23 32 34 24 14 30 25 17 25] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.153 s \n",
            "\n",
            "Accuracy rate for 84.580000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.96      0.93       980\n",
            "        1.0       0.87      0.99      0.92      1135\n",
            "        2.0       0.80      0.87      0.83      1032\n",
            "        3.0       0.80      0.87      0.83      1010\n",
            "        4.0       0.82      0.81      0.82       982\n",
            "        5.0       0.83      0.67      0.74       892\n",
            "        6.0       0.86      0.90      0.88       958\n",
            "        7.0       0.91      0.86      0.88      1028\n",
            "        8.0       0.88      0.66      0.75       974\n",
            "        9.0       0.80      0.83      0.81      1009\n",
            "\n",
            "avg / total       0.85      0.85      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    0    5    2    1    3   20    1    4    0]\n",
            " [   0 1121    0    6    1    0    3    0    4    0]\n",
            " [  22   18  902   14   11    2   26   17   16    4]\n",
            " [   5   12   35  878    1   31    2    9   27   10]\n",
            " [   1    8   16    0  800    1   22    3    3  128]\n",
            " [  21   27   13  121   38  597   40   13   13    9]\n",
            " [  10    9   56    0   11    4  863    0    5    0]\n",
            " [   3   51   28    6   21    3    2  879    6   29]\n",
            " [  22   33   70   65   13   69   21   10  639   32]\n",
            " [  13   13    8   10   76   11    2   29   12  835]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [38 25 49 60 45 77 42 46 69 49] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 26.897 s \n",
            "\n",
            "Accuracy rate for 87.380000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.96      0.95       980\n",
            "        1.0       0.94      0.96      0.95      1135\n",
            "        2.0       0.90      0.83      0.86      1032\n",
            "        3.0       0.79      0.89      0.84      1010\n",
            "        4.0       0.89      0.86      0.87       982\n",
            "        5.0       0.78      0.82      0.80       892\n",
            "        6.0       0.91      0.92      0.91       958\n",
            "        7.0       0.88      0.87      0.88      1028\n",
            "        8.0       0.88      0.77      0.82       974\n",
            "        9.0       0.84      0.85      0.84      1009\n",
            "\n",
            "avg / total       0.88      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    0    3    2    1   22    9    2    0    0]\n",
            " [   0 1093    2   11    1    2    2    7   17    0]\n",
            " [  12    9  860   45    7   20   27   23   24    5]\n",
            " [   9    6   20  902    0   40    1   15   12    5]\n",
            " [   1    2    8    1  841    8   20    7    2   92]\n",
            " [  19    3    2   84   11  729   17    9   13    5]\n",
            " [  11    4   17    3   11   26  877    5    4    0]\n",
            " [   0   30   25    7   16    1    0  895    5   49]\n",
            " [   9    9   15   78    8   77   13    9  746   10]\n",
            " [   4    6    8   16   46    8    2   44   21  854]]\n",
            "--------------------------------\n",
            "final active learning accuracies [84.58, 87.38]\n",
            "saved Active-learning-experiment-6.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', '.ipython', '.cache', '.config', 'scikit_learn_data', '.rnd', 'Active-learning-experiment-3.pkl', '.local']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 7, using model = SvmModel, selection_function = MarginSamplingSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [16 10 10 15  9 11 14 15 12 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.509 s \n",
            "\n",
            "Accuracy rate for 79.450000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.96      0.91       980\n",
            "        1.0       0.89      0.92      0.91      1135\n",
            "        2.0       0.86      0.75      0.80      1032\n",
            "        3.0       0.75      0.86      0.80      1010\n",
            "        4.0       0.72      0.69      0.71       982\n",
            "        5.0       0.77      0.58      0.67       892\n",
            "        6.0       0.86      0.77      0.81       958\n",
            "        7.0       0.85      0.88      0.86      1028\n",
            "        8.0       0.72      0.74      0.73       974\n",
            "        9.0       0.65      0.75      0.70      1009\n",
            "\n",
            "avg / total       0.80      0.79      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    0    3    4    5   10    8    1    6    3]\n",
            " [   0 1047   10    2    0    5    1    2   68    0]\n",
            " [  43   22  770   33   12    4   57   39   38   14]\n",
            " [   6   14   20  866    1   13    6   23   47   14]\n",
            " [   2   14    2    0  674    9   15    9   15  242]\n",
            " [  27   13    4  168   14  520   16    9   91   30]\n",
            " [  31   17   46    0   79   42  740    0    3    0]\n",
            " [   5   21   17    6   10    2    0  904    8   55]\n",
            " [  16   21   11   54   20   54   19   12  725   42]\n",
            " [  14    7   10   18  115   12    0   64   10  759]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59875, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [19 17 25 34 31 28 28 20 25 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 14.638 s \n",
            "\n",
            "Accuracy rate for 84.100000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.95      0.94       980\n",
            "        1.0       0.93      0.96      0.94      1135\n",
            "        2.0       0.81      0.83      0.82      1032\n",
            "        3.0       0.72      0.86      0.79      1010\n",
            "        4.0       0.76      0.90      0.82       982\n",
            "        5.0       0.80      0.63      0.71       892\n",
            "        6.0       0.93      0.87      0.90       958\n",
            "        7.0       0.91      0.86      0.88      1028\n",
            "        8.0       0.81      0.79      0.80       974\n",
            "        9.0       0.84      0.72      0.78      1009\n",
            "\n",
            "avg / total       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 927    0    4    3    2   24    6    7    5    2]\n",
            " [   0 1087   15    4    2    2    2    1   21    1]\n",
            " [  23   25  852   31   18    3   29   10   40    1]\n",
            " [   2    6   26  871    2   45    3   13   29   13]\n",
            " [   1    1   42    0  888    0    6    0    5   39]\n",
            " [  12   11   10  199   20  565    8    4   49   14]\n",
            " [  16    4   29    5   27   25  836    0   16    0]\n",
            " [   3   22   36   11   36    1    1  884    5   29]\n",
            " [   8    8   14   70   17   39   10    3  769   36]\n",
            " [   6    5   23   14  163    6    1   52    8  731]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [20 27 35 50 38 53 52 31 36 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 21.178 s \n",
            "\n",
            "Accuracy rate for 86.360000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.90      0.92       980\n",
            "        1.0       0.94      0.97      0.96      1135\n",
            "        2.0       0.83      0.83      0.83      1032\n",
            "        3.0       0.80      0.89      0.84      1010\n",
            "        4.0       0.79      0.90      0.84       982\n",
            "        5.0       0.83      0.73      0.78       892\n",
            "        6.0       0.88      0.95      0.91       958\n",
            "        7.0       0.90      0.90      0.90      1028\n",
            "        8.0       0.83      0.78      0.81       974\n",
            "        9.0       0.88      0.76      0.82      1009\n",
            "\n",
            "avg / total       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 880    0    9    5    4   42   28    9    3    0]\n",
            " [   0 1105    0    5    0    2    4    1   18    0]\n",
            " [  13   27  860   29   21    4   19   14   43    2]\n",
            " [   3    3   25  896    5   24   10   21   21    2]\n",
            " [   1    1   45    0  882    0    9    1    6   37]\n",
            " [  11    5    5  115   24  649   32    3   40    8]\n",
            " [   1    3   19    1   10    9  914    0    1    0]\n",
            " [   4   12   20   10   26    0    0  923    7   26]\n",
            " [   5   15   33   37   21   45   27    3  761   27]\n",
            " [   5    5   17   17  127    4    1   53   14  766]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59625, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [29 31 50 63 50 74 55 44 51 53] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 27.983 s \n",
            "\n",
            "Accuracy rate for 88.160000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.92      0.93       980\n",
            "        1.0       0.94      0.99      0.96      1135\n",
            "        2.0       0.87      0.86      0.87      1032\n",
            "        3.0       0.82      0.88      0.85      1010\n",
            "        4.0       0.83      0.93      0.88       982\n",
            "        5.0       0.83      0.79      0.81       892\n",
            "        6.0       0.91      0.93      0.92       958\n",
            "        7.0       0.89      0.90      0.90      1028\n",
            "        8.0       0.89      0.79      0.84       974\n",
            "        9.0       0.88      0.80      0.84      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 906    0    3    4    3   46   16    2    0    0]\n",
            " [   0 1120    0    4    1    2    2    1    5    0]\n",
            " [  15   18  891   31   15    2   16   17   22    5]\n",
            " [   5    5   27  886    3   39    8   19   16    2]\n",
            " [   1    2   12    0  912    1    9    1    2   42]\n",
            " [  11    8    6   85   12  707   23    5   27    8]\n",
            " [  12    3   16    1   18    9  895    0    4    0]\n",
            " [   0   13   16    6   22    0    0  930    4   37]\n",
            " [   6   15   44   44   20   39   15   15  765   11]\n",
            " [   7    4   13   22   91    3    0   52   13  804]]\n",
            "--------------------------------\n",
            "final active learning accuracies [79.45, 84.1, 86.36, 88.16000000000001]\n",
            "saved Active-learning-experiment-7.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', '.ipython', '.cache', '.config', 'scikit_learn_data', '.rnd', 'Active-learning-experiment-3.pkl', '.local', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 8, using model = SvmModel, selection_function = MarginSamplingSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [9 3 7 3 5 4 9 2 4 4] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 3.106 s \n",
            "\n",
            "Accuracy rate for 59.100000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.84      0.80       980\n",
            "        1.0       0.85      0.74      0.79      1135\n",
            "        2.0       0.59      0.63      0.61      1032\n",
            "        3.0       0.48      0.36      0.41      1010\n",
            "        4.0       0.62      0.62      0.62       982\n",
            "        5.0       0.39      0.58      0.47       892\n",
            "        6.0       0.65      0.89      0.75       958\n",
            "        7.0       0.91      0.31      0.46      1028\n",
            "        8.0       0.34      0.36      0.35       974\n",
            "        9.0       0.54      0.57      0.56      1009\n",
            "\n",
            "avg / total       0.62      0.59      0.59     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[825   0  32   2   4  37  77   0   3   0]\n",
            " [  0 840  29   1   2  73   4   0 186   0]\n",
            " [ 36  34 651 134  29   4  80   4  56   4]\n",
            " [ 56  12 111 368   4 388   5  15  40  11]\n",
            " [  0  16  12   0 611  47 107   1  24 164]\n",
            " [ 62  14  53   7  59 518  80   3  92   4]\n",
            " [ 35   3  40   0   8  16 855   0   0   1]\n",
            " [  0  39  62  39  76  37   9 320 175 271]\n",
            " [ 63  22  85 210  15 131  68   1 346  33]\n",
            " [ 12  11  25   8 182  68  29   9  89 576]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 6. ... 9. 8. 8.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 0 ... 9 8 8]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [11 11 11  8  7  7 10  4 14 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.130 s \n",
            "\n",
            "Accuracy rate for 69.910000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.86      0.93      0.89       980\n",
            "        1.0       0.77      0.98      0.86      1135\n",
            "        2.0       0.75      0.77      0.76      1032\n",
            "        3.0       0.90      0.44      0.59      1010\n",
            "        4.0       0.73      0.60      0.66       982\n",
            "        5.0       0.50      0.49      0.50       892\n",
            "        6.0       0.81      0.84      0.82       958\n",
            "        7.0       0.91      0.37      0.53      1028\n",
            "        8.0       0.62      0.69      0.65       974\n",
            "        9.0       0.48      0.84      0.61      1009\n",
            "\n",
            "avg / total       0.74      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 907    5    9    2    0   13   32    2    2    8]\n",
            " [   0 1111    1    1    0    1    3    0   17    1]\n",
            " [  14   54  795   11   37    1   38    6   59   17]\n",
            " [  33   45   86  448    3  277    5   17   75   21]\n",
            " [   1    4   12    0  589   29   41    3   15  288]\n",
            " [  37  108    8    7   31  438   30    2  172   59]\n",
            " [  39   16   68    0   11   22  800    0    0    2]\n",
            " [   1   28   10   10   33    9    0  383   57  497]\n",
            " [  16   70   64   15   11   64   28    0  671   35]\n",
            " [   6    5    8    6   88   15    7    6   19  849]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [13 12 18 15 13 15 12 12 22 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.216 s \n",
            "\n",
            "Accuracy rate for 75.660000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.92      0.88       980\n",
            "        1.0       0.84      0.96      0.90      1135\n",
            "        2.0       0.72      0.83      0.77      1032\n",
            "        3.0       0.86      0.58      0.69      1010\n",
            "        4.0       0.76      0.72      0.74       982\n",
            "        5.0       0.62      0.69      0.65       892\n",
            "        6.0       0.91      0.83      0.86       958\n",
            "        7.0       0.83      0.52      0.64      1028\n",
            "        8.0       0.70      0.73      0.71       974\n",
            "        9.0       0.59      0.76      0.67      1009\n",
            "\n",
            "avg / total       0.77      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 898    1   27    3    0   27   16    3    2    3]\n",
            " [   0 1093    5    1    0    7    1    0   27    1]\n",
            " [  14   56  854    9   16    4   15   13   47    4]\n",
            " [  53   26   68  583    3  189    3   25   40   20]\n",
            " [   1    5   37    1  709   24   16   16    9  164]\n",
            " [  56   38   21   44   13  618    9    5   59   29]\n",
            " [  29    6   61    0   24   33  793    7    5    0]\n",
            " [   0   23   57    0   24   12    0  538   89  285]\n",
            " [  17   53   39   27   10   71   19    6  712   20]\n",
            " [   4    2   11    7  133   18    4   34   28  768]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 0. ... 9. 4. 8.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 0 ... 9 8 8]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [20 13 23 24 22 21 15 15 25 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.110 s \n",
            "\n",
            "Accuracy rate for 81.410000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.96      0.91       980\n",
            "        1.0       0.86      0.97      0.91      1135\n",
            "        2.0       0.82      0.82      0.82      1032\n",
            "        3.0       0.84      0.71      0.77      1010\n",
            "        4.0       0.82      0.85      0.83       982\n",
            "        5.0       0.67      0.74      0.70       892\n",
            "        6.0       0.92      0.83      0.87       958\n",
            "        7.0       0.88      0.71      0.79      1028\n",
            "        8.0       0.78      0.75      0.76       974\n",
            "        9.0       0.71      0.78      0.75      1009\n",
            "\n",
            "avg / total       0.82      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    2   11    5    0   12    1    0    2    3]\n",
            " [   0 1098    2    1    0    8    1    0   23    2]\n",
            " [  10   43  844   28   19    4   23   24   33    4]\n",
            " [  25   16   36  714    1  169    5   12   24    8]\n",
            " [   2    3    7    1  831   10    7    4    8  109]\n",
            " [  38   36   17   34   18  663   12    1   53   20]\n",
            " [  43    6   51    2   27   27  798    2    2    0]\n",
            " [   4   30   27    3   17   24    0  728   35  160]\n",
            " [  14   44   27   57   16   43   21    9  729   14]\n",
            " [   8    2    6    9   85   32    1   44   30  792]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [22 15 29 31 27 25 20 27 27 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 15.030 s \n",
            "\n",
            "Accuracy rate for 82.690000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.95      0.92       980\n",
            "        1.0       0.88      0.96      0.92      1135\n",
            "        2.0       0.82      0.83      0.83      1032\n",
            "        3.0       0.79      0.75      0.77      1010\n",
            "        4.0       0.82      0.88      0.85       982\n",
            "        5.0       0.70      0.72      0.71       892\n",
            "        6.0       0.89      0.83      0.86       958\n",
            "        7.0       0.91      0.78      0.84      1028\n",
            "        8.0       0.81      0.73      0.77       974\n",
            "        9.0       0.74      0.81      0.77      1009\n",
            "\n",
            "avg / total       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 934    0   11   15    0    8    4    0    4    4]\n",
            " [   0 1093    3    3    1   11    2    2   19    1]\n",
            " [   7   35  859   26   21    2   25   22   32    3]\n",
            " [  22   14   30  755    3  147    6   12   17    4]\n",
            " [   2    3    8    1  860    9   13    4    3   79]\n",
            " [  34   26   11   55   17  638   25    1   58   27]\n",
            " [  24    5   81    2   23   23  799    1    0    0]\n",
            " [   3   22   14    3   16    3    1  801    8  157]\n",
            " [  16   40   24   75   19   48   18    7  712   15]\n",
            " [   4    2    8   15   86   25    0   29   22  818]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [27 23 30 36 32 31 21 35 31 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 17.640 s \n",
            "\n",
            "Accuracy rate for 85.070000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.97      0.93       980\n",
            "        1.0       0.89      0.98      0.93      1135\n",
            "        2.0       0.83      0.84      0.84      1032\n",
            "        3.0       0.81      0.78      0.79      1010\n",
            "        4.0       0.84      0.89      0.86       982\n",
            "        5.0       0.73      0.76      0.74       892\n",
            "        6.0       0.92      0.84      0.87       958\n",
            "        7.0       0.92      0.86      0.89      1028\n",
            "        8.0       0.86      0.76      0.81       974\n",
            "        9.0       0.82      0.81      0.81      1009\n",
            "\n",
            "avg / total       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 947    0    7   10    1   10    1    2    0    2]\n",
            " [   0 1111    3    3    1    4    3    0   10    0]\n",
            " [  11   32  871   22   22    0   24   20   28    2]\n",
            " [  14   15   26  789    2  129    5   11   12    7]\n",
            " [   2    1    5    1  871   10    8    2    9   73]\n",
            " [  35   17   12   68   15  676   17    6   27   19]\n",
            " [  28    5   78    1   21   20  800    1    3    1]\n",
            " [   3   35   13    1   12    5    0  887   10   62]\n",
            " [  17   27   32   63   14   45   15    6  740   15]\n",
            " [   4    8    4   18   74   31    1   31   23  815]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [29 24 33 41 35 39 30 40 37 42] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 20.933 s \n",
            "\n",
            "Accuracy rate for 85.920000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.95      0.91       980\n",
            "        1.0       0.90      0.98      0.94      1135\n",
            "        2.0       0.82      0.85      0.84      1032\n",
            "        3.0       0.86      0.77      0.81      1010\n",
            "        4.0       0.85      0.92      0.88       982\n",
            "        5.0       0.75      0.77      0.76       892\n",
            "        6.0       0.88      0.88      0.88       958\n",
            "        7.0       0.92      0.89      0.90      1028\n",
            "        8.0       0.85      0.75      0.80       974\n",
            "        9.0       0.87      0.80      0.84      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 933    0   18    3    0   15    5    1    2    3]\n",
            " [   0 1111    4    2    1    3    3    0   11    0]\n",
            " [   7   26  878   12   22    2   34   21   25    5]\n",
            " [  18   12   36  779    1  117   10   12   21    4]\n",
            " [   2    2    7    0  906    7    8    1   10   39]\n",
            " [  40   12   16   44   21  688   23    5   34    9]\n",
            " [  28    4   57    2   13   12  840    0    1    1]\n",
            " [   4   30   15    2   11    5    1  915    6   39]\n",
            " [  23   33   32   50   15   39   29    5  732   16]\n",
            " [   6    5    5   15   82   27    1   37   21  810]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [32 24 36 46 38 47 35 48 45 49] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.489 s \n",
            "\n",
            "Accuracy rate for 86.890000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.96      0.92       980\n",
            "        1.0       0.93      0.98      0.95      1135\n",
            "        2.0       0.85      0.86      0.86      1032\n",
            "        3.0       0.85      0.80      0.82      1010\n",
            "        4.0       0.86      0.92      0.89       982\n",
            "        5.0       0.76      0.77      0.77       892\n",
            "        6.0       0.90      0.89      0.90       958\n",
            "        7.0       0.89      0.90      0.90      1028\n",
            "        8.0       0.87      0.78      0.82       974\n",
            "        9.0       0.88      0.80      0.84      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    0    8    1    1   24    2    1    0    1]\n",
            " [   0 1110    5    4    1    4    3    0    8    0]\n",
            " [  13   15  891    7   20    6   24   27   25    4]\n",
            " [  32    7   27  807    1   85    7   11   27    6]\n",
            " [   1    0    8    1  902   10    7    4    5   44]\n",
            " [  34    8   10   65    9  688   24    6   34   14]\n",
            " [  21    2   58    3    9   12  853    0    0    0]\n",
            " [   3   24   17    1    9    5    2  929    4   34]\n",
            " [  16   26   22   41   15   40   23   19  762   10]\n",
            " [   5    5    5   18   85   26    1   46   13  805]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [34 26 41 54 44 51 38 51 52 59] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 26.643 s \n",
            "\n",
            "Accuracy rate for 87.800000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.97      0.93       980\n",
            "        1.0       0.94      0.98      0.96      1135\n",
            "        2.0       0.87      0.88      0.88      1032\n",
            "        3.0       0.84      0.82      0.83      1010\n",
            "        4.0       0.86      0.93      0.89       982\n",
            "        5.0       0.79      0.76      0.77       892\n",
            "        6.0       0.91      0.90      0.91       958\n",
            "        7.0       0.91      0.91      0.91      1028\n",
            "        8.0       0.88      0.79      0.83       974\n",
            "        9.0       0.87      0.82      0.84      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 948    0    7    1    2   17    2    1    1    1]\n",
            " [   0 1110    2    3    1    3    4    0   12    0]\n",
            " [  13   11  911   14   19    4   22   20   17    1]\n",
            " [  25    6   22  832    2   81    3   11   21    7]\n",
            " [   1    0    8    1  909    5    9    2    3   44]\n",
            " [  27    8    4   78   15  675   20    5   35   25]\n",
            " [  23    2   46    6    8    8  864    0    0    1]\n",
            " [   1   19   19    1   10    3    0  931    5   39]\n",
            " [  17   17   23   39   17   46   20   12  772   11]\n",
            " [  10    7    5   15   74   17    1   41   11  828]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [43 30 45 62 48 57 43 53 56 63] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 29.372 s \n",
            "\n",
            "Accuracy rate for 87.600000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.96      0.92       980\n",
            "        1.0       0.91      0.98      0.94      1135\n",
            "        2.0       0.87      0.87      0.87      1032\n",
            "        3.0       0.84      0.82      0.83      1010\n",
            "        4.0       0.87      0.91      0.89       982\n",
            "        5.0       0.79      0.76      0.77       892\n",
            "        6.0       0.91      0.90      0.91       958\n",
            "        7.0       0.92      0.90      0.91      1028\n",
            "        8.0       0.88      0.79      0.83       974\n",
            "        9.0       0.87      0.84      0.85      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 945    0    8    1    1   16    2    3    2    2]\n",
            " [   0 1108    4    3    1    2    5    0   12    0]\n",
            " [  13   12  896   29   18    3   22   15   22    2]\n",
            " [  15   13   22  831    4   74    3   18   25    5]\n",
            " [   2    3    6    1  897    7    9    3    2   52]\n",
            " [  39   16    7   72   16  680   26    4   20   12]\n",
            " [  30    4   35    3    6   13  866    0    0    1]\n",
            " [   1   22   18    1   12    5    0  927    5   37]\n",
            " [  15   26   26   38   18   47   16   10  765   13]\n",
            " [   9    7    4   16   63   19    1   33   12  845]]\n",
            "--------------------------------\n",
            "final active learning accuracies [59.099999999999994, 69.91000000000001, 75.66000000000001, 81.41000000000001, 82.69, 85.07000000000001, 85.92, 86.89, 87.8, 87.6]\n",
            "saved Active-learning-experiment-8.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', '.rnd', 'Active-learning-experiment-3.pkl', '.local', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 9, using model = SvmModel, selection_function = MarginSamplingSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [1 4 3 3 1 3 3 3 4] [0 1 2 3 4 5 6 7 8]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 1.655 s \n",
            "\n",
            "Accuracy rate for 50.160000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.46      0.62       980\n",
            "        1.0       0.70      0.91      0.79      1135\n",
            "        2.0       0.67      0.35      0.46      1032\n",
            "        3.0       0.63      0.56      0.59      1010\n",
            "        4.0       0.66      0.13      0.22       982\n",
            "        5.0       0.24      0.39      0.30       892\n",
            "        6.0       0.72      0.76      0.74       958\n",
            "        7.0       0.41      0.59      0.48      1028\n",
            "        8.0       0.32      0.80      0.46       974\n",
            "        9.0       0.00      0.00      0.00      1009\n",
            "\n",
            "avg / total       0.53      0.50      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 453    0    3   62    2  335   27    3   95    0]\n",
            " [   0 1035    1    2    0    0    6    1   90    0]\n",
            " [  14   79  361   37    0   19  147   29  346    0]\n",
            " [   5   21   10  570    0   23   24   29  328    0]\n",
            " [   2   56   11    1  132  284   36  275  185    0]\n",
            " [   3   68    2  149    0  348   27   28  267    0]\n",
            " [   2   10  133    5    5   42  732    6   23    0]\n",
            " [   0   88    5    5    2  164    0  607  157    0]\n",
            " [   0   45    6   54    0   50   22   19  778    0]\n",
            " [   3   69    4   22   58  201    0  487  165    0]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59975,) [0. 0. 8. ... 7. 1. 8.]\n",
            "probabilities: (59975, 9) \n",
            " [5 5 8 ... 5 8 8]\n",
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [2 6 6 4 5 5 8 4 7 3] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 3.232 s \n",
            "\n",
            "Accuracy rate for 63.730000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.60      0.74       980\n",
            "        1.0       0.71      0.94      0.81      1135\n",
            "        2.0       0.67      0.58      0.62      1032\n",
            "        3.0       0.71      0.64      0.67      1010\n",
            "        4.0       0.67      0.53      0.59       982\n",
            "        5.0       0.57      0.45      0.50       892\n",
            "        6.0       0.70      0.91      0.79       958\n",
            "        7.0       0.60      0.55      0.58      1028\n",
            "        8.0       0.41      0.72      0.53       974\n",
            "        9.0       0.58      0.42      0.49      1009\n",
            "\n",
            "avg / total       0.66      0.64      0.63     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 585    2   49   38    6  120  130    2   41    7]\n",
            " [   0 1067    2    1    0    1   12    1   51    0]\n",
            " [   6  218  595   11    8    7   77   15   94    1]\n",
            " [   0   46   42  643    0   29   15   16  217    2]\n",
            " [   0   15    6    0  518   38   52   87   54  212]\n",
            " [   5   25   29  166   10  401   49    3  199    5]\n",
            " [   4   14   42    0   12    9  868    1    8    0]\n",
            " [   1   62   33    0   16   10    1  570  286   49]\n",
            " [   5   43   61   39    9   44   34   11  703   25]\n",
            " [   3   15   31   13  189   42    3  246   44  423]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 6. ... 9. 9. 9.]\n",
            "probabilities: (59950, 10) \n",
            " [8 8 8 ... 7 5 5]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [ 6  9  7  5  8  6  8  7 11  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.679 s \n",
            "\n",
            "Accuracy rate for 70.140000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.79      0.84       980\n",
            "        1.0       0.68      0.98      0.80      1135\n",
            "        2.0       0.72      0.54      0.62      1032\n",
            "        3.0       0.67      0.59      0.63      1010\n",
            "        4.0       0.75      0.74      0.75       982\n",
            "        5.0       0.70      0.36      0.47       892\n",
            "        6.0       0.78      0.89      0.83       958\n",
            "        7.0       0.77      0.71      0.74      1028\n",
            "        8.0       0.48      0.76      0.59       974\n",
            "        9.0       0.72      0.61      0.66      1009\n",
            "\n",
            "avg / total       0.72      0.70      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 770    1   20   25    1   35   47    1   77    3]\n",
            " [   0 1108    4    1    1    1    4    0   16    0]\n",
            " [  23  203  559   16   25    6   83   31   83    3]\n",
            " [   6   84   40  597    4   23   12   13  224    7]\n",
            " [   1   32   13    5  731    7   30   49   24   90]\n",
            " [   8   54   16  175   17  320   41    6  250    5]\n",
            " [  23   25   23    1    8   17  848    2   11    0]\n",
            " [   4   36   37    2   25    7    0  731   93   93]\n",
            " [   8   58   35   33   30   19   19    3  737   32]\n",
            " [  13   21   34   41  136   21    2  115   13  613]]\n",
            "--------------------------------\n",
            "val predicted: (59925,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59925, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 7  9  9 15 11 10  8 10 12  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.220 s \n",
            "\n",
            "Accuracy rate for 74.400000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.73      0.82       980\n",
            "        1.0       0.71      0.98      0.82      1135\n",
            "        2.0       0.79      0.56      0.65      1032\n",
            "        3.0       0.63      0.75      0.68      1010\n",
            "        4.0       0.78      0.87      0.82       982\n",
            "        5.0       0.61      0.44      0.51       892\n",
            "        6.0       0.84      0.85      0.85       958\n",
            "        7.0       0.80      0.83      0.81      1028\n",
            "        8.0       0.63      0.73      0.67       974\n",
            "        9.0       0.80      0.64      0.71      1009\n",
            "\n",
            "avg / total       0.75      0.74      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 719    2   26   49    2   86   42    4   46    4]\n",
            " [   0 1109    3    2    0    1    4    0   16    0]\n",
            " [  23  200  574   63   19    8   53   33   51    8]\n",
            " [   0   50   18  761    7   42    4   20  106    2]\n",
            " [   0   18    4    6  858    6   30   10    1   49]\n",
            " [   3   50    9  218   18  394   10    9  172    9]\n",
            " [  15   25   24    7   17   47  814    1    8    0]\n",
            " [   4   34   36    3   30    3    0  856    4   58]\n",
            " [   2   47   22   77   26   36   10   12  707   35]\n",
            " [   8   21   11   31  130   20    1  129   10  648]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [12 11 11 17 12 11 10 12 20  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.736 s \n",
            "\n",
            "Accuracy rate for 78.990000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.89      0.89       980\n",
            "        1.0       0.75      0.97      0.85      1135\n",
            "        2.0       0.85      0.66      0.74      1032\n",
            "        3.0       0.72      0.74      0.73      1010\n",
            "        4.0       0.78      0.90      0.84       982\n",
            "        5.0       0.77      0.46      0.57       892\n",
            "        6.0       0.86      0.87      0.87       958\n",
            "        7.0       0.83      0.90      0.86      1028\n",
            "        8.0       0.65      0.83      0.73       974\n",
            "        9.0       0.87      0.63      0.73      1009\n",
            "\n",
            "avg / total       0.80      0.79      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 871    1   10   11    2   28   34    4   18    1]\n",
            " [   0 1101    3    2    4    0    3    0   22    0]\n",
            " [  37  122  686   32   21    5   49   31   43    6]\n",
            " [   5   49   24  751    7   18    8   17  131    0]\n",
            " [   1   16    2    5  882    5   13    4    9   45]\n",
            " [  21   73   18  165   10  406   14    8  174    3]\n",
            " [  17   27   22    8   12   33  831    0    8    0]\n",
            " [   4   32   18    5   20    0    1  926    7   15]\n",
            " [  12   22   22   29   13   21    8   14  812   21]\n",
            " [  12   21    5   36  155   12    0  111   24  633]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) [0. 0. 6. ... 9. 9. 9.]\n",
            "probabilities: (59875, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [14 12 15 20 12 16 10 15 23 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.193 s \n",
            "\n",
            "Accuracy rate for 80.370000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.91      0.90       980\n",
            "        1.0       0.79      0.97      0.88      1135\n",
            "        2.0       0.85      0.73      0.79      1032\n",
            "        3.0       0.72      0.77      0.74      1010\n",
            "        4.0       0.87      0.80      0.84       982\n",
            "        5.0       0.69      0.44      0.54       892\n",
            "        6.0       0.91      0.83      0.87       958\n",
            "        7.0       0.85      0.91      0.88      1028\n",
            "        8.0       0.67      0.85      0.75       974\n",
            "        9.0       0.82      0.76      0.79      1009\n",
            "\n",
            "avg / total       0.81      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 891    1    6    6    0   27   19    9   19    2]\n",
            " [   0 1106    3    2    2    0    3    0   19    0]\n",
            " [  12   93  754   39   12   11   24   27   53    7]\n",
            " [  11   34   31  774    5   25    1   16  110    3]\n",
            " [   1   23    5    1  790   17   12    5    6  122]\n",
            " [  42   46   11  194    5  395   10   10  170    9]\n",
            " [  28   26   39    6    8   44  797    4    6    0]\n",
            " [   3   26   20    6    9    1    1  932    8   22]\n",
            " [  11   23   15   24   14   30    5   13  831    8]\n",
            " [  10   14    2   29   61   22    0   77   27  767]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59850,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [16 13 20 22 17 20 11 16 23 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.545 s \n",
            "\n",
            "Accuracy rate for 82.760000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.95      0.92       980\n",
            "        1.0       0.82      0.97      0.89      1135\n",
            "        2.0       0.85      0.79      0.82      1032\n",
            "        3.0       0.77      0.80      0.79      1010\n",
            "        4.0       0.85      0.84      0.85       982\n",
            "        5.0       0.72      0.54      0.62       892\n",
            "        6.0       0.94      0.81      0.87       958\n",
            "        7.0       0.87      0.89      0.88      1028\n",
            "        8.0       0.73      0.84      0.78       974\n",
            "        9.0       0.85      0.79      0.82      1009\n",
            "\n",
            "avg / total       0.83      0.83      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 930    1    0    0    0   28    8    6    6    1]\n",
            " [   0 1102    2    7    0    2    3    0   19    0]\n",
            " [  19   54  815   25   17   20   11   33   32    6]\n",
            " [  11   24   32  813    4   25    2   17   79    3]\n",
            " [   2   20    7    0  829   10   13    3    3   95]\n",
            " [  32   52    6  155    6  480    9    6  135   11]\n",
            " [  29   15   48    4   14   61  777    1    7    2]\n",
            " [   5   31   28    6   13    1    1  918    6   19]\n",
            " [   9   28   21   24   21   28    6   11  819    7]\n",
            " [  10   13    5   25   74   10    0   61   18  793]]\n",
            "--------------------------------\n",
            "val predicted: (59825,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59825, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [17 14 26 25 20 24 12 17 25 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.143 s \n",
            "\n",
            "Accuracy rate for 84.350000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.94      0.92       980\n",
            "        1.0       0.85      0.98      0.91      1135\n",
            "        2.0       0.85      0.83      0.84      1032\n",
            "        3.0       0.81      0.80      0.81      1010\n",
            "        4.0       0.85      0.87      0.86       982\n",
            "        5.0       0.73      0.63      0.68       892\n",
            "        6.0       0.92      0.83      0.87       958\n",
            "        7.0       0.87      0.88      0.88      1028\n",
            "        8.0       0.76      0.83      0.79       974\n",
            "        9.0       0.87      0.81      0.84      1009\n",
            "\n",
            "avg / total       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 922    1    0    1    0   35    9    6    5    1]\n",
            " [   0 1112    4    1    0    1    4    0   13    0]\n",
            " [  19   45  858   15   20    6   19   27   17    6]\n",
            " [  13   18   31  811    5   42    4   11   70    5]\n",
            " [   1   13    6    0  851   12   18    3    3   75]\n",
            " [  34   31    6  121    6  559   12    4  110    9]\n",
            " [  22   13   37    6   19   61  791    0    9    0]\n",
            " [   8   31   27    5   23    1    0  909   10   14]\n",
            " [   7   26   32   22   20   36    5   13  804    9]\n",
            " [   9   12    3   19   56    9    1   69   13  818]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [19 14 27 27 25 29 14 20 29 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.695 s \n",
            "\n",
            "Accuracy rate for 85.780000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.95      0.92       980\n",
            "        1.0       0.87      0.98      0.92      1135\n",
            "        2.0       0.87      0.83      0.85      1032\n",
            "        3.0       0.82      0.83      0.83      1010\n",
            "        4.0       0.82      0.90      0.86       982\n",
            "        5.0       0.75      0.70      0.73       892\n",
            "        6.0       0.93      0.84      0.88       958\n",
            "        7.0       0.87      0.89      0.88      1028\n",
            "        8.0       0.83      0.82      0.83       974\n",
            "        9.0       0.89      0.80      0.84      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 931    1    3    0    2   19    9    6    7    2]\n",
            " [   0 1113    4    2    0    1    3    0   12    0]\n",
            " [  21   39  859   18   23    3   15   27   22    5]\n",
            " [  12   20   29  842    5   59    2    9   28    4]\n",
            " [   1   12    8    1  885    8   14    0    3   50]\n",
            " [  32   28    5  108    7  627   10    7   60    8]\n",
            " [  25   10   25    1   23   63  803    0    8    0]\n",
            " [   4   22   23    9   25    1    0  912   10   22]\n",
            " [   5   26   28   21   23   45    4   15  802    5]\n",
            " [   7    9    1   21   80    8    1   67   11  804]]\n",
            "--------------------------------\n",
            "val predicted: (59775,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59775, 10) \n",
            " [0 0 8 ... 9 9 7]\n",
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [21 14 28 28 27 33 19 23 33 24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 14.861 s \n",
            "\n",
            "Accuracy rate for 86.620000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.97      0.93       980\n",
            "        1.0       0.89      0.98      0.93      1135\n",
            "        2.0       0.87      0.84      0.85      1032\n",
            "        3.0       0.84      0.81      0.82      1010\n",
            "        4.0       0.84      0.91      0.87       982\n",
            "        5.0       0.78      0.75      0.76       892\n",
            "        6.0       0.93      0.87      0.90       958\n",
            "        7.0       0.89      0.89      0.89      1028\n",
            "        8.0       0.83      0.82      0.83       974\n",
            "        9.0       0.91      0.80      0.85      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 946    0    2    0    4   14    7    2    4    1]\n",
            " [   0 1111    8    2    1    0    1    0   12    0]\n",
            " [  26   38  865   16   15    7   20   22   21    2]\n",
            " [  12   16   27  821    6   75    4   11   33    5]\n",
            " [   1   10   17    1  893    5   12    0    3   40]\n",
            " [  23   23    1   83    7  669   10    4   66    6]\n",
            " [  33    9   26    3   10   36  835    0    6    0]\n",
            " [   4   21   19   11   28    0    1  914    7   23]\n",
            " [   7   15   22   30   26   45   11   12  802    4]\n",
            " [   8    9    7   16   78   11    1   63   10  806]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [23 14 33 32 30 37 21 24 35 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 16.444 s \n",
            "\n",
            "Accuracy rate for 87.460000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.97      0.94       980\n",
            "        1.0       0.90      0.98      0.94      1135\n",
            "        2.0       0.82      0.87      0.85      1032\n",
            "        3.0       0.84      0.86      0.85      1010\n",
            "        4.0       0.84      0.90      0.87       982\n",
            "        5.0       0.81      0.76      0.78       892\n",
            "        6.0       0.93      0.88      0.90       958\n",
            "        7.0       0.91      0.89      0.90      1028\n",
            "        8.0       0.87      0.81      0.84       974\n",
            "        9.0       0.91      0.81      0.86      1009\n",
            "\n",
            "avg / total       0.88      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 948    0    4    0    3   11    5    4    3    2]\n",
            " [   0 1110    5    4    0    1    3    0   12    0]\n",
            " [  13   34  900   14   12    7   20   13   16    3]\n",
            " [   8   15   28  865    3   51    3   10   24    3]\n",
            " [   2    7   29    1  887    2   12    2    4   36]\n",
            " [  24   18    7   92   15  676   12   11   33    4]\n",
            " [  32    5   35    2    6   35  839    0    4    0]\n",
            " [   4   20   34    5   21    0    1  910    8   25]\n",
            " [   5   12   34   33   23   45   11    8  793   10]\n",
            " [   9    9   15   12   88    8    1   37   12  818]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59725,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59725, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [24 17 34 33 33 42 23 29 39 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 17.955 s \n",
            "\n",
            "Accuracy rate for 87.640000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.97      0.94       980\n",
            "        1.0       0.89      0.98      0.93      1135\n",
            "        2.0       0.82      0.84      0.83      1032\n",
            "        3.0       0.86      0.84      0.85      1010\n",
            "        4.0       0.83      0.92      0.87       982\n",
            "        5.0       0.83      0.79      0.81       892\n",
            "        6.0       0.93      0.89      0.91       958\n",
            "        7.0       0.89      0.91      0.90      1028\n",
            "        8.0       0.88      0.83      0.85       974\n",
            "        9.0       0.93      0.78      0.85      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 947    0    6    0    5   10    4    6    2    0]\n",
            " [   0 1111    6    3    0    1    2    0   12    0]\n",
            " [  13   57  869   13   15    6   18   18   20    3]\n",
            " [  12   17   28  849    3   57    6    8   26    4]\n",
            " [   1    3   29    0  903    0   10    3    2   31]\n",
            " [  22   13   10   73   16  704   13    8   29    4]\n",
            " [  25    5   37    2    9   24  850    0    6    0]\n",
            " [   4   26   26    4   14    0    1  934    5   14]\n",
            " [   9   13   33   29   22   36    9    9  807    7]\n",
            " [   9    8   10   12  102    6    1   59   12  790]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [25 19 39 38 35 45 24 32 40 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.560 s \n",
            "\n",
            "Accuracy rate for 88.080000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.98      0.95       980\n",
            "        1.0       0.89      0.98      0.93      1135\n",
            "        2.0       0.84      0.86      0.85      1032\n",
            "        3.0       0.85      0.85      0.85      1010\n",
            "        4.0       0.83      0.93      0.88       982\n",
            "        5.0       0.84      0.80      0.82       892\n",
            "        6.0       0.94      0.89      0.91       958\n",
            "        7.0       0.90      0.90      0.90      1028\n",
            "        8.0       0.89      0.82      0.86       974\n",
            "        9.0       0.92      0.78      0.84      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 956    0    4    0    4    9    3    1    3    0]\n",
            " [   0 1110    5    4    1    1    2    0   12    0]\n",
            " [  11   51  887   11   16    4   18   15   17    2]\n",
            " [  13   18   28  859    4   50    4    7   22    5]\n",
            " [   2    2   27    0  909    0    9    2    2   29]\n",
            " [  17   17    9   73   17  714   11    6   23    5]\n",
            " [  25    6   36    2    9   21  856    0    3    0]\n",
            " [   4   20   25    9   16    0    1  930    9   14]\n",
            " [   7   13   26   32   19   44    9   12  803    9]\n",
            " [   8    8   15   16   96    7    1   65    9  784]]\n",
            "--------------------------------\n",
            "val predicted: (59675,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59675, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [26 20 41 42 35 51 26 32 44 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 20.651 s \n",
            "\n",
            "Accuracy rate for 88.750000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.98      0.95       980\n",
            "        1.0       0.89      0.98      0.93      1135\n",
            "        2.0       0.84      0.86      0.85      1032\n",
            "        3.0       0.85      0.86      0.86      1010\n",
            "        4.0       0.86      0.91      0.88       982\n",
            "        5.0       0.85      0.81      0.83       892\n",
            "        6.0       0.93      0.90      0.92       958\n",
            "        7.0       0.94      0.90      0.92      1028\n",
            "        8.0       0.89      0.82      0.86       974\n",
            "        9.0       0.91      0.83      0.87      1009\n",
            "\n",
            "avg / total       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 956    0    3    0    3   10    5    1    2    0]\n",
            " [   0 1115    5    2    0    1    1    0   11    0]\n",
            " [  11   50  890   10   16    4   18   11   19    3]\n",
            " [  10   16   29  870    4   47    2    7   21    4]\n",
            " [   1    3   23    3  892    0   10    2    3   45]\n",
            " [  21   15    9   74   13  721   12    1   21    5]\n",
            " [  23    5   27    1    9   23  866    0    4    0]\n",
            " [   5   25   26    9   13    0    4  923    5   18]\n",
            " [   6   17   39   36   16   33    8   12  803    4]\n",
            " [   8    8    8   16   77   12    1   30   10  839]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [30 22 41 47 36 53 27 33 49 37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 22.325 s \n",
            "\n",
            "Accuracy rate for 88.680000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.97      0.94       980\n",
            "        1.0       0.89      0.98      0.94      1135\n",
            "        2.0       0.86      0.87      0.86      1032\n",
            "        3.0       0.83      0.87      0.85      1010\n",
            "        4.0       0.86      0.91      0.88       982\n",
            "        5.0       0.87      0.80      0.83       892\n",
            "        6.0       0.94      0.90      0.92       958\n",
            "        7.0       0.93      0.89      0.91      1028\n",
            "        8.0       0.88      0.84      0.86       974\n",
            "        9.0       0.91      0.82      0.86      1009\n",
            "\n",
            "avg / total       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 954    0    3    0    0   13    5    1    4    0]\n",
            " [   0 1113    4    1    0    2    1    0   14    0]\n",
            " [  17   41  894   14   17    3   16    9   18    3]\n",
            " [  14   12   28  877    6   33    1    7   27    5]\n",
            " [   4    4   19    5  890    0    9    2    4   45]\n",
            " [  17   20   10   82    9  714   11    3   20    6]\n",
            " [  24    4   33    2   10   21  859    1    4    0]\n",
            " [   3   26   26    9   14    0    2  918    7   23]\n",
            " [   9   17   13   54   19   26    5   10  817    4]\n",
            " [  14    8    9   17   75    7    0   38    9  832]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59625, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [31 23 46 52 41 54 28 34 53 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.701 s \n",
            "\n",
            "Accuracy rate for 89.020000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.97      0.94       980\n",
            "        1.0       0.91      0.98      0.95      1135\n",
            "        2.0       0.86      0.88      0.87      1032\n",
            "        3.0       0.84      0.86      0.85      1010\n",
            "        4.0       0.86      0.91      0.89       982\n",
            "        5.0       0.86      0.80      0.83       892\n",
            "        6.0       0.93      0.91      0.92       958\n",
            "        7.0       0.92      0.90      0.91      1028\n",
            "        8.0       0.88      0.85      0.87       974\n",
            "        9.0       0.92      0.82      0.87      1009\n",
            "\n",
            "avg / total       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    1    4    0    0   14    5    1    3    0]\n",
            " [   0 1115    4    1    0    3    1    0   11    0]\n",
            " [  13   24  905    9   17    7   25    7   22    3]\n",
            " [  14   14   33  870    5   30    2    8   30    4]\n",
            " [   3    2   23    3  898    2   12    3    2   34]\n",
            " [  22   13    7   83   11  715    9    4   23    5]\n",
            " [  26    5   23    2    9   19  867    0    7    0]\n",
            " [   3   25   25   10   17    0    2  923    2   21]\n",
            " [   7   15   18   40   14   27    8   11  829    5]\n",
            " [   9    8    9   17   73   12    1   41   11  828]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59600,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [32 24 48 58 42 58 29 34 57 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 25.124 s \n",
            "\n",
            "Accuracy rate for 89.390000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.97      0.94       980\n",
            "        1.0       0.91      0.98      0.95      1135\n",
            "        2.0       0.87      0.89      0.88      1032\n",
            "        3.0       0.83      0.86      0.85      1010\n",
            "        4.0       0.87      0.92      0.90       982\n",
            "        5.0       0.86      0.82      0.84       892\n",
            "        6.0       0.95      0.91      0.93       958\n",
            "        7.0       0.94      0.89      0.91      1028\n",
            "        8.0       0.88      0.84      0.86       974\n",
            "        9.0       0.92      0.84      0.88      1009\n",
            "\n",
            "avg / total       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 950    1    2    0    0   21    3    1    2    0]\n",
            " [   0 1115    3    2    0    4    0    0   11    0]\n",
            " [  18   22  914   12   16    5   13    7   23    2]\n",
            " [  10   15   34  873    2   29    2    6   33    6]\n",
            " [   3    4   19    5  905    1    9    3    2   31]\n",
            " [  16   13    9   80    9  727    7    4   23    4]\n",
            " [  22    5   25    1    8   21  874    0    2    0]\n",
            " [   5   23   20   13   15    1    2  918    4   27]\n",
            " [   4   15   15   55   19   26    9    9  817    5]\n",
            " [   9    8   11   14   64   14    1   33    9  846]]\n",
            "--------------------------------\n",
            "val predicted: (59575,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59575, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [35 25 48 63 43 63 30 36 59 48] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 26.530 s \n",
            "\n",
            "Accuracy rate for 89.570000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.97      0.94       980\n",
            "        1.0       0.93      0.98      0.95      1135\n",
            "        2.0       0.88      0.89      0.88      1032\n",
            "        3.0       0.83      0.87      0.85      1010\n",
            "        4.0       0.88      0.91      0.90       982\n",
            "        5.0       0.86      0.80      0.83       892\n",
            "        6.0       0.95      0.91      0.93       958\n",
            "        7.0       0.95      0.90      0.92      1028\n",
            "        8.0       0.87      0.84      0.86       974\n",
            "        9.0       0.90      0.86      0.88      1009\n",
            "\n",
            "avg / total       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 954    1    0    2    0   18    2    1    2    0]\n",
            " [   0 1113    3    4    0    3    0    0   12    0]\n",
            " [  13   19  914   18   12    3   13    8   27    5]\n",
            " [  11    9   33  883    3   27    1    7   31    5]\n",
            " [   3    4   14    4  898    1   10    2    7   39]\n",
            " [  22   11    7   88    8  712    9    3   25    7]\n",
            " [  23    3   21    2    7   22  876    0    4    0]\n",
            " [   3   23   21    5   15    0    2  921    6   32]\n",
            " [   5   13   15   49   14   31    9    8  823    7]\n",
            " [   9    7   11    9   60   12    1   23   14  863]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [36 25 50 65 46 68 32 37 65 51] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 28.135 s \n",
            "\n",
            "Accuracy rate for 89.660000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.97      0.94       980\n",
            "        1.0       0.92      0.98      0.95      1135\n",
            "        2.0       0.88      0.87      0.88      1032\n",
            "        3.0       0.84      0.88      0.86      1010\n",
            "        4.0       0.88      0.91      0.90       982\n",
            "        5.0       0.87      0.82      0.84       892\n",
            "        6.0       0.95      0.92      0.93       958\n",
            "        7.0       0.95      0.90      0.92      1028\n",
            "        8.0       0.87      0.85      0.86       974\n",
            "        9.0       0.90      0.85      0.87      1009\n",
            "\n",
            "avg / total       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 950    1    5    2    0   18    1    1    2    0]\n",
            " [   0 1107    6    3    0    2    1    0   16    0]\n",
            " [  14   25  902   21   11    5   18    7   26    3]\n",
            " [   9    9   32  889    3   30    1    7   24    6]\n",
            " [   2    3   10    3  896    1   13    1    7   46]\n",
            " [  22    8    6   79    6  733   11    1   21    5]\n",
            " [  19    5   25    2    6   18  881    0    2    0]\n",
            " [   3   21   17    4   13    1    0  927    9   33]\n",
            " [   6   13   18   50   12   29    5    8  827    6]\n",
            " [   9    7    4   11   71   10    1   27   15  854]]\n",
            "--------------------------------\n",
            "val predicted: (59525,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59525, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [37 28 52 68 48 72 33 39 71 52] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 29.644 s \n",
            "\n",
            "Accuracy rate for 89.800000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.96      0.95       980\n",
            "        1.0       0.92      0.98      0.95      1135\n",
            "        2.0       0.88      0.87      0.88      1032\n",
            "        3.0       0.85      0.89      0.87      1010\n",
            "        4.0       0.88      0.91      0.90       982\n",
            "        5.0       0.86      0.82      0.84       892\n",
            "        6.0       0.95      0.91      0.93       958\n",
            "        7.0       0.94      0.90      0.92      1028\n",
            "        8.0       0.87      0.87      0.87       974\n",
            "        9.0       0.89      0.84      0.87      1009\n",
            "\n",
            "avg / total       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    1    7    2    0   22    3    1    1    0]\n",
            " [   0 1114    6    1    0    1    1    0   12    0]\n",
            " [  11   27  902   17   10    7   17   10   28    3]\n",
            " [   5   11   25  895    2   27    1   10   29    5]\n",
            " [   2    4   13    2  898    1   10    0    5   47]\n",
            " [  18    7    9   76    5  734    9    1   26    7]\n",
            " [  20    3   26    2    7   21  876    0    3    0]\n",
            " [   0   22   19    3   14    1    0  926    7   36]\n",
            " [   5   15   16   40   11   28    6    6  843    4]\n",
            " [  10    7    6   10   73    9    1   27   17  849]]\n",
            "--------------------------------\n",
            "final active learning accuracies [50.160000000000004, 63.73, 70.14, 74.4, 78.99000000000001, 80.36999999999999, 82.76, 84.35000000000001, 85.78, 86.61999999999999, 87.46000000000001, 87.64, 88.08, 88.75, 88.68, 89.02, 89.39, 89.57000000000001, 89.66, 89.8]\n",
            "saved Active-learning-experiment-9.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 10, using model = SvmModel, selection_function = MarginSamplingSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [0 1 0 4 0 1 1 1 1 1] [1 3 5 6 7 8 9]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n",
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.716 s \n",
            "\n",
            "Accuracy rate for 31.860000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.00      0.00      0.00       980\n",
            "        1.0       0.79      0.68      0.73      1135\n",
            "        2.0       0.00      0.00      0.00      1032\n",
            "        3.0       0.20      0.92      0.32      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.09      0.04      0.06       892\n",
            "        6.0       0.35      0.33      0.34       958\n",
            "        7.0       0.47      0.60      0.53      1028\n",
            "        8.0       0.22      0.23      0.22       974\n",
            "        9.0       0.41      0.29      0.34      1009\n",
            "\n",
            "avg / total       0.26      0.32      0.26     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  0   0   0 445   0  82 221   8 216   8]\n",
            " [  0 775   0 339   0   2   0  13   6   0]\n",
            " [  0  18   0 817   0   2 103  49  28  15]\n",
            " [  0   7   0 929   0  17   9  24  20   4]\n",
            " [  0  47   0 390   0   1  91 150 122 181]\n",
            " [  0   5   0 580   0  37  33  35 198   4]\n",
            " [  0  41   0 268   0 213 313  40  46  37]\n",
            " [  0  29   0 157   0   2   7 615  88 130]\n",
            " [  0  32   0 593   0  40  26  23 221  39]\n",
            " [  0  24   0 198   0   5  85 342  59 296]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59990,) [3. 3. 5. ... 7. 9. 9.]\n",
            "probabilities: (59990, 7) \n",
            " [1 1 1 ... 1 1 1]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [ 2  2  0 10  0  2  1  1  1  1] [0 1 3 5 6 7 8 9]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 1.151 s \n",
            "\n",
            "Accuracy rate for 37.600000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.85      0.46      0.59       980\n",
            "        1.0       0.55      0.95      0.70      1135\n",
            "        2.0       0.00      0.00      0.00      1032\n",
            "        3.0       0.34      0.76      0.47      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.16      0.61      0.25       892\n",
            "        6.0       0.69      0.22      0.33       958\n",
            "        7.0       0.56      0.46      0.50      1028\n",
            "        8.0       0.83      0.05      0.10       974\n",
            "        9.0       0.35      0.20      0.25      1009\n",
            "\n",
            "avg / total       0.43      0.38      0.32     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 447    3    0  159    0  342   21    6    1    1]\n",
            " [   0 1076    0    3    0   56    0    0    0    0]\n",
            " [  25  241    0  612    0   92   34   18    0   10]\n",
            " [   0   33    0  766    0  192    2   10    0    7]\n",
            " [   7   99    0   96    0  526   11   86    1  156]\n",
            " [   7   50    0  271    0  543    7   12    0    2]\n",
            " [  28   64    0   31    0  608  211   10    0    6]\n",
            " [   3  105    0    6    0  290    0  469    8  147]\n",
            " [   2  235    0  282    0  350    9   11   50   35]\n",
            " [   8   53    0   32    0  488   12  218    0  198]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59980,) [0. 0. 5. ... 7. 9. 9.]\n",
            "probabilities: (59980, 8) \n",
            " [0 2 2 ... 2 2 2]\n",
            "trainset before (20, 784) (20,)\n",
            "trainset after (30, 784) (30,)\n",
            "updated train set: (30, 784) (30,) unique(labels): [ 7  2  2 10  2  3  1  1  1  1] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59970, 784) (59970,)\n",
            "\n",
            "Train set: (30, 784) y: (30,)\n",
            "Val   set: (59970, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 1.775 s \n",
            "\n",
            "Accuracy rate for 46.230000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.81      0.80       980\n",
            "        1.0       0.58      0.95      0.72      1135\n",
            "        2.0       0.81      0.18      0.29      1032\n",
            "        3.0       0.44      0.62      0.51      1010\n",
            "        4.0       0.33      0.56      0.41       982\n",
            "        5.0       0.27      0.75      0.39       892\n",
            "        6.0       0.84      0.20      0.32       958\n",
            "        7.0       0.62      0.41      0.49      1028\n",
            "        8.0       0.88      0.03      0.06       974\n",
            "        9.0       0.27      0.10      0.14      1009\n",
            "\n",
            "avg / total       0.58      0.46      0.42     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 793    2    0   13   26  138    5    2    0    1]\n",
            " [   0 1075    0    3    0   57    0    0    0    0]\n",
            " [  53  221  185  468   22   51   14   16    0    2]\n",
            " [   4   31    2  625   10  322    2    7    0    7]\n",
            " [   5   76    2   10  547  193    3   53    0   93]\n",
            " [   8   45    3   98   64  667    2    4    0    1]\n",
            " [  99   32    7   11  170  450  187    1    0    1]\n",
            " [  16   97    7    2  249   93    0  417    4  143]\n",
            " [  21  218   16  188  104  361    7    8   30   21]\n",
            " [  11   44    7   16  486  181    2  165    0   97]]\n",
            "--------------------------------\n",
            "val predicted: (59970,) [0. 0. 5. ... 7. 9. 9.]\n",
            "probabilities: (59970, 10) \n",
            " [0 0 0 ... 4 3 3]\n",
            "trainset before (30, 784) (30,)\n",
            "trainset after (40, 784) (40,)\n",
            "updated train set: (40, 784) (40,) unique(labels): [ 7  2  3 10  4  3  3  3  2  3] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59960, 784) (59960,)\n",
            "\n",
            "Train set: (40, 784) y: (40,)\n",
            "Val   set: (59960, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 2.415 s \n",
            "\n",
            "Accuracy rate for 58.410000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.78      0.82       980\n",
            "        1.0       0.66      0.95      0.78      1135\n",
            "        2.0       0.71      0.28      0.40      1032\n",
            "        3.0       0.47      0.61      0.53      1010\n",
            "        4.0       0.49      0.64      0.55       982\n",
            "        5.0       0.37      0.68      0.48       892\n",
            "        6.0       0.89      0.55      0.68       958\n",
            "        7.0       0.72      0.58      0.64      1028\n",
            "        8.0       0.79      0.18      0.29       974\n",
            "        9.0       0.47      0.57      0.51      1009\n",
            "\n",
            "avg / total       0.64      0.58      0.57     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 769    2   27   15    7  123    8   10    0   19]\n",
            " [   0 1075    0    3    0   56    0    1    0    0]\n",
            " [  38  181  286  378   10   24   34   23    5   53]\n",
            " [   3   26    9  618   12  313    1   13    7    8]\n",
            " [   2   37    4    2  626   29   10   22    2  248]\n",
            " [   7   41    2  106   65  603    7   23    6   32]\n",
            " [  49   23   30    7  152  152  523    1    0   21]\n",
            " [   7   73    5    1   88   31    0  599   24  200]\n",
            " [   9  160   22  185   93  249    4   11  171   70]\n",
            " [   4   19   18    9  224   31    0  131    2  571]]\n",
            "--------------------------------\n",
            "val predicted: (59960,) [0. 0. 5. ... 7. 9. 9.]\n",
            "probabilities: (59960, 10) \n",
            " [0 0 0 ... 7 9 9]\n",
            "trainset before (40, 784) (40,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [ 7  2  4 10  6  4  5  4  2  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 2.982 s \n",
            "\n",
            "Accuracy rate for 60.340000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.74      0.81       980\n",
            "        1.0       0.76      0.85      0.80      1135\n",
            "        2.0       0.58      0.47      0.52      1032\n",
            "        3.0       0.56      0.61      0.58      1010\n",
            "        4.0       0.57      0.65      0.61       982\n",
            "        5.0       0.41      0.72      0.52       892\n",
            "        6.0       0.88      0.58      0.70       958\n",
            "        7.0       0.68      0.48      0.56      1028\n",
            "        8.0       0.83      0.14      0.24       974\n",
            "        9.0       0.44      0.77      0.56      1009\n",
            "\n",
            "avg / total       0.66      0.60      0.59     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[727   1  79  16   5 126   6  10   0  10]\n",
            " [  0 966   0   3   1  40   1  69   0  55]\n",
            " [ 31 123 490 228  33  16  34  35   3  39]\n",
            " [  3   4  18 612   6 305   0  17   2  43]\n",
            " [  0  13  24   1 637   8  22   9   0 268]\n",
            " [  4  22  19  78  36 645   6   9   1  72]\n",
            " [ 30   7  82   4 171  91 554   4   0  15]\n",
            " [  5  37   9   1  59  23   1 489  22 382]\n",
            " [  6  99  95 139  70 312   8   5 138 102]\n",
            " [  3   4  34   6  96  19   0  70   1 776]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 5. ... 7. 9. 9.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 5 ... 9 9 9]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (60, 784) (60,)\n",
            "updated train set: (60, 784) (60,) unique(labels): [ 7  5  5 10  6  5  6  6  3  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59940, 784) (59940,)\n",
            "\n",
            "Train set: (60, 784) y: (60,)\n",
            "Val   set: (59940, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 3.609 s \n",
            "\n",
            "Accuracy rate for 65.980000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.73      0.81       980\n",
            "        1.0       0.73      0.99      0.84      1135\n",
            "        2.0       0.64      0.53      0.58      1032\n",
            "        3.0       0.58      0.59      0.58      1010\n",
            "        4.0       0.65      0.65      0.65       982\n",
            "        5.0       0.48      0.74      0.58       892\n",
            "        6.0       0.87      0.67      0.75       958\n",
            "        7.0       0.79      0.59      0.68      1028\n",
            "        8.0       0.90      0.30      0.45       974\n",
            "        9.0       0.49      0.78      0.60      1009\n",
            "\n",
            "avg / total       0.71      0.66      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 714    3   76   17    2  129   15   12    1   11]\n",
            " [   0 1122    1    3    1    3    1    3    0    1]\n",
            " [  17  132  548  195   25    7   41   29    6   32]\n",
            " [   2   46   10  592    3  275    0   16   14   52]\n",
            " [   0   19   25    1  636    4   15    6    0  276]\n",
            " [   3   46   21   79   27  659    8    9    1   39]\n",
            " [  31   25   94    4  111   49  639    0    0    5]\n",
            " [   2   36   10    1   36    7    0  607    8  321]\n",
            " [   8  102   45  121   48  235   17   12  295   91]\n",
            " [   2    6   32    6   85   18    0   73    1  786]]\n",
            "--------------------------------\n",
            "val predicted: (59940,) [0. 0. 5. ... 7. 9. 9.]\n",
            "probabilities: (59940, 10) \n",
            " [0 0 5 ... 7 9 9]\n",
            "trainset before (60, 784) (60,)\n",
            "trainset after (70, 784) (70,)\n",
            "updated train set: (70, 784) (70,) unique(labels): [ 8  6  5 12  7  8  6  8  3  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59930, 784) (59930,)\n",
            "\n",
            "Train set: (70, 784) y: (70,)\n",
            "Val   set: (59930, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.231 s \n",
            "\n",
            "Accuracy rate for 65.010000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.78      0.83       980\n",
            "        1.0       0.66      0.99      0.79      1135\n",
            "        2.0       0.70      0.45      0.55      1032\n",
            "        3.0       0.61      0.59      0.60      1010\n",
            "        4.0       0.57      0.69      0.63       982\n",
            "        5.0       0.44      0.79      0.56       892\n",
            "        6.0       0.91      0.64      0.75       958\n",
            "        7.0       0.76      0.62      0.68      1028\n",
            "        8.0       0.91      0.28      0.42       974\n",
            "        9.0       0.54      0.64      0.58      1009\n",
            "\n",
            "avg / total       0.70      0.65      0.64     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 769    2   33    6   49   93   13   10    1    4]\n",
            " [   0 1123    0    4    1    2    0    4    0    1]\n",
            " [  32  142  466  239   77    6   25   23    6   16]\n",
            " [   5   66    7  598   10  275    0   12   11   26]\n",
            " [   0   24   13    0  674   50   13   23    0  185]\n",
            " [   5   39   11   64   24  707    7   13    1   21]\n",
            " [  31   26   78    9  143   52  616    2    0    1]\n",
            " [   1   46    7    1   51   36    0  633    8  245]\n",
            " [  13  213   33   55   28  285    6   18  270   53]\n",
            " [   8   11   21    4  116  105    0   99    0  645]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59930,) [0. 0. 5. ... 7. 9. 9.]\n",
            "probabilities: (59930, 10) \n",
            " [0 0 5 ... 7 9 9]\n",
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [10  6  7 13  9  8  6  9  4  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.745 s \n",
            "\n",
            "Accuracy rate for 69.860000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.85      0.86       980\n",
            "        1.0       0.72      0.99      0.83      1135\n",
            "        2.0       0.62      0.58      0.60      1032\n",
            "        3.0       0.66      0.67      0.66      1010\n",
            "        4.0       0.68      0.81      0.74       982\n",
            "        5.0       0.58      0.79      0.67       892\n",
            "        6.0       0.91      0.55      0.69       958\n",
            "        7.0       0.77      0.61      0.68      1028\n",
            "        8.0       0.84      0.42      0.56       974\n",
            "        9.0       0.57      0.69      0.62      1009\n",
            "\n",
            "avg / total       0.72      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 835    1   30    2   19   78   11    2    1    1]\n",
            " [   0 1124    0    3    0    1    0    4    2    1]\n",
            " [  24  114  594  177   49    3   13   23   27    8]\n",
            " [   4   52   10  677    6  184    0   12   31   34]\n",
            " [   4   23    5    1  791    6   13    6    0  133]\n",
            " [  10   26   13   61   37  706    6   17    1   15]\n",
            " [  65   30  213    6   66   47  529    0    0    2]\n",
            " [   2   32   14    4   38    8    0  623   14  293]\n",
            " [   6  146   45   91   48  167    8   12  411   40]\n",
            " [   6   18   30    8  109   26    0  114    2  696]]\n",
            "--------------------------------\n",
            "val predicted: (59920,) [0. 0. 5. ... 7. 9. 7.]\n",
            "probabilities: (59920, 10) \n",
            " [0 0 5 ... 7 9 7]\n",
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [11  6 10 16  9  8  7  9  4 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.295 s \n",
            "\n",
            "Accuracy rate for 72.290000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.86      0.92      0.88       980\n",
            "        1.0       0.72      0.99      0.83      1135\n",
            "        2.0       0.63      0.64      0.64      1032\n",
            "        3.0       0.67      0.76      0.71      1010\n",
            "        4.0       0.73      0.79      0.76       982\n",
            "        5.0       0.63      0.75      0.69       892\n",
            "        6.0       0.89      0.54      0.68       958\n",
            "        7.0       0.87      0.61      0.72      1028\n",
            "        8.0       0.87      0.40      0.55       974\n",
            "        9.0       0.60      0.80      0.69      1009\n",
            "\n",
            "avg / total       0.75      0.72      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 898    0   14    4    1   36   22    2    1    2]\n",
            " [   0 1122    0    5    0    1    1    3    2    1]\n",
            " [  17  126  660  142   18    3   11   22   23   10]\n",
            " [   8   41   15  763    2  130    0    9   18   24]\n",
            " [   5   17    9    2  776    8   16    3    0  146]\n",
            " [  24   27   24   72   37  667    6   13    1   21]\n",
            " [  65   32  222    7   76   32  522    0    0    2]\n",
            " [  12   28   18   14   39   14    0  626   12  265]\n",
            " [   9  146   54  116   40  142   10    5  388   64]\n",
            " [  12   15   29   17   74   20    0   34    1  807]]\n",
            "--------------------------------\n",
            "val predicted: (59910,) [0. 0. 5. ... 7. 9. 9.]\n",
            "probabilities: (59910, 10) \n",
            " [0 0 5 ... 9 9 9]\n",
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [11  6 12 18 10  9  7 10  7 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.996 s \n",
            "\n",
            "Accuracy rate for 74.650000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.91      0.89       980\n",
            "        1.0       0.83      0.97      0.90      1135\n",
            "        2.0       0.66      0.73      0.70      1032\n",
            "        3.0       0.67      0.78      0.72      1010\n",
            "        4.0       0.67      0.81      0.73       982\n",
            "        5.0       0.70      0.73      0.72       892\n",
            "        6.0       0.91      0.54      0.68       958\n",
            "        7.0       0.85      0.65      0.74      1028\n",
            "        8.0       0.80      0.59      0.68       974\n",
            "        9.0       0.63      0.72      0.67      1009\n",
            "\n",
            "avg / total       0.76      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 895    0   12    7    2   34   19    8    2    1]\n",
            " [   0 1100    7    6    0    1    1    4   15    1]\n",
            " [  19   72  758   98   19    2   10   18   28    8]\n",
            " [   7   22   14  785    4  121    0   12   32   13]\n",
            " [   5   12    9   13  792    3   14    4    8  122]\n",
            " [  17   13   16   68   48  651    5   26   36   12]\n",
            " [  60   21  228   11   88   28  516    1    5    0]\n",
            " [   4   25   21   15   44    4    0  668   12  235]\n",
            " [  13   46   52  137   39   63    5    7  571   41]\n",
            " [   9    9   23   33  152   17    0   36    1  729]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 5. ... 7. 9. 9.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 5 ... 7 9 9]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [12  6 14 19 10 12 10 10  7 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.570 s \n",
            "\n",
            "Accuracy rate for 76.240000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.90      0.90       980\n",
            "        1.0       0.85      0.96      0.90      1135\n",
            "        2.0       0.68      0.75      0.72      1032\n",
            "        3.0       0.69      0.76      0.72      1010\n",
            "        4.0       0.71      0.79      0.75       982\n",
            "        5.0       0.68      0.81      0.74       892\n",
            "        6.0       0.83      0.70      0.76       958\n",
            "        7.0       0.88      0.65      0.75      1028\n",
            "        8.0       0.85      0.56      0.67       974\n",
            "        9.0       0.64      0.72      0.68      1009\n",
            "\n",
            "avg / total       0.77      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 878    0   10    7    0   29   51    2    3    0]\n",
            " [   0 1093    9    7    0    5    3    4   13    1]\n",
            " [  15   64  776   85   18    3   29   13   24    5]\n",
            " [   6   15   17  767    3  143    3   12   32   12]\n",
            " [   4   14   16   10  777   14   17    5    7  118]\n",
            " [  12    1   14   68   24  726   19   12    7    9]\n",
            " [  20   19  176    4   49   20  669    0    1    0]\n",
            " [   4   23   40   12   38   12    0  666   10  223]\n",
            " [  14   47   50  128   38   98   12    5  546   36]\n",
            " [  10    8   27   31  149   22    1   34    1  726]]\n",
            "--------------------------------\n",
            "val predicted: (59890,) [0. 0. 5. ... 7. 9. 9.]\n",
            "probabilities: (59890, 10) \n",
            " [0 0 5 ... 9 9 9]\n",
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [12  7 14 20 11 12 11 10 12 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.275 s \n",
            "\n",
            "Accuracy rate for 77.370000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.89      0.91       980\n",
            "        1.0       0.83      0.96      0.89      1135\n",
            "        2.0       0.71      0.77      0.74      1032\n",
            "        3.0       0.72      0.82      0.76      1010\n",
            "        4.0       0.71      0.79      0.75       982\n",
            "        5.0       0.73      0.71      0.72       892\n",
            "        6.0       0.86      0.73      0.79       958\n",
            "        7.0       0.89      0.66      0.76      1028\n",
            "        8.0       0.79      0.69      0.73       974\n",
            "        9.0       0.64      0.68      0.66      1009\n",
            "\n",
            "avg / total       0.78      0.77      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 875    0   11    8    0   26   39    2   19    0]\n",
            " [   0 1095    8    6    0    3    2    3   17    1]\n",
            " [  15   60  792   63   15    4   24   15   39    5]\n",
            " [   5   15   17  824    1   81    5   10   37   15]\n",
            " [   4   28   15   11  780   15   13    3    4  109]\n",
            " [  11    6    9  118   24  632   24   11   47   10]\n",
            " [  15   23  147    3   40   16  699    0   15    0]\n",
            " [   4   31   40   16   31   13    0  679    5  209]\n",
            " [  11   49   42   64   24   61    9    4  672   38]\n",
            " [  10   10   32   33  181   20    1   32    1  689]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59880,) [0. 0. 5. ... 7. 9. 9.]\n",
            "probabilities: (59880, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [13  9 15 21 11 14 12 11 13 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.836 s \n",
            "\n",
            "Accuracy rate for 77.590000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.89      0.91       980\n",
            "        1.0       0.83      0.98      0.90      1135\n",
            "        2.0       0.69      0.77      0.73      1032\n",
            "        3.0       0.73      0.85      0.79      1010\n",
            "        4.0       0.70      0.79      0.74       982\n",
            "        5.0       0.75      0.74      0.75       892\n",
            "        6.0       0.85      0.73      0.78       958\n",
            "        7.0       0.88      0.64      0.74      1028\n",
            "        8.0       0.84      0.67      0.75       974\n",
            "        9.0       0.64      0.67      0.65      1009\n",
            "\n",
            "avg / total       0.78      0.78      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 875    0   15    6    0   26   39    2   17    0]\n",
            " [   0 1117    1    7    0    4    4    1    0    1]\n",
            " [  20   66  792   57   14    2   33   13   30    5]\n",
            " [   4   16   18  858    3   54    3    7   31   16]\n",
            " [   2   21   26    9  772   24   15   10    6   97]\n",
            " [   8    3   10  119   18  656   23   13   36    6]\n",
            " [  14   13  165    4   51   10  697    0    4    0]\n",
            " [   4   41   39   17   28   22    0  662    3  212]\n",
            " [  11   64   45   60   34   51    8    6  657   38]\n",
            " [  11   11   31   32  189   20    1   39    2  673]]\n",
            "--------------------------------\n",
            "val predicted: (59870,) [0. 0. 5. ... 7. 9. 9.]\n",
            "probabilities: (59870, 10) \n",
            " [0 0 5 ... 7 9 9]\n",
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [13 10 16 21 11 14 13 14 16 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.405 s \n",
            "\n",
            "Accuracy rate for 78.700000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.90      0.91       980\n",
            "        1.0       0.84      0.99      0.91      1135\n",
            "        2.0       0.72      0.76      0.74      1032\n",
            "        3.0       0.73      0.85      0.78      1010\n",
            "        4.0       0.69      0.78      0.73       982\n",
            "        5.0       0.79      0.69      0.74       892\n",
            "        6.0       0.85      0.77      0.81       958\n",
            "        7.0       0.85      0.75      0.79      1028\n",
            "        8.0       0.80      0.73      0.76       974\n",
            "        9.0       0.70      0.63      0.67      1009\n",
            "\n",
            "avg / total       0.79      0.79      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 882    0   17    5    1   18   33    2   22    0]\n",
            " [   0 1119    1    6    0    0    1    0    7    1]\n",
            " [  21   66  782   76   14    2   31   13   25    2]\n",
            " [   5   17   18  854    4   52    1   14   35   10]\n",
            " [   2   17   31   10  764   10   26   13    6  103]\n",
            " [   7    7    6  124   18  618   22   15   68    7]\n",
            " [  11   11  128    4   49   11  736    0    8    0]\n",
            " [   4   33   34   12   28   20    0  767    3  127]\n",
            " [  13   50   39   55   33   36   12    6  708   22]\n",
            " [  13   10   33   24  191   16    1   76    5  640]]\n",
            "--------------------------------\n",
            "val predicted: (59860,) [0. 0. 5. ... 7. 9. 9.]\n",
            "probabilities: (59860, 10) \n",
            " [0 0 8 ... 7 9 9]\n",
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [14 10 16 23 14 16 13 15 17 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.955 s \n",
            "\n",
            "Accuracy rate for 79.060000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.90      0.90       980\n",
            "        1.0       0.85      0.98      0.91      1135\n",
            "        2.0       0.73      0.75      0.74      1032\n",
            "        3.0       0.74      0.85      0.79      1010\n",
            "        4.0       0.67      0.89      0.77       982\n",
            "        5.0       0.80      0.67      0.73       892\n",
            "        6.0       0.87      0.77      0.82       958\n",
            "        7.0       0.84      0.74      0.79      1028\n",
            "        8.0       0.80      0.74      0.77       974\n",
            "        9.0       0.75      0.57      0.65      1009\n",
            "\n",
            "avg / total       0.79      0.79      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 885    0   15    9    1   18   33    3   16    0]\n",
            " [   0 1116    0    4    2    0    1    3    8    1]\n",
            " [  24   69  778   53   20    2   31   15   39    1]\n",
            " [   8   14   15  854    4   55    1   16   33   10]\n",
            " [   5    8   30    8  872    1   12    2    3   41]\n",
            " [  15    7    5  133   33  602   20    8   63    6]\n",
            " [   9   11  122    4   54   12  736    0   10    0]\n",
            " [   3   29   33   13   51   18    0  763    4  114]\n",
            " [  27   47   33   45   28   34    9   10  720   21]\n",
            " [  20    8   41   30  232   10    1   83    4  580]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [14 10 16 23 14 17 14 18 17 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.530 s \n",
            "\n",
            "Accuracy rate for 80.060000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.89      0.89       980\n",
            "        1.0       0.87      0.98      0.92      1135\n",
            "        2.0       0.77      0.75      0.76      1032\n",
            "        3.0       0.75      0.84      0.79      1010\n",
            "        4.0       0.68      0.85      0.75       982\n",
            "        5.0       0.81      0.68      0.74       892\n",
            "        6.0       0.84      0.83      0.84       958\n",
            "        7.0       0.88      0.79      0.83      1028\n",
            "        8.0       0.80      0.73      0.76       974\n",
            "        9.0       0.73      0.64      0.68      1009\n",
            "\n",
            "avg / total       0.80      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 871    0   15    8    1   16   49    3   17    0]\n",
            " [   0 1113    0    6    3    1    2    3    7    0]\n",
            " [  24   65  770   48   12    1   50   21   38    3]\n",
            " [   7    8   13  846    2   61    6   16   33   18]\n",
            " [   6    8   30    8  836    1    9    3    1   80]\n",
            " [  14    4    5  123   26  609   26   10   64   11]\n",
            " [   7    6   76    3   46    9  797    0   14    0]\n",
            " [   3   18   34    4   48   10    0  809    2  100]\n",
            " [  26   45   30   47   31   34    9    9  714   29]\n",
            " [  16    7   30   28  230    8    2   43    4  641]]\n",
            "--------------------------------\n",
            "val predicted: (59840,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59840, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [15 12 17 23 14 19 16 19 17 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.043 s \n",
            "\n",
            "Accuracy rate for 81.210000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.91      0.91       980\n",
            "        1.0       0.87      0.99      0.92      1135\n",
            "        2.0       0.79      0.75      0.77      1032\n",
            "        3.0       0.76      0.85      0.80      1010\n",
            "        4.0       0.73      0.85      0.78       982\n",
            "        5.0       0.80      0.68      0.74       892\n",
            "        6.0       0.86      0.87      0.86       958\n",
            "        7.0       0.88      0.79      0.83      1028\n",
            "        8.0       0.82      0.73      0.77       974\n",
            "        9.0       0.72      0.68      0.70      1009\n",
            "\n",
            "avg / total       0.81      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 894    0   13    8    0   14   40    2    9    0]\n",
            " [   0 1118    1    6    3    1    1    3    1    1]\n",
            " [  23   67  779   46    9    2   46   20   37    3]\n",
            " [  10   10   13  854    1   52    7   19   29   15]\n",
            " [   2    9   26    6  834    4    9    3    1   88]\n",
            " [  16    5    4  129   22  610   25   10   59   12]\n",
            " [   8    6   62    3   21   12  833    0   13    0]\n",
            " [   3   13   34    5   45    9    1  807    2  109]\n",
            " [  21   52   27   51   26   33   10   11  709   34]\n",
            " [  15    7   25   23  189   23    2   39    3  683]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59830,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59830, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [15 12 17 24 17 20 18 19 17 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.552 s \n",
            "\n",
            "Accuracy rate for 82.320000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.91      0.91       980\n",
            "        1.0       0.88      0.98      0.93      1135\n",
            "        2.0       0.83      0.74      0.78      1032\n",
            "        3.0       0.78      0.85      0.81      1010\n",
            "        4.0       0.74      0.87      0.80       982\n",
            "        5.0       0.80      0.72      0.76       892\n",
            "        6.0       0.84      0.92      0.88       958\n",
            "        7.0       0.90      0.78      0.83      1028\n",
            "        8.0       0.84      0.72      0.78       974\n",
            "        9.0       0.73      0.72      0.73      1009\n",
            "\n",
            "avg / total       0.82      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 892    0   13    8    1   14   41    2    9    0]\n",
            " [   0 1117    1    6    3    1    2    3    1    1]\n",
            " [  23   61  765   45   14    3   58   21   38    4]\n",
            " [  10   10   13  854    1   60    8   18   24   12]\n",
            " [   2    9   21    2  853    3   13    2    1   76]\n",
            " [  14    5    4  110   23  639   26    9   45   17]\n",
            " [   6    3   28    2   14   11  881    0   13    0]\n",
            " [   3   13   31    4   52    5    2  798    2  118]\n",
            " [  20   51   25   44   23   43   12   11  706   39]\n",
            " [  16    6   21   17  172   17    3   27    3  727]]\n",
            "--------------------------------\n",
            "val predicted: (59820,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59820, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [16 12 19 24 18 23 19 19 19 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.435 s \n",
            "\n",
            "Accuracy rate for 83.170000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.93      0.91       980\n",
            "        1.0       0.90      0.99      0.94      1135\n",
            "        2.0       0.84      0.81      0.82      1032\n",
            "        3.0       0.82      0.84      0.83      1010\n",
            "        4.0       0.73      0.88      0.80       982\n",
            "        5.0       0.79      0.73      0.76       892\n",
            "        6.0       0.85      0.92      0.88       958\n",
            "        7.0       0.91      0.78      0.84      1028\n",
            "        8.0       0.85      0.72      0.78       974\n",
            "        9.0       0.75      0.69      0.72      1009\n",
            "\n",
            "avg / total       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 916    0    7    1    0   15   34    1    6    0]\n",
            " [   0 1118    1    6    1    2    2    3    1    1]\n",
            " [  16   32  835   34   22    2   50   16   22    3]\n",
            " [  17    8   17  850    1   50   10   16   30   11]\n",
            " [   3    7   18    2  868    6   12    3    6   57]\n",
            " [  24    6    7   90   27  655   25    7   39   12]\n",
            " [  12    3   30    2   11   10  877    0   13    0]\n",
            " [   4   14   29    4   44   11    3  797    2  120]\n",
            " [  20   47   33   38   26   59   11    8  703   29]\n",
            " [  18    6   22   15  195   20    3   28    4  698]]\n",
            "--------------------------------\n",
            "val predicted: (59810,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59810, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [16 12 20 25 19 25 19 19 20 25] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.935 s \n",
            "\n",
            "Accuracy rate for 83.780000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.93      0.92       980\n",
            "        1.0       0.91      0.99      0.94      1135\n",
            "        2.0       0.84      0.80      0.82      1032\n",
            "        3.0       0.82      0.84      0.83      1010\n",
            "        4.0       0.75      0.87      0.81       982\n",
            "        5.0       0.79      0.76      0.78       892\n",
            "        6.0       0.86      0.91      0.88       958\n",
            "        7.0       0.91      0.77      0.83      1028\n",
            "        8.0       0.85      0.73      0.79       974\n",
            "        9.0       0.76      0.76      0.76      1009\n",
            "\n",
            "avg / total       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 914    0    8    2    0   15   34    1    6    0]\n",
            " [   0 1118    0    6    1    2    2    3    2    1]\n",
            " [  17   34  829   35   20    3   50   15   24    5]\n",
            " [  14    8   18  844    2   58   11   15   28   12]\n",
            " [   3    6   14    5  850    8   10    4    4   78]\n",
            " [  19    4    3   80   28  678   23    5   43    9]\n",
            " [  12    3   29    2   11   11  875    0   15    0]\n",
            " [   4   12   37    5   52   10    3  793    2  110]\n",
            " [  19   45   29   38   30   48   11    9  715   30]\n",
            " [  15    4   18   16  135   21    3   31    4  762]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [16 14 21 27 19 25 20 19 22 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.460 s \n",
            "\n",
            "Accuracy rate for 84.600000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.94      0.92       980\n",
            "        1.0       0.90      0.99      0.94      1135\n",
            "        2.0       0.84      0.81      0.82      1032\n",
            "        3.0       0.81      0.86      0.83      1010\n",
            "        4.0       0.78      0.86      0.82       982\n",
            "        5.0       0.81      0.75      0.78       892\n",
            "        6.0       0.87      0.92      0.89       958\n",
            "        7.0       0.92      0.77      0.84      1028\n",
            "        8.0       0.87      0.74      0.80       974\n",
            "        9.0       0.76      0.80      0.78      1009\n",
            "\n",
            "avg / total       0.85      0.85      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 917    0    8    1    1   17   31    1    4    0]\n",
            " [   0 1122    0    6    1    2    2    1    1    0]\n",
            " [  16   35  833   42   18    4   40   14   25    5]\n",
            " [  13    8   19  864    1   42    9   16   26   12]\n",
            " [   2    9   15    4  849    6   13    4    3   77]\n",
            " [  18    4    2   92   26  672   22    6   38   12]\n",
            " [   8    4   31    3   13   12  877    0   10    0]\n",
            " [   4   17   35    5   51   10    3  791    3  109]\n",
            " [  19   38   29   37   27   49    8    8  725   34]\n",
            " [  15    6   18   15  102   14    5   21    3  810]]\n",
            "--------------------------------\n",
            "val predicted: (59790,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59790, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [16 14 21 28 21 27 20 20 24 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.999 s \n",
            "\n",
            "Accuracy rate for 84.580000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.93      0.91       980\n",
            "        1.0       0.91      0.99      0.95      1135\n",
            "        2.0       0.86      0.80      0.83      1032\n",
            "        3.0       0.80      0.83      0.81      1010\n",
            "        4.0       0.78      0.87      0.82       982\n",
            "        5.0       0.79      0.74      0.76       892\n",
            "        6.0       0.88      0.92      0.89       958\n",
            "        7.0       0.91      0.78      0.84      1028\n",
            "        8.0       0.86      0.75      0.80       974\n",
            "        9.0       0.77      0.82      0.80      1009\n",
            "\n",
            "avg / total       0.85      0.85      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 913    0    8    2    0   17   32    2    6    0]\n",
            " [   0 1121    0    5    1    1    2    1    4    0]\n",
            " [  15   33  830   43   20    5   40   15   26    5]\n",
            " [  17    7   23  839    1   60    8   16   27   12]\n",
            " [   2    8    8    5  852    8   11    3    2   83]\n",
            " [  23    5    2   98   25  659   22    8   40   10]\n",
            " [   8    3   33    2   13   11  877    0   11    0]\n",
            " [   4   13   29    3   56    5    2  806    2  108]\n",
            " [  19   33   25   42   30   52    3    9  733   28]\n",
            " [  15    6    9   15   91   15    5   22    3  828]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59780,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59780, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [16 14 21 31 23 27 21 21 26 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.608 s \n",
            "\n",
            "Accuracy rate for 84.470000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.93      0.92       980\n",
            "        1.0       0.92      0.99      0.95      1135\n",
            "        2.0       0.87      0.80      0.84      1032\n",
            "        3.0       0.80      0.84      0.82      1010\n",
            "        4.0       0.78      0.88      0.83       982\n",
            "        5.0       0.78      0.72      0.75       892\n",
            "        6.0       0.87      0.90      0.89       958\n",
            "        7.0       0.91      0.77      0.83      1028\n",
            "        8.0       0.85      0.77      0.81       974\n",
            "        9.0       0.77      0.82      0.79      1009\n",
            "\n",
            "avg / total       0.85      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 916    0    8    2    0   18   32    1    3    0]\n",
            " [   0 1120    0    6    1    2    1    2    3    0]\n",
            " [  15   33  830   36   20    4   43   12   31    8]\n",
            " [  17    8   22  847    1   62    5   16   19   13]\n",
            " [   3    9    6    3  865    7    9    1    2   77]\n",
            " [  21    7    2  107   26  638   26   10   48    7]\n",
            " [   9    4   27    1   18   16  863    0   20    0]\n",
            " [   5   10   32    2   59    6    3  791    4  116]\n",
            " [  20   28   19   37   26   48    4   11  748   33]\n",
            " [  14    5    8   16   92   12    5   24    4  829]]\n",
            "--------------------------------\n",
            "val predicted: (59770,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59770, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [16 15 21 31 23 30 22 24 28 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 14.336 s \n",
            "\n",
            "Accuracy rate for 85.070000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.94      0.92       980\n",
            "        1.0       0.92      0.99      0.95      1135\n",
            "        2.0       0.87      0.80      0.83      1032\n",
            "        3.0       0.80      0.84      0.82      1010\n",
            "        4.0       0.79      0.88      0.83       982\n",
            "        5.0       0.77      0.75      0.76       892\n",
            "        6.0       0.88      0.89      0.88       958\n",
            "        7.0       0.93      0.81      0.87      1028\n",
            "        8.0       0.85      0.78      0.81       974\n",
            "        9.0       0.80      0.82      0.81      1009\n",
            "\n",
            "avg / total       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 919    0    7    2    0   20   27    1    4    0]\n",
            " [   0 1118    0    6    1    1    2    2    5    0]\n",
            " [  15   32  827   38   20   11   46   11   24    8]\n",
            " [  17    8   20  845    3   64    4   15   20   14]\n",
            " [   3   12    5    5  860   11   10    0    4   72]\n",
            " [  16    4    2  102   20  665   20   12   46    5]\n",
            " [  11    3   33    1   20   18  850    0   22    0]\n",
            " [   5   15   32    2   50    4    3  837    5   75]\n",
            " [  13   24   17   35   28   61    3    9  755   29]\n",
            " [  14    5   11   18   89   12    4   17    8  831]]\n",
            "--------------------------------\n",
            "val predicted: (59760,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59760, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [16 15 23 31 24 32 24 25 29 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 15.069 s \n",
            "\n",
            "Accuracy rate for 85.640000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.94      0.93       980\n",
            "        1.0       0.92      0.98      0.95      1135\n",
            "        2.0       0.89      0.82      0.85      1032\n",
            "        3.0       0.83      0.82      0.82      1010\n",
            "        4.0       0.79      0.87      0.83       982\n",
            "        5.0       0.76      0.79      0.77       892\n",
            "        6.0       0.88      0.91      0.89       958\n",
            "        7.0       0.92      0.81      0.87      1028\n",
            "        8.0       0.85      0.77      0.81       974\n",
            "        9.0       0.80      0.83      0.82      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 920    0    7    2    0   21   25    2    3    0]\n",
            " [   0 1117    0    6    1    1    2    2    6    0]\n",
            " [  15   28  845   31   16    8   47   13   23    6]\n",
            " [  15    7   22  830    3   77    5   15   20   16]\n",
            " [   2   11    8    5  859    8    9    0    4   76]\n",
            " [  14    2    1   80   22  702   20   12   35    4]\n",
            " [  10    3   19    1   15   16  870    0   24    0]\n",
            " [   5   14   33    1   50    3    3  837    4   78]\n",
            " [  11   31   13   30   28   77    4    8  746   26]\n",
            " [  13    5    6   18   89   12    4   16    8  838]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [16 16 23 32 28 32 25 28 29 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 16.161 s \n",
            "\n",
            "Accuracy rate for 85.750000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.94      0.93       980\n",
            "        1.0       0.92      0.98      0.95      1135\n",
            "        2.0       0.88      0.82      0.85      1032\n",
            "        3.0       0.82      0.84      0.83      1010\n",
            "        4.0       0.78      0.90      0.84       982\n",
            "        5.0       0.77      0.79      0.78       892\n",
            "        6.0       0.88      0.90      0.89       958\n",
            "        7.0       0.93      0.82      0.87      1028\n",
            "        8.0       0.86      0.76      0.81       974\n",
            "        9.0       0.81      0.80      0.81      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 923    0    7    2    1   23   20    1    3    0]\n",
            " [   0 1115    0    5    1    1    3    2    8    0]\n",
            " [  14   30  848   29   15    7   48   13   22    6]\n",
            " [  14    5   23  848    3   74    3   11   17   12]\n",
            " [   2    6    8    3  885    1    8    0    4   65]\n",
            " [  14    3    2   74   23  704   23   14   32    3]\n",
            " [  13    4   22    1   19   18  859    0   22    0]\n",
            " [   4   13   32    4   49    0    2  847    5   72]\n",
            " [  11   32   13   35   29   79    4    7  738   26]\n",
            " [  16    5    5   27  112   11    3   17    5  808]]\n",
            "--------------------------------\n",
            "val predicted: (59740,) [0. 0. 0. ... 9. 4. 9.]\n",
            "probabilities: (59740, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [16 17 23 34 28 37 26 28 29 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 16.931 s \n",
            "\n",
            "Accuracy rate for 85.700000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.94      0.92       980\n",
            "        1.0       0.93      0.98      0.95      1135\n",
            "        2.0       0.88      0.81      0.84      1032\n",
            "        3.0       0.80      0.84      0.82      1010\n",
            "        4.0       0.78      0.90      0.84       982\n",
            "        5.0       0.76      0.81      0.78       892\n",
            "        6.0       0.88      0.90      0.89       958\n",
            "        7.0       0.93      0.82      0.87      1028\n",
            "        8.0       0.89      0.75      0.82       974\n",
            "        9.0       0.82      0.80      0.81      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 919    0    7    2    1   26   20    2    3    0]\n",
            " [   0 1111    0    5    1    5    5    1    7    0]\n",
            " [  14   25  838   45   15    6   45   13   25    6]\n",
            " [  16    3   23  850    1   74    4   10   16   13]\n",
            " [   2    5    8    5  884    4    8    1    5   60]\n",
            " [  13    2    2   89   20  719   19   10   15    3]\n",
            " [  14    2   22    1   17   23  864    0   15    0]\n",
            " [   4   17   33    6   51    0    2  844    4   67]\n",
            " [  14   28   14   37   27   79    7    6  734   28]\n",
            " [  15    6    6   25  115   13    3   16    3  807]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59730,) [0. 0. 0. ... 9. 4. 9.]\n",
            "probabilities: (59730, 10) \n",
            " [0 0 0 ... 9 4 9]\n",
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [16 17 23 36 28 38 28 30 30 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 16.945 s \n",
            "\n",
            "Accuracy rate for 86.180000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.94      0.92       980\n",
            "        1.0       0.92      0.98      0.95      1135\n",
            "        2.0       0.89      0.81      0.85      1032\n",
            "        3.0       0.81      0.83      0.82      1010\n",
            "        4.0       0.80      0.91      0.85       982\n",
            "        5.0       0.76      0.82      0.79       892\n",
            "        6.0       0.88      0.91      0.90       958\n",
            "        7.0       0.93      0.83      0.88      1028\n",
            "        8.0       0.89      0.75      0.82       974\n",
            "        9.0       0.83      0.83      0.83      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 917    0    7    2    1   26   21    3    3    0]\n",
            " [   0 1109    0    7    1    5    5    1    7    0]\n",
            " [  14   27  836   40   15    6   49   16   23    6]\n",
            " [  19    4   23  836    1   73    4   11   23   16]\n",
            " [   2    5    7    3  894    2   10    2    7   50]\n",
            " [  13    2    2   79   18  729   19   12   12    6]\n",
            " [  11    3   19    2   19   22  875    0    7    0]\n",
            " [   3   19   32    4   43    0    2  853    5   67]\n",
            " [  13   29   14   34   23   88    6    4  735   28]\n",
            " [  15    4    4   21   96   10    3   17    5  834]]\n",
            "--------------------------------\n",
            "val predicted: (59720,) [0. 0. 0. ... 9. 4. 9.]\n",
            "probabilities: (59720, 10) \n",
            " [0 0 0 ... 9 4 9]\n",
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [16 17 23 38 28 41 30 30 33 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 24.023 s \n",
            "\n",
            "Accuracy rate for 86.580000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.92      0.92       980\n",
            "        1.0       0.93      0.98      0.95      1135\n",
            "        2.0       0.90      0.81      0.85      1032\n",
            "        3.0       0.82      0.83      0.82      1010\n",
            "        4.0       0.81      0.91      0.85       982\n",
            "        5.0       0.76      0.84      0.80       892\n",
            "        6.0       0.88      0.91      0.90       958\n",
            "        7.0       0.94      0.83      0.88      1028\n",
            "        8.0       0.88      0.79      0.83       974\n",
            "        9.0       0.83      0.82      0.83      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 906    0    7    2    1   39   21    1    3    0]\n",
            " [   0 1109    0    5    1    8    4    1    7    0]\n",
            " [  14   24  841   35   17    5   47   18   26    5]\n",
            " [  16    3   22  839    2   83    3   11   20   11]\n",
            " [   2    5    7    3  889    3    9    2   11   51]\n",
            " [  14    1    2   69   14  749   20    2   16    5]\n",
            " [  12    4   14    2   20   21  874    0   11    0]\n",
            " [   3   19   30    5   42    0    2  854    5   68]\n",
            " [  14   19   10   44   16   67    7    3  765   29]\n",
            " [  14    4    3   23   96   12    3   17    5  832]]\n",
            "--------------------------------\n",
            "val predicted: (59710,) [0. 0. 0. ... 9. 4. 9.]\n",
            "probabilities: (59710, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [16 18 24 39 29 42 30 30 37 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 20.758 s \n",
            "\n",
            "Accuracy rate for 86.510000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.92      0.92       980\n",
            "        1.0       0.93      0.98      0.95      1135\n",
            "        2.0       0.89      0.81      0.85      1032\n",
            "        3.0       0.83      0.83      0.83      1010\n",
            "        4.0       0.81      0.90      0.86       982\n",
            "        5.0       0.76      0.84      0.80       892\n",
            "        6.0       0.89      0.91      0.90       958\n",
            "        7.0       0.93      0.83      0.88      1028\n",
            "        8.0       0.87      0.80      0.83       974\n",
            "        9.0       0.83      0.81      0.82      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 906    0    8    2    1   40   19    1    3    0]\n",
            " [   0 1109    0    5    1    8    4    1    7    0]\n",
            " [  14   24  837   33   15    5   47   19   33    5]\n",
            " [  13    2   20  839    1   84    3   13   25   10]\n",
            " [   2    5    7    3  886    5    8    1   11   54]\n",
            " [  10    3    2   66   16  750   20    2   19    4]\n",
            " [  11    4   15    2   19   22  872    0   13    0]\n",
            " [   3   24   33    3   34    4    2  852    5   68]\n",
            " [  11   17   11   37   17   64    7    5  780   25]\n",
            " [  17    5    3   25  100   11    3   20    5  820]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [16 19 26 39 29 43 30 31 39 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.440 s \n",
            "\n",
            "Accuracy rate for 86.710000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.93      0.92       980\n",
            "        1.0       0.92      0.98      0.95      1135\n",
            "        2.0       0.88      0.80      0.84      1032\n",
            "        3.0       0.83      0.84      0.83      1010\n",
            "        4.0       0.82      0.89      0.86       982\n",
            "        5.0       0.77      0.84      0.80       892\n",
            "        6.0       0.88      0.91      0.90       958\n",
            "        7.0       0.93      0.83      0.88      1028\n",
            "        8.0       0.87      0.81      0.84       974\n",
            "        9.0       0.83      0.83      0.83      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 911    0    6    2    1   37   18    1    4    0]\n",
            " [   0 1112    0    5    1    7    4    1    5    0]\n",
            " [  15   31  825   29   17    8   49   18   34    6]\n",
            " [  13    1   18  844    0   81    3   15   22   13]\n",
            " [   3    6    9    3  877    1    8    1    9   65]\n",
            " [  10    0    5   67   13  750   19    2   21    5]\n",
            " [  12    3   19    2   18   20  869    0   15    0]\n",
            " [   3   26   32    3   36    1    2  856    6   63]\n",
            " [  11   19   11   36   19   55    7    6  789   21]\n",
            " [  14    5    8   23   83   12    3   18    5  838]]\n",
            "--------------------------------\n",
            "val predicted: (59690,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59690, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [17 20 28 40 30 44 30 32 41 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 26.392 s \n",
            "\n",
            "Accuracy rate for 87.090000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.94      0.93       980\n",
            "        1.0       0.93      0.98      0.95      1135\n",
            "        2.0       0.88      0.82      0.85      1032\n",
            "        3.0       0.85      0.83      0.84      1010\n",
            "        4.0       0.82      0.89      0.85       982\n",
            "        5.0       0.77      0.85      0.81       892\n",
            "        6.0       0.89      0.91      0.90       958\n",
            "        7.0       0.94      0.84      0.88      1028\n",
            "        8.0       0.87      0.82      0.84       974\n",
            "        9.0       0.84      0.82      0.83      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 919    0    3    2    1   38   14    1    2    0]\n",
            " [   0 1108    1    5    1    9    4    1    6    0]\n",
            " [  16   21  846   25   16    9   46   13   36    4]\n",
            " [  13    2   22  839    2   81    3   14   20   14]\n",
            " [   4    6   12    3  877    0    9    1    8   62]\n",
            " [  14    1    4   56   14  756   19    2   22    4]\n",
            " [   9    3   19    1   15   21  876    0   14    0]\n",
            " [   3   27   32    4   38    0    2  859    5   58]\n",
            " [  14   19   11   30   16   55    6    7  797   19]\n",
            " [  15    5    9   17   94   12    3   16    6  832]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59680,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59680, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [17 21 29 42 31 45 30 33 41 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 24.393 s \n",
            "\n",
            "Accuracy rate for 86.910000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.94      0.93       980\n",
            "        1.0       0.92      0.98      0.95      1135\n",
            "        2.0       0.87      0.82      0.85      1032\n",
            "        3.0       0.86      0.83      0.84      1010\n",
            "        4.0       0.81      0.88      0.85       982\n",
            "        5.0       0.77      0.84      0.81       892\n",
            "        6.0       0.89      0.91      0.90       958\n",
            "        7.0       0.94      0.83      0.88      1028\n",
            "        8.0       0.88      0.81      0.84       974\n",
            "        9.0       0.83      0.83      0.83      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 919    0    3    3    1   37   14    1    2    0]\n",
            " [   0 1111    1    4    0    8    4    1    6    0]\n",
            " [  15   32  845   17   14    9   45   11   37    7]\n",
            " [  14    3   24  839    3   80    3   17   16   11]\n",
            " [   2    6   19    2  867    0    7    1    7   71]\n",
            " [  13    1    5   58   18  753   20    2   20    2]\n",
            " [   9    3   19    0   18   20  875    0   14    0]\n",
            " [   2   27   35    3   40    3    2  852    6   58]\n",
            " [  16   22    8   35   14   49    6   11  791   22]\n",
            " [  15    7    7   16   91   13    2   14    5  839]]\n",
            "--------------------------------\n",
            "val predicted: (59670,) [0. 0. 0. ... 9. 4. 9.]\n",
            "probabilities: (59670, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [17 21 31 42 33 46 30 34 42 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 26.199 s \n",
            "\n",
            "Accuracy rate for 87.130000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.93      0.92       980\n",
            "        1.0       0.92      0.98      0.95      1135\n",
            "        2.0       0.88      0.84      0.86      1032\n",
            "        3.0       0.87      0.83      0.85      1010\n",
            "        4.0       0.82      0.86      0.84       982\n",
            "        5.0       0.77      0.85      0.80       892\n",
            "        6.0       0.91      0.91      0.91       958\n",
            "        7.0       0.93      0.83      0.88      1028\n",
            "        8.0       0.88      0.83      0.85       974\n",
            "        9.0       0.82      0.84      0.83      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 914    0    3    3    1   43   13    1    2    0]\n",
            " [   0 1110    2    3    1    8    4    1    6    0]\n",
            " [  16   29  867   15   15    9   33   11   31    6]\n",
            " [  13    2   24  840    2   84    3   18   17    7]\n",
            " [   2    6   17    1  848    1    6    1    8   92]\n",
            " [  14    2    4   57   16  755   18    2   21    3]\n",
            " [   9    3   18    0   16   27  872    0   13    0]\n",
            " [   3   27   34    3   35    2    2  857    6   59]\n",
            " [  12   23    7   30   16   46    4   11  806   19]\n",
            " [  17    7    8   17   81    9    1   19    6  844]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) [0. 0. 0. ... 9. 4. 9.]\n",
            "probabilities: (59660, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [17 23 32 42 33 47 31 36 45 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 21.873 s \n",
            "\n",
            "Accuracy rate for 87.430000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.93      0.92       980\n",
            "        1.0       0.92      0.98      0.95      1135\n",
            "        2.0       0.89      0.84      0.87      1032\n",
            "        3.0       0.86      0.83      0.84      1010\n",
            "        4.0       0.83      0.87      0.85       982\n",
            "        5.0       0.78      0.84      0.81       892\n",
            "        6.0       0.92      0.92      0.92       958\n",
            "        7.0       0.94      0.84      0.89      1028\n",
            "        8.0       0.88      0.83      0.85       974\n",
            "        9.0       0.82      0.83      0.83      1009\n",
            "\n",
            "avg / total       0.88      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 913    0    4    4    1   45   11    1    1    0]\n",
            " [   0 1117    2    3    1    2    4    1    5    0]\n",
            " [  19   24  871   17   12    5   32   11   35    6]\n",
            " [  13    5   22  839    4   80    2   16   22    7]\n",
            " [   2    6   13    0  852    1    8    0    3   97]\n",
            " [  15    3    2   61   17  753   16    1   23    1]\n",
            " [   9    4   14    0   12   27  879    0   13    0]\n",
            " [   3   27   35    3   29    0    2  868    5   56]\n",
            " [   8   24    9   33   16   44    4   10  810   16]\n",
            " [  17    8    6   16   82   10    1   20    8  841]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 0. ... 9. 4. 9.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 9 4 9]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [18 23 33 44 34 48 31 37 47 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 29.129 s \n",
            "\n",
            "Accuracy rate for 87.750000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.94      0.93       980\n",
            "        1.0       0.92      0.99      0.95      1135\n",
            "        2.0       0.89      0.86      0.88      1032\n",
            "        3.0       0.87      0.83      0.85      1010\n",
            "        4.0       0.81      0.86      0.84       982\n",
            "        5.0       0.79      0.85      0.82       892\n",
            "        6.0       0.92      0.92      0.92       958\n",
            "        7.0       0.94      0.85      0.89      1028\n",
            "        8.0       0.88      0.84      0.86       974\n",
            "        9.0       0.83      0.82      0.82      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 924    0    2    4    2   34   12    1    1    0]\n",
            " [   0 1118    2    3    2    2    4    0    4    0]\n",
            " [  17   22  891    7   10    5   30   12   32    6]\n",
            " [  10    6   28  835    5   76    2   13   25   10]\n",
            " [   2    6   13    1  849    1    9    0    6   95]\n",
            " [  10    3    1   57   22  760   16    1   20    2]\n",
            " [  11    4   13    0   11   24  880    0   15    0]\n",
            " [   4   26   33    4   28    0    2  876    3   52]\n",
            " [  10   23    8   37   16   42    3    9  816   10]\n",
            " [  13    7    5   13  100   13    1   23    8  826]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59640, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [19 23 34 44 35 51 32 37 48 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 28.933 s \n",
            "\n",
            "Accuracy rate for 87.970000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.94      0.94       980\n",
            "        1.0       0.92      0.99      0.95      1135\n",
            "        2.0       0.88      0.86      0.87      1032\n",
            "        3.0       0.87      0.83      0.85      1010\n",
            "        4.0       0.82      0.88      0.85       982\n",
            "        5.0       0.79      0.85      0.82       892\n",
            "        6.0       0.91      0.91      0.91       958\n",
            "        7.0       0.94      0.85      0.89      1028\n",
            "        8.0       0.88      0.83      0.86       974\n",
            "        9.0       0.84      0.83      0.83      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 922    0    3    4    2   32   14    1    2    0]\n",
            " [   0 1119    2    3    1    2    4    0    4    0]\n",
            " [  17   24  887    9   11    3   30   14   30    7]\n",
            " [   7    6   29  841    3   74    3   14   24    9]\n",
            " [   1    6   16    1  868    1    9    0    5   75]\n",
            " [   9    1    1   58   19  762   18    2   19    3]\n",
            " [  11    5   19    0   15   23  874    0   11    0]\n",
            " [   3   27   34    5   27    1    2  872    2   55]\n",
            " [   6   22    7   39   16   46    3    9  812   14]\n",
            " [  10    7    5    8   95   15    1   18   10  840]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59630,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59630, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [21 23 34 45 36 54 32 37 48 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 24.852 s \n",
            "\n",
            "Accuracy rate for 88.230000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.96      0.94       980\n",
            "        1.0       0.92      0.98      0.95      1135\n",
            "        2.0       0.89      0.86      0.87      1032\n",
            "        3.0       0.88      0.81      0.84      1010\n",
            "        4.0       0.84      0.88      0.86       982\n",
            "        5.0       0.79      0.88      0.83       892\n",
            "        6.0       0.92      0.91      0.91       958\n",
            "        7.0       0.94      0.85      0.89      1028\n",
            "        8.0       0.88      0.84      0.86       974\n",
            "        9.0       0.84      0.86      0.85      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    0    3    4    2   18    8    1    1    0]\n",
            " [   0 1117    2    4    2    2    4    0    4    0]\n",
            " [  22   22  885   15    9    3   26   15   29    6]\n",
            " [  14    5   22  820    3   93    5   14   25    9]\n",
            " [   2    7   18    0  863    1    8    0    7   76]\n",
            " [  15    1    0   40   16  781   13    2   19    5]\n",
            " [  22    5   20    0   12   20  867    0   12    0]\n",
            " [   1   29   33    8   28    0    2  869    2   56]\n",
            " [   8   22    8   34   15   51    4    8  814   10]\n",
            " [   8    6    3   11   77   16    1   15    8  864]]\n",
            "--------------------------------\n",
            "val predicted: (59620,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59620, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [21 23 36 47 37 55 33 38 48 52] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 22.831 s \n",
            "\n",
            "Accuracy rate for 88.230000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.96      0.94       980\n",
            "        1.0       0.93      0.98      0.96      1135\n",
            "        2.0       0.89      0.86      0.87      1032\n",
            "        3.0       0.87      0.82      0.84      1010\n",
            "        4.0       0.82      0.89      0.86       982\n",
            "        5.0       0.79      0.88      0.84       892\n",
            "        6.0       0.93      0.91      0.92       958\n",
            "        7.0       0.94      0.84      0.89      1028\n",
            "        8.0       0.88      0.82      0.85       974\n",
            "        9.0       0.84      0.84      0.84      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    0    6    4    2   17    8    2    1    0]\n",
            " [   0 1117    3    2    2    2    4    0    5    0]\n",
            " [  20   17  884   22    9    1   26   12   34    7]\n",
            " [  14    6   19  828    2   92    4   14   22    9]\n",
            " [   2    7   16    0  878    1    5    0    5   68]\n",
            " [  13    1    1   36   18  787   13    3   16    4]\n",
            " [  19    4   17    1   12   20  876    0    9    0]\n",
            " [   1   27   27    9   31    1    2  868    5   57]\n",
            " [   8   18   10   42   21   52    4    7  799   13]\n",
            " [   7    6    7    9   90   17    0   16   11  846]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59610, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [22 23 36 49 38 57 35 38 50 52] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.284 s \n",
            "\n",
            "Accuracy rate for 88.220000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.96      0.94       980\n",
            "        1.0       0.93      0.98      0.95      1135\n",
            "        2.0       0.90      0.85      0.88      1032\n",
            "        3.0       0.86      0.82      0.84      1010\n",
            "        4.0       0.82      0.90      0.86       982\n",
            "        5.0       0.79      0.88      0.83       892\n",
            "        6.0       0.93      0.92      0.92       958\n",
            "        7.0       0.94      0.85      0.89      1028\n",
            "        8.0       0.89      0.82      0.86       974\n",
            "        9.0       0.84      0.84      0.84      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 938    0    8    4    1   18    8    2    1    0]\n",
            " [   0 1113    2    2    2    2    4    0   10    0]\n",
            " [  19   18  882   22   12    6   28   11   27    7]\n",
            " [  19    5   17  826    4   94    4   13   18   10]\n",
            " [   2    5   18    0  885    1    4    0    3   64]\n",
            " [  18    2    3   35   16  784   12    3   14    5]\n",
            " [  12    4   12    1   13   29  879    0    8    0]\n",
            " [   1   26   27   12   30    1    2  869    3   57]\n",
            " [  11   20    7   44   20   46    4    6  800   16]\n",
            " [   6    6    6   11   91   16    0   16   11  846]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [22 24 36 51 39 59 35 39 53 52] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.677 s \n",
            "\n",
            "Accuracy rate for 88.160000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.96      0.93       980\n",
            "        1.0       0.92      0.98      0.95      1135\n",
            "        2.0       0.89      0.85      0.87      1032\n",
            "        3.0       0.86      0.81      0.83      1010\n",
            "        4.0       0.83      0.90      0.87       982\n",
            "        5.0       0.79      0.87      0.83       892\n",
            "        6.0       0.93      0.91      0.92       958\n",
            "        7.0       0.94      0.85      0.89      1028\n",
            "        8.0       0.88      0.83      0.86       974\n",
            "        9.0       0.85      0.84      0.85      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 936    0    7    5    2   22    6    1    1    0]\n",
            " [   0 1114    2    2    2    2    4    0    9    0]\n",
            " [  20   19  881   26   11    5   27   12   27    4]\n",
            " [  20    3   18  820    4   88    5   14   29    9]\n",
            " [   2    6   19    0  885    1    3    0    3   63]\n",
            " [  20    1    4   42   13  779   13    2   14    4]\n",
            " [  12    4   14    1   15   27  876    0    9    0]\n",
            " [   1   28   28   13   26    0    2  869    4   57]\n",
            " [  10   25    7   38   16   48    4    8  809    9]\n",
            " [   6    5    5   12   88   17    0   16   13  847]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59590, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [22 25 37 51 41 59 36 40 54 55] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 24.337 s \n",
            "\n",
            "Accuracy rate for 88.030000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.95      0.93       980\n",
            "        1.0       0.93      0.98      0.95      1135\n",
            "        2.0       0.89      0.85      0.87      1032\n",
            "        3.0       0.87      0.81      0.84      1010\n",
            "        4.0       0.83      0.90      0.87       982\n",
            "        5.0       0.78      0.88      0.83       892\n",
            "        6.0       0.94      0.91      0.92       958\n",
            "        7.0       0.94      0.86      0.90      1028\n",
            "        8.0       0.88      0.82      0.85       974\n",
            "        9.0       0.84      0.83      0.84      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 933    0   11    4    3   22    5    1    1    0]\n",
            " [   0 1112    3    1    2    2    3    0   11    1]\n",
            " [  20   20  880   26   12    2   25   13   28    6]\n",
            " [  20    3   19  815    3   90    4   14   30   12]\n",
            " [   2    2   15    0  887    3    3    0    3   67]\n",
            " [  20    1    5   40   12  781   14    2   14    3]\n",
            " [  12    4   21    1   12   28  872    0    8    0]\n",
            " [   1   28   22    9   25    0    1  883    5   54]\n",
            " [  10   25    9   35   16   53    4    9  800   13]\n",
            " [   6    6    7   10   96   16    1   15   12  840]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59580,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59580, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [22 25 39 51 42 59 36 40 57 59] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 25.018 s \n",
            "\n",
            "Accuracy rate for 88.380000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.95      0.93       980\n",
            "        1.0       0.93      0.98      0.95      1135\n",
            "        2.0       0.89      0.86      0.87      1032\n",
            "        3.0       0.87      0.81      0.84      1010\n",
            "        4.0       0.85      0.90      0.87       982\n",
            "        5.0       0.79      0.87      0.83       892\n",
            "        6.0       0.94      0.92      0.93       958\n",
            "        7.0       0.94      0.86      0.90      1028\n",
            "        8.0       0.88      0.83      0.85       974\n",
            "        9.0       0.84      0.86      0.85      1009\n",
            "\n",
            "avg / total       0.89      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 932    0   10    5    3   23    5    1    1    0]\n",
            " [   0 1112    4    1    2    2    3    0   10    1]\n",
            " [  19   21  884   21   11    3   23   14   29    7]\n",
            " [  19    3   21  817    2   88    3   13   32   12]\n",
            " [   1    3   17    0  882    3    3    0    3   70]\n",
            " [  19    1    5   40   13  780   14    2   14    4]\n",
            " [  12    4   17    1   11   27  877    0    9    0]\n",
            " [   1   25   25    6   25    0    1  881    3   61]\n",
            " [  10   21    8   39   16   51    5   10  805    9]\n",
            " [   4    6    6    6   72   15    1   17   14  868]]\n",
            "--------------------------------\n",
            "val predicted: (59570,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59570, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [22 25 39 53 42 60 37 43 59 60] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 25.357 s \n",
            "\n",
            "Accuracy rate for 88.390000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.95      0.94       980\n",
            "        1.0       0.93      0.98      0.95      1135\n",
            "        2.0       0.89      0.86      0.87      1032\n",
            "        3.0       0.87      0.81      0.84      1010\n",
            "        4.0       0.85      0.90      0.87       982\n",
            "        5.0       0.79      0.87      0.82       892\n",
            "        6.0       0.94      0.91      0.93       958\n",
            "        7.0       0.94      0.86      0.90      1028\n",
            "        8.0       0.87      0.83      0.85       974\n",
            "        9.0       0.84      0.87      0.85      1009\n",
            "\n",
            "avg / total       0.89      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 931    0   12    4    3   23    4    3    0    0]\n",
            " [   0 1112    4    1    2    2    3    0   10    1]\n",
            " [  16   21  884   20   12    5   23   15   29    7]\n",
            " [  15    4   20  818    2   92    4   13   31   11]\n",
            " [   1    3   17    0  880    3    4    0    3   71]\n",
            " [  21    2    6   40   14  773   11    3   19    3]\n",
            " [  12    4   13    2   11   30  873    0   13    0]\n",
            " [   1   27   21    8   23    0    1  883    2   62]\n",
            " [   8   20    9   37   16   45    5   12  809   13]\n",
            " [   4    6    8    6   69   10    0   15   15  876]]\n",
            "--------------------------------\n",
            "val predicted: (59560,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59560, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [22 25 41 53 45 61 37 43 60 63] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 26.061 s \n",
            "\n",
            "Accuracy rate for 88.640000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.95      0.94       980\n",
            "        1.0       0.93      0.98      0.96      1135\n",
            "        2.0       0.89      0.87      0.88      1032\n",
            "        3.0       0.88      0.81      0.85      1010\n",
            "        4.0       0.85      0.90      0.88       982\n",
            "        5.0       0.78      0.87      0.82       892\n",
            "        6.0       0.94      0.91      0.93       958\n",
            "        7.0       0.94      0.86      0.90      1028\n",
            "        8.0       0.87      0.83      0.85       974\n",
            "        9.0       0.84      0.87      0.86      1009\n",
            "\n",
            "avg / total       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 934    0    9    4    3   23    3    3    1    0]\n",
            " [   0 1113    3    1    1    3    3    0   10    1]\n",
            " [  16   14  898   17   11    5   26   12   30    3]\n",
            " [  14    4   19  818    2   96    3   13   30   11]\n",
            " [   1    4   16    0  884    2    4    0    3   68]\n",
            " [  20    2    6   40   18  774    9    3   14    6]\n",
            " [  12    4   13    2   13   28  873    0   13    0]\n",
            " [   1   25   29    6   21    1    1  881    1   62]\n",
            " [   8   22   10   31   16   48    5    9  813   12]\n",
            " [   3    6    6    6   67   11    0   19   15  876]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [22 25 42 56 46 63 38 44 60 64] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 26.561 s \n",
            "\n",
            "Accuracy rate for 88.980000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.95      0.94       980\n",
            "        1.0       0.93      0.98      0.96      1135\n",
            "        2.0       0.89      0.87      0.88      1032\n",
            "        3.0       0.88      0.84      0.86      1010\n",
            "        4.0       0.84      0.91      0.88       982\n",
            "        5.0       0.81      0.87      0.83       892\n",
            "        6.0       0.95      0.91      0.93       958\n",
            "        7.0       0.94      0.86      0.90      1028\n",
            "        8.0       0.88      0.83      0.86       974\n",
            "        9.0       0.85      0.86      0.85      1009\n",
            "\n",
            "avg / total       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 933    0   10    4    4   20    4    3    1    1]\n",
            " [   0 1113    3    2    1    3    3    0    9    1]\n",
            " [  16   15  898   17   10    6   22   14   31    3]\n",
            " [  17    4   19  853    2   66    1   12   24   12]\n",
            " [   1    4   15    0  894    2    4    0    3   59]\n",
            " [  23    1    6   41   17  772   10    3   12    7]\n",
            " [  12    4   11    3   11   29  875    0   13    0]\n",
            " [   1   24   29    7   22    1    1  886    1   56]\n",
            " [   7   22   10   32   18   49    5    9  809   13]\n",
            " [   3    6    5    8   80   11    0   18   13  865]]\n",
            "--------------------------------\n",
            "val predicted: (59540,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59540, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [24 25 43 57 48 64 38 44 63 64] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 27.301 s \n",
            "\n",
            "Accuracy rate for 89.060000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.96      0.94       980\n",
            "        1.0       0.93      0.98      0.95      1135\n",
            "        2.0       0.89      0.87      0.88      1032\n",
            "        3.0       0.88      0.84      0.86      1010\n",
            "        4.0       0.84      0.92      0.88       982\n",
            "        5.0       0.81      0.86      0.84       892\n",
            "        6.0       0.95      0.91      0.93       958\n",
            "        7.0       0.94      0.86      0.90      1028\n",
            "        8.0       0.88      0.83      0.85       974\n",
            "        9.0       0.86      0.86      0.86      1009\n",
            "\n",
            "avg / total       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 939    0    9    4    1   18    4    3    1    1]\n",
            " [   0 1107    3    2    1    3    3    0   15    1]\n",
            " [  14   14  898   20   13    5   18   15   31    4]\n",
            " [  17    3   19  853    3   65    1   12   26   11]\n",
            " [   2    2   14    0  899    2    5    0    3   55]\n",
            " [  23    1    6   40   18  771    8    3   16    6]\n",
            " [  17    3   12    3   10   32  872    0    9    0]\n",
            " [   1   23   29    6   25    1    1  886    2   54]\n",
            " [   7   26   10   29   17   44    7    8  811   15]\n",
            " [   3    6    5    7   77   12    0   17   12  870]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59530,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59530, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [24 25 43 59 50 65 38 46 64 66] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 27.904 s \n",
            "\n",
            "Accuracy rate for 89.340000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.96      0.94       980\n",
            "        1.0       0.94      0.98      0.96      1135\n",
            "        2.0       0.90      0.87      0.88      1032\n",
            "        3.0       0.89      0.85      0.87      1010\n",
            "        4.0       0.85      0.92      0.89       982\n",
            "        5.0       0.81      0.87      0.84       892\n",
            "        6.0       0.95      0.91      0.93       958\n",
            "        7.0       0.94      0.86      0.90      1028\n",
            "        8.0       0.88      0.84      0.86       974\n",
            "        9.0       0.86      0.87      0.86      1009\n",
            "\n",
            "avg / total       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    0    9    4    1   19    4    4    1    1]\n",
            " [   0 1108    3    2    1    3    3    0   14    1]\n",
            " [  15   15  899   20   12    4   18   15   30    4]\n",
            " [  14    3   17  856    3   64    1   14   27   11]\n",
            " [   2    2   13    0  905    1    5    0    3   51]\n",
            " [  26    2    5   31   18  777    9    2   16    6]\n",
            " [  17    3   12    3   10   32  872    0    9    0]\n",
            " [   1   23   30    4   24    0    1  886    2   57]\n",
            " [   6   17   10   33   17   44    7    6  819   15]\n",
            " [   4    5    5    7   70   13    0   18   12  875]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59520, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [26 25 44 61 50 67 38 47 65 67] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 28.575 s \n",
            "\n",
            "Accuracy rate for 89.300000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.96      0.94       980\n",
            "        1.0       0.94      0.98      0.96      1135\n",
            "        2.0       0.89      0.87      0.88      1032\n",
            "        3.0       0.89      0.85      0.87      1010\n",
            "        4.0       0.86      0.92      0.89       982\n",
            "        5.0       0.81      0.86      0.83       892\n",
            "        6.0       0.95      0.91      0.93       958\n",
            "        7.0       0.93      0.86      0.89      1028\n",
            "        8.0       0.88      0.84      0.86       974\n",
            "        9.0       0.85      0.86      0.86      1009\n",
            "\n",
            "avg / total       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    0    5    4    1   19    2    4    1    1]\n",
            " [   0 1111    4    4    1    3    2    0    9    1]\n",
            " [  16   16  901   20   12    6   15   14   28    4]\n",
            " [  15    2   21  860    2   58    0   14   30    8]\n",
            " [   2    2   13    0  902    2    5    1    3   52]\n",
            " [  31    1    5   34   17  767    9    2   17    9]\n",
            " [  16    3   14    2    7   32  876    0    8    0]\n",
            " [   0   23   31    3   22    0    2  883    4   60]\n",
            " [   5   14    9   34   16   52    7    6  815   16]\n",
            " [   4    5    5    8   68   13    0   22   12  872]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59510, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [27 25 45 61 52 69 39 48 67 67] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 29.260 s \n",
            "\n",
            "Accuracy rate for 89.520000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.96      0.93       980\n",
            "        1.0       0.95      0.98      0.96      1135\n",
            "        2.0       0.90      0.88      0.89      1032\n",
            "        3.0       0.89      0.86      0.87      1010\n",
            "        4.0       0.86      0.92      0.89       982\n",
            "        5.0       0.82      0.87      0.84       892\n",
            "        6.0       0.96      0.91      0.93       958\n",
            "        7.0       0.93      0.86      0.90      1028\n",
            "        8.0       0.89      0.84      0.86       974\n",
            "        9.0       0.85      0.87      0.86      1009\n",
            "\n",
            "avg / total       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 938    0    4    4    3   25    2    3    1    0]\n",
            " [   0 1112    3    4    1    2    3    0    9    1]\n",
            " [  16   13  904   20   12    7   16   16   26    2]\n",
            " [  16    2   20  865    3   55    0   15   26    8]\n",
            " [   2    2   14    0  902    1    4    1    3   53]\n",
            " [  25    1    4   35   21  774    8    3   16    5]\n",
            " [  19    3   14    3   11   28  874    0    6    0]\n",
            " [   1   22   28    3   19    0    1  889    4   61]\n",
            " [   7   14   10   36   16   41    6    7  818   19]\n",
            " [   7    5    5    7   62   13    0   19   15  876]]\n",
            "--------------------------------\n",
            "final active learning accuracies [31.86, 37.6, 46.23, 58.41, 60.34, 65.98, 65.01, 69.86, 72.28999999999999, 74.65, 76.24, 77.37, 77.59, 78.7, 79.06, 80.06, 81.21000000000001, 82.32000000000001, 83.17, 83.78, 84.6, 84.58, 84.47, 85.07000000000001, 85.64, 85.75, 85.7, 86.18, 86.58, 86.50999999999999, 86.71, 87.09, 86.91, 87.13, 87.42999999999999, 87.75, 87.97, 88.23, 88.23, 88.22, 88.16000000000001, 88.03, 88.38000000000001, 88.39, 88.64, 88.98, 89.05999999999999, 89.34, 89.3, 89.52]\n",
            "saved Active-learning-experiment-10.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', '.nv', 'Active-learning-experiment-10.pkl', '.keras', 'Active-learning-experiment-7.pkl']\n",
            "{\n",
            "  \"SvmModel\": {\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.86,\n",
            "          37.6,\n",
            "          46.23,\n",
            "          58.41,\n",
            "          60.34,\n",
            "          65.98,\n",
            "          65.01,\n",
            "          69.86,\n",
            "          72.28999999999999,\n",
            "          74.65,\n",
            "          76.24,\n",
            "          77.37,\n",
            "          77.59,\n",
            "          78.7,\n",
            "          79.06,\n",
            "          80.06,\n",
            "          81.21000000000001,\n",
            "          82.32000000000001,\n",
            "          83.17,\n",
            "          83.78,\n",
            "          84.6,\n",
            "          84.58,\n",
            "          84.47,\n",
            "          85.07000000000001,\n",
            "          85.64,\n",
            "          85.75,\n",
            "          85.7,\n",
            "          86.18,\n",
            "          86.58,\n",
            "          86.50999999999999,\n",
            "          86.71,\n",
            "          87.09,\n",
            "          86.91,\n",
            "          87.13,\n",
            "          87.42999999999999,\n",
            "          87.75,\n",
            "          87.97,\n",
            "          88.23,\n",
            "          88.23,\n",
            "          88.22,\n",
            "          88.16000000000001,\n",
            "          88.03,\n",
            "          88.38000000000001,\n",
            "          88.39,\n",
            "          88.64,\n",
            "          88.98,\n",
            "          89.05999999999999,\n",
            "          89.34,\n",
            "          89.3,\n",
            "          89.52\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          50.160000000000004,\n",
            "          63.73,\n",
            "          70.14,\n",
            "          74.4,\n",
            "          78.99000000000001,\n",
            "          80.36999999999999,\n",
            "          82.76,\n",
            "          84.35000000000001,\n",
            "          85.78,\n",
            "          86.61999999999999,\n",
            "          87.46000000000001,\n",
            "          87.64,\n",
            "          88.08,\n",
            "          88.75,\n",
            "          88.68,\n",
            "          89.02,\n",
            "          89.39,\n",
            "          89.57000000000001,\n",
            "          89.66,\n",
            "          89.8\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          59.099999999999994,\n",
            "          69.91000000000001,\n",
            "          75.66000000000001,\n",
            "          81.41000000000001,\n",
            "          82.69,\n",
            "          85.07000000000001,\n",
            "          85.92,\n",
            "          86.89,\n",
            "          87.8,\n",
            "          87.6\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.45,\n",
            "          84.1,\n",
            "          86.36,\n",
            "          88.16000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.58,\n",
            "          87.38\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.009999999999998,\n",
            "          33.54,\n",
            "          48.67,\n",
            "          57.34,\n",
            "          61.68,\n",
            "          64.75999999999999,\n",
            "          69.28,\n",
            "          71.97,\n",
            "          73.2,\n",
            "          74.03,\n",
            "          75.08,\n",
            "          76.01,\n",
            "          76.55,\n",
            "          77.42999999999999,\n",
            "          77.75,\n",
            "          79.72,\n",
            "          80.78,\n",
            "          81.62,\n",
            "          81.8,\n",
            "          82.03,\n",
            "          81.82000000000001,\n",
            "          82.72,\n",
            "          82.94,\n",
            "          83.03,\n",
            "          83.72,\n",
            "          83.81,\n",
            "          83.72,\n",
            "          83.95,\n",
            "          84.38,\n",
            "          85.02,\n",
            "          85.36,\n",
            "          85.65,\n",
            "          85.26,\n",
            "          85.37,\n",
            "          85.37,\n",
            "          85.19,\n",
            "          85.18,\n",
            "          85.61999999999999,\n",
            "          85.47,\n",
            "          85.61999999999999,\n",
            "          85.78,\n",
            "          86.00999999999999,\n",
            "          86.05000000000001,\n",
            "          85.96000000000001,\n",
            "          85.96000000000001,\n",
            "          86.0,\n",
            "          86.24000000000001,\n",
            "          86.6,\n",
            "          86.66,\n",
            "          86.81\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.449999999999996,\n",
            "          67.88,\n",
            "          72.25,\n",
            "          77.82,\n",
            "          79.19,\n",
            "          80.32000000000001,\n",
            "          81.19,\n",
            "          81.91000000000001,\n",
            "          82.67999999999999,\n",
            "          82.89,\n",
            "          82.89,\n",
            "          83.05,\n",
            "          83.91999999999999,\n",
            "          84.69,\n",
            "          84.77,\n",
            "          84.66,\n",
            "          85.0,\n",
            "          85.3,\n",
            "          85.79,\n",
            "          86.08\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          56.38999999999999,\n",
            "          72.92999999999999,\n",
            "          78.44,\n",
            "          81.0,\n",
            "          82.73,\n",
            "          83.52000000000001,\n",
            "          84.35000000000001,\n",
            "          85.17,\n",
            "          86.17,\n",
            "          86.66\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          73.76,\n",
            "          83.52000000000001,\n",
            "          85.6,\n",
            "          86.44\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.02000000000001,\n",
            "          85.64\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 11, using model = SvmModel, selection_function = EntropySelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [21 33 27 33 24 20 19 32 22 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.151 s \n",
            "\n",
            "Accuracy rate for 83.110000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.83      0.89       980\n",
            "        1.0       0.86      0.99      0.92      1135\n",
            "        2.0       0.82      0.77      0.80      1032\n",
            "        3.0       0.72      0.87      0.79      1010\n",
            "        4.0       0.83      0.84      0.84       982\n",
            "        5.0       0.72      0.73      0.73       892\n",
            "        6.0       0.91      0.89      0.90       958\n",
            "        7.0       0.89      0.86      0.88      1028\n",
            "        8.0       0.82      0.70      0.76       974\n",
            "        9.0       0.80      0.80      0.80      1009\n",
            "\n",
            "avg / total       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 814    1    2   38    1   84   24    5    9    2]\n",
            " [   0 1122    2    3    0    0    3    1    3    1]\n",
            " [  16   22  798   95   14   11   12   19   44    1]\n",
            " [   6    8   25  876    0   37    6   18   12   22]\n",
            " [   0   12   34    3  829   11   16    3    4   70]\n",
            " [   5   26    8   92   21  649   17    9   52   13]\n",
            " [   6   14   21    8   21   29  849    0   10    0]\n",
            " [   2   26   31    2   10    1    1  884    3   68]\n",
            " [   3   62   28   84   18   57    5   11  682   24]\n",
            " [   7   11   20   12   81   18    3   40    9  808]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 8. ... 9. 9. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 8 ... 9 9 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [42 33 38 55 69 45 40 64 60 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 26.286 s \n",
            "\n",
            "Accuracy rate for 84.530000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.92      0.90       980\n",
            "        1.0       0.93      0.98      0.95      1135\n",
            "        2.0       0.87      0.79      0.83      1032\n",
            "        3.0       0.75      0.85      0.80      1010\n",
            "        4.0       0.82      0.92      0.87       982\n",
            "        5.0       0.72      0.74      0.73       892\n",
            "        6.0       0.91      0.87      0.89       958\n",
            "        7.0       0.91      0.81      0.86      1028\n",
            "        8.0       0.81      0.77      0.79       974\n",
            "        9.0       0.84      0.78      0.81      1009\n",
            "\n",
            "avg / total       0.85      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 900    0    0    3    4   46   21    3    2    1]\n",
            " [   0 1107    3    8    1    3    2    1   10    0]\n",
            " [  15    7  813   80   18   17   28   11   39    4]\n",
            " [  17    6   16  862    5   48    6   10   32    8]\n",
            " [   8    0   13    0  902    9    4   11    8   27]\n",
            " [  20   13   10  108   11  661   12    5   46    6]\n",
            " [  32    3   17    4   13   44  836    1    8    0]\n",
            " [   3   23   40    9   11    1    0  837    7   97]\n",
            " [  11   25   20   68   14   64    8    4  752    8]\n",
            " [   4    8    5    8  124   21    0   37   19  783]]\n",
            "--------------------------------\n",
            "final active learning accuracies [83.11, 84.53]\n",
            "saved Active-learning-experiment-11.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', '.nv', 'Active-learning-experiment-10.pkl', '.keras', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 12, using model = SvmModel, selection_function = EntropySelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [15 12  8 15 16 11  8 15 15 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.587 s \n",
            "\n",
            "Accuracy rate for 78.400000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.94      0.83       980\n",
            "        1.0       0.81      0.97      0.89      1135\n",
            "        2.0       0.91      0.62      0.74      1032\n",
            "        3.0       0.77      0.79      0.78      1010\n",
            "        4.0       0.80      0.77      0.79       982\n",
            "        5.0       0.59      0.64      0.61       892\n",
            "        6.0       0.93      0.84      0.88       958\n",
            "        7.0       0.88      0.82      0.85      1028\n",
            "        8.0       0.68      0.62      0.65       974\n",
            "        9.0       0.77      0.79      0.78      1009\n",
            "\n",
            "avg / total       0.79      0.78      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 926    1    0    6    1   20   14    4    6    2]\n",
            " [   0 1103    1    2    0   10    4    1   14    0]\n",
            " [  50  103  635   49   27   26   11   19  103    9]\n",
            " [  29   18    5  802    0   86    4   10   51    5]\n",
            " [  12   14    9    4  761   24    6    4    3  145]\n",
            " [  73   10    0   99   10  570    9   15   99    7]\n",
            " [  79    4   12    4   28   20  800    7    2    2]\n",
            " [   6   58   26   17   16   10    0  838    2   55]\n",
            " [  46   36    0   43   19  184   11   14  604   17]\n",
            " [  21   10    6   13   88   18    2   43    7  801]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) [0. 0. 0. ... 9. 9. 5.]\n",
            "probabilities: (59875, 10) \n",
            " [0 0 0 ... 9 9 5]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [17 13 36 25 19 11 31 58 27 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.876 s \n",
            "\n",
            "Accuracy rate for 78.210000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.93      0.85       980\n",
            "        1.0       0.89      0.95      0.92      1135\n",
            "        2.0       0.76      0.61      0.68      1032\n",
            "        3.0       0.72      0.73      0.72      1010\n",
            "        4.0       0.79      0.83      0.81       982\n",
            "        5.0       0.70      0.56      0.62       892\n",
            "        6.0       0.84      0.77      0.81       958\n",
            "        7.0       0.84      0.87      0.85      1028\n",
            "        8.0       0.65      0.76      0.70       974\n",
            "        9.0       0.82      0.78      0.80      1009\n",
            "\n",
            "avg / total       0.78      0.78      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 913    1    6    5    4   12   13    9   13    4]\n",
            " [   0 1073   35    2    0    5    4    1   15    0]\n",
            " [  27   43  627   64   12    4   60   39  152    4]\n",
            " [  39   20   18  737    4   83    9   27   69    4]\n",
            " [   4    6   16   12  817    7   17   14    8   81]\n",
            " [  65    9    9  132   29  498   14   13  115    8]\n",
            " [  82    4   61    2   45   10  740    0   13    1]\n",
            " [   1   11   33   12   15    2    0  894    3   57]\n",
            " [  16   25   10   43   12   79   21   13  740   15]\n",
            " [  12   10    5   20   97    8    1   57   17  782]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [37 16 43 44 33 43 35 58 48 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 20.502 s \n",
            "\n",
            "Accuracy rate for 80.080000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.77      0.96      0.85       980\n",
            "        1.0       0.92      0.94      0.93      1135\n",
            "        2.0       0.84      0.65      0.73      1032\n",
            "        3.0       0.76      0.75      0.76      1010\n",
            "        4.0       0.81      0.82      0.81       982\n",
            "        5.0       0.72      0.70      0.71       892\n",
            "        6.0       0.91      0.78      0.84       958\n",
            "        7.0       0.86      0.87      0.86      1028\n",
            "        8.0       0.65      0.81      0.72       974\n",
            "        9.0       0.82      0.72      0.76      1009\n",
            "\n",
            "avg / total       0.81      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    0    5    3    1   21    2   10    1    0]\n",
            " [   0 1062   15   10    1   11    0    0   36    0]\n",
            " [  22   41  669   45   13    4   36   33  164    5]\n",
            " [  33    7   19  760    2   82    5   16   85    1]\n",
            " [  19    0   10    6  810   21    9    8    3   96]\n",
            " [  44    2   12   83    8  620    8    6  108    1]\n",
            " [ 123    2   32    1   15   24  746    0   15    0]\n",
            " [   2   11   33   11   17   13    0  891    3   47]\n",
            " [  26   19    4   37   11   45   16   12  791   13]\n",
            " [  16   12    2   38  128   15    1   57   18  722]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59625, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [37 50 49 49 40 52 52 65 72 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 27.139 s \n",
            "\n",
            "Accuracy rate for 81.000000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.83      0.95      0.89       980\n",
            "        1.0       0.91      0.90      0.91      1135\n",
            "        2.0       0.88      0.70      0.78      1032\n",
            "        3.0       0.76      0.77      0.77      1010\n",
            "        4.0       0.77      0.79      0.78       982\n",
            "        5.0       0.74      0.67      0.70       892\n",
            "        6.0       0.90      0.87      0.88       958\n",
            "        7.0       0.87      0.86      0.87      1028\n",
            "        8.0       0.67      0.82      0.74       974\n",
            "        9.0       0.78      0.74      0.76      1009\n",
            "\n",
            "avg / total       0.81      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 934    0    5    2    1   23    6    6    2    1]\n",
            " [   0 1027   21   19    0    6    2   18   41    1]\n",
            " [  23   41  721   42   14    6   34   43  106    2]\n",
            " [  32   13   11  778    1   62    7   16   86    4]\n",
            " [   9    1    9    2  775   43   20    2    5  116]\n",
            " [  31    4    5   93    9  599   12    7  121   11]\n",
            " [  55    8   16    0   19   18  832    0   10    0]\n",
            " [   1   17   19    9   21    4    1  889    7   60]\n",
            " [  19    8    5   47   13   40   12   16  803   11]\n",
            " [  15    5    6   26  157    9    1   29   19  742]]\n",
            "--------------------------------\n",
            "final active learning accuracies [78.4, 78.21000000000001, 80.08, 81.0]\n",
            "saved Active-learning-experiment-12.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', '.nv', 'Active-learning-experiment-10.pkl', '.keras', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 13, using model = SvmModel, selection_function = EntropySelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [6 6 4 5 3 3 5 5 7 6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 3.209 s \n",
            "\n",
            "Accuracy rate for 64.550000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.69      0.90      0.78       980\n",
            "        1.0       0.81      0.96      0.88      1135\n",
            "        2.0       0.59      0.60      0.60      1032\n",
            "        3.0       0.67      0.60      0.63      1010\n",
            "        4.0       0.73      0.29      0.41       982\n",
            "        5.0       0.63      0.27      0.38       892\n",
            "        6.0       0.84      0.66      0.74       958\n",
            "        7.0       0.61      0.67      0.64      1028\n",
            "        8.0       0.55      0.71      0.62       974\n",
            "        9.0       0.48      0.71      0.57      1009\n",
            "\n",
            "avg / total       0.66      0.65      0.63     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 886    0    7   23    0   31   24    0    7    2]\n",
            " [   0 1090    4    1    0   17    0   10   13    0]\n",
            " [  35   90  619   67   11   23   29   13  128   17]\n",
            " [  45    4   52  610    1   31    7   50  200   10]\n",
            " [   1   20   32   21  281    4   21  121   16  465]\n",
            " [ 194   19   13  142   19  238   22   51  168   26]\n",
            " [  72   10  150    5   50   10  631    6   19    5]\n",
            " [   4   49   84    2    2    3    2  685   18  179]\n",
            " [  39   47   28   33    5   19   12   11  694   86]\n",
            " [  11   15   56   10   14    1    2  170    9  721]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 6  6  6  5  6 35  6  8 15  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.928 s \n",
            "\n",
            "Accuracy rate for 68.750000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.69      0.83      0.76       980\n",
            "        1.0       0.87      0.94      0.91      1135\n",
            "        2.0       0.63      0.68      0.65      1032\n",
            "        3.0       0.80      0.64      0.71      1010\n",
            "        4.0       0.75      0.43      0.55       982\n",
            "        5.0       0.60      0.51      0.55       892\n",
            "        6.0       0.87      0.70      0.78       958\n",
            "        7.0       0.66      0.64      0.65      1028\n",
            "        8.0       0.59      0.79      0.67       974\n",
            "        9.0       0.52      0.67      0.58      1009\n",
            "\n",
            "avg / total       0.70      0.69      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 817    0   11   15    0   85   27    4   20    1]\n",
            " [   0 1069    4    2    1    6    3    7   43    0]\n",
            " [  26   70  698   50   16   11   22    8  122    9]\n",
            " [  57    2   55  651    1   82    6   53   96    7]\n",
            " [   1    7   38   10  422    3   17   79   27  378]\n",
            " [ 174    6   11   62    7  455   10   37  124    6]\n",
            " [  41    2  102    5   41   31  671    0   52   13]\n",
            " [   1   37   90    1   12   36    2  653   26  170]\n",
            " [  47   19   29   14    1   31   11   13  765   44]\n",
            " [  13   10   66    6   59   19    3  132   27  674]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 0 ... 9 7 7]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [13  8 10 12  6 55  6 10 23  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.015 s \n",
            "\n",
            "Accuracy rate for 71.340000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.92      0.80       980\n",
            "        1.0       0.89      0.92      0.91      1135\n",
            "        2.0       0.70      0.72      0.71      1032\n",
            "        3.0       0.78      0.67      0.72      1010\n",
            "        4.0       0.76      0.39      0.52       982\n",
            "        5.0       0.59      0.71      0.64       892\n",
            "        6.0       0.92      0.65      0.76       958\n",
            "        7.0       0.72      0.72      0.72      1028\n",
            "        8.0       0.63      0.78      0.70       974\n",
            "        9.0       0.55      0.62      0.58      1009\n",
            "\n",
            "avg / total       0.73      0.71      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 904    0   11    2    0   46   12    1    4    0]\n",
            " [   0 1049    2    4    0    6    2   22   50    0]\n",
            " [  48   38  745   62   14   14   14   14   78    5]\n",
            " [  80    3   22  679    0  111    3   19   88    5]\n",
            " [   3   18   43   22  385   39   11   67   69  325]\n",
            " [ 111    9    3   72    3  630    4    9   51    0]\n",
            " [  64    5  110    1   36   68  621    0   42   11]\n",
            " [   8   21   54    4    9   48    2  737   19  126]\n",
            " [  43   19   20   12    0   60    2   13  762   43]\n",
            " [  15   15   57   17   60   45    2  135   41  622]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 0 ... 9 7 7]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [13  8 13 12 41 61  6 12 23 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.634 s \n",
            "\n",
            "Accuracy rate for 74.120000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.70      0.91      0.79       980\n",
            "        1.0       0.91      0.93      0.92      1135\n",
            "        2.0       0.77      0.65      0.71      1032\n",
            "        3.0       0.78      0.66      0.71      1010\n",
            "        4.0       0.76      0.74      0.75       982\n",
            "        5.0       0.54      0.67      0.60       892\n",
            "        6.0       0.95      0.63      0.75       958\n",
            "        7.0       0.77      0.69      0.73      1028\n",
            "        8.0       0.66      0.79      0.72       974\n",
            "        9.0       0.67      0.72      0.69      1009\n",
            "\n",
            "avg / total       0.76      0.74      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 891    0   11    2    1   62    8    0    4    1]\n",
            " [   0 1056    0    6    1    9    1   17   45    0]\n",
            " [  60   41  675   75   29   22   11   20   83   16]\n",
            " [  79    1   17  664    1  128    2   19   91    8]\n",
            " [   4    3    5    2  724   63    2   31   22  126]\n",
            " [ 111    6    3   75    9  599    3    9   77    0]\n",
            " [  64    5   75    1   96   77  599    0   40    1]\n",
            " [   4   15   51    5   12   60    0  709   12  160]\n",
            " [  44   18   13   11    7   48    3   11  771   48]\n",
            " [  16   11   26    7   67   37    0   99   22  724]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 9 7 7]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [14 11 19 15 49 61 18 14 29 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 14.510 s \n",
            "\n",
            "Accuracy rate for 75.960000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.90      0.79       980\n",
            "        1.0       0.90      0.94      0.92      1135\n",
            "        2.0       0.76      0.68      0.72      1032\n",
            "        3.0       0.75      0.70      0.72      1010\n",
            "        4.0       0.84      0.77      0.81       982\n",
            "        5.0       0.59      0.62      0.61       892\n",
            "        6.0       0.92      0.76      0.83       958\n",
            "        7.0       0.80      0.72      0.76      1028\n",
            "        8.0       0.64      0.74      0.69       974\n",
            "        9.0       0.72      0.73      0.72      1009\n",
            "\n",
            "avg / total       0.77      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 878    0   10    7    0   74    9    0    2    0]\n",
            " [   0 1065    4    7    0    5    3    4   47    0]\n",
            " [  44   48  706   77   14   10   27   18   87    1]\n",
            " [  84    3   14  710    2   78    4   26   78   11]\n",
            " [   2    3   12    2  760   55   10   19   44   75]\n",
            " [ 104   11    5  100    8  555    3    7   89   10]\n",
            " [  61    5   72    1   12   53  725    0   29    0]\n",
            " [   0   11   73   17   16   25    1  742   14  129]\n",
            " [  44   24    9   20    7   70    8    9  721   62]\n",
            " [  13   11   20    8   85   14    2  104   18  734]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [16 28 22 20 53 70 22 16 32 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 17.435 s \n",
            "\n",
            "Accuracy rate for 77.040000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.69      0.88      0.77       980\n",
            "        1.0       0.88      0.94      0.91      1135\n",
            "        2.0       0.74      0.70      0.72      1032\n",
            "        3.0       0.85      0.61      0.71      1010\n",
            "        4.0       0.82      0.80      0.81       982\n",
            "        5.0       0.62      0.75      0.68       892\n",
            "        6.0       0.89      0.80      0.84       958\n",
            "        7.0       0.78      0.75      0.77      1028\n",
            "        8.0       0.71      0.73      0.72       974\n",
            "        9.0       0.76      0.73      0.74      1009\n",
            "\n",
            "avg / total       0.78      0.77      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 861    0   10    3    1   82   16    2    4    1]\n",
            " [   1 1062    8    8    1   11    4    0   40    0]\n",
            " [  69   79  721   39   17    8   29   20   50    0]\n",
            " [ 105    8   42  620    3  129    0   25   67   11]\n",
            " [   4    0   11    2  789   27   21   46   26   56]\n",
            " [  87    9    8   34   11  665    6    3   61    8]\n",
            " [  50    3   62    0   20   45  765    0   13    0]\n",
            " [   1   12   81    7   22   12    1  770   16  106]\n",
            " [  59   19   17    7    6   69   14   14  715   54]\n",
            " [  14    9   16    6   90   22    0  101   15  736]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [29 29 27 21 54 71 26 21 41 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 20.444 s \n",
            "\n",
            "Accuracy rate for 76.850000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.70      0.87      0.78       980\n",
            "        1.0       0.92      0.92      0.92      1135\n",
            "        2.0       0.77      0.67      0.72      1032\n",
            "        3.0       0.83      0.56      0.67      1010\n",
            "        4.0       0.82      0.80      0.81       982\n",
            "        5.0       0.65      0.70      0.67       892\n",
            "        6.0       0.86      0.87      0.86       958\n",
            "        7.0       0.78      0.78      0.78      1028\n",
            "        8.0       0.64      0.78      0.70       974\n",
            "        9.0       0.76      0.72      0.74      1009\n",
            "\n",
            "avg / total       0.78      0.77      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 855    0    9    3    1   71   31    3    5    2]\n",
            " [   1 1045    2   10    2   12    4    0   59    0]\n",
            " [  52   46  693   51   21    6   45   18   97    3]\n",
            " [ 139    5   33  567    2   95    0   17  122   30]\n",
            " [   1    0   14    2  781   32   27   64   17   44]\n",
            " [  91    7    8   32    9  622   11    4   91   17]\n",
            " [  26    2   46    2   13   27  829    0   13    0]\n",
            " [   2   11   71    9   28   10    2  801   13   81]\n",
            " [  45   11    9    6    6   61   11   13  761   51]\n",
            " [  12    6   20    2   88   17    1  112   20  731]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [33 29 32 29 57 83 27 31 43 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.251 s \n",
            "\n",
            "Accuracy rate for 79.190000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.83      0.87      0.85       980\n",
            "        1.0       0.93      0.92      0.93      1135\n",
            "        2.0       0.78      0.68      0.73      1032\n",
            "        3.0       0.78      0.75      0.76      1010\n",
            "        4.0       0.86      0.82      0.84       982\n",
            "        5.0       0.70      0.72      0.71       892\n",
            "        6.0       0.88      0.84      0.86       958\n",
            "        7.0       0.77      0.77      0.77      1028\n",
            "        8.0       0.64      0.81      0.71       974\n",
            "        9.0       0.77      0.73      0.75      1009\n",
            "\n",
            "avg / total       0.80      0.79      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 853    0   28    8    0   62   23    2    3    1]\n",
            " [   0 1044    1   10    2    8    6    0   64    0]\n",
            " [  27   43  700   57   18   11   34   22  118    2]\n",
            " [  47    3   36  753    1   35    1   17  100   17]\n",
            " [   4    0    7    0  804   19   25   56   16   51]\n",
            " [  45    5    4   81    5  645    7    3   89    8]\n",
            " [  16    2   47    6   18   49  801    1   18    0]\n",
            " [  13   12   49   11   13    4    0  795   24  107]\n",
            " [  15    8    9   27    5   68    9   10  786   37]\n",
            " [  12    5   15   11   69   17    1  124   17  738]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [34 33 34 32 71 85 34 34 49 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 26.083 s \n",
            "\n",
            "Accuracy rate for 80.510000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.88      0.86       980\n",
            "        1.0       0.92      0.91      0.92      1135\n",
            "        2.0       0.79      0.68      0.73      1032\n",
            "        3.0       0.80      0.77      0.78      1010\n",
            "        4.0       0.85      0.88      0.86       982\n",
            "        5.0       0.72      0.73      0.72       892\n",
            "        6.0       0.90      0.87      0.88       958\n",
            "        7.0       0.82      0.78      0.80      1028\n",
            "        8.0       0.66      0.79      0.72       974\n",
            "        9.0       0.77      0.74      0.76      1009\n",
            "\n",
            "avg / total       0.81      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 864    0   14    6    1   69   23    2    1    0]\n",
            " [   0 1035   12   10    0    7    6    0   64    1]\n",
            " [  25   45  706   53   18   11   32   18  121    3]\n",
            " [  43    2   30  775    0   42    0   19   86   13]\n",
            " [   2    0    6    0  862    8   13   36   11   44]\n",
            " [  47    5    5   84    7  651   13    2   70    8]\n",
            " [  14    2   43    4    9   37  837    1   11    0]\n",
            " [   7   11   54   15   13    3    0  802   12  111]\n",
            " [  20   11    7   24    7   70   10   11  770   44]\n",
            " [  12    8   22    2   96   12    1   90   17  749]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [34 35 44 39 76 95 39 37 53 48] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 29.105 s \n",
            "\n",
            "Accuracy rate for 80.990000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.83      0.86      0.85       980\n",
            "        1.0       0.93      0.91      0.92      1135\n",
            "        2.0       0.80      0.68      0.74      1032\n",
            "        3.0       0.83      0.77      0.80      1010\n",
            "        4.0       0.84      0.88      0.86       982\n",
            "        5.0       0.69      0.75      0.72       892\n",
            "        6.0       0.90      0.89      0.90       958\n",
            "        7.0       0.86      0.79      0.82      1028\n",
            "        8.0       0.65      0.80      0.72       974\n",
            "        9.0       0.79      0.75      0.77      1009\n",
            "\n",
            "avg / total       0.82      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 845    0   10    5    2  104   11    1    1    1]\n",
            " [   0 1036   14    9    2   10    5    2   57    0]\n",
            " [  28   49  706   32   15   11   43   14  130    4]\n",
            " [  56    1   25  773    1   41    1   11   93    8]\n",
            " [   3    0   11    0  868   10    8   34   17   31]\n",
            " [  42    6    8   63    5  670   11    2   75   10]\n",
            " [  10    1   33    2   11   35  852    0   14    0]\n",
            " [   5   10   50   13   18    6    0  807   15  104]\n",
            " [  19    7    4   26    5   68   13    8  784   40]\n",
            " [  10    7   21    5  108   10    0   63   27  758]]\n",
            "--------------------------------\n",
            "final active learning accuracies [64.55, 68.75, 71.34, 74.11999999999999, 75.96000000000001, 77.03999999999999, 76.85, 79.19, 80.51, 80.99]\n",
            "saved Active-learning-experiment-13.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', '.nv', 'Active-learning-experiment-10.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 14, using model = SvmModel, selection_function = EntropySelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [2 0 3 2 5 2 3 4 2 2] [0 2 3 4 5 6 7 8 9]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 1.669 s \n",
            "\n",
            "Accuracy rate for 50.330000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.70      0.74       980\n",
            "        1.0       0.00      0.00      0.00      1135\n",
            "        2.0       0.60      0.67      0.63      1032\n",
            "        3.0       0.64      0.36      0.46      1010\n",
            "        4.0       0.31      0.95      0.47       982\n",
            "        5.0       0.42      0.28      0.34       892\n",
            "        6.0       0.48      0.60      0.53       958\n",
            "        7.0       0.81      0.80      0.81      1028\n",
            "        8.0       0.53      0.65      0.58       974\n",
            "        9.0       0.20      0.07      0.10      1009\n",
            "\n",
            "avg / total       0.47      0.50      0.46     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[689   0  64   3  31  84  22   5   3  79]\n",
            " [  0   0  11  23 461  24 389   1 226   0]\n",
            " [  7   0 688   1 101  15  66  39 112   3]\n",
            " [ 12   0 149 360  74 199  34  36  81  65]\n",
            " [  2   0  25   0 933   0   8  10   4   0]\n",
            " [ 32   0  34 136 164 254  77  13 106  76]\n",
            " [122   0 106   0 145   3 578   0   1   3]\n",
            " [  1   0  14   2 145   8   2 825  23   8]\n",
            " [ 20   0  49  38 126  19  24  21 637  40]\n",
            " [  1   0   7   3 846   0   3  66  14  69]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59975,) [0. 0. 8. ... 7. 4. 7.]\n",
            "probabilities: (59975, 9) \n",
            " [3 3 0 ... 6 3 6]\n",
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [ 2  0  3  4 26  2  4  4  2  3] [0 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 2.970 s \n",
            "\n",
            "Accuracy rate for 51.590000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.64      0.73       980\n",
            "        1.0       0.00      0.00      0.00      1135\n",
            "        2.0       0.68      0.60      0.64      1032\n",
            "        3.0       0.62      0.57      0.60      1010\n",
            "        4.0       0.34      0.97      0.50       982\n",
            "        5.0       0.49      0.24      0.32       892\n",
            "        6.0       0.39      0.72      0.51       958\n",
            "        7.0       0.89      0.78      0.83      1028\n",
            "        8.0       0.54      0.61      0.57       974\n",
            "        9.0       0.20      0.08      0.11      1009\n",
            "\n",
            "avg / total       0.49      0.52      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[631   0  57   9  11  70  90   0   3 109]\n",
            " [  0   0   9  44 264   4 652   0 162   0]\n",
            " [  5   0 619  54  89  13  98  17 121  16]\n",
            " [  4   0  71 579  57 121  23  14  77  64]\n",
            " [  1   0   3   0 948   0  29   0   1   0]\n",
            " [ 28   0  19 182 155 217 116  10 107  58]\n",
            " [ 70   0  83   1 100   2 694   0   1   7]\n",
            " [  1   0   8   1 167   5  17 801  21   7]\n",
            " [ 12   0  33  61 149  14  41  11 591  62]\n",
            " [  2   0   6   4 852   0  12  43  11  79]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59950,) [0. 0. 8. ... 7. 4. 7.]\n",
            "probabilities: (59950, 9) \n",
            " [7 7 0 ... 6 0 0]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [ 2  1 12 17 26  2  4  6  2  3] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.339 s \n",
            "\n",
            "Accuracy rate for 56.600000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.85      0.63      0.72       980\n",
            "        1.0       0.81      0.35      0.49      1135\n",
            "        2.0       0.62      0.73      0.67      1032\n",
            "        3.0       0.38      0.84      0.52      1010\n",
            "        4.0       0.39      0.93      0.55       982\n",
            "        5.0       0.57      0.19      0.29       892\n",
            "        6.0       0.68      0.70      0.69       958\n",
            "        7.0       0.83      0.73      0.78      1028\n",
            "        8.0       0.85      0.49      0.62       974\n",
            "        9.0       0.27      0.07      0.11      1009\n",
            "\n",
            "avg / total       0.63      0.57      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[617   0  97  10  10  67  80   0   2  97]\n",
            " [  0 394   1 620  46   0  69   0   5   0]\n",
            " [  5   4 754 101  75   2  47  23  20   1]\n",
            " [  4   0  32 844  40  50   6  15   8  11]\n",
            " [  1  24  22   1 916   0  15   2   1   0]\n",
            " [ 21   0  36 403 112 172  69   4  50  25]\n",
            " [ 66   2  94   5 113   1 670   0   1   6]\n",
            " [  1  46  48  31 143   1   4 746   0   8]\n",
            " [ 10   6 108 166  95   9  22  40 475  43]\n",
            " [  2  12  15  43 796   0   2  67   0  72]]\n",
            "--------------------------------\n",
            "val predicted: (59925,) [0. 0. 8. ... 7. 3. 3.]\n",
            "probabilities: (59925, 10) \n",
            " [9 9 9 ... 7 4 7]\n",
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [26  1 12 17 26  3  4  6  2  3] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.128 s \n",
            "\n",
            "Accuracy rate for 60.240000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.93      0.82       980\n",
            "        1.0       0.81      0.35      0.49      1135\n",
            "        2.0       0.71      0.71      0.71      1032\n",
            "        3.0       0.40      0.79      0.53      1010\n",
            "        4.0       0.40      0.93      0.56       982\n",
            "        5.0       0.69      0.42      0.52       892\n",
            "        6.0       0.70      0.64      0.67       958\n",
            "        7.0       0.83      0.72      0.77      1028\n",
            "        8.0       0.86      0.49      0.62       974\n",
            "        9.0       0.61      0.06      0.12      1009\n",
            "\n",
            "avg / total       0.68      0.60      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[916   0  21   3   1  12  24   0   1   2]\n",
            " [  0 394   1 615  45   1  73   0   6   0]\n",
            " [ 36   4 731  91  74   4  50  22  20   0]\n",
            " [ 11   0  23 802  37 103   4  14   8   8]\n",
            " [  2  24  22   1 915   0  15   2   1   0]\n",
            " [ 48   0  16 250  88 374  66   3  42   5]\n",
            " [179   2  54   4  97   8 612   0   0   2]\n",
            " [ 17  45  48  28 132   3   5 742   0   8]\n",
            " [ 33   6 102 156  93  35  19  40 473  17]\n",
            " [ 14  11  15  44 791   1   1  67   0  65]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 0. ... 7. 3. 3.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 0 ... 7 4 3]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [26  1 12 18 26 26  4  6  3  3] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.636 s \n",
            "\n",
            "Accuracy rate for 61.570000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.77      0.90      0.83       980\n",
            "        1.0       0.84      0.35      0.49      1135\n",
            "        2.0       0.75      0.68      0.72      1032\n",
            "        3.0       0.42      0.72      0.53      1010\n",
            "        4.0       0.41      0.93      0.57       982\n",
            "        5.0       0.54      0.71      0.61       892\n",
            "        6.0       0.78      0.60      0.68       958\n",
            "        7.0       0.84      0.70      0.76      1028\n",
            "        8.0       0.84      0.55      0.67       974\n",
            "        9.0       0.68      0.06      0.12      1009\n",
            "\n",
            "avg / total       0.69      0.62      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[884   0  12   3   1  71   7   0   1   1]\n",
            " [  0 394   0 636  37  26  35   0   7   0]\n",
            " [ 36   3 706  97  69  12  44  21  44   0]\n",
            " [  4   0  16 725  37 180   1  13  26   8]\n",
            " [  2  21  22   2 916   1  15   2   1   0]\n",
            " [ 14   0   7  98  76 631  41   2  19   4]\n",
            " [165   2  45   1  98  66 576   0   5   0]\n",
            " [ 14  36  45  24 121  57   3 721   0   7]\n",
            " [ 21   7  75  93  69 105  16  38 539  11]\n",
            " [ 14   8  12  40 788  15   0  65   2  65]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) [0. 0. 5. ... 7. 3. 3.]\n",
            "probabilities: (59875, 10) \n",
            " [0 0 5 ... 7 3 3]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [26  1 15 20 26 26  4  6 22  4] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.783 s \n",
            "\n",
            "Accuracy rate for 63.500000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.89      0.84       980\n",
            "        1.0       0.87      0.33      0.48      1135\n",
            "        2.0       0.74      0.78      0.76      1032\n",
            "        3.0       0.42      0.69      0.52      1010\n",
            "        4.0       0.45      0.90      0.60       982\n",
            "        5.0       0.57      0.68      0.62       892\n",
            "        6.0       0.84      0.57      0.68       958\n",
            "        7.0       0.90      0.66      0.76      1028\n",
            "        8.0       0.68      0.73      0.71       974\n",
            "        9.0       0.79      0.17      0.28      1009\n",
            "\n",
            "avg / total       0.71      0.64      0.62     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[876   0  17   2   1  65   5   0  13   1]\n",
            " [  0 377   6 670  31  19  14   0  18   0]\n",
            " [ 25   1 809  69  53   9  29   7  27   3]\n",
            " [  4   0  36 697  31 192   1   7  38   4]\n",
            " [  2  15  29   5 882   0  10   0  34   5]\n",
            " [ 10   0   5  91  51 606  35   1  83  10]\n",
            " [161   2  68   8  98  61 544   0  14   2]\n",
            " [ 10  34  66  23 129  42   1 675  30  18]\n",
            " [ 14   1  52  56  51  59   7  18 714   2]\n",
            " [ 10   3   7  45 641  13   0  46  74 170]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 8. ... 7. 3. 3.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 8 ... 8 3 3]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [27  1 15 20 27 27  8 21 22  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.302 s \n",
            "\n",
            "Accuracy rate for 66.740000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.89      0.87       980\n",
            "        1.0       0.93      0.33      0.49      1135\n",
            "        2.0       0.79      0.76      0.77      1032\n",
            "        3.0       0.44      0.71      0.54      1010\n",
            "        4.0       0.50      0.94      0.65       982\n",
            "        5.0       0.62      0.68      0.65       892\n",
            "        6.0       0.83      0.72      0.78       958\n",
            "        7.0       0.75      0.85      0.79      1028\n",
            "        8.0       0.73      0.71      0.72       974\n",
            "        9.0       0.87      0.13      0.22      1009\n",
            "\n",
            "avg / total       0.73      0.67      0.65     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[874   0  16   1   1  60   5   6  14   3]\n",
            " [  0 378   6 652  44   9  26   5  15   0]\n",
            " [ 27   0 785  64  51   5  42  25  29   4]\n",
            " [  5   0  37 716  22 177   3  18  31   1]\n",
            " [  1   3   8   0 927   1   9  19  11   3]\n",
            " [ 10   0   7  92  53 610  36  12  69   3]\n",
            " [ 97   2  37   5  45  58 694   6  14   0]\n",
            " [  2  21  33   5  71   1   1 870  20   4]\n",
            " [ 10   1  62  60  50  55  15  28 692   1]\n",
            " [  9   2   7  23 605   6   1 174  54 128]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59825,) [0. 0. 8. ... 7. 7. 7.]\n",
            "probabilities: (59825, 10) \n",
            " [0 0 8 ... 7 7 7]\n",
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [30  1 22 21 28 31 15 21 24  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.362 s \n",
            "\n",
            "Accuracy rate for 68.190000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.89      0.91       980\n",
            "        1.0       0.94      0.33      0.49      1135\n",
            "        2.0       0.79      0.79      0.79      1032\n",
            "        3.0       0.50      0.64      0.56      1010\n",
            "        4.0       0.54      0.96      0.69       982\n",
            "        5.0       0.55      0.76      0.64       892\n",
            "        6.0       0.70      0.85      0.77       958\n",
            "        7.0       0.76      0.83      0.80      1028\n",
            "        8.0       0.75      0.71      0.73       974\n",
            "        9.0       0.90      0.13      0.23      1009\n",
            "\n",
            "avg / total       0.74      0.68      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[872   0  21   1   5  44  14   5  14   4]\n",
            " [  0 376   5 451  14  88 197   0   4   0]\n",
            " [ 16   1 811  34  62  11  55  13  27   2]\n",
            " [  5   0  47 646  13 236   4  16  42   1]\n",
            " [  2   2   5   0 943   1   5  14   9   1]\n",
            " [ 14   0   8  53  31 676  35   6  68   1]\n",
            " [  9   1  29   3  26  70 812   0   8   0]\n",
            " [  2  20  47   6  74   5   3 854  12   5]\n",
            " [ 14   1  52  40  36  88  26  21 695   1]\n",
            " [ 11   0   8  50 557  15   1 191  42 134]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 8. ... 7. 3. 7.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 8 ... 7 7 7]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [36  1 26 21 30 34 15 22 24 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.902 s \n",
            "\n",
            "Accuracy rate for 68.020000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.89      0.89       980\n",
            "        1.0       0.93      0.33      0.48      1135\n",
            "        2.0       0.75      0.82      0.79      1032\n",
            "        3.0       0.51      0.63      0.56      1010\n",
            "        4.0       0.53      0.96      0.68       982\n",
            "        5.0       0.49      0.72      0.58       892\n",
            "        6.0       0.83      0.80      0.81       958\n",
            "        7.0       0.81      0.80      0.80      1028\n",
            "        8.0       0.75      0.71      0.73       974\n",
            "        9.0       0.73      0.22      0.34      1009\n",
            "\n",
            "avg / total       0.73      0.68      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[873   0   5   1   7  57  18   3  12   4]\n",
            " [  0 371  44 484   4 180  48   0   4   0]\n",
            " [ 13   0 849  20  51  15  33  14  32   5]\n",
            " [ 10   0  58 640  10 234   3  14  32   9]\n",
            " [  3   3   3   0 938   9   3   9   5   9]\n",
            " [ 21   0  15  49  34 639  20   4  91  19]\n",
            " [ 28   1  31   1  63  60 762   0  11   1]\n",
            " [  1  21  64   3  80  14   2 818   8  17]\n",
            " [ 18   2  57  33  29  83  25  20 687  20]\n",
            " [  4   0   5  34 560  25   1 123  32 225]]\n",
            "--------------------------------\n",
            "val predicted: (59775,) [0. 0. 8. ... 7. 4. 7.]\n",
            "probabilities: (59775, 10) \n",
            " [0 0 8 ... 7 4 7]\n",
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [36  1 26 23 40 35 15 22 29 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.157 s \n",
            "\n",
            "Accuracy rate for 69.800000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.89      0.90       980\n",
            "        1.0       0.95      0.32      0.48      1135\n",
            "        2.0       0.78      0.81      0.79      1032\n",
            "        3.0       0.46      0.61      0.52      1010\n",
            "        4.0       0.57      0.92      0.70       982\n",
            "        5.0       0.50      0.69      0.58       892\n",
            "        6.0       0.89      0.82      0.85       958\n",
            "        7.0       0.87      0.79      0.83      1028\n",
            "        8.0       0.71      0.78      0.74       974\n",
            "        9.0       0.78      0.43      0.55      1009\n",
            "\n",
            "avg / total       0.75      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[868   0  10   1   2  65  21   4   7   2]\n",
            " [  0 362  44 549  38 117  12   0  12   1]\n",
            " [ 13   0 832  28  52  10  25  12  57   3]\n",
            " [  6   0  55 618   6 255   1  11  49   9]\n",
            " [  3   1   2   0 904   6   4   4   7  51]\n",
            " [ 15   0  14  54  33 615  15   4 115  27]\n",
            " [ 31   1  20   1  38  70 782   0  14   1]\n",
            " [  3  16  63   8  78  17   1 810  12  20]\n",
            " [ 12   1  31  49  29  58  16  13 760   5]\n",
            " [  4   0   1  41 408  14   1  71  40 429]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 8. ... 7. 9. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 8 ... 7 9 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [37 21 29 23 40 35 15 23 29 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.501 s \n",
            "\n",
            "Accuracy rate for 75.880000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.87      0.88       980\n",
            "        1.0       0.94      0.82      0.87      1135\n",
            "        2.0       0.80      0.83      0.82      1032\n",
            "        3.0       0.72      0.62      0.66      1010\n",
            "        4.0       0.59      0.92      0.72       982\n",
            "        5.0       0.51      0.68      0.58       892\n",
            "        6.0       0.91      0.81      0.86       958\n",
            "        7.0       0.88      0.82      0.85      1028\n",
            "        8.0       0.73      0.78      0.75       974\n",
            "        9.0       0.80      0.43      0.56      1009\n",
            "\n",
            "avg / total       0.78      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[856   0   8   1   2  78  20   4   9   2]\n",
            " [  0 926  22  83   9  86   2   0   7   0]\n",
            " [ 17  11 859  20  46  11  18  10  38   2]\n",
            " [  5   0  50 624   6 254   2  12  48   9]\n",
            " [  4   2   2   0 901   8   3   4   7  51]\n",
            " [ 17   5  17  50  33 610  15   5 114  26]\n",
            " [ 33   2  26   1  37  70 775   0  13   1]\n",
            " [  5  31  61   3  55  10   0 843   5  15]\n",
            " [ 12   6  26  49  27  60  17  14 758   5]\n",
            " [  6   3   1  38 404  12   1  69  39 436]]\n",
            "--------------------------------\n",
            "val predicted: (59725,) [0. 0. 8. ... 7. 9. 7.]\n",
            "probabilities: (59725, 10) \n",
            " [0 0 8 ... 7 9 7]\n",
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [37 41 29 23 40 35 17 24 31 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 14.612 s \n",
            "\n",
            "Accuracy rate for 77.240000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.88      0.89       980\n",
            "        1.0       0.90      0.96      0.93      1135\n",
            "        2.0       0.83      0.82      0.83      1032\n",
            "        3.0       0.82      0.62      0.70      1010\n",
            "        4.0       0.59      0.91      0.72       982\n",
            "        5.0       0.57      0.67      0.61       892\n",
            "        6.0       0.88      0.82      0.85       958\n",
            "        7.0       0.88      0.79      0.84      1028\n",
            "        8.0       0.70      0.77      0.73       974\n",
            "        9.0       0.79      0.45      0.57      1009\n",
            "\n",
            "avg / total       0.79      0.77      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 863    0    5    1    2   74   24    3    6    2]\n",
            " [   0 1087    5    6    5    6    3    0   23    0]\n",
            " [  17   20  849   18   47    8   23   14   34    2]\n",
            " [   5    3   50  625    6  236    7   11   57   10]\n",
            " [   5    4    2    0  893    4    5    9   11   49]\n",
            " [  16   10   15   47   33  597   13    3  130   28]\n",
            " [  36    3   18    1   45   56  788    0   10    1]\n",
            " [   5   48   59    2   58    9    0  815   10   22]\n",
            " [  12   26   20   32   32   48   29   16  753    6]\n",
            " [   6   10    2   32  394   13    0   52   46  454]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59700,) [0. 0. 8. ... 7. 9. 7.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 8 ... 7 9 7]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [38 45 31 27 40 40 18 24 36 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 16.111 s \n",
            "\n",
            "Accuracy rate for 78.090000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.88      0.89       980\n",
            "        1.0       0.90      0.96      0.93      1135\n",
            "        2.0       0.84      0.84      0.84      1032\n",
            "        3.0       0.74      0.65      0.69      1010\n",
            "        4.0       0.61      0.87      0.72       982\n",
            "        5.0       0.58      0.70      0.64       892\n",
            "        6.0       0.90      0.81      0.85       958\n",
            "        7.0       0.92      0.78      0.84      1028\n",
            "        8.0       0.73      0.76      0.74       974\n",
            "        9.0       0.79      0.54      0.64      1009\n",
            "\n",
            "avg / total       0.79      0.78      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 862    0    9    1    2   64   26    8    7    1]\n",
            " [   0 1086    1   32    1    4    1    0   10    0]\n",
            " [   8   24  863   24   34   19   22    8   29    1]\n",
            " [  11    3   51  660    4  222    4    7   40    8]\n",
            " [   4    5    1    3  854    5    4    5   25   76]\n",
            " [  18    7   14   71   26  624    9    3  104   16]\n",
            " [  32    2   12    2   60   63  772    0   15    0]\n",
            " [   4   45   52   22   50    4    1  806    6   38]\n",
            " [   9   31   19   50   41   52   18   11  736    7]\n",
            " [   7    8    7   31  332   10    0   32   36  546]]\n",
            "--------------------------------\n",
            "val predicted: (59675,) [0. 0. 0. ... 7. 9. 7.]\n",
            "probabilities: (59675, 10) \n",
            " [0 0 0 ... 7 9 7]\n",
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [39 47 35 28 41 40 21 33 39 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 17.853 s \n",
            "\n",
            "Accuracy rate for 79.380000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.88      0.88       980\n",
            "        1.0       0.92      0.96      0.94      1135\n",
            "        2.0       0.83      0.79      0.81      1032\n",
            "        3.0       0.75      0.63      0.69      1010\n",
            "        4.0       0.71      0.89      0.79       982\n",
            "        5.0       0.57      0.73      0.64       892\n",
            "        6.0       0.90      0.84      0.87       958\n",
            "        7.0       0.88      0.84      0.86      1028\n",
            "        8.0       0.71      0.75      0.73       974\n",
            "        9.0       0.83      0.62      0.71      1009\n",
            "\n",
            "avg / total       0.80      0.79      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 861    1    8    0    2   84   17    2    3    2]\n",
            " [   0 1086    2   29    1    2    6    0    9    0]\n",
            " [  14   13  817   39   21   16   33   11   64    4]\n",
            " [  19    3   54  641    3  238    2   10   30   10]\n",
            " [   4    3    4    3  873    4    4    9   30   48]\n",
            " [  22    6    9   57   24  652   12    6   91   13]\n",
            " [  36    1   25    2   11   64  800    0   19    0]\n",
            " [   3   31   42   10   33    6    0  861    5   37]\n",
            " [  20   24   17   49   33   69   15   12  726    9]\n",
            " [   8   11    5   21  225    9    0   68   41  621]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 0. ... 7. 9. 7.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 7 9 7]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [40 49 37 29 46 47 23 34 39 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.324 s \n",
            "\n",
            "Accuracy rate for 80.400000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.86      0.87       980\n",
            "        1.0       0.88      0.97      0.92      1135\n",
            "        2.0       0.84      0.78      0.81      1032\n",
            "        3.0       0.79      0.63      0.70      1010\n",
            "        4.0       0.72      0.92      0.81       982\n",
            "        5.0       0.59      0.74      0.65       892\n",
            "        6.0       0.91      0.86      0.89       958\n",
            "        7.0       0.89      0.85      0.87      1028\n",
            "        8.0       0.74      0.75      0.75       974\n",
            "        9.0       0.84      0.66      0.74      1009\n",
            "\n",
            "avg / total       0.81      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 847    1    5    0    3  106   12    3    2    1]\n",
            " [   0 1097    2   16    2    4    4    0   10    0]\n",
            " [  16   47  802   30   23   14   25    9   61    5]\n",
            " [  23   10   67  641    2  205    4   11   34   13]\n",
            " [   3    2    5    5  900    2    5    7   20   33]\n",
            " [  23    9    9   41   31  659    9    7   76   28]\n",
            " [  24    3   15    4   10   55  828    0   18    1]\n",
            " [   2   28   37   16   25    3    0  875    5   37]\n",
            " [  18   34   14   38   30   69   17   15  730    9]\n",
            " [   9   10    1   20  218    8    1   56   25  661]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) [0. 0. 0. ... 7. 9. 7.]\n",
            "probabilities: (59625, 10) \n",
            " [0 0 0 ... 7 9 7]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [41 50 43 32 48 48 26 34 39 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 20.763 s \n",
            "\n",
            "Accuracy rate for 80.990000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.85      0.88       980\n",
            "        1.0       0.90      0.96      0.93      1135\n",
            "        2.0       0.83      0.81      0.82      1032\n",
            "        3.0       0.81      0.67      0.73      1010\n",
            "        4.0       0.75      0.89      0.81       982\n",
            "        5.0       0.60      0.74      0.67       892\n",
            "        6.0       0.91      0.89      0.90       958\n",
            "        7.0       0.90      0.84      0.87      1028\n",
            "        8.0       0.77      0.71      0.74       974\n",
            "        9.0       0.76      0.71      0.73      1009\n",
            "\n",
            "avg / total       0.82      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 836    1    5    1    0  111   21    4    1    0]\n",
            " [   0 1095    2   17    2    5    4    0    9    1]\n",
            " [  13   27  839   20   23   16   20    9   59    6]\n",
            " [  16    5   71  672    1  177    2   10   31   25]\n",
            " [   4    2    7    6  877    4   11    5   12   54]\n",
            " [  23    9    8   27   27  664   12    6   63   53]\n",
            " [  12    2   21    4   10   45  849    0   15    0]\n",
            " [   2   27   38   18   23    3    0  863    3   51]\n",
            " [  18   38   10   49   31   68   15   14  692   39]\n",
            " [   4   11    8   17  177   11    1   51   17  712]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 0. ... 7. 9. 9.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 0 ... 7 9 9]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [43 54 47 33 51 52 27 35 43 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 21.599 s \n",
            "\n",
            "Accuracy rate for 80.290000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.82      0.85       980\n",
            "        1.0       0.86      0.96      0.90      1135\n",
            "        2.0       0.84      0.78      0.81      1032\n",
            "        3.0       0.78      0.69      0.73      1010\n",
            "        4.0       0.74      0.91      0.82       982\n",
            "        5.0       0.61      0.74      0.67       892\n",
            "        6.0       0.92      0.87      0.90       958\n",
            "        7.0       0.90      0.83      0.87      1028\n",
            "        8.0       0.77      0.72      0.74       974\n",
            "        9.0       0.76      0.68      0.72      1009\n",
            "\n",
            "avg / total       0.81      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 805    2    4    0    3  139   22    4    1    0]\n",
            " [   0 1087    3   24    1    4    2    0   13    1]\n",
            " [   7   68  800   31   24   12   22    9   53    6]\n",
            " [  24    6   48  701    2  167    1   11   25   25]\n",
            " [   6    1    4    5  895    2    6    3    8   52]\n",
            " [  29   14   10   26   26  659    8    7   61   52]\n",
            " [  13    2   15    7   13   46  838    0   24    0]\n",
            " [   3   29   44   15   17    2    0  857    6   55]\n",
            " [  24   48   14   67   28   50    6   11  699   27]\n",
            " [   5   11    7   25  199    7    1   50   16  688]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59575,) [0. 0. 0. ... 7. 9. 9.]\n",
            "probabilities: (59575, 10) \n",
            " [0 0 0 ... 7 9 9]\n",
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [43 55 49 38 53 57 27 40 45 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.725 s \n",
            "\n",
            "Accuracy rate for 80.120000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.80      0.84       980\n",
            "        1.0       0.88      0.96      0.92      1135\n",
            "        2.0       0.85      0.77      0.81      1032\n",
            "        3.0       0.77      0.76      0.76      1010\n",
            "        4.0       0.74      0.89      0.80       982\n",
            "        5.0       0.61      0.71      0.65       892\n",
            "        6.0       0.93      0.86      0.89       958\n",
            "        7.0       0.89      0.82      0.86      1028\n",
            "        8.0       0.79      0.73      0.76       974\n",
            "        9.0       0.72      0.69      0.70      1009\n",
            "\n",
            "avg / total       0.81      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 781    0    8    1    4  157   20    4    3    2]\n",
            " [   0 1085    3   27    1    6    0    0   11    2]\n",
            " [   9   58  798   44   22   12   17   10   55    7]\n",
            " [  15    4   25  770    5  141    0   13   17   20]\n",
            " [   4    1    2   12  872    4    5    6    9   67]\n",
            " [  29   10   23   43   19  632    9    6   55   66]\n",
            " [  14    2   29   11   17   43  823    0   19    0]\n",
            " [   3   25   40   12   20    1    1  848   10   68]\n",
            " [  28   43   10   68   20   36    9    8  709   43]\n",
            " [   5    8    3   18  205    6    1   54   15  694]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 7. 9. 9.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 7 9 9]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [45 56 50 39 56 60 30 42 52 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 24.898 s \n",
            "\n",
            "Accuracy rate for 79.760000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.85      0.81      0.83       980\n",
            "        1.0       0.89      0.95      0.92      1135\n",
            "        2.0       0.84      0.78      0.81      1032\n",
            "        3.0       0.76      0.74      0.75      1010\n",
            "        4.0       0.74      0.88      0.80       982\n",
            "        5.0       0.61      0.67      0.64       892\n",
            "        6.0       0.93      0.83      0.88       958\n",
            "        7.0       0.89      0.82      0.85      1028\n",
            "        8.0       0.77      0.76      0.76       974\n",
            "        9.0       0.72      0.72      0.72      1009\n",
            "\n",
            "avg / total       0.80      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 792    1   13    1    2  139   24    4    2    2]\n",
            " [   0 1074    2   25    1    4    0    0   26    3]\n",
            " [   9   56  800   46   17   14   20   12   53    5]\n",
            " [  20    7   25  744    5  146    1   14   24   24]\n",
            " [   6    0    7    8  862    5    6    5   12   71]\n",
            " [  35   10   21   60   15  601    4    9   63   74]\n",
            " [  20    2   36   11   39   34  797    0   19    0]\n",
            " [   5   22   37   12   37    1    1  841    8   64]\n",
            " [  37   31   10   54   15   31    7    6  737   46]\n",
            " [   8    6    4   16  178    8    1   49   11  728]]\n",
            "--------------------------------\n",
            "val predicted: (59525,) [0. 0. 0. ... 7. 9. 9.]\n",
            "probabilities: (59525, 10) \n",
            " [0 0 0 ... 7 9 9]\n",
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [46 58 55 40 58 65 34 45 52 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 26.468 s \n",
            "\n",
            "Accuracy rate for 80.370000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.80      0.82       980\n",
            "        1.0       0.89      0.94      0.91      1135\n",
            "        2.0       0.85      0.76      0.80      1032\n",
            "        3.0       0.79      0.73      0.76      1010\n",
            "        4.0       0.78      0.90      0.84       982\n",
            "        5.0       0.61      0.72      0.66       892\n",
            "        6.0       0.89      0.88      0.89       958\n",
            "        7.0       0.90      0.83      0.86      1028\n",
            "        8.0       0.76      0.71      0.73       974\n",
            "        9.0       0.73      0.75      0.74      1009\n",
            "\n",
            "avg / total       0.81      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 780    0    4    1    1  160   27    4    1    2]\n",
            " [   0 1071    3   25    1    4    0    0   28    3]\n",
            " [  14   50  781   42   11   15   38   12   64    5]\n",
            " [  27    7   31  742    4  130    1   14   29   25]\n",
            " [   3    0    5    6  881    7    9    5   11   55]\n",
            " [  26   13   12   42    9  638   12   11   62   67]\n",
            " [  19    2   23    5   19   33  846    0   11    0]\n",
            " [   3   21   40   14   23    2    1  850   10   64]\n",
            " [  44   35   17   46   16   45   12    8  694   57]\n",
            " [   9    7    6   13  158    8    3   45    6  754]]\n",
            "--------------------------------\n",
            "final active learning accuracies [50.33, 51.59, 56.599999999999994, 60.24, 61.57, 63.5, 66.74, 68.19, 68.02, 69.8, 75.88000000000001, 77.24, 78.09, 79.38, 80.4, 80.99, 80.28999999999999, 80.12, 79.75999999999999, 80.36999999999999]\n",
            "saved Active-learning-experiment-14.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', '.nv', 'Active-learning-experiment-10.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 15, using model = SvmModel, selection_function = EntropySelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [1 2 1 1 0 2 0 1 0 2] [0 1 2 3 5 7 9]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n",
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.716 s \n",
            "\n",
            "Accuracy rate for 35.930000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.35      0.12      0.18       980\n",
            "        1.0       0.53      0.91      0.67      1135\n",
            "        2.0       0.39      0.56      0.46      1032\n",
            "        3.0       0.64      0.40      0.49      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.27      0.34      0.30       892\n",
            "        6.0       0.00      0.00      0.00       958\n",
            "        7.0       0.43      0.36      0.39      1028\n",
            "        8.0       0.00      0.00      0.00       974\n",
            "        9.0       0.22      0.79      0.34      1009\n",
            "\n",
            "avg / total       0.29      0.36      0.29     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 122    5  267   16    0  275    0  187    0  108]\n",
            " [   0 1029   36    6    0    0    0    1    0   63]\n",
            " [  23  228  573   46    0    8    0    7    0  147]\n",
            " [  32  144   81  402    0  236    0    3    0  112]\n",
            " [  16   42  163    0    0   57    0   52    0  652]\n",
            " [  22   83  128   51    0  300    0   58    0  250]\n",
            " [  87  113  150    0    0   85    0   27    0  496]\n",
            " [   1   82    6   14    0   41    0  373    0  511]\n",
            " [  33  188   54   79    0   67    0   57    0  496]\n",
            " [  16   20   21   13    0   36    0  109    0  794]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59990,) [5. 2. 5. ... 7. 9. 9.]\n",
            "probabilities: (59990, 7) \n",
            " [4 4 4 ... 6 6 6]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [ 1 12  1  1  0  2  0  1  0  2] [0 1 2 3 5 7 9]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 1.152 s \n",
            "\n",
            "Accuracy rate for 35.970000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.34      0.12      0.18       980\n",
            "        1.0       0.52      0.93      0.66      1135\n",
            "        2.0       0.39      0.56      0.46      1032\n",
            "        3.0       0.64      0.39      0.48      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.27      0.32      0.29       892\n",
            "        6.0       0.00      0.00      0.00       958\n",
            "        7.0       0.43      0.36      0.39      1028\n",
            "        8.0       0.00      0.00      0.00       974\n",
            "        9.0       0.22      0.79      0.35      1009\n",
            "\n",
            "avg / total       0.29      0.36      0.29     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 122    8  267   14    0  276    0  187    0  106]\n",
            " [   0 1050   36    6    0    1    0    1    0   41]\n",
            " [  24  216  573   47    0    9    0    7    0  156]\n",
            " [  32  179   81  392    0  226    0    3    0   97]\n",
            " [  17   47  162    0    0   52    0   52    0  652]\n",
            " [  22  104  128   51    0  289    0   58    0  240]\n",
            " [  89  118  149    0    0   86    0   27    0  489]\n",
            " [   1   81    6   14    0   33    0  375    0  518]\n",
            " [  33  209   54   74    0   66    0   57    0  481]\n",
            " [  16   20   21   13    0   34    0  109    0  796]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59980,) [5. 2. 5. ... 7. 9. 9.]\n",
            "probabilities: (59980, 7) \n",
            " [4 4 4 ... 2 2 6]\n",
            "trainset before (20, 784) (20,)\n",
            "trainset after (30, 784) (30,)\n",
            "updated train set: (30, 784) (30,) unique(labels): [ 1 18  1  3  2  2  0  1  0  2] [0 1 2 3 4 5 7 9]\n",
            "val set: (59970, 784) (59970,)\n",
            "\n",
            "Train set: (30, 784) y: (30,)\n",
            "Val   set: (59970, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 1.659 s \n",
            "\n",
            "Accuracy rate for 40.330000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.35      0.12      0.17       980\n",
            "        1.0       0.56      0.92      0.70      1135\n",
            "        2.0       0.39      0.53      0.45      1032\n",
            "        3.0       0.37      0.71      0.48      1010\n",
            "        4.0       0.37      0.35      0.36       982\n",
            "        5.0       0.32      0.22      0.26       892\n",
            "        6.0       0.00      0.00      0.00       958\n",
            "        7.0       0.43      0.36      0.39      1028\n",
            "        8.0       0.00      0.00      0.00       974\n",
            "        9.0       0.34      0.70      0.46      1009\n",
            "\n",
            "avg / total       0.32      0.40      0.34     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 113    5  253  242    3  156    0  183    0   25]\n",
            " [   0 1046   35   20   31    0    0    1    0    2]\n",
            " [  19  170  546  163  103    0    0    4    0   27]\n",
            " [  27   93   74  714    2   80    0    3    0   17]\n",
            " [  16   39  154   34  343   32    0   48    0  316]\n",
            " [  18   83  121  306   58  193    0   55    0   58]\n",
            " [  80  131  145   63  192   49    0   25    0  273]\n",
            " [   1   59    6  100  105   26    0  368    0  363]\n",
            " [  33  223   53  263   33   42    0   57    0  270]\n",
            " [  16   24   21   50   49   30    0  109    0  710]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59970,) [5. 2. 5. ... 7. 9. 9.]\n",
            "probabilities: (59970, 8) \n",
            " [5 5 5 ... 3 3 3]\n",
            "trainset before (30, 784) (30,)\n",
            "trainset after (40, 784) (40,)\n",
            "updated train set: (40, 784) (40,) unique(labels): [ 1 18  1  3  2  2  0  1  0 12] [0 1 2 3 4 5 7 9]\n",
            "val set: (59960, 784) (59960,)\n",
            "\n",
            "Train set: (40, 784) y: (40,)\n",
            "Val   set: (59960, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 2.280 s \n",
            "\n",
            "Accuracy rate for 39.390000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.34      0.11      0.17       980\n",
            "        1.0       0.60      0.92      0.73      1135\n",
            "        2.0       0.38      0.52      0.44      1032\n",
            "        3.0       0.36      0.70      0.48      1010\n",
            "        4.0       0.34      0.27      0.30       982\n",
            "        5.0       0.31      0.21      0.25       892\n",
            "        6.0       0.00      0.00      0.00       958\n",
            "        7.0       0.42      0.35      0.38      1028\n",
            "        8.0       0.00      0.00      0.00       974\n",
            "        9.0       0.31      0.73      0.43      1009\n",
            "\n",
            "avg / total       0.31      0.39      0.33     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 107    4  252  242    2  164    0  188    0   21]\n",
            " [   0 1044   35   20   31    0    0    1    0    4]\n",
            " [  20  174  541  166  108    1    0    5    0   17]\n",
            " [  23   85   74  702    2   94    0    3    0   27]\n",
            " [  15   24  153   32  264   25    0   49    0  420]\n",
            " [  17   63  123  278   41  187    0   55    0  128]\n",
            " [  76   96  148   67  196   32    0   25    0  318]\n",
            " [   2   59    7  124   82   34    0  361    0  359]\n",
            " [  33  180   53  240   27   47    0   55    0  339]\n",
            " [  20   13   25   59   32   19    0  108    0  733]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59960,) [5. 2. 5. ... 7. 9. 9.]\n",
            "probabilities: (59960, 8) \n",
            " [3 1 3 ... 7 7 7]\n",
            "trainset before (40, 784) (40,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [ 1 18  1  3  2 12  0  1  0 12] [0 1 2 3 4 5 7 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 2.784 s \n",
            "\n",
            "Accuracy rate for 41.350000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.31      0.10      0.15       980\n",
            "        1.0       0.61      0.92      0.74      1135\n",
            "        2.0       0.40      0.53      0.45      1032\n",
            "        3.0       0.40      0.70      0.51      1010\n",
            "        4.0       0.34      0.28      0.31       982\n",
            "        5.0       0.37      0.43      0.40       892\n",
            "        6.0       0.00      0.00      0.00       958\n",
            "        7.0       0.42      0.35      0.38      1028\n",
            "        8.0       0.00      0.00      0.00       974\n",
            "        9.0       0.34      0.71      0.46      1009\n",
            "\n",
            "avg / total       0.33      0.41      0.35     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  99    2  249  149    2  278    0  192    0    9]\n",
            " [   0 1045   31   21   33    0    0    1    0    4]\n",
            " [  22  168  543  166  109    4    0    5    0   15]\n",
            " [  31   88   75  709    2   82    0    3    0   20]\n",
            " [  18   24  134   32  271   46    0   51    0  406]\n",
            " [  17   52  109  195   32  388    0   56    0   43]\n",
            " [  71   81  146   66  201   98    0   26    0  269]\n",
            " [   3   59    7  127   84   17    0  359    0  372]\n",
            " [  34  177   48  240   26  119    0   55    0  275]\n",
            " [  20   12   23   62   33   30    0  108    0  721]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59950,) [5. 2. 5. ... 7. 9. 9.]\n",
            "probabilities: (59950, 8) \n",
            " [5 5 3 ... 7 3 3]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (60, 784) (60,)\n",
            "updated train set: (60, 784) (60,) unique(labels): [ 1 18 11  3  2 12  0  1  0 12] [0 1 2 3 4 5 7 9]\n",
            "val set: (59940, 784) (59940,)\n",
            "\n",
            "Train set: (60, 784) y: (60,)\n",
            "Val   set: (59940, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 3.401 s \n",
            "\n",
            "Accuracy rate for 42.990000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.37      0.16      0.22       980\n",
            "        1.0       0.63      0.93      0.75      1135\n",
            "        2.0       0.49      0.54      0.51      1032\n",
            "        3.0       0.39      0.72      0.51      1010\n",
            "        4.0       0.38      0.33      0.35       982\n",
            "        5.0       0.35      0.45      0.39       892\n",
            "        6.0       0.00      0.00      0.00       958\n",
            "        7.0       0.40      0.35      0.38      1028\n",
            "        8.0       0.00      0.00      0.00       974\n",
            "        9.0       0.35      0.73      0.47      1009\n",
            "\n",
            "avg / total       0.34      0.43      0.37     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 152    2   50  193    7  341    0  227    0    8]\n",
            " [   0 1053   22   21   34    0    0    1    0    4]\n",
            " [  33  132  554  188   99   12    0    5    0    9]\n",
            " [  29   80   55  726    3   94    0    3    0   20]\n",
            " [  27   27   32   36  322   64    0   48    0  426]\n",
            " [  26   52   81  202   33  398    0   55    0   45]\n",
            " [  64   75  252   70  196   67    0   34    0  200]\n",
            " [   4   59    2  131   82   15    0  360    0  375]\n",
            " [  47  169   81  228   26  102    0   55    0  266]\n",
            " [  24   11    0   67   36   33    0  104    0  734]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59940,) [5. 5. 5. ... 7. 9. 9.]\n",
            "probabilities: (59940, 8) \n",
            " [5 5 5 ... 7 7 7]\n",
            "trainset before (60, 784) (60,)\n",
            "trainset after (70, 784) (70,)\n",
            "updated train set: (70, 784) (70,) unique(labels): [ 1 18 16  3  6 12  0  1  1 12] [0 1 2 3 4 5 7 8 9]\n",
            "val set: (59930, 784) (59930,)\n",
            "\n",
            "Train set: (70, 784) y: (70,)\n",
            "Val   set: (59930, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 3.851 s \n",
            "\n",
            "Accuracy rate for 46.230000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.42      0.15      0.22       980\n",
            "        1.0       0.74      0.88      0.80      1135\n",
            "        2.0       0.36      0.84      0.50      1032\n",
            "        3.0       0.45      0.66      0.54      1010\n",
            "        4.0       0.48      0.42      0.45       982\n",
            "        5.0       0.39      0.50      0.44       892\n",
            "        6.0       0.00      0.00      0.00       958\n",
            "        7.0       0.65      0.35      0.46      1028\n",
            "        8.0       0.36      0.01      0.01       974\n",
            "        9.0       0.39      0.71      0.50      1009\n",
            "\n",
            "avg / total       0.43      0.46      0.40     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[149   0 248 143  15 359   0  59   2   5]\n",
            " [  0 998  79  11  44   0   0   0   0   3]\n",
            " [ 32  27 871  68  25   4   0   2   0   3]\n",
            " [ 28  60 143 670   3  85   0   3   0  18]\n",
            " [ 30  14  38  16 408  61   0  20   0 395]\n",
            " [ 23  35  82 196  51 446   0   5   7  47]\n",
            " [ 20  40 721  16 106  23   0   4   0  28]\n",
            " [  3  40  47 116  92  15   0 363   0 352]\n",
            " [ 45 125 175 197  42 113   0   7   5 265]\n",
            " [ 24  12  26  46  59  34   0  95   0 713]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59930,) [5. 2. 5. ... 7. 9. 9.]\n",
            "probabilities: (59930, 9) \n",
            " [5 2 5 ... 8 8 8]\n",
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [ 1 18 16 13  6 12  0  1  1 12] [0 1 2 3 4 5 7 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.309 s \n",
            "\n",
            "Accuracy rate for 46.180000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.43      0.15      0.22       980\n",
            "        1.0       0.74      0.88      0.80      1135\n",
            "        2.0       0.36      0.84      0.50      1032\n",
            "        3.0       0.45      0.68      0.54      1010\n",
            "        4.0       0.49      0.41      0.45       982\n",
            "        5.0       0.39      0.49      0.43       892\n",
            "        6.0       0.00      0.00      0.00       958\n",
            "        7.0       0.65      0.36      0.46      1028\n",
            "        8.0       0.36      0.01      0.01       974\n",
            "        9.0       0.39      0.70      0.50      1009\n",
            "\n",
            "avg / total       0.43      0.46      0.40     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[143   0 244 146  15 362   0  63   2   5]\n",
            " [  0 995  84   8  45   0   0   0   0   3]\n",
            " [ 30  27 872  67  25   5   0   2   0   4]\n",
            " [ 20  61 144 688   1  73   0   3   0  20]\n",
            " [ 28  14  38  21 406  61   0  20   0 394]\n",
            " [ 21  34  90 199  52 436   0   5   7  48]\n",
            " [ 20  40 721  16 105  24   0   4   0  28]\n",
            " [  3  41  54  86  99  20   0 365   0 360]\n",
            " [ 42 115 160 266  31 102   0   7   5 246]\n",
            " [ 24  12  28  46  57  39   0  95   0 708]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59920,) [5. 2. 5. ... 7. 9. 9.]\n",
            "probabilities: (59920, 9) \n",
            " [5 2 5 ... 8 8 8]\n",
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [ 1 18 16 13  6 13  0  9  1 13] [0 1 2 3 4 5 7 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.833 s \n",
            "\n",
            "Accuracy rate for 47.260000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.36      0.09      0.14       980\n",
            "        1.0       0.78      0.87      0.82      1135\n",
            "        2.0       0.39      0.83      0.53      1032\n",
            "        3.0       0.52      0.65      0.58      1010\n",
            "        4.0       0.54      0.34      0.42       982\n",
            "        5.0       0.30      0.56      0.40       892\n",
            "        6.0       0.00      0.00      0.00       958\n",
            "        7.0       0.78      0.51      0.61      1028\n",
            "        8.0       0.36      0.00      0.01       974\n",
            "        9.0       0.37      0.77      0.50      1009\n",
            "\n",
            "avg / total       0.45      0.47      0.41     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 88   0 131  92   4 644   0  14   2   5]\n",
            " [  0 989  81   7  44   0   0   8   0   6]\n",
            " [ 27  28 853  61  17  13   0  22   0  11]\n",
            " [ 16  44 135 659   0 113   0  17   0  26]\n",
            " [ 20  11  35  15 338 111   0   3   0 449]\n",
            " [ 17  27  72 146  30 502   0  11   5  82]\n",
            " [ 16  37 725  13  87  48   0   0   0  32]\n",
            " [  2  36  23  55  52  19   0 521   0 320]\n",
            " [ 37  84 118 189  15 129   0  26   4 372]\n",
            " [ 23   9  19  34  36  69   0  47   0 772]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59910,) [5. 5. 5. ... 9. 9. 7.]\n",
            "probabilities: (59910, 9) \n",
            " [5 5 5 ... 8 8 8]\n",
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 1 18 18 15  6 13  0 12  3 14] [0 1 2 3 4 5 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.420 s \n",
            "\n",
            "Accuracy rate for 52.500000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.09      0.17       980\n",
            "        1.0       0.86      0.87      0.87      1135\n",
            "        2.0       0.34      0.89      0.49      1032\n",
            "        3.0       0.58      0.72      0.64      1010\n",
            "        4.0       0.68      0.24      0.36       982\n",
            "        5.0       0.33      0.46      0.38       892\n",
            "        6.0       0.00      0.00      0.00       958\n",
            "        7.0       0.81      0.77      0.79      1028\n",
            "        8.0       0.72      0.30      0.42       974\n",
            "        9.0       0.44      0.80      0.56      1009\n",
            "\n",
            "avg / total       0.56      0.53      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 92   0 272  68   1 513   0   6  21   7]\n",
            " [  0 989 113   7   7   0   0   6   4   9]\n",
            " [  1  10 915  43   7   5   0  41   4   6]\n",
            " [  4  13 113 727   0  53   0  37  35  28]\n",
            " [  0  10 106  24 237  58   0   4   2 541]\n",
            " [  4  24  87 222  17 406   0  15  38  79]\n",
            " [ 10  31 769  18  49  46   0   0   4  31]\n",
            " [  0  13  44  13  14   8   0 789   3 144]\n",
            " [ 15  47 191 105   6  92   0  37 292 189]\n",
            " [  0  10  57  31  11  51   0  41   5 803]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59900,) [5. 5. 5. ... 9. 9. 9.]\n",
            "probabilities: (59900, 9) \n",
            " [5 5 5 ... 8 8 8]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [ 1 18 18 15  6 21  0 13  4 14] [0 1 2 3 4 5 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.968 s \n",
            "\n",
            "Accuracy rate for 52.400000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.10      0.17       980\n",
            "        1.0       0.90      0.83      0.86      1135\n",
            "        2.0       0.35      0.86      0.50      1032\n",
            "        3.0       0.61      0.69      0.65      1010\n",
            "        4.0       0.69      0.19      0.30       982\n",
            "        5.0       0.35      0.52      0.42       892\n",
            "        6.0       0.00      0.00      0.00       958\n",
            "        7.0       0.60      0.79      0.68      1028\n",
            "        8.0       0.60      0.42      0.49       974\n",
            "        9.0       0.49      0.74      0.59      1009\n",
            "\n",
            "avg / total       0.54      0.52      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 97   0 284  61   0 502   0  18  18   0]\n",
            " [  0 944  77   5   6   1   0  59  41   2]\n",
            " [  1  10 884  35   7  15   0  68   7   5]\n",
            " [  5  11 102 698   0  59   0  53  57  25]\n",
            " [  1  10  99  15 188  80   0 110   1 478]\n",
            " [  4   7  61 213   7 466   0   5 104  25]\n",
            " [ 10  24 779  15  40  33   0   1  38  18]\n",
            " [  0  11  32  10  16  16   0 810   1 132]\n",
            " [ 14  25 161  70   1 107   0  88 407 101]\n",
            " [  0   8  45  26   8  43   0 129   4 746]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59890,) [5. 5. 5. ... 9. 9. 7.]\n",
            "probabilities: (59890, 9) \n",
            " [5 5 5 ... 8 8 8]\n",
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [ 1 18 18 15  8 27  0 14  5 14] [0 1 2 3 4 5 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.582 s \n",
            "\n",
            "Accuracy rate for 51.260000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.10      0.18       980\n",
            "        1.0       0.90      0.78      0.83      1135\n",
            "        2.0       0.37      0.84      0.52      1032\n",
            "        3.0       0.63      0.71      0.67      1010\n",
            "        4.0       0.55      0.14      0.23       982\n",
            "        5.0       0.31      0.56      0.40       892\n",
            "        6.0       0.00      0.00      0.00       958\n",
            "        7.0       0.52      0.82      0.64      1028\n",
            "        8.0       0.57      0.41      0.48       974\n",
            "        9.0       0.55      0.67      0.60      1009\n",
            "\n",
            "avg / total       0.52      0.51      0.46     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 99   0 284  50   0 493   0  50   4   0]\n",
            " [  0 880  15   5  49   2   0  49 133   2]\n",
            " [  1  11 871  28   4  30   0  72  10   5]\n",
            " [  6  11 103 721   1  62   0  40  39  27]\n",
            " [  1   8  82  13 140 169   0 235   0 334]\n",
            " [  4   9  52 222   1 499   0   9  87   9]\n",
            " [ 11  20 713   7  40 103   0  40  17   7]\n",
            " [  0  10  28   4   9  32   0 840   2 103]\n",
            " [ 13  18 147  74   2 169   0  78 396  77]\n",
            " [  0   7  30  24   9  62   0 193   4 680]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59880,) [5. 5. 5. ... 9. 5. 5.]\n",
            "probabilities: (59880, 9) \n",
            " [5 5 5 ... 8 5 5]\n",
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [ 1 18 18 15  9 28  6 14  6 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.133 s \n",
            "\n",
            "Accuracy rate for 51.690000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.10      0.18       980\n",
            "        1.0       0.94      0.75      0.83      1135\n",
            "        2.0       0.39      0.84      0.53      1032\n",
            "        3.0       0.64      0.71      0.68      1010\n",
            "        4.0       0.44      0.11      0.18       982\n",
            "        5.0       0.30      0.52      0.38       892\n",
            "        6.0       0.89      0.15      0.25       958\n",
            "        7.0       0.49      0.75      0.59      1028\n",
            "        8.0       0.56      0.52      0.54       974\n",
            "        9.0       0.54      0.63      0.58      1009\n",
            "\n",
            "avg / total       0.60      0.52      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[102   0 246  49   0 534   1  30  18   0]\n",
            " [  0 849  12   4  83   2   1  41 141   2]\n",
            " [  1  10 867  24   5  36   0  64  23   2]\n",
            " [  6   7 101 720   3  43   4  35  60  31]\n",
            " [  0  12  83  20 112 204   2 278   1 270]\n",
            " [  4   5  46 214   0 466   6  10 132   9]\n",
            " [ 11   2 665   5  18  58 141  43  14   1]\n",
            " [  0   4  25   3  23  29   0 773   4 167]\n",
            " [ 15   7 147  48   3 136   3  55 502  58]\n",
            " [  0   3  38  35   9  40   0 243   4 637]]\n",
            "--------------------------------\n",
            "val predicted: (59870,) [5. 5. 5. ... 9. 9. 9.]\n",
            "probabilities: (59870, 10) \n",
            " [5 5 8 ... 9 9 9]\n",
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [ 1 20 18 18  9 28  9 14  8 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.332 s \n",
            "\n",
            "Accuracy rate for 51.800000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.72      0.10      0.18       980\n",
            "        1.0       0.92      0.73      0.81      1135\n",
            "        2.0       0.39      0.81      0.53      1032\n",
            "        3.0       0.61      0.74      0.67      1010\n",
            "        4.0       0.41      0.11      0.17       982\n",
            "        5.0       0.31      0.53      0.39       892\n",
            "        6.0       0.90      0.13      0.22       958\n",
            "        7.0       0.49      0.75      0.60      1028\n",
            "        8.0       0.58      0.58      0.58       974\n",
            "        9.0       0.55      0.63      0.58      1009\n",
            "\n",
            "avg / total       0.59      0.52      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[102   0 243  61   0 512   0  29  33   0]\n",
            " [  0 828   5   4  90   2   1  34 170   1]\n",
            " [  1  18 837  28   5  34   2  57  48   2]\n",
            " [  5   9  81 747   0  42   1  40  55  30]\n",
            " [  0  11  86  25 107 195   2 283   2 271]\n",
            " [  4  12  47 268   1 469   5  12  67   7]\n",
            " [ 16   4 662  12  20  50 123  43  28   0]\n",
            " [  0   5  24   6  22  29   0 769   5 168]\n",
            " [ 13   7 119  46   4 122   3  46 563  51]\n",
            " [  0   3  38  37   9  42   0 242   3 635]]\n",
            "--------------------------------\n",
            "val predicted: (59860,) [5. 5. 8. ... 9. 9. 9.]\n",
            "probabilities: (59860, 10) \n",
            " [5 5 8 ... 9 5 9]\n",
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 1 22 20 20  9 29 12 14  8 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.055 s \n",
            "\n",
            "Accuracy rate for 53.180000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.10      0.18       980\n",
            "        1.0       0.93      0.75      0.83      1135\n",
            "        2.0       0.39      0.81      0.52      1032\n",
            "        3.0       0.59      0.74      0.66      1010\n",
            "        4.0       0.51      0.09      0.16       982\n",
            "        5.0       0.33      0.56      0.41       892\n",
            "        6.0       0.89      0.28      0.42       958\n",
            "        7.0       0.52      0.74      0.61      1028\n",
            "        8.0       0.58      0.56      0.57       974\n",
            "        9.0       0.56      0.62      0.59      1009\n",
            "\n",
            "avg / total       0.61      0.53      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 98   0 259  83   0 493   1  19  27   0]\n",
            " [  0 856   7   3  45   5   7  30 181   1]\n",
            " [  1  18 839  31   2  38   3  48  49   3]\n",
            " [  5   9  90 743   0  52   2  29  54  26]\n",
            " [  0   9 149  53  90 158   1 269   1 252]\n",
            " [  4  12  66 231   0 496   7   6  64   6]\n",
            " [ 15   3 549   4  10  65 267  27  18   0]\n",
            " [  0  10  28  15  18  35   0 760   5 157]\n",
            " [ 12   4 149  48   3 113  13  42 545  45]\n",
            " [  0   3  42  45   7  44   0 241   3 624]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [5. 5. 8. ... 9. 5. 9.]\n",
            "probabilities: (59850, 10) \n",
            " [5 5 8 ... 9 5 5]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [ 1 23 21 22  9 29 14 15 11 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.842 s \n",
            "\n",
            "Accuracy rate for 53.820000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.10      0.17       980\n",
            "        1.0       0.95      0.82      0.88      1135\n",
            "        2.0       0.41      0.85      0.56      1032\n",
            "        3.0       0.59      0.65      0.62      1010\n",
            "        4.0       0.70      0.07      0.13       982\n",
            "        5.0       0.32      0.50      0.39       892\n",
            "        6.0       0.86      0.35      0.50       958\n",
            "        7.0       0.51      0.65      0.57      1028\n",
            "        8.0       0.52      0.70      0.59       974\n",
            "        9.0       0.54      0.61      0.57      1009\n",
            "\n",
            "avg / total       0.62      0.54      0.51     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 96   0 253  80   0 496   4   2  49   0]\n",
            " [  0 933   9   7   7   5   4   8 161   1]\n",
            " [  1  17 875  25   1  31   9  29  39   5]\n",
            " [  3   5 104 655   0  58   3  38 124  20]\n",
            " [  0   4 146  65  73 156  14 281   6 237]\n",
            " [  2  10  45 158   0 444   9  12 207   5]\n",
            " [  8   3 508   5   8  47 340  13  26   0]\n",
            " [  0   8  35  36  11  43   0 673   6 216]\n",
            " [ 11   3  80  39   0  85  12  31 679  34]\n",
            " [  0   2  58  43   5  39   0 234  14 614]]\n",
            "--------------------------------\n",
            "val predicted: (59840,) [5. 5. 5. ... 9. 5. 9.]\n",
            "probabilities: (59840, 10) \n",
            " [5 5 5 ... 9 5 5]\n",
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [ 1 26 23 22 10 30 16 15 12 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.554 s \n",
            "\n",
            "Accuracy rate for 55.890000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.81      0.10      0.18       980\n",
            "        1.0       0.94      0.93      0.94      1135\n",
            "        2.0       0.40      0.83      0.54      1032\n",
            "        3.0       0.60      0.66      0.63      1010\n",
            "        4.0       0.80      0.10      0.18       982\n",
            "        5.0       0.35      0.55      0.43       892\n",
            "        6.0       0.83      0.43      0.57       958\n",
            "        7.0       0.51      0.64      0.57      1028\n",
            "        8.0       0.57      0.66      0.61       974\n",
            "        9.0       0.55      0.60      0.57      1009\n",
            "\n",
            "avg / total       0.64      0.56      0.53     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 101    0  285   71    0  474    6    2   41    0]\n",
            " [   0 1057   12    6    3    2    2    0   52    1]\n",
            " [   1   30  853   32    2   24   15   24   49    2]\n",
            " [   3    3   90  665    0   53    4   44  124   24]\n",
            " [   0    4  171   62   99  119   27  269    8  223]\n",
            " [   2    8   58  146    0  488    9   13  161    7]\n",
            " [   6    2  447    4    2   48  410   12   27    0]\n",
            " [   0   12   51   39   10   38    1  660    8  209]\n",
            " [  11    7   85   39    0   91   19   39  646   37]\n",
            " [   0    1   63   43    7   43    0  231   11  610]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59830,) [5. 5. 5. ... 9. 5. 5.]\n",
            "probabilities: (59830, 10) \n",
            " [5 5 5 ... 9 5 5]\n",
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [ 1 29 23 24 10 32 16 15 14 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.242 s \n",
            "\n",
            "Accuracy rate for 56.120000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.11      0.19       980\n",
            "        1.0       0.91      0.94      0.93      1135\n",
            "        2.0       0.40      0.81      0.54      1032\n",
            "        3.0       0.62      0.68      0.65      1010\n",
            "        4.0       0.84      0.08      0.15       982\n",
            "        5.0       0.38      0.59      0.46       892\n",
            "        6.0       0.85      0.41      0.56       958\n",
            "        7.0       0.55      0.59      0.57      1028\n",
            "        8.0       0.56      0.63      0.60       974\n",
            "        9.0       0.50      0.68      0.58      1009\n",
            "\n",
            "avg / total       0.65      0.56      0.53     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 105    1  315   37    0  450    4    3   64    1]\n",
            " [   0 1072    9    8    1    1    2    0   41    1]\n",
            " [   1   33  836   28    1   27   16   23   61    6]\n",
            " [   3    8   97  683    0   33    5   43  110   28]\n",
            " [   0    3  145   82   82  115   15  200    9  331]\n",
            " [   2   11   64  134    0  524    8    6  138    5]\n",
            " [   6    2  438    3    2   65  395   10   37    0]\n",
            " [   0   24   51   28    7   37    0  611   10  260]\n",
            " [  11   17   82   63    0   82   17   36  618   48]\n",
            " [   0    7   52   39    5   28    0  177   15  686]]\n",
            "--------------------------------\n",
            "val predicted: (59820,) [5. 2. 5. ... 9. 9. 9.]\n",
            "probabilities: (59820, 10) \n",
            " [5 2 5 ... 9 5 5]\n",
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [ 1 29 24 26 17 32 16 15 14 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.419 s \n",
            "\n",
            "Accuracy rate for 57.270000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.81      0.10      0.18       980\n",
            "        1.0       0.91      0.94      0.93      1135\n",
            "        2.0       0.39      0.79      0.52      1032\n",
            "        3.0       0.64      0.71      0.67      1010\n",
            "        4.0       0.86      0.22      0.35       982\n",
            "        5.0       0.39      0.60      0.47       892\n",
            "        6.0       0.86      0.40      0.55       958\n",
            "        7.0       0.59      0.58      0.59      1028\n",
            "        8.0       0.55      0.63      0.59       974\n",
            "        9.0       0.53      0.67      0.59      1009\n",
            "\n",
            "avg / total       0.66      0.57      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  99    1  313   23    0  475    5    3   61    0]\n",
            " [   0 1072    8    8    1    1    3    0   41    1]\n",
            " [   1   35  814   42    1   21   17   21   76    4]\n",
            " [   3    7   75  716    1   37    3   28  114   26]\n",
            " [   0    2  179   67  215  107   15  141    5  251]\n",
            " [   2   11   62  111    2  538    7    8  146    5]\n",
            " [   6    2  453    2    6   66  384    6   33    0]\n",
            " [   0   25   51   30   13   37    0  600   10  262]\n",
            " [  11   18   75   66    1   85   14   38  616   50]\n",
            " [   0    7   69   47   10   27    0  164   12  673]]\n",
            "--------------------------------\n",
            "val predicted: (59810,) [5. 2. 5. ... 9. 9. 9.]\n",
            "probabilities: (59810, 10) \n",
            " [5 2 5 ... 9 5 5]\n",
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [ 2 30 24 26 20 32 19 16 15 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.842 s \n",
            "\n",
            "Accuracy rate for 59.410000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.59      0.08      0.14       980\n",
            "        1.0       0.91      0.93      0.92      1135\n",
            "        2.0       0.41      0.77      0.53      1032\n",
            "        3.0       0.67      0.73      0.70      1010\n",
            "        4.0       0.80      0.33      0.47       982\n",
            "        5.0       0.40      0.59      0.48       892\n",
            "        6.0       0.83      0.53      0.65       958\n",
            "        7.0       0.57      0.62      0.60      1028\n",
            "        8.0       0.58      0.65      0.61       974\n",
            "        9.0       0.56      0.64      0.60      1009\n",
            "\n",
            "avg / total       0.64      0.59      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  79    1  360   27    0  446   12    3   52    0]\n",
            " [   2 1055    7    5    1    3    4    0   57    1]\n",
            " [   2   40  792   35    3   20   25   28   83    4]\n",
            " [  14   10   78  737    3   35    4   32   73   24]\n",
            " [   1    3  118   53  326   82   27  169   12  191]\n",
            " [   7    8   59  123   12  529   17    6  126    5]\n",
            " [   3    4  367    1    6   52  507    1   17    0]\n",
            " [   0   20   45   23   20   41    0  639   15  225]\n",
            " [  26   17   59   51    4   83   13   43  629   49]\n",
            " [   0    6   51   39   33   27    1  192   12  648]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [5. 2. 0. ... 9. 9. 9.]\n",
            "probabilities: (59800, 10) \n",
            " [5 2 5 ... 9 5 5]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [ 5 31 26 26 20 32 19 16 17 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.268 s \n",
            "\n",
            "Accuracy rate for 59.950000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.50      0.11      0.18       980\n",
            "        1.0       0.90      0.94      0.92      1135\n",
            "        2.0       0.44      0.78      0.56      1032\n",
            "        3.0       0.67      0.71      0.69      1010\n",
            "        4.0       0.82      0.32      0.46       982\n",
            "        5.0       0.42      0.55      0.48       892\n",
            "        6.0       0.85      0.50      0.63       958\n",
            "        7.0       0.57      0.62      0.60      1028\n",
            "        8.0       0.52      0.73      0.60       974\n",
            "        9.0       0.60      0.67      0.63      1009\n",
            "\n",
            "avg / total       0.63      0.60      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 107    0  258   29    0  406    5    3  172    0]\n",
            " [  19 1062    4    3    2    3    4    0   38    0]\n",
            " [   7   45  806   30    3   17   12   29   79    4]\n",
            " [  33   12   69  714    2   33    4   33   94   16]\n",
            " [   2    2  121   51  316   79   27  180   45  159]\n",
            " [  12    6   51  127   13  491   13    4  170    5]\n",
            " [   6    4  401    1    5   43  478    2   18    0]\n",
            " [   0   22   44   22   14   26    0  642   21  237]\n",
            " [  30   17   41   51    4   48   17   39  707   20]\n",
            " [   0    5   41   38   27   16    0  189   21  672]]\n",
            "--------------------------------\n",
            "val predicted: (59790,) [5. 2. 8. ... 9. 9. 9.]\n",
            "probabilities: (59790, 10) \n",
            " [5 5 8 ... 9 9 9]\n",
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [ 6 32 26 28 24 33 19 16 18 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 11.945 s \n",
            "\n",
            "Accuracy rate for 62.630000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.54      0.18      0.27       980\n",
            "        1.0       0.90      0.94      0.92      1135\n",
            "        2.0       0.46      0.77      0.58      1032\n",
            "        3.0       0.70      0.75      0.73      1010\n",
            "        4.0       0.76      0.52      0.62       982\n",
            "        5.0       0.43      0.57      0.49       892\n",
            "        6.0       0.89      0.47      0.62       958\n",
            "        7.0       0.63      0.60      0.61      1028\n",
            "        8.0       0.57      0.72      0.64       974\n",
            "        9.0       0.61      0.66      0.63      1009\n",
            "\n",
            "avg / total       0.65      0.63      0.62     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 180    0  214   39    0  438    3    3  103    0]\n",
            " [  11 1063    6    1    2    3    2    0   47    0]\n",
            " [  12   43  799   38    8   19   12   25   73    3]\n",
            " [  50    8   51  762    2   19    3   29   71   15]\n",
            " [   2    3   79   36  511   55   11  114   33  138]\n",
            " [  17    9   47  119   13  511   11    2  160    3]\n",
            " [  21    4  396    1   15   47  454    1   19    0]\n",
            " [   0   20   49   18   32   32    0  617   19  241]\n",
            " [  38   19   41   44   13   45   14   35  704   21]\n",
            " [   1    6   38   33   74   22    0  159   14  662]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59780,) [5. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59780, 10) \n",
            " [5 5 8 ... 9 9 9]\n",
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [ 8 32 27 30 25 34 19 18 19 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.187 s \n",
            "\n",
            "Accuracy rate for 61.340000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.50      0.14      0.22       980\n",
            "        1.0       0.91      0.93      0.92      1135\n",
            "        2.0       0.46      0.77      0.57      1032\n",
            "        3.0       0.66      0.72      0.69      1010\n",
            "        4.0       0.72      0.52      0.60       982\n",
            "        5.0       0.40      0.57      0.47       892\n",
            "        6.0       0.91      0.42      0.58       958\n",
            "        7.0       0.63      0.65      0.64      1028\n",
            "        8.0       0.56      0.74      0.63       974\n",
            "        9.0       0.63      0.61      0.62      1009\n",
            "\n",
            "avg / total       0.64      0.61      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 139    0  219   49    0  496    2    1   74    0]\n",
            " [  11 1050    6    2    2    2    2    0   60    0]\n",
            " [  12   39  792   42    7   28   12   19   79    2]\n",
            " [  41    9   63  724    6   27    1   22  104   13]\n",
            " [   4    2   91   28  510   57    4  133   27  126]\n",
            " [  14   10   44  112   18  511    7    4  168    4]\n",
            " [  33    5  402    1   31   54  406    1   25    0]\n",
            " [   0   22   41   21   33   24    0  668   15  204]\n",
            " [  21   16   36   67   17   47   10   23  717   20]\n",
            " [   1    6   38   45   80   21    0  185   16  617]]\n",
            "--------------------------------\n",
            "val predicted: (59770,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59770, 10) \n",
            " [5 5 0 ... 9 9 5]\n",
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [ 9 32 29 32 25 34 20 22 19 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 12.865 s \n",
            "\n",
            "Accuracy rate for 63.880000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.59      0.24      0.35       980\n",
            "        1.0       0.91      0.93      0.92      1135\n",
            "        2.0       0.49      0.78      0.60      1032\n",
            "        3.0       0.69      0.73      0.71      1010\n",
            "        4.0       0.75      0.59      0.66       982\n",
            "        5.0       0.40      0.56      0.47       892\n",
            "        6.0       0.91      0.42      0.58       958\n",
            "        7.0       0.65      0.77      0.71      1028\n",
            "        8.0       0.59      0.73      0.65       974\n",
            "        9.0       0.68      0.56      0.61      1009\n",
            "\n",
            "avg / total       0.67      0.64      0.63     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 240    0  169   32    0  496    1    3   39    0]\n",
            " [   6 1051    6    1    2    3    1    0   65    0]\n",
            " [  14   36  808   27   10   28   12   28   68    1]\n",
            " [  62    9   50  738   10   19    6   19   84   13]\n",
            " [   4    2   64   31  583   53    4   83   35  123]\n",
            " [  16   12   45  126   20  497    9    4  159    4]\n",
            " [  27    5  418    1   33   45  407    2   20    0]\n",
            " [   0   24   27   13   28   26    0  791   12  107]\n",
            " [  35   15   35   53   18   46    9   36  707   20]\n",
            " [   1    6   29   49   73   23    0  248   14  566]]\n",
            "--------------------------------\n",
            "val predicted: (59760,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59760, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [14 32 30 32 25 35 21 22 20 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 13.442 s \n",
            "\n",
            "Accuracy rate for 65.340000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.63      0.28      0.39       980\n",
            "        1.0       0.91      0.92      0.92      1135\n",
            "        2.0       0.50      0.78      0.61      1032\n",
            "        3.0       0.71      0.73      0.72      1010\n",
            "        4.0       0.78      0.58      0.67       982\n",
            "        5.0       0.40      0.56      0.47       892\n",
            "        6.0       0.91      0.51      0.65       958\n",
            "        7.0       0.67      0.77      0.72      1028\n",
            "        8.0       0.60      0.73      0.66       974\n",
            "        9.0       0.69      0.60      0.64      1009\n",
            "\n",
            "avg / total       0.68      0.65      0.65     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 272    0  163   20    0  490    3    4   28    0]\n",
            " [   4 1049    7    1    2    2    3    0   67    0]\n",
            " [  16   38  806   28   11   30   12   27   62    2]\n",
            " [  33    8   75  742    9   24    7   18   79   15]\n",
            " [   8    1   68   27  569   54    3   82   31  139]\n",
            " [  21   11   50  124   16  500   12    4  149    5]\n",
            " [  29    4  356    0   21   40  485    1   22    0]\n",
            " [   1   23   27   13   27   24    0  794   15  104]\n",
            " [  43   16   36   49   15   56   10   29  709   11]\n",
            " [   3    5   29   43   58   26    0  221   16  608]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [14 32 33 33 25 36 23 22 22 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 14.225 s \n",
            "\n",
            "Accuracy rate for 65.770000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.70      0.28      0.40       980\n",
            "        1.0       0.91      0.93      0.92      1135\n",
            "        2.0       0.49      0.77      0.59      1032\n",
            "        3.0       0.72      0.74      0.73      1010\n",
            "        4.0       0.79      0.55      0.65       982\n",
            "        5.0       0.42      0.53      0.47       892\n",
            "        6.0       0.90      0.54      0.67       958\n",
            "        7.0       0.70      0.77      0.73      1028\n",
            "        8.0       0.57      0.76      0.65       974\n",
            "        9.0       0.67      0.66      0.66      1009\n",
            "\n",
            "avg / total       0.69      0.66      0.65     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 271    0  176   26    0  440    6    2   58    1]\n",
            " [   4 1051    5    2    2    2    1    0   68    0]\n",
            " [  15   38  790   30    6   26    9   27   83    8]\n",
            " [  25    7   77  743    7   33    6   17   78   17]\n",
            " [   4    1   80   26  537   45    6   83   35  165]\n",
            " [  22    7   52  111   14  475   22    4  179    6]\n",
            " [  14    3  358    1   19   22  517    1   23    0]\n",
            " [   1   23   28   13   33   18    0  790   13  109]\n",
            " [  30   18   37   41   15   43    7   25  738   20]\n",
            " [   2    4   25   41   50   18    0  185   19  665]]\n",
            "--------------------------------\n",
            "val predicted: (59740,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59740, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [17 32 34 33 27 37 24 23 22 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 14.672 s \n",
            "\n",
            "Accuracy rate for 66.900000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.67      0.36      0.47       980\n",
            "        1.0       0.91      0.93      0.92      1135\n",
            "        2.0       0.49      0.76      0.60      1032\n",
            "        3.0       0.73      0.73      0.73      1010\n",
            "        4.0       0.80      0.64      0.71       982\n",
            "        5.0       0.43      0.52      0.47       892\n",
            "        6.0       0.90      0.52      0.66       958\n",
            "        7.0       0.69      0.78      0.73      1028\n",
            "        8.0       0.60      0.76      0.67       974\n",
            "        9.0       0.68      0.63      0.66      1009\n",
            "\n",
            "avg / total       0.70      0.67      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 349    0  166   15    0  427    5    1   16    1]\n",
            " [   1 1052    4    2    2    2    1    0   70    1]\n",
            " [  17   36  787   33    5   28   11   24   85    6]\n",
            " [  44    7   69  739    9   34    5   16   69   18]\n",
            " [   2    3   48   21  632   30    4   85   32  125]\n",
            " [  49   11   56  114   12  462   19    4  158    7]\n",
            " [   6    3  391    1   16   18  497    0   26    0]\n",
            " [   1   17   29   10   26   17    0  797   10  121]\n",
            " [  45   17   31   37   14   37    8   30  740   15]\n",
            " [   5    6   18   39   70   20    0  197   19  635]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59730,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59730, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [17 32 34 35 28 37 24 27 22 24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 15.214 s \n",
            "\n",
            "Accuracy rate for 67.960000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.35      0.47       980\n",
            "        1.0       0.91      0.93      0.92      1135\n",
            "        2.0       0.49      0.76      0.60      1032\n",
            "        3.0       0.71      0.77      0.74      1010\n",
            "        4.0       0.84      0.66      0.74       982\n",
            "        5.0       0.42      0.49      0.46       892\n",
            "        6.0       0.92      0.52      0.66       958\n",
            "        7.0       0.71      0.84      0.77      1028\n",
            "        8.0       0.60      0.75      0.67       974\n",
            "        9.0       0.73      0.65      0.69      1009\n",
            "\n",
            "avg / total       0.71      0.68      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 347    0  163   25    0  422    5    2   16    0]\n",
            " [   1 1052    4    2    2    2    1    0   71    0]\n",
            " [  20   37  787   34    7   28   10   22   82    5]\n",
            " [  25    5   64  781    7   27    2   21   68   10]\n",
            " [   3    2   55   18  645   31    4   79   29  116]\n",
            " [  36   11   51  159    9  440   13    5  158   10]\n",
            " [   6    3  395    1   11   18  498    0   26    0]\n",
            " [   2   16   23    7   13   10    0  860   10   87]\n",
            " [  42   18   34   43   11   40    9   32  732   13]\n",
            " [   6    7   24   32   62   18    0  187   19  654]]\n",
            "--------------------------------\n",
            "val predicted: (59720,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59720, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [17 33 34 38 30 39 24 28 23 24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 15.921 s \n",
            "\n",
            "Accuracy rate for 68.270000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.68      0.35      0.46       980\n",
            "        1.0       0.91      0.94      0.92      1135\n",
            "        2.0       0.50      0.75      0.60      1032\n",
            "        3.0       0.76      0.75      0.76      1010\n",
            "        4.0       0.83      0.69      0.76       982\n",
            "        5.0       0.41      0.55      0.47       892\n",
            "        6.0       0.92      0.52      0.67       958\n",
            "        7.0       0.72      0.80      0.76      1028\n",
            "        8.0       0.63      0.73      0.68       974\n",
            "        9.0       0.72      0.66      0.69      1009\n",
            "\n",
            "avg / total       0.71      0.68      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 343    1  124    5    1  487    4    4   11    0]\n",
            " [   0 1070    4    3    1    2    1    0   54    0]\n",
            " [  20   48  777   26    8   42   11   21   73    6]\n",
            " [  37    5   59  761    7   33    2   24   70   12]\n",
            " [   2    1   47   14  682   33    4   66   23  110]\n",
            " [  45    8   62  107    8  489   10   15  138   10]\n",
            " [   5    3  394    0    9   22  501    0   24    0]\n",
            " [   2   21   25    7   20   11    0  824    6  112]\n",
            " [  42   14   37   57    9   49   11   28  712   15]\n",
            " [   5    8   24   22   74   20    0  168   20  668]]\n",
            "--------------------------------\n",
            "val predicted: (59710,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59710, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [17 33 36 39 31 40 24 28 25 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 16.819 s \n",
            "\n",
            "Accuracy rate for 67.440000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.30      0.43       980\n",
            "        1.0       0.91      0.94      0.92      1135\n",
            "        2.0       0.50      0.77      0.61      1032\n",
            "        3.0       0.76      0.74      0.75      1010\n",
            "        4.0       0.85      0.66      0.74       982\n",
            "        5.0       0.42      0.58      0.49       892\n",
            "        6.0       0.94      0.52      0.66       958\n",
            "        7.0       0.69      0.80      0.74      1028\n",
            "        8.0       0.60      0.76      0.67       974\n",
            "        9.0       0.70      0.61      0.65      1009\n",
            "\n",
            "avg / total       0.71      0.67      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 296    0  127    6    0  506    2    5   38    0]\n",
            " [   0 1062    6    2    1    2    0    0   62    0]\n",
            " [   9   48  796   23    6   39    7   13   88    3]\n",
            " [  29    6   54  749    5   41    2   23   89   12]\n",
            " [   1    0   49   14  652   28    5   83   19  131]\n",
            " [  29    7   53  101    9  515    9    9  147   13]\n",
            " [   8    3  394    0    9   29  494    1   20    0]\n",
            " [   1   18   34   11   21    9    0  827   11   96]\n",
            " [  30   14   32   58   10   46    9   20  742   13]\n",
            " [   4    6   49   22   57   14    0  221   25  611]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59700, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [18 34 36 42 31 41 25 28 27 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 17.266 s \n",
            "\n",
            "Accuracy rate for 68.450000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.37      0.50       980\n",
            "        1.0       0.91      0.93      0.92      1135\n",
            "        2.0       0.51      0.77      0.61      1032\n",
            "        3.0       0.73      0.79      0.76      1010\n",
            "        4.0       0.85      0.68      0.76       982\n",
            "        5.0       0.44      0.60      0.51       892\n",
            "        6.0       0.93      0.52      0.67       958\n",
            "        7.0       0.68      0.79      0.73      1028\n",
            "        8.0       0.65      0.73      0.69       974\n",
            "        9.0       0.69      0.60      0.64      1009\n",
            "\n",
            "avg / total       0.72      0.68      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 363    1   93   14    0  483    3    3   20    0]\n",
            " [   0 1060    4    3    1    2    0    0   65    0]\n",
            " [  11   53  793   30    7   33   11   13   77    4]\n",
            " [  21    6   63  796    2   36    2   21   52   11]\n",
            " [   3    0   46   10  669   29    6   83   18  118]\n",
            " [  36    5   44  115   11  539    8    8  111   15]\n",
            " [  12    2  396    1    6   28  498    1   14    0]\n",
            " [   1   18   35    9   18   10    0  812   13  112]\n",
            " [  29   10   37   85   14   39   10   25  709   16]\n",
            " [   3    6   51   29   57   18    0  227   12  606]]\n",
            "--------------------------------\n",
            "val predicted: (59690,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59690, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [20 34 37 42 32 43 25 29 30 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 17.993 s \n",
            "\n",
            "Accuracy rate for 68.630000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.37      0.49       980\n",
            "        1.0       0.91      0.94      0.93      1135\n",
            "        2.0       0.51      0.78      0.61      1032\n",
            "        3.0       0.74      0.78      0.76      1010\n",
            "        4.0       0.86      0.66      0.75       982\n",
            "        5.0       0.45      0.59      0.51       892\n",
            "        6.0       0.93      0.51      0.66       958\n",
            "        7.0       0.68      0.80      0.74      1028\n",
            "        8.0       0.65      0.75      0.70       974\n",
            "        9.0       0.70      0.60      0.65      1009\n",
            "\n",
            "avg / total       0.72      0.69      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 361    1  110   10    0  484    3    2    9    0]\n",
            " [   0 1072    5    4    1    3    0    0   50    0]\n",
            " [   8   56  804   29    4   24   11   15   77    4]\n",
            " [  22    5   63  792    2   34    2   21   58   11]\n",
            " [   2    0   52    9  652   27    6   88   32  114]\n",
            " [  48    8   40  114    7  530    7    7  120   11]\n",
            " [  17    4  393    1    7   35  489    1   11    0]\n",
            " [   1   19   37    9   14    7    0  826   11  104]\n",
            " [  35    9   35   76   12   30    9   21  734   13]\n",
            " [   3    6   50   25   61   11    0  226   24  603]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59680,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59680, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [20 34 38 43 34 44 26 31 31 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 18.488 s \n",
            "\n",
            "Accuracy rate for 68.000000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.34      0.46       980\n",
            "        1.0       0.90      0.94      0.92      1135\n",
            "        2.0       0.50      0.75      0.60      1032\n",
            "        3.0       0.72      0.80      0.76      1010\n",
            "        4.0       0.86      0.67      0.75       982\n",
            "        5.0       0.44      0.60      0.51       892\n",
            "        6.0       0.92      0.51      0.66       958\n",
            "        7.0       0.69      0.78      0.74      1028\n",
            "        8.0       0.64      0.75      0.69       974\n",
            "        9.0       0.69      0.60      0.64      1009\n",
            "\n",
            "avg / total       0.71      0.68      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 329    1  112    7    0  512    4    2   13    0]\n",
            " [   0 1072    5    4    1    3    0    0   50    0]\n",
            " [   8   60  775   41    3   31   14   12   84    4]\n",
            " [  19    4   58  805    2   35    1   19   56   11]\n",
            " [   0    0   59   12  654   32    6   68   33  118]\n",
            " [  37    9   38  119    8  535    6   12  118   10]\n",
            " [  19    4  388    1    6   36  490    1   13    0]\n",
            " [   1   20   42   12   16    5    0  805   15  112]\n",
            " [  35   10   30   89   10   30   10   15  734   11]\n",
            " [   3    7   51   26   61    7    0  227   26  601]]\n",
            "--------------------------------\n",
            "val predicted: (59670,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59670, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [20 34 38 46 37 46 27 31 32 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.289 s \n",
            "\n",
            "Accuracy rate for 68.470000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.74      0.32      0.45       980\n",
            "        1.0       0.90      0.95      0.93      1135\n",
            "        2.0       0.51      0.75      0.61      1032\n",
            "        3.0       0.70      0.80      0.75      1010\n",
            "        4.0       0.86      0.73      0.79       982\n",
            "        5.0       0.43      0.58      0.49       892\n",
            "        6.0       0.92      0.52      0.66       958\n",
            "        7.0       0.70      0.79      0.74      1028\n",
            "        8.0       0.65      0.74      0.69       974\n",
            "        9.0       0.70      0.59      0.64      1009\n",
            "\n",
            "avg / total       0.72      0.68      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 315    1  106   18    0  520    3    2   15    0]\n",
            " [   0 1080    4    7    1    3    0    0   40    0]\n",
            " [   7   61  776   29    5   32   16   11   92    3]\n",
            " [  16    4   47  811    3   32    3   15   67   12]\n",
            " [   0    0   42    9  718   19    5   56   26  107]\n",
            " [  31    8   29  159    6  521    8   11  109   10]\n",
            " [  19    3  375    1   11   42  496    0   11    0]\n",
            " [   2   19   40    9   15    8    0  813   11  111]\n",
            " [  34   15   37   88    9   27    8   25  720   11]\n",
            " [   2    7   51   28   64   12    0  231   17  597]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59660, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [20 35 38 47 38 50 27 32 33 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 19.651 s \n",
            "\n",
            "Accuracy rate for 68.770000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.74      0.33      0.45       980\n",
            "        1.0       0.90      0.95      0.93      1135\n",
            "        2.0       0.51      0.75      0.60      1032\n",
            "        3.0       0.70      0.80      0.74      1010\n",
            "        4.0       0.87      0.74      0.80       982\n",
            "        5.0       0.45      0.61      0.52       892\n",
            "        6.0       0.92      0.52      0.66       958\n",
            "        7.0       0.68      0.77      0.72      1028\n",
            "        8.0       0.66      0.74      0.70       974\n",
            "        9.0       0.72      0.62      0.67      1009\n",
            "\n",
            "avg / total       0.72      0.69      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 321    0  126   24    0  488    4    4   13    0]\n",
            " [   0 1081    4    6    1    4    0    0   39    0]\n",
            " [   7   64  772   32    5   28   16   14   91    3]\n",
            " [  14    3   46  809    3   35    3   25   63    9]\n",
            " [   0    0   40   10  722   11    4   80   28   87]\n",
            " [  31    6   34  153    9  542    7   12   85   13]\n",
            " [  21    3  376    1   11   40  494    1   11    0]\n",
            " [   2   24   41   13   16   10    0  790   18  114]\n",
            " [  35   12   39   85    8   36    7   21  719   12]\n",
            " [   2    6   49   31   59    9    0  207   19  627]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59650, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [20 35 40 48 39 52 28 34 33 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 20.069 s \n",
            "\n",
            "Accuracy rate for 68.800000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.33      0.45       980\n",
            "        1.0       0.91      0.95      0.93      1135\n",
            "        2.0       0.53      0.75      0.62      1032\n",
            "        3.0       0.69      0.78      0.73      1010\n",
            "        4.0       0.87      0.73      0.79       982\n",
            "        5.0       0.42      0.59      0.49       892\n",
            "        6.0       0.92      0.56      0.69       958\n",
            "        7.0       0.68      0.78      0.73      1028\n",
            "        8.0       0.67      0.73      0.70       974\n",
            "        9.0       0.71      0.62      0.66      1009\n",
            "\n",
            "avg / total       0.72      0.69      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 319    0  100   24    0  517    6    4   10    0]\n",
            " [   0 1080    5    7    2    6    0    0   35    0]\n",
            " [   7   60  769   34    2   37   17   14   89    3]\n",
            " [  17    4   46  791    4   48    3   27   62    8]\n",
            " [   0    0   33    8  717   18    4   80   26   96]\n",
            " [  34    5   35  163    5  530    9   12   87   12]\n",
            " [  17    3  347    1   12   36  532    1    9    0]\n",
            " [   2   22   32   11   15    9    0  805   15  117]\n",
            " [  37   11   32   81   10   47   10   19  713   14]\n",
            " [   3    7   43   30   58    8    0  218   18  624]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59640, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [20 35 40 49 39 53 29 35 35 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 20.628 s \n",
            "\n",
            "Accuracy rate for 69.170000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.33      0.45       980\n",
            "        1.0       0.91      0.95      0.93      1135\n",
            "        2.0       0.57      0.73      0.64      1032\n",
            "        3.0       0.70      0.79      0.74      1010\n",
            "        4.0       0.88      0.68      0.77       982\n",
            "        5.0       0.41      0.58      0.48       892\n",
            "        6.0       0.91      0.58      0.70       958\n",
            "        7.0       0.67      0.83      0.74      1028\n",
            "        8.0       0.66      0.75      0.70       974\n",
            "        9.0       0.72      0.64      0.68      1009\n",
            "\n",
            "avg / total       0.72      0.69      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 320    0   90   23    0  535    6    3    3    0]\n",
            " [   0 1081    4    8    1    5    0    0   36    0]\n",
            " [   8   64  755   27    2   36   18   14  105    3]\n",
            " [  19    3   31  799    3   46    3   23   73   10]\n",
            " [   0    0   33    8  664   18    3  116   29  111]\n",
            " [  23    6   25  174    6  518   15   14   98   13]\n",
            " [  14    3  322    1   13   40  552    1   12    0]\n",
            " [   2   18   23    5    7    8    0  850   13  102]\n",
            " [  38   11   14   75    8   46   11   24  734   13]\n",
            " [   3    7   31   25   49   11    0  224   15  644]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59630,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59630, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [21 35 42 51 41 54 29 35 37 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 21.228 s \n",
            "\n",
            "Accuracy rate for 68.970000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.72      0.31      0.44       980\n",
            "        1.0       0.92      0.94      0.93      1135\n",
            "        2.0       0.58      0.74      0.65      1032\n",
            "        3.0       0.69      0.80      0.74      1010\n",
            "        4.0       0.87      0.65      0.75       982\n",
            "        5.0       0.41      0.57      0.47       892\n",
            "        6.0       0.91      0.62      0.74       958\n",
            "        7.0       0.66      0.82      0.73      1028\n",
            "        8.0       0.64      0.75      0.69       974\n",
            "        9.0       0.72      0.64      0.68      1009\n",
            "\n",
            "avg / total       0.72      0.69      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 307    0  102   31    0  523    6    3    8    0]\n",
            " [   0 1071    5    7    1    4    0    0   47    0]\n",
            " [   6   47  762   26    3   40   19   15  111    3]\n",
            " [  13    3   36  809    2   32    3   23   80    9]\n",
            " [   1    0   35    8  640   32    3  127   26  110]\n",
            " [  29    6   26  172    8  504   15   14  107   11]\n",
            " [  18    3  279    1   16   38  592    1   10    0]\n",
            " [   2   18   27    6   10    9    0  841   12  103]\n",
            " [  44    9   11   75   11   50   10   24  730   10]\n",
            " [   6    7   29   31   44   12    0  225   14  641]]\n",
            "--------------------------------\n",
            "val predicted: (59620,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59620, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [22 36 43 53 42 54 30 35 38 37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 21.946 s \n",
            "\n",
            "Accuracy rate for 69.330000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.28      0.40       980\n",
            "        1.0       0.91      0.95      0.93      1135\n",
            "        2.0       0.59      0.73      0.65      1032\n",
            "        3.0       0.70      0.81      0.75      1010\n",
            "        4.0       0.87      0.67      0.76       982\n",
            "        5.0       0.40      0.56      0.47       892\n",
            "        6.0       0.90      0.62      0.74       958\n",
            "        7.0       0.70      0.82      0.76      1028\n",
            "        8.0       0.65      0.76      0.70       974\n",
            "        9.0       0.70      0.66      0.68      1009\n",
            "\n",
            "avg / total       0.72      0.69      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 277    0  112   26    0  535    9    3   18    0]\n",
            " [   0 1081    4    6    1    5    0    0   38    0]\n",
            " [   6   56  755   27    6   37   24   10  106    5]\n",
            " [  20    5   32  814    2   31    4   18   76    8]\n",
            " [   1    0   34    8  659   25    2   88   14  151]\n",
            " [  29    8   23  176    6  500   16   13  110   11]\n",
            " [  19    3  267    1   22   35  598    1   12    0]\n",
            " [   2   18   28    6    7    8    0  842   10  107]\n",
            " [  31   14    9   70    7   59   13   22  737   12]\n",
            " [   7    7   26   26   44   10    0  202   17  670]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59610, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [22 36 43 53 45 60 30 35 38 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 22.519 s \n",
            "\n",
            "Accuracy rate for 69.680000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.27      0.39       980\n",
            "        1.0       0.91      0.95      0.93      1135\n",
            "        2.0       0.59      0.73      0.65      1032\n",
            "        3.0       0.70      0.80      0.75      1010\n",
            "        4.0       0.87      0.70      0.78       982\n",
            "        5.0       0.41      0.58      0.48       892\n",
            "        6.0       0.89      0.62      0.73       958\n",
            "        7.0       0.71      0.82      0.76      1028\n",
            "        8.0       0.66      0.76      0.71       974\n",
            "        9.0       0.70      0.67      0.68      1009\n",
            "\n",
            "avg / total       0.72      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 268    0  120   25    0  534    9    2   22    0]\n",
            " [   0 1082    4    7    1    3    1    0   37    0]\n",
            " [   6   56  755   26    8   31   25   10  110    5]\n",
            " [  21    4   34  809    2   36    4   17   73   10]\n",
            " [   1    0   26    8  692   17    3   81   13  141]\n",
            " [  28    7   21  185    5  514   15   12   93   12]\n",
            " [  15    2  267    1   30   39  592    1   11    0]\n",
            " [   2   17   26    5    7    7    0  839   10  115]\n",
            " [  30   14    8   66    9   60   13   22  741   11]\n",
            " [   9    7   28   23   43    9    0  198   16  676]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59600, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [22 37 44 55 47 61 30 36 40 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.113 s \n",
            "\n",
            "Accuracy rate for 69.950000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.28      0.40       980\n",
            "        1.0       0.89      0.95      0.92      1135\n",
            "        2.0       0.58      0.71      0.64      1032\n",
            "        3.0       0.71      0.81      0.76      1010\n",
            "        4.0       0.84      0.76      0.80       982\n",
            "        5.0       0.42      0.58      0.48       892\n",
            "        6.0       0.90      0.61      0.73       958\n",
            "        7.0       0.74      0.80      0.77      1028\n",
            "        8.0       0.66      0.76      0.71       974\n",
            "        9.0       0.71      0.68      0.69      1009\n",
            "\n",
            "avg / total       0.72      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 271    0  130   24    0  526    9    2   18    0]\n",
            " [   0 1075    3   12    1    5    0    0   39    0]\n",
            " [   6   80  732   28   10   31   24   11  105    5]\n",
            " [  19    5   31  822    2   29    3   18   71   10]\n",
            " [   2    0   27    4  748    9    2   52   14  124]\n",
            " [  31    8   21  182    4  513   13   15   92   13]\n",
            " [  13    2  259    0   46   41  585    0   12    0]\n",
            " [   2   16   26    4   14    6    0  824   14  122]\n",
            " [  29   12   10   69   11   63   13   18  743    6]\n",
            " [   8    8   28   20   59    9    0  174   21  682]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59590, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [22 37 45 56 48 64 30 36 41 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 23.944 s \n",
            "\n",
            "Accuracy rate for 70.340000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.28      0.40       980\n",
            "        1.0       0.90      0.95      0.92      1135\n",
            "        2.0       0.61      0.71      0.66      1032\n",
            "        3.0       0.71      0.81      0.75      1010\n",
            "        4.0       0.86      0.73      0.79       982\n",
            "        5.0       0.39      0.58      0.47       892\n",
            "        6.0       0.91      0.61      0.73       958\n",
            "        7.0       0.78      0.80      0.79      1028\n",
            "        8.0       0.66      0.77      0.71       974\n",
            "        9.0       0.71      0.73      0.72      1009\n",
            "\n",
            "avg / total       0.73      0.70      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 273    0   78   11    0  597    9    2   10    0]\n",
            " [   0 1073    5   13    1    6    0    0   37    0]\n",
            " [   6   65  737   28   11   37   23   11  110    4]\n",
            " [  10    6   29  819    2   38    3   19   75    9]\n",
            " [   1    1   28    5  712   16    2   48   15  154]\n",
            " [  30    9   17  175    5  520   10   13   99   14]\n",
            " [  15    2  260    1   36   49  584    1   10    0]\n",
            " [   2   19   26    5   11    8    0  827   17  113]\n",
            " [  29   13    9   78    7   55    9   18  750    6]\n",
            " [   7    9   27   26   42   10    0  128   21  739]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59580,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59580, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [22 37 46 56 48 65 33 36 42 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 24.498 s \n",
            "\n",
            "Accuracy rate for 70.470000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.29      0.41       980\n",
            "        1.0       0.89      0.95      0.92      1135\n",
            "        2.0       0.59      0.70      0.64      1032\n",
            "        3.0       0.72      0.81      0.76      1010\n",
            "        4.0       0.87      0.75      0.80       982\n",
            "        5.0       0.39      0.58      0.47       892\n",
            "        6.0       0.89      0.58      0.70       958\n",
            "        7.0       0.80      0.76      0.78      1028\n",
            "        8.0       0.65      0.77      0.71       974\n",
            "        9.0       0.72      0.79      0.75      1009\n",
            "\n",
            "avg / total       0.73      0.70      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 280    0   76   12    0  590   13    2    7    0]\n",
            " [   0 1073    3   15    0    4    1    0   38    1]\n",
            " [   7   74  725   27   10   39   23   12  113    2]\n",
            " [  10    6   30  821    2   33    3   17   77   11]\n",
            " [   2    1   29    3  737   17    2   50   15  126]\n",
            " [  31    9   16  170    5  521   12   14  104   10]\n",
            " [  15    1  290    1   38   51  556    0    6    0]\n",
            " [   2   18   23    5   14    7    0  782   21  156]\n",
            " [  28   12    8   76    7   54   17   13  753    6]\n",
            " [   8    6   30   15   38    9    0   83   21  799]]\n",
            "--------------------------------\n",
            "val predicted: (59570,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59570, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [22 38 46 58 48 66 34 36 43 49] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 24.949 s \n",
            "\n",
            "Accuracy rate for 71.190000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.28      0.41       980\n",
            "        1.0       0.90      0.96      0.93      1135\n",
            "        2.0       0.60      0.70      0.65      1032\n",
            "        3.0       0.72      0.82      0.77      1010\n",
            "        4.0       0.86      0.74      0.79       982\n",
            "        5.0       0.40      0.60      0.48       892\n",
            "        6.0       0.88      0.60      0.71       958\n",
            "        7.0       0.80      0.79      0.79      1028\n",
            "        8.0       0.67      0.78      0.72       974\n",
            "        9.0       0.73      0.78      0.76      1009\n",
            "\n",
            "avg / total       0.74      0.71      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 279    0   74   14    0  592   13    1    6    1]\n",
            " [   0 1093    3    5    0    4    0    0   29    1]\n",
            " [   7   69  726   29    9   40   27   12  111    2]\n",
            " [  10    8   24  831    3   35    4   16   70    9]\n",
            " [   2    0   28    6  723   18    2   51   15  137]\n",
            " [  30   10   16  166    4  531   15   13   97   10]\n",
            " [   9    1  277    2   45   44  572    0    8    0]\n",
            " [   3   16   24    9   15    5    0  808   23  125]\n",
            " [  27   14    8   71    8   47   16   13  764    6]\n",
            " [   7    7   27   17   36    6    0   93   24  792]]\n",
            "--------------------------------\n",
            "val predicted: (59560,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59560, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [22 39 46 61 49 67 35 36 44 51] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 25.264 s \n",
            "\n",
            "Accuracy rate for 71.970000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.30      0.43       980\n",
            "        1.0       0.89      0.96      0.92      1135\n",
            "        2.0       0.63      0.70      0.66      1032\n",
            "        3.0       0.73      0.80      0.77      1010\n",
            "        4.0       0.87      0.75      0.80       982\n",
            "        5.0       0.41      0.57      0.48       892\n",
            "        6.0       0.88      0.67      0.76       958\n",
            "        7.0       0.80      0.80      0.80      1028\n",
            "        8.0       0.65      0.79      0.72       974\n",
            "        9.0       0.74      0.78      0.76      1009\n",
            "\n",
            "avg / total       0.74      0.72      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 298    0   74   12    0  569   18    1    7    1]\n",
            " [   0 1092    2    5    0    2    1    0   32    1]\n",
            " [   9   72  724   27    8   38   35   12  105    2]\n",
            " [  13    8   28  811    3   36    4   16   79   12]\n",
            " [   2    1   22    3  734   20    3   49   14  134]\n",
            " [  32   12   15  156    6  512   15   13  118   13]\n",
            " [   7    1  236    1   36   31  639    0    7    0]\n",
            " [   3   19   25   11   13    6    0  823   21  107]\n",
            " [  26   16    9   67    8   44   14   13  772    5]\n",
            " [   6    8   23   17   35    5    0   97   26  792]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59550, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [22 40 47 61 52 69 36 37 44 52] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 26.145 s \n",
            "\n",
            "Accuracy rate for 72.260000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.77      0.30      0.43       980\n",
            "        1.0       0.88      0.96      0.92      1135\n",
            "        2.0       0.64      0.70      0.67      1032\n",
            "        3.0       0.73      0.81      0.77      1010\n",
            "        4.0       0.86      0.76      0.80       982\n",
            "        5.0       0.41      0.57      0.48       892\n",
            "        6.0       0.87      0.69      0.77       958\n",
            "        7.0       0.81      0.79      0.80      1028\n",
            "        8.0       0.66      0.80      0.72       974\n",
            "        9.0       0.73      0.80      0.76      1009\n",
            "\n",
            "avg / total       0.74      0.72      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 291    0   77   12    2  566   24    0    7    1]\n",
            " [   0 1093    2    6    0    5    0    0   28    1]\n",
            " [   9   79  722   33   10   30   30   13  104    2]\n",
            " [  12    7   24  816    2   36    4   17   79   13]\n",
            " [   3    1   25    2  742   16    3   42   13  135]\n",
            " [  28   11   17  158    3  506   20   14  119   16]\n",
            " [   3    2  206    1   51   27  662    0    6    0]\n",
            " [   2   20   26   13   10    5    0  815   16  121]\n",
            " [  26   17    8   66    8   38   16   12  775    8]\n",
            " [   6    8   22   15   39    5    0   89   21  804]]\n",
            "--------------------------------\n",
            "val predicted: (59540,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59540, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [22 40 49 62 53 70 36 38 46 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 27.030 s \n",
            "\n",
            "Accuracy rate for 72.060000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.29      0.42       980\n",
            "        1.0       0.89      0.96      0.92      1135\n",
            "        2.0       0.64      0.70      0.67      1032\n",
            "        3.0       0.73      0.82      0.77      1010\n",
            "        4.0       0.86      0.77      0.81       982\n",
            "        5.0       0.41      0.58      0.48       892\n",
            "        6.0       0.88      0.67      0.76       958\n",
            "        7.0       0.82      0.77      0.80      1028\n",
            "        8.0       0.67      0.79      0.72       974\n",
            "        9.0       0.72      0.79      0.75      1009\n",
            "\n",
            "avg / total       0.74      0.72      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 281    0   70   10    2  587   21    1    8    0]\n",
            " [   0 1087    4    6    0    4    1    0   32    1]\n",
            " [   7   73  726   41    8   33   26   10  104    4]\n",
            " [  12    8   18  829    1   30    3   17   75   17]\n",
            " [   1    1   22    2  757   18    3   30   11  137]\n",
            " [  27   11   16  156    3  518   20   10  116   15]\n",
            " [   2    2  226    1   51   27  642    0    7    0]\n",
            " [   2   22   30   12   15    6    0  794   15  132]\n",
            " [  22   17    9   64    6   46   17   14  772    7]\n",
            " [   5    7   20   15   42    9    0   93   18  800]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59530,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59530, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [24 42 50 63 53 71 37 38 48 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 27.473 s \n",
            "\n",
            "Accuracy rate for 71.980000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.30      0.44       980\n",
            "        1.0       0.90      0.96      0.93      1135\n",
            "        2.0       0.63      0.71      0.67      1032\n",
            "        3.0       0.74      0.82      0.77      1010\n",
            "        4.0       0.85      0.77      0.81       982\n",
            "        5.0       0.40      0.56      0.47       892\n",
            "        6.0       0.86      0.64      0.73       958\n",
            "        7.0       0.82      0.78      0.80      1028\n",
            "        8.0       0.66      0.80      0.72       974\n",
            "        9.0       0.72      0.79      0.75      1009\n",
            "\n",
            "avg / total       0.74      0.72      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 297    0   57   10    2  582   20    1   11    0]\n",
            " [   0 1090    5    4    0    3    2    0   30    1]\n",
            " [  10   71  732   34    8   33   25   10  105    4]\n",
            " [  11    4   19  825    2   26    4   18   83   18]\n",
            " [   1    1   22    1  761   18    4   27   10  137]\n",
            " [  23   12   15  163    3  499   21   11  132   13]\n",
            " [   5    2  244    1   56   31  614    0    5    0]\n",
            " [   1   15   33   10   15    6    0  801   12  135]\n",
            " [  21   15   10   60    6   40   25   13  778    6]\n",
            " [   6    6   19   14   43    8    0   93   19  801]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59520, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [25 42 52 63 53 71 41 39 50 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 28.032 s \n",
            "\n",
            "Accuracy rate for 72.550000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.77      0.33      0.46       980\n",
            "        1.0       0.90      0.96      0.92      1135\n",
            "        2.0       0.67      0.70      0.68      1032\n",
            "        3.0       0.71      0.80      0.75      1010\n",
            "        4.0       0.86      0.77      0.81       982\n",
            "        5.0       0.41      0.56      0.47       892\n",
            "        6.0       0.88      0.72      0.79       958\n",
            "        7.0       0.82      0.79      0.80      1028\n",
            "        8.0       0.66      0.79      0.72       974\n",
            "        9.0       0.72      0.80      0.76      1009\n",
            "\n",
            "avg / total       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 319    0   60   10    1  565   17    1    6    1]\n",
            " [   0 1085    6    6    0    4    0    0   33    1]\n",
            " [  14   72  723   44    7   32   29    8  100    3]\n",
            " [  18    4   18  810    1   26    3   19   93   18]\n",
            " [   1    1   21    1  752   17    2   42    8  137]\n",
            " [  23   12   15  165    4  497   21   11  130   14]\n",
            " [   3    2  187    1   39   31  690    0    5    0]\n",
            " [   3   15   31   11   13    5    0  808    8  134]\n",
            " [  26   15    9   75    6   36   23    9  768    7]\n",
            " [   6    6   17   13   47    8    0   88   21  803]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) [5. 5. 0. ... 9. 9. 9.]\n",
            "probabilities: (59510, 10) \n",
            " [5 5 0 ... 9 9 9]\n",
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [25 42 53 63 57 71 42 40 53 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training svm...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 29.037 s \n",
            "\n",
            "Accuracy rate for 72.790000 \n",
            "Classification report for classifier SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
            "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
            "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
            "  tol=0.001, verbose=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.32      0.45       980\n",
            "        1.0       0.89      0.95      0.92      1135\n",
            "        2.0       0.69      0.71      0.70      1032\n",
            "        3.0       0.72      0.79      0.75      1010\n",
            "        4.0       0.89      0.78      0.83       982\n",
            "        5.0       0.40      0.55      0.47       892\n",
            "        6.0       0.89      0.76      0.82       958\n",
            "        7.0       0.81      0.78      0.79      1028\n",
            "        8.0       0.63      0.80      0.70       974\n",
            "        9.0       0.72      0.79      0.76      1009\n",
            "\n",
            "avg / total       0.75      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 309    0   62   10    2  571   15    1   10    0]\n",
            " [   0 1081    5    6    0    4    1    0   37    1]\n",
            " [  13   73  734   42    7   31   22    8  100    2]\n",
            " [  16    4   18  794    1   24    2   19  114   18]\n",
            " [   1    0   23    1  766   16    4   43   10  118]\n",
            " [  22   12   11  160    4  490   25   12  143   13]\n",
            " [   2    2  153    2   36   29  728    0    6    0]\n",
            " [   3   15   29   12    7    4    0  806    8  144]\n",
            " [  26   16    9   68    4   37   24    8  775    7]\n",
            " [   6    6   18   11   37    7    0  103   25  796]]\n",
            "--------------------------------\n",
            "final active learning accuracies [35.93, 35.97, 40.33, 39.39, 41.349999999999994, 42.99, 46.23, 46.18, 47.260000000000005, 52.5, 52.400000000000006, 51.25999999999999, 51.690000000000005, 51.800000000000004, 53.18000000000001, 53.82, 55.88999999999999, 56.120000000000005, 57.269999999999996, 59.41, 59.95, 62.629999999999995, 61.339999999999996, 63.88, 65.34, 65.77, 66.9, 67.96, 68.27, 67.44, 68.45, 68.63, 68.0, 68.47, 68.77, 68.8, 69.17, 68.97, 69.33, 69.67999999999999, 69.95, 70.34, 70.47, 71.19, 71.97, 72.26, 72.06, 71.98, 72.55, 72.78999999999999]\n",
            "saved Active-learning-experiment-15.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-10.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "{\n",
            "  \"SvmModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          35.93,\n",
            "          35.97,\n",
            "          40.33,\n",
            "          39.39,\n",
            "          41.349999999999994,\n",
            "          42.99,\n",
            "          46.23,\n",
            "          46.18,\n",
            "          47.260000000000005,\n",
            "          52.5,\n",
            "          52.400000000000006,\n",
            "          51.25999999999999,\n",
            "          51.690000000000005,\n",
            "          51.800000000000004,\n",
            "          53.18000000000001,\n",
            "          53.82,\n",
            "          55.88999999999999,\n",
            "          56.120000000000005,\n",
            "          57.269999999999996,\n",
            "          59.41,\n",
            "          59.95,\n",
            "          62.629999999999995,\n",
            "          61.339999999999996,\n",
            "          63.88,\n",
            "          65.34,\n",
            "          65.77,\n",
            "          66.9,\n",
            "          67.96,\n",
            "          68.27,\n",
            "          67.44,\n",
            "          68.45,\n",
            "          68.63,\n",
            "          68.0,\n",
            "          68.47,\n",
            "          68.77,\n",
            "          68.8,\n",
            "          69.17,\n",
            "          68.97,\n",
            "          69.33,\n",
            "          69.67999999999999,\n",
            "          69.95,\n",
            "          70.34,\n",
            "          70.47,\n",
            "          71.19,\n",
            "          71.97,\n",
            "          72.26,\n",
            "          72.06,\n",
            "          71.98,\n",
            "          72.55,\n",
            "          72.78999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          50.33,\n",
            "          51.59,\n",
            "          56.599999999999994,\n",
            "          60.24,\n",
            "          61.57,\n",
            "          63.5,\n",
            "          66.74,\n",
            "          68.19,\n",
            "          68.02,\n",
            "          69.8,\n",
            "          75.88000000000001,\n",
            "          77.24,\n",
            "          78.09,\n",
            "          79.38,\n",
            "          80.4,\n",
            "          80.99,\n",
            "          80.28999999999999,\n",
            "          80.12,\n",
            "          79.75999999999999,\n",
            "          80.36999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          64.55,\n",
            "          68.75,\n",
            "          71.34,\n",
            "          74.11999999999999,\n",
            "          75.96000000000001,\n",
            "          77.03999999999999,\n",
            "          76.85,\n",
            "          79.19,\n",
            "          80.51,\n",
            "          80.99\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          78.4,\n",
            "          78.21000000000001,\n",
            "          80.08,\n",
            "          81.0\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.11,\n",
            "          84.53\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.86,\n",
            "          37.6,\n",
            "          46.23,\n",
            "          58.41,\n",
            "          60.34,\n",
            "          65.98,\n",
            "          65.01,\n",
            "          69.86,\n",
            "          72.28999999999999,\n",
            "          74.65,\n",
            "          76.24,\n",
            "          77.37,\n",
            "          77.59,\n",
            "          78.7,\n",
            "          79.06,\n",
            "          80.06,\n",
            "          81.21000000000001,\n",
            "          82.32000000000001,\n",
            "          83.17,\n",
            "          83.78,\n",
            "          84.6,\n",
            "          84.58,\n",
            "          84.47,\n",
            "          85.07000000000001,\n",
            "          85.64,\n",
            "          85.75,\n",
            "          85.7,\n",
            "          86.18,\n",
            "          86.58,\n",
            "          86.50999999999999,\n",
            "          86.71,\n",
            "          87.09,\n",
            "          86.91,\n",
            "          87.13,\n",
            "          87.42999999999999,\n",
            "          87.75,\n",
            "          87.97,\n",
            "          88.23,\n",
            "          88.23,\n",
            "          88.22,\n",
            "          88.16000000000001,\n",
            "          88.03,\n",
            "          88.38000000000001,\n",
            "          88.39,\n",
            "          88.64,\n",
            "          88.98,\n",
            "          89.05999999999999,\n",
            "          89.34,\n",
            "          89.3,\n",
            "          89.52\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          50.160000000000004,\n",
            "          63.73,\n",
            "          70.14,\n",
            "          74.4,\n",
            "          78.99000000000001,\n",
            "          80.36999999999999,\n",
            "          82.76,\n",
            "          84.35000000000001,\n",
            "          85.78,\n",
            "          86.61999999999999,\n",
            "          87.46000000000001,\n",
            "          87.64,\n",
            "          88.08,\n",
            "          88.75,\n",
            "          88.68,\n",
            "          89.02,\n",
            "          89.39,\n",
            "          89.57000000000001,\n",
            "          89.66,\n",
            "          89.8\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          59.099999999999994,\n",
            "          69.91000000000001,\n",
            "          75.66000000000001,\n",
            "          81.41000000000001,\n",
            "          82.69,\n",
            "          85.07000000000001,\n",
            "          85.92,\n",
            "          86.89,\n",
            "          87.8,\n",
            "          87.6\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.45,\n",
            "          84.1,\n",
            "          86.36,\n",
            "          88.16000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.58,\n",
            "          87.38\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.009999999999998,\n",
            "          33.54,\n",
            "          48.67,\n",
            "          57.34,\n",
            "          61.68,\n",
            "          64.75999999999999,\n",
            "          69.28,\n",
            "          71.97,\n",
            "          73.2,\n",
            "          74.03,\n",
            "          75.08,\n",
            "          76.01,\n",
            "          76.55,\n",
            "          77.42999999999999,\n",
            "          77.75,\n",
            "          79.72,\n",
            "          80.78,\n",
            "          81.62,\n",
            "          81.8,\n",
            "          82.03,\n",
            "          81.82000000000001,\n",
            "          82.72,\n",
            "          82.94,\n",
            "          83.03,\n",
            "          83.72,\n",
            "          83.81,\n",
            "          83.72,\n",
            "          83.95,\n",
            "          84.38,\n",
            "          85.02,\n",
            "          85.36,\n",
            "          85.65,\n",
            "          85.26,\n",
            "          85.37,\n",
            "          85.37,\n",
            "          85.19,\n",
            "          85.18,\n",
            "          85.61999999999999,\n",
            "          85.47,\n",
            "          85.61999999999999,\n",
            "          85.78,\n",
            "          86.00999999999999,\n",
            "          86.05000000000001,\n",
            "          85.96000000000001,\n",
            "          85.96000000000001,\n",
            "          86.0,\n",
            "          86.24000000000001,\n",
            "          86.6,\n",
            "          86.66,\n",
            "          86.81\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.449999999999996,\n",
            "          67.88,\n",
            "          72.25,\n",
            "          77.82,\n",
            "          79.19,\n",
            "          80.32000000000001,\n",
            "          81.19,\n",
            "          81.91000000000001,\n",
            "          82.67999999999999,\n",
            "          82.89,\n",
            "          82.89,\n",
            "          83.05,\n",
            "          83.91999999999999,\n",
            "          84.69,\n",
            "          84.77,\n",
            "          84.66,\n",
            "          85.0,\n",
            "          85.3,\n",
            "          85.79,\n",
            "          86.08\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          56.38999999999999,\n",
            "          72.92999999999999,\n",
            "          78.44,\n",
            "          81.0,\n",
            "          82.73,\n",
            "          83.52000000000001,\n",
            "          84.35000000000001,\n",
            "          85.17,\n",
            "          86.17,\n",
            "          86.66\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          73.76,\n",
            "          83.52000000000001,\n",
            "          85.6,\n",
            "          86.44\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.02000000000001,\n",
            "          85.64\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 16, using model = RfModel, selection_function = RandomSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [32 26 27 28 24 24 19 16 31 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.695 s \n",
            "\n",
            "Accuracy rate for 83.190000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.96      0.88       980\n",
            "        1.0       0.86      0.99      0.92      1135\n",
            "        2.0       0.88      0.79      0.83      1032\n",
            "        3.0       0.76      0.87      0.81      1010\n",
            "        4.0       0.85      0.82      0.84       982\n",
            "        5.0       0.77      0.60      0.68       892\n",
            "        6.0       0.92      0.83      0.87       958\n",
            "        7.0       0.89      0.82      0.85      1028\n",
            "        8.0       0.77      0.86      0.81       974\n",
            "        9.0       0.80      0.75      0.77      1009\n",
            "\n",
            "avg / total       0.83      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 936    0    2    1    0   11   11    1   17    1]\n",
            " [   0 1120    1    5    0    2    3    0    4    0]\n",
            " [  35   61  812   10   10    8   16   24   36   20]\n",
            " [   7    4   33  874    0   19    0   11   52   10]\n",
            " [   5   16    5    4  809   28   20    6   21   68]\n",
            " [  34   15    3  205    3  539    9    4   74    6]\n",
            " [  76   11   18    0   19   31  794    0    9    0]\n",
            " [   8   38   27    5   16    3    0  844    8   79]\n",
            " [  15   25   18   27    8   23    9    7  835    7]\n",
            " [  22   12    2   15   90   33    2   50   27  756]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 8. ... 7. 9. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 8 ... 7 9 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [62 51 53 56 47 44 46 40 53 48] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.480 s \n",
            "\n",
            "Accuracy rate for 88.150000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.98      0.92       980\n",
            "        1.0       0.91      0.99      0.94      1135\n",
            "        2.0       0.91      0.87      0.89      1032\n",
            "        3.0       0.81      0.91      0.86      1010\n",
            "        4.0       0.88      0.86      0.87       982\n",
            "        5.0       0.88      0.74      0.80       892\n",
            "        6.0       0.94      0.89      0.91       958\n",
            "        7.0       0.90      0.85      0.88      1028\n",
            "        8.0       0.91      0.83      0.87       974\n",
            "        9.0       0.83      0.86      0.85      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 962    0    0    1    0    6    5    1    5    0]\n",
            " [   0 1119    2    5    0    1    3    2    3    0]\n",
            " [  27   31  894    7   12    5   10   25   14    7]\n",
            " [  11    4   15  922    0   15    1   17   17    8]\n",
            " [   2    9    4    1  847    8   15    3    9   84]\n",
            " [  34   12    0  139    4  658   13   10   12   10]\n",
            " [  43    6    3    1   28   23  853    0    1    0]\n",
            " [   7   28   40    2   11    0    1  877    6   56]\n",
            " [  12   18   18   48   14   19    8   10  811   16]\n",
            " [  13    9    4   16   43   11    3   27   11  872]]\n",
            "--------------------------------\n",
            "final active learning accuracies [83.19, 88.14999999999999]\n",
            "saved Active-learning-experiment-16.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-10.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 17, using model = RfModel, selection_function = RandomSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [12 18 11 11 11  7 11 12 13 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.831 s \n",
            "\n",
            "Accuracy rate for 71.500000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.74      0.97      0.84       980\n",
            "        1.0       0.72      0.99      0.84      1135\n",
            "        2.0       0.88      0.58      0.70      1032\n",
            "        3.0       0.77      0.79      0.78      1010\n",
            "        4.0       0.71      0.49      0.58       982\n",
            "        5.0       0.90      0.17      0.28       892\n",
            "        6.0       0.83      0.80      0.81       958\n",
            "        7.0       0.92      0.70      0.80      1028\n",
            "        8.0       0.77      0.66      0.71       974\n",
            "        9.0       0.45      0.91      0.60      1009\n",
            "\n",
            "avg / total       0.77      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    1    1    2    3    0    8    0    5    8]\n",
            " [   0 1127    1    2    0    0    3    0    0    2]\n",
            " [  64  108  599   32   29    2   60   27   51   60]\n",
            " [  52   23   17  795    0    9    1   12   40   61]\n",
            " [   3   28    0    1  478    0   27    1    6  438]\n",
            " [ 105   65   12  147   18  149   34    4   58  300]\n",
            " [  53   24    7    3   94    3  762    0   10    2]\n",
            " [  18   84    3    1   20    0    3  721   13  165]\n",
            " [  22   84   44   36    6    2   14    8  646  112]\n",
            " [  11   18    0   10   27    0    5   12    5  921]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59875, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [25 29 25 18 21 25 29 22 23 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.734 s \n",
            "\n",
            "Accuracy rate for 82.390000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.86      0.96      0.91       980\n",
            "        1.0       0.86      0.99      0.92      1135\n",
            "        2.0       0.89      0.78      0.83      1032\n",
            "        3.0       0.91      0.75      0.82      1010\n",
            "        4.0       0.86      0.62      0.72       982\n",
            "        5.0       0.74      0.77      0.76       892\n",
            "        6.0       0.81      0.91      0.85       958\n",
            "        7.0       0.95      0.79      0.87      1028\n",
            "        8.0       0.89      0.71      0.79       974\n",
            "        9.0       0.62      0.92      0.74      1009\n",
            "\n",
            "avg / total       0.84      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    1    2    0    1    9   18    0    5    1]\n",
            " [   0 1122    2    2    0    3    3    0    2    1]\n",
            " [  43   26  807   12   17   11   59   14   27   16]\n",
            " [  33    8   16  759    2  117    3    8   23   41]\n",
            " [   0   16    1    0  612   12   64    0    5  272]\n",
            " [  41    6    6   23    7  686   26    6    9   82]\n",
            " [  17    4    5    0   39   25  868    0    0    0]\n",
            " [   3   68   24    0   11    4    1  816   12   89]\n",
            " [  13   42   48   35    6   41   22    4  696   67]\n",
            " [   9   18    0    2   16   13    9    7    5  930]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [36 45 41 28 32 41 41 33 35 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.208 s \n",
            "\n",
            "Accuracy rate for 85.760000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.86      0.97      0.92       980\n",
            "        1.0       0.87      0.99      0.93      1135\n",
            "        2.0       0.89      0.85      0.87      1032\n",
            "        3.0       0.88      0.80      0.84      1010\n",
            "        4.0       0.92      0.72      0.81       982\n",
            "        5.0       0.82      0.83      0.82       892\n",
            "        6.0       0.84      0.94      0.89       958\n",
            "        7.0       0.93      0.82      0.87      1028\n",
            "        8.0       0.92      0.74      0.82       974\n",
            "        9.0       0.71      0.90      0.79      1009\n",
            "\n",
            "avg / total       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 955    1    0    0    0    8   10    0    4    2]\n",
            " [   0 1128    1    1    0    1    4    0    0    0]\n",
            " [  29   29  878   12   11    9   24   17   15    8]\n",
            " [  32    8   25  806    0   71    5   11   23   29]\n",
            " [   0   12    3    1  703    5   61    1    6  190]\n",
            " [  49    6    4   41    3  737   28    4    6   14]\n",
            " [  17    5    5    0   11   21  898    0    1    0]\n",
            " [   2   62   40    1   13    2    1  842    5   60]\n",
            " [  10   35   27   41    7   42   23    4  722   63]\n",
            " [  13   16    6    8   16    7   10   22    4  907]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59625, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [55 57 49 41 43 51 52 47 49 56] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.583 s \n",
            "\n",
            "Accuracy rate for 87.560000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.98      0.92       980\n",
            "        1.0       0.89      0.99      0.94      1135\n",
            "        2.0       0.91      0.86      0.88      1032\n",
            "        3.0       0.90      0.83      0.87      1010\n",
            "        4.0       0.92      0.76      0.83       982\n",
            "        5.0       0.84      0.84      0.84       892\n",
            "        6.0       0.85      0.95      0.89       958\n",
            "        7.0       0.93      0.85      0.89      1028\n",
            "        8.0       0.93      0.79      0.86       974\n",
            "        9.0       0.76      0.90      0.82      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 957    1    0    0    0    7    9    2    4    0]\n",
            " [   0 1124    2    2    0    1    5    0    1    0]\n",
            " [  30   26  883   10   14    9   21   18   16    5]\n",
            " [  19    8   22  839    1   62    4   11   22   22]\n",
            " [   1   11    2    0  747    5   58    2    3  153]\n",
            " [  38    5    1   46    3  752   29    5    7    6]\n",
            " [  24    4    5    0    8   10  907    0    0    0]\n",
            " [   5   54   35    1    9    1    1  869    5   48]\n",
            " [  10   23   19   25    7   36   30    4  774   46]\n",
            " [  12   11    6    6   26   13    8   19    4  904]]\n",
            "--------------------------------\n",
            "final active learning accuracies [71.5, 82.39, 85.76, 87.56]\n",
            "saved Active-learning-experiment-17.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 18, using model = RfModel, selection_function = RandomSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [2 7 4 5 5 8 4 7 1 7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.798 s \n",
            "\n",
            "Accuracy rate for 56.860000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.44      0.59       980\n",
            "        1.0       0.58      0.99      0.73      1135\n",
            "        2.0       0.84      0.46      0.60      1032\n",
            "        3.0       0.61      0.49      0.55      1010\n",
            "        4.0       0.72      0.41      0.52       982\n",
            "        5.0       0.35      0.69      0.47       892\n",
            "        6.0       0.66      0.73      0.69       958\n",
            "        7.0       0.61      0.71      0.66      1028\n",
            "        8.0       0.31      0.03      0.06       974\n",
            "        9.0       0.44      0.67      0.53      1009\n",
            "\n",
            "avg / total       0.60      0.57      0.54     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 429   11    5   15    0  273   98  102   38    9]\n",
            " [   0 1127    0    1    0    2    2    3    0    0]\n",
            " [   3  214  478   42    1   23  143   68   15   45]\n",
            " [   2  155   12  496    0  250   19   42    0   34]\n",
            " [   2   27    6    6  404   66   25   77   19  350]\n",
            " [   7   76    2   94    2  616   20   19    1   55]\n",
            " [  12   43   55    1   12  100  698   19    0   18]\n",
            " [   2   68    9    1    3   11    1  733    0  200]\n",
            " [  18  193    1  137   15  348   54   23   34  151]\n",
            " [  10   22    3   17  125   48    3  106    4  671]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 5. 6. ... 9. 9. 9.]\n",
            "probabilities: (59950, 10) \n",
            " [0 5 6 ... 9 9 9]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 9 11 10 14  7 16  6 12  4 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.595 s \n",
            "\n",
            "Accuracy rate for 69.430000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.72      0.88      0.79       980\n",
            "        1.0       0.78      0.99      0.88      1135\n",
            "        2.0       0.87      0.72      0.79      1032\n",
            "        3.0       0.64      0.82      0.72      1010\n",
            "        4.0       0.87      0.47      0.61       982\n",
            "        5.0       0.46      0.77      0.57       892\n",
            "        6.0       0.91      0.47      0.62       958\n",
            "        7.0       0.77      0.86      0.81      1028\n",
            "        8.0       0.95      0.10      0.18       974\n",
            "        9.0       0.56      0.81      0.66      1009\n",
            "\n",
            "avg / total       0.76      0.69      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 861    1    4    8    0   88   13    4    0    1]\n",
            " [   0 1124    1    4    0    5    0    0    0    1]\n",
            " [  23   81  746   74    5   23    8   29    5   38]\n",
            " [   2   22   23  827    0  107    0   19    0   10]\n",
            " [  20   16    8   11  459   37   10   73    0  348]\n",
            " [  32   30    5   94    2  684    3   22    0   20]\n",
            " [ 223   10   28    4   36  187  447   11    0   12]\n",
            " [   5   45   24    6    1    2    0  885    0   60]\n",
            " [  13   90   16  257    5  326    9   16   97  145]\n",
            " [  25   14    4   15   18   34    0   86    0  813]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 6. ... 9. 9. 5.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 6 ... 9 9 5]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [13 17 14 19 10 22 10 18  7 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.084 s \n",
            "\n",
            "Accuracy rate for 71.870000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.81      0.94      0.87       980\n",
            "        1.0       0.76      0.99      0.86      1135\n",
            "        2.0       0.90      0.73      0.81      1032\n",
            "        3.0       0.67      0.79      0.73      1010\n",
            "        4.0       0.86      0.40      0.55       982\n",
            "        5.0       0.54      0.75      0.63       892\n",
            "        6.0       0.96      0.61      0.75       958\n",
            "        7.0       0.73      0.86      0.79      1028\n",
            "        8.0       0.96      0.22      0.36       974\n",
            "        9.0       0.52      0.83      0.64      1009\n",
            "\n",
            "avg / total       0.77      0.72      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 924    1    3    4    0   37    5    4    1    1]\n",
            " [   0 1125    2    5    0    3    0    0    0    0]\n",
            " [  26   84  756   46    3    9    6   51    5   46]\n",
            " [   9   27   14  802    0  122    1   21    1   13]\n",
            " [   4   26    2    5  394   26    8   63    0  454]\n",
            " [  30   40    3   77    2  668    2   31    0   39]\n",
            " [ 107   14   27    5   42  134  584   24    1   20]\n",
            " [   8   41   14    6    2    3    0  882    0   72]\n",
            " [   8  105   19  238    9  210    3   40  213  129]\n",
            " [  18   17    1    8    5   29    0   92    0  839]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 6. ... 7. 9. 7.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 6 ... 7 9 7]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [21 25 16 22 16 30 14 23  8 25] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.410 s \n",
            "\n",
            "Accuracy rate for 75.680000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.96      0.86       980\n",
            "        1.0       0.79      0.99      0.88      1135\n",
            "        2.0       0.92      0.74      0.82      1032\n",
            "        3.0       0.71      0.78      0.74      1010\n",
            "        4.0       0.89      0.57      0.70       982\n",
            "        5.0       0.56      0.82      0.66       892\n",
            "        6.0       0.96      0.71      0.82       958\n",
            "        7.0       0.82      0.85      0.84      1028\n",
            "        8.0       0.98      0.22      0.36       974\n",
            "        9.0       0.59      0.87      0.71      1009\n",
            "\n",
            "avg / total       0.80      0.76      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    1    0    0    0   32    4    1    0    2]\n",
            " [   0 1123    2    4    0    6    0    0    0    0]\n",
            " [  34   83  763   46    3   17    6   41    4   35]\n",
            " [  18   20   15  792    0  121    0   26    0   18]\n",
            " [  14   15    3    1  564   41   10   35    0  299]\n",
            " [  35   19    2   62    2  730    4   11    0   27]\n",
            " [ 114    6    9    3   45   86  684    9    0    2]\n",
            " [   8   35   16    4    1    9    0  877    0   78]\n",
            " [  17  107   15  200   12  236    7   22  214  144]\n",
            " [  19   17    1    8    9   30    0   44    0  881]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 0. ... 7. 9. 7.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 7 9 7]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [24 28 18 28 22 33 22 31 13 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.634 s \n",
            "\n",
            "Accuracy rate for 80.010000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.96      0.90       980\n",
            "        1.0       0.82      0.99      0.90      1135\n",
            "        2.0       0.97      0.71      0.82      1032\n",
            "        3.0       0.77      0.80      0.79      1010\n",
            "        4.0       0.86      0.65      0.74       982\n",
            "        5.0       0.62      0.83      0.71       892\n",
            "        6.0       0.90      0.83      0.86       958\n",
            "        7.0       0.84      0.88      0.86      1028\n",
            "        8.0       0.95      0.45      0.61       974\n",
            "        9.0       0.65      0.88      0.75      1009\n",
            "\n",
            "avg / total       0.82      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    1    0    0    0   27   13    1    1    0]\n",
            " [   0 1122    1    3    0    5    2    0    1    1]\n",
            " [  38   74  731   51    9   18   17   46   12   36]\n",
            " [  14   20    8  812    0  100    2   20    8   26]\n",
            " [  11   12    0    0  642   22   26   39    0  230]\n",
            " [  31   13    0   61    5  742    5   10    2   23]\n",
            " [  47    4    4    1   47   53  793    8    0    1]\n",
            " [   7   34   10    6    3    8    0  903    0   57]\n",
            " [  10   71    1  113   14  194   19   11  434  107]\n",
            " [  18    9    0   10   28   24    0   34    1  885]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 6. ... 7. 9. 5.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 6 ... 7 9 5]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [30 34 26 31 24 35 27 38 19 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.861 s \n",
            "\n",
            "Accuracy rate for 82.060000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.96      0.89       980\n",
            "        1.0       0.83      0.99      0.90      1135\n",
            "        2.0       0.91      0.74      0.82      1032\n",
            "        3.0       0.80      0.84      0.82      1010\n",
            "        4.0       0.90      0.62      0.73       982\n",
            "        5.0       0.74      0.82      0.78       892\n",
            "        6.0       0.89      0.86      0.88       958\n",
            "        7.0       0.89      0.87      0.88      1028\n",
            "        8.0       0.93      0.58      0.71       974\n",
            "        9.0       0.63      0.90      0.75      1009\n",
            "\n",
            "avg / total       0.84      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    1    1    1    0   18   17    1    4    0]\n",
            " [   0 1122    1    5    0    3    2    0    1    1]\n",
            " [  27   88  760   39    7   11   21   29   18   32]\n",
            " [  10   10   16  849    0   71    1   11    8   34]\n",
            " [  16   10    2    0  609   14   25   27    0  279]\n",
            " [  31   11    2   59    4  730   11    7    7   30]\n",
            " [  63    3    3    1   24   31  823    6    0    4]\n",
            " [   9   39   23    4    2    6    1  899    1   44]\n",
            " [   6   63   20   91    8   86   22   11  564  103]\n",
            " [  15    7    3    9   24   17    0   18    3  913]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [32 38 29 38 32 37 33 46 25 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.104 s \n",
            "\n",
            "Accuracy rate for 84.500000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.95      0.91       980\n",
            "        1.0       0.86      0.99      0.92      1135\n",
            "        2.0       0.93      0.78      0.85      1032\n",
            "        3.0       0.81      0.86      0.83      1010\n",
            "        4.0       0.85      0.78      0.81       982\n",
            "        5.0       0.79      0.77      0.78       892\n",
            "        6.0       0.86      0.88      0.87       958\n",
            "        7.0       0.89      0.89      0.89      1028\n",
            "        8.0       0.91      0.63      0.75       974\n",
            "        9.0       0.72      0.89      0.79      1009\n",
            "\n",
            "avg / total       0.85      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 933    1    0    0    0   13   24    1    8    0]\n",
            " [   0 1121    3    2    0    4    2    0    0    3]\n",
            " [  25   46  809   23    8    5   23   36   24   33]\n",
            " [   7    8   18  865    1   52    6   17   10   26]\n",
            " [   8   12    4    0  765    8   28    6    1  150]\n",
            " [  23   13    2   83   10  688   15   13   10   35]\n",
            " [  50    5    1    1   43   13  839    4    1    1]\n",
            " [   3   38   18    7    4    7    0  916    1   34]\n",
            " [   5   52   15   69   26   65   36   15  615   76]\n",
            " [  11    9    0   12   40   13    0   20    5  899]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 8. ... 7. 9. 9.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 8 ... 7 9 9]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [37 45 32 43 38 41 38 54 30 42] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.404 s \n",
            "\n",
            "Accuracy rate for 85.920000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.95      0.92       980\n",
            "        1.0       0.88      0.99      0.93      1135\n",
            "        2.0       0.94      0.80      0.86      1032\n",
            "        3.0       0.81      0.87      0.84      1010\n",
            "        4.0       0.85      0.81      0.83       982\n",
            "        5.0       0.83      0.75      0.79       892\n",
            "        6.0       0.87      0.91      0.89       958\n",
            "        7.0       0.88      0.92      0.90      1028\n",
            "        8.0       0.92      0.69      0.79       974\n",
            "        9.0       0.75      0.88      0.81      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 929    1    1    0    0   15   23    1    9    1]\n",
            " [   0 1122    3    4    0    2    3    1    0    0]\n",
            " [  20   33  821   18   12    5   25   43   27   28]\n",
            " [   8   12   15  876    1   41    4   23    8   22]\n",
            " [   8   13    2    2  796    2   31    3    2  123]\n",
            " [  22   15    1   92   11  669   17   21    8   36]\n",
            " [  33    5    0    1   29   11  874    4    1    0]\n",
            " [   2   23   18    5    3    2    1  949    1   24]\n",
            " [   5   42    9   67   25   51   28   20  671   56]\n",
            " [  13    9    2   13   56   10    0   17    4  885]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59600,) [0. 0. 8. ... 7. 9. 9.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 8 ... 7 9 9]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [41 49 37 50 44 45 40 62 34 48] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.552 s \n",
            "\n",
            "Accuracy rate for 86.760000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.96      0.93       980\n",
            "        1.0       0.89      0.99      0.93      1135\n",
            "        2.0       0.94      0.82      0.87      1032\n",
            "        3.0       0.84      0.88      0.86      1010\n",
            "        4.0       0.86      0.79      0.82       982\n",
            "        5.0       0.86      0.79      0.82       892\n",
            "        6.0       0.88      0.89      0.89       958\n",
            "        7.0       0.88      0.92      0.90      1028\n",
            "        8.0       0.94      0.72      0.81       974\n",
            "        9.0       0.74      0.89      0.81      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    1    1    0    0   10   21    2    4    0]\n",
            " [   0 1120    2    4    0    3    3    1    2    0]\n",
            " [  17   32  843   18    9    5   21   39   18   30]\n",
            " [   9    9   18  891    2   28    4   21    9   19]\n",
            " [   5    8    2    1  776    3   28    4    3  152]\n",
            " [  24   16    1   63   10  705   15   19    6   33]\n",
            " [  38    5    1    2   34   17  857    3    0    1]\n",
            " [   1   25   18    6    1    3    1  947    2   24]\n",
            " [   6   38   10   65   28   35   21   21  702   48]\n",
            " [  12    9    0   12   43   15    0   21    3  894]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 8. ... 7. 9. 9.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 8 ... 7 9 9]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [50 53 42 58 47 48 52 65 35 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.639 s \n",
            "\n",
            "Accuracy rate for 87.320000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.97      0.93       980\n",
            "        1.0       0.89      0.99      0.94      1135\n",
            "        2.0       0.93      0.82      0.87      1032\n",
            "        3.0       0.82      0.90      0.86      1010\n",
            "        4.0       0.86      0.82      0.84       982\n",
            "        5.0       0.88      0.78      0.83       892\n",
            "        6.0       0.87      0.92      0.89       958\n",
            "        7.0       0.88      0.92      0.90      1028\n",
            "        8.0       0.95      0.72      0.82       974\n",
            "        9.0       0.79      0.88      0.83      1009\n",
            "\n",
            "avg / total       0.88      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 948    1    1    0    0    7   18    1    4    0]\n",
            " [   0 1125    1    3    0    2    3    1    0    0]\n",
            " [  21   27  842   16    9    4   32   38   20   23]\n",
            " [  10    8   19  909    1   19    5   20    5   14]\n",
            " [   5    9    3    0  807    5   32    5    1  115]\n",
            " [  27   15    1   79   12  696   14   18    5   25]\n",
            " [  29    5    1    0   36    7  879    1    0    0]\n",
            " [   2   24   21    7    3    3    0  946    0   22]\n",
            " [   5   36   11   75   27   34   27   22  697   40]\n",
            " [  12    9    1   14   47   14    2   25    2  883]]\n",
            "--------------------------------\n",
            "final active learning accuracies [56.86, 69.43, 71.87, 75.68, 80.01, 82.06, 84.5, 85.92, 86.76, 87.32]\n",
            "saved Active-learning-experiment-18.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 19, using model = RfModel, selection_function = RandomSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [3 1 3 3 3 3 4 3 0 2] [0 1 2 3 4 5 6 7 9]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n",
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.688 s \n",
            "\n",
            "Accuracy rate for 51.640000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.77      0.68      0.72       980\n",
            "        1.0       0.90      0.55      0.69      1135\n",
            "        2.0       0.73      0.38      0.50      1032\n",
            "        3.0       0.47      0.69      0.56      1010\n",
            "        4.0       0.56      0.71      0.63       982\n",
            "        5.0       0.27      0.19      0.22       892\n",
            "        6.0       0.45      0.85      0.59       958\n",
            "        7.0       0.36      0.71      0.48      1028\n",
            "        8.0       0.00      0.00      0.00       974\n",
            "        9.0       0.50      0.36      0.42      1009\n",
            "\n",
            "avg / total       0.51      0.52      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[664   0   6  60   1   7 236   6   0   0]\n",
            " [  0 628   6  96   3 140   5 257   0   0]\n",
            " [ 72  14 397  22  49  71 209 188   0  10]\n",
            " [ 18   4   8 696  18  94  92  72   0   8]\n",
            " [  9   2   4  10 701   4  58 107   0  87]\n",
            " [ 14   3   7 335  44 167 106 182   0  34]\n",
            " [ 32   2   4   1  63  21 814  21   0   0]\n",
            " [ 24   7   3  30  59   5   3 734   0 163]\n",
            " [  8  32  99 178  47 118 252 178   0  62]\n",
            " [ 17   3  11  61 263   1  24 266   0 363]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59975,) [0. 0. 6. ... 7. 7. 7.]\n",
            "probabilities: (59975, 9) \n",
            " [0 0 6 ... 7 7 7]\n",
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [5 6 4 4 4 6 7 6 2 6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.729 s \n",
            "\n",
            "Accuracy rate for 60.720000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.77      0.66      0.71       980\n",
            "        1.0       0.69      0.97      0.81      1135\n",
            "        2.0       0.87      0.40      0.55      1032\n",
            "        3.0       0.73      0.48      0.58      1010\n",
            "        4.0       0.81      0.48      0.60       982\n",
            "        5.0       0.40      0.59      0.48       892\n",
            "        6.0       0.58      0.84      0.69       958\n",
            "        7.0       0.53      0.82      0.64      1028\n",
            "        8.0       0.89      0.08      0.15       974\n",
            "        9.0       0.48      0.70      0.57      1009\n",
            "\n",
            "avg / total       0.68      0.61      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 648    0    1   14    0   89  185   19    0   24]\n",
            " [   0 1098    1    0    0   16    3   17    0    0]\n",
            " [  55  157  411    2   31   39   71  169    0   97]\n",
            " [  19   44   10  484    5  260   58   89    9   32]\n",
            " [  10   15    0    1  473   11   43   66    0  363]\n",
            " [  11   30    1  124   12  526   74   84    1   29]\n",
            " [  53   24    2    0   19   29  802   28    0    1]\n",
            " [  24   39    2    2    9    5    1  846    0  100]\n",
            " [  10  160   43   29    6  305  134   75   78  134]\n",
            " [  16   13    0    9   30   24    3  208    0  706]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 6. ... 7. 7. 7.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 6 ... 7 7 7]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [ 8 10  5  6  6  8 12  9  2  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.107 s \n",
            "\n",
            "Accuracy rate for 65.450000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.88      0.83       980\n",
            "        1.0       0.68      0.98      0.81      1135\n",
            "        2.0       0.90      0.44      0.59      1032\n",
            "        3.0       0.75      0.65      0.70      1010\n",
            "        4.0       0.71      0.52      0.60       982\n",
            "        5.0       0.51      0.56      0.53       892\n",
            "        6.0       0.63      0.81      0.71       958\n",
            "        7.0       0.63      0.84      0.72      1028\n",
            "        8.0       0.93      0.04      0.08       974\n",
            "        9.0       0.50      0.77      0.60      1009\n",
            "\n",
            "avg / total       0.71      0.65      0.62     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 861    1    0    0    1   41   69    4    0    3]\n",
            " [   0 1111    0    0    0    0    5   19    0    0]\n",
            " [  54  183  452    6   35   19   84  159    0   40]\n",
            " [  42   20    6  653    3  172   37   54    2   21]\n",
            " [   1   18    1    3  509    4   31   28    0  387]\n",
            " [  32   40    1  105   36  500   60   38    1   79]\n",
            " [  39   31    0    0   62   33  774   18    0    1]\n",
            " [  27   40    3    2   30    0    2  865    0   59]\n",
            " [  11  176   37   77   19  208  159   44   41  202]\n",
            " [  21    4    1   22   24   11    5  142    0  779]]\n",
            "--------------------------------\n",
            "val predicted: (59925,) [0. 0. 6. ... 7. 7. 7.]\n",
            "probabilities: (59925, 10) \n",
            " [0 0 6 ... 7 7 7]\n",
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 9 15  7  8  8 12 15 13  3 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.413 s \n",
            "\n",
            "Accuracy rate for 70.290000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.85      0.88       980\n",
            "        1.0       0.68      0.97      0.80      1135\n",
            "        2.0       0.88      0.51      0.64      1032\n",
            "        3.0       0.81      0.71      0.75      1010\n",
            "        4.0       0.82      0.61      0.70       982\n",
            "        5.0       0.53      0.69      0.60       892\n",
            "        6.0       0.66      0.89      0.75       958\n",
            "        7.0       0.65      0.91      0.76      1028\n",
            "        8.0       0.98      0.13      0.22       974\n",
            "        9.0       0.60      0.73      0.66      1009\n",
            "\n",
            "avg / total       0.75      0.70      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 832    1    0    0    0   45   85   15    0    2]\n",
            " [   0 1100    0    7    0    0    3   25    0    0]\n",
            " [  39  173  524    7   22   21  138   87    1   20]\n",
            " [  13   27   16  717    2  148   23   49    1   14]\n",
            " [   0   16    0    8  598   17   34   44    0  265]\n",
            " [   9   24    0   65   26  618   44   52    1   53]\n",
            " [   3   29    0    0   39   28  848   11    0    0]\n",
            " [   2   43    7    0    6    5    2  934    0   29]\n",
            " [   6  208   47   69    8  251  110   46  123  106]\n",
            " [   9    7    3   17   24   31    6  177    0  735]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 6. ... 7. 7. 7.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 6 ... 7 7 7]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [11 16  9  9 14 15 17 14  5 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.751 s \n",
            "\n",
            "Accuracy rate for 72.940000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.85      0.86       980\n",
            "        1.0       0.71      0.99      0.83      1135\n",
            "        2.0       0.92      0.52      0.67      1032\n",
            "        3.0       0.84      0.69      0.76      1010\n",
            "        4.0       0.74      0.67      0.70       982\n",
            "        5.0       0.55      0.77      0.64       892\n",
            "        6.0       0.71      0.86      0.78       958\n",
            "        7.0       0.82      0.84      0.83      1028\n",
            "        8.0       0.86      0.21      0.34       974\n",
            "        9.0       0.59      0.86      0.70      1009\n",
            "\n",
            "avg / total       0.76      0.73      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 832    2    3    0    1   53   75    6    1    7]\n",
            " [   0 1120    1    1    0    0    4    9    0    0]\n",
            " [  49  168  541   14   33   21  110   58    6   32]\n",
            " [  20   29   12  701    4  138   29   26   22   29]\n",
            " [   0   11    0    0  654    5   14    8    0  290]\n",
            " [   9   13    1   49   38  687   44   19    3   29]\n",
            " [   6   22    1    0   71   34  822    2    0    0]\n",
            " [   3   43    8    0   21    7    1  868    1   76]\n",
            " [  20  154   17   63   20  287   54   22  203  134]\n",
            " [  12   13    4    8   42   15    2   47    0  866]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) [0. 0. 5. ... 9. 5. 7.]\n",
            "probabilities: (59875, 10) \n",
            " [0 0 5 ... 9 5 7]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [13 21 13 12 17 18 17 16  6 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.991 s \n",
            "\n",
            "Accuracy rate for 76.080000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.88      0.89       980\n",
            "        1.0       0.73      0.99      0.84      1135\n",
            "        2.0       0.87      0.62      0.72      1032\n",
            "        3.0       0.78      0.78      0.78      1010\n",
            "        4.0       0.75      0.79      0.77       982\n",
            "        5.0       0.58      0.79      0.67       892\n",
            "        6.0       0.76      0.82      0.79       958\n",
            "        7.0       0.85      0.83      0.84      1028\n",
            "        8.0       0.94      0.23      0.36       974\n",
            "        9.0       0.69      0.84      0.76      1009\n",
            "\n",
            "avg / total       0.79      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 860    1    0    0    2   68   45    1    1    2]\n",
            " [   0 1125    2    1    0    0    3    3    1    0]\n",
            " [  30  159  637   20   30   16   72   55    1   12]\n",
            " [  12   17   16  791    5   98   18   29   12   12]\n",
            " [   0   10    1    2  778    5   11    6    0  169]\n",
            " [  10   22    2   81   24  702   36    7    0    8]\n",
            " [   8   20    1    0   91   52  785    1    0    0]\n",
            " [   7   49   17    0   21    7    1  858    0   68]\n",
            " [  11  130   54  113   27  241   55   15  220  108]\n",
            " [  14   14    1    8   53   30    2   35    0  852]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 5. ... 9. 5. 9.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 5 ... 9 5 9]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [16 25 13 15 22 19 21 18  8 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.146 s \n",
            "\n",
            "Accuracy rate for 77.510000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.91      0.89       980\n",
            "        1.0       0.74      0.99      0.85      1135\n",
            "        2.0       0.90      0.56      0.69      1032\n",
            "        3.0       0.74      0.84      0.79      1010\n",
            "        4.0       0.72      0.84      0.78       982\n",
            "        5.0       0.68      0.72      0.70       892\n",
            "        6.0       0.75      0.86      0.81       958\n",
            "        7.0       0.84      0.85      0.84      1028\n",
            "        8.0       0.98      0.34      0.51       974\n",
            "        9.0       0.72      0.79      0.76      1009\n",
            "\n",
            "avg / total       0.80      0.78      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 891    1    0    0    2   43   40    2    0    1]\n",
            " [   0 1124    0    2    0    0    4    5    0    0]\n",
            " [  47  157  580   26   28   13  104   64    4    9]\n",
            " [  13   19   11  852    8   51   15   25    1   15]\n",
            " [   0   10    1    1  827    6   12    5    0  120]\n",
            " [  15   19    2  124   28  645   40    8    1   10]\n",
            " [  15   15    1    0   67   31  828    1    0    0]\n",
            " [   6   39   16    1   29    6    2  869    0   60]\n",
            " [  16  121   36  130   44  135   50   18  333   91]\n",
            " [  15   11    1   10  118   15    3   34    0  802]]\n",
            "--------------------------------\n",
            "val predicted: (59825,) [0. 0. 6. ... 9. 9. 7.]\n",
            "probabilities: (59825, 10) \n",
            " [0 0 6 ... 9 9 7]\n",
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [16 28 13 20 26 22 21 26  9 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.304 s \n",
            "\n",
            "Accuracy rate for 77.780000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.91      0.90       980\n",
            "        1.0       0.76      0.98      0.85      1135\n",
            "        2.0       0.91      0.54      0.68      1032\n",
            "        3.0       0.70      0.87      0.78      1010\n",
            "        4.0       0.67      0.91      0.77       982\n",
            "        5.0       0.69      0.70      0.70       892\n",
            "        6.0       0.79      0.87      0.83       958\n",
            "        7.0       0.80      0.90      0.85      1028\n",
            "        8.0       0.97      0.41      0.58       974\n",
            "        9.0       0.83      0.65      0.73      1009\n",
            "\n",
            "avg / total       0.80      0.78      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 892    1    0    0    1   51   34    1    0    0]\n",
            " [   0 1117    1    5    0    2    3    6    1    0]\n",
            " [  50  147  562   27   44   15   91   83   10    3]\n",
            " [   9   20    9  881    7   39    7   31    0    7]\n",
            " [   1    6    1    3  896    7   13    9    0   46]\n",
            " [  10   11    2  177   28  626   28    6    0    4]\n",
            " [  15   14    0    0   56   39  832    2    0    0]\n",
            " [   3   32   14    2   23    5    1  922    1   25]\n",
            " [  15  119   28  141   48   98   42   38  398   47]\n",
            " [   9   11    1   20  239   22    3   52    0  652]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 6. ... 9. 7. 7.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 6 ... 9 7 7]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [19 31 15 23 28 24 21 30 15 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.504 s \n",
            "\n",
            "Accuracy rate for 79.350000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.92      0.90       980\n",
            "        1.0       0.79      0.99      0.88      1135\n",
            "        2.0       0.94      0.57      0.71      1032\n",
            "        3.0       0.72      0.85      0.78      1010\n",
            "        4.0       0.64      0.92      0.75       982\n",
            "        5.0       0.72      0.76      0.74       892\n",
            "        6.0       0.85      0.84      0.84       958\n",
            "        7.0       0.83      0.90      0.86      1028\n",
            "        8.0       0.90      0.57      0.69       974\n",
            "        9.0       0.87      0.61      0.72      1009\n",
            "\n",
            "avg / total       0.81      0.79      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 900    1    0    2    3   39   30    2    3    0]\n",
            " [   0 1120    0    4    1    1    3    3    3    0]\n",
            " [  48  134  586   50   52   12   51   65   32    2]\n",
            " [   8   23    9  861    6   54    4   29   11    5]\n",
            " [   0    4    1    3  904    8   10    7    1   44]\n",
            " [   8   14    2  137   26  676   23    4    2    0]\n",
            " [  17   10    2    1   80   43  802    3    0    0]\n",
            " [   4   31   15    1   24    6    1  921    7   18]\n",
            " [  18   73    9  133   51   71   23   24  552   20]\n",
            " [  18   14    0   12  271   23    2   51    5  613]]\n",
            "--------------------------------\n",
            "val predicted: (59775,) [0. 0. 3. ... 7. 5. 7.]\n",
            "probabilities: (59775, 10) \n",
            " [0 0 3 ... 7 5 7]\n",
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [21 33 16 23 31 26 26 35 16 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.644 s \n",
            "\n",
            "Accuracy rate for 80.390000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.92      0.89       980\n",
            "        1.0       0.81      0.98      0.89      1135\n",
            "        2.0       0.94      0.55      0.69      1032\n",
            "        3.0       0.72      0.85      0.78      1010\n",
            "        4.0       0.72      0.92      0.81       982\n",
            "        5.0       0.74      0.73      0.74       892\n",
            "        6.0       0.82      0.90      0.86       958\n",
            "        7.0       0.79      0.90      0.84      1028\n",
            "        8.0       0.90      0.57      0.70       974\n",
            "        9.0       0.87      0.68      0.77      1009\n",
            "\n",
            "avg / total       0.82      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 897    1    0    1    3   31   44    2    1    0]\n",
            " [   0 1117    1    3    0    1    3    5    5    0]\n",
            " [  51  127  564   48   55   15   58   79   31    4]\n",
            " [   8   13    7  856    7   63    5   33   10    8]\n",
            " [   1    4    1    0  906    8   13   11    0   38]\n",
            " [   8   13    2  156   21  655   29    6    0    2]\n",
            " [  20    7    1    0   46   15  866    3    0    0]\n",
            " [  10   25   13    1   18    5    1  930    8   17]\n",
            " [  17   66    8  121   37   65   36   32  560   32]\n",
            " [  19   11    1   10  170   24    5   74    7  688]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59750,) [0. 0. 6. ... 7. 5. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 6 ... 7 5 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [26 36 18 27 31 29 27 38 17 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.779 s \n",
            "\n",
            "Accuracy rate for 81.600000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.91      0.90       980\n",
            "        1.0       0.81      0.98      0.89      1135\n",
            "        2.0       0.94      0.56      0.70      1032\n",
            "        3.0       0.71      0.87      0.78      1010\n",
            "        4.0       0.74      0.90      0.81       982\n",
            "        5.0       0.78      0.75      0.77       892\n",
            "        6.0       0.83      0.91      0.87       958\n",
            "        7.0       0.82      0.92      0.87      1028\n",
            "        8.0       0.90      0.59      0.71       974\n",
            "        9.0       0.86      0.75      0.80      1009\n",
            "\n",
            "avg / total       0.83      0.82      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 889    1    0    6    3   25   49    5    2    0]\n",
            " [   0 1113    0    3    1    3    3    7    5    0]\n",
            " [  48  127  578   62   43   14   51   76   31    2]\n",
            " [   6   10   10  874    5   53    2   31   11    8]\n",
            " [   1    7    1    1  887    6   10    4    1   64]\n",
            " [   6   12    2  144   27  673   22    5    0    1]\n",
            " [  15    8    1    0   53   10  868    3    0    0]\n",
            " [   4   26   15    1    9    5    1  945    7   15]\n",
            " [  15   59    9  132   34   59   30   27  577   32]\n",
            " [  16   11    1   16  134   17    4   48    6  756]]\n",
            "--------------------------------\n",
            "val predicted: (59725,) [0. 0. 6. ... 9. 9. 7.]\n",
            "probabilities: (59725, 10) \n",
            " [0 0 6 ... 9 9 7]\n",
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [26 40 19 30 39 29 32 40 18 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.945 s \n",
            "\n",
            "Accuracy rate for 81.170000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.90      0.89       980\n",
            "        1.0       0.80      0.98      0.89      1135\n",
            "        2.0       0.95      0.54      0.68      1032\n",
            "        3.0       0.69      0.90      0.78      1010\n",
            "        4.0       0.73      0.91      0.81       982\n",
            "        5.0       0.81      0.72      0.76       892\n",
            "        6.0       0.82      0.92      0.87       958\n",
            "        7.0       0.83      0.90      0.86      1028\n",
            "        8.0       0.90      0.59      0.71       974\n",
            "        9.0       0.86      0.73      0.79      1009\n",
            "\n",
            "avg / total       0.83      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 882    1    0   16    4   18   54    2    3    0]\n",
            " [   0 1117    1    3    1    1    4    3    5    0]\n",
            " [  46  135  553   65   61    9   51   76   35    1]\n",
            " [   6   13    7  908    4   29    5   26    7    5]\n",
            " [   1    6    0    1  898    8   11    5    1   51]\n",
            " [   8   12    2  162   23  644   34    4    0    3]\n",
            " [  18    7    0    1   39   11  879    3    0    0]\n",
            " [   4   27   15    3   14    4    1  926    7   27]\n",
            " [  15   59    7  143   33   55   29   25  573   35]\n",
            " [  16   11    0   16  157   16    3   49    4  737]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 6. ... 9. 9. 7.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 6 ... 9 9 7]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [27 46 23 31 41 32 32 42 21 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.082 s \n",
            "\n",
            "Accuracy rate for 82.730000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.90      0.90       980\n",
            "        1.0       0.81      0.99      0.89      1135\n",
            "        2.0       0.94      0.58      0.72      1032\n",
            "        3.0       0.75      0.88      0.81      1010\n",
            "        4.0       0.70      0.92      0.80       982\n",
            "        5.0       0.79      0.77      0.78       892\n",
            "        6.0       0.85      0.90      0.87       958\n",
            "        7.0       0.90      0.88      0.89      1028\n",
            "        8.0       0.89      0.67      0.76       974\n",
            "        9.0       0.86      0.76      0.80      1009\n",
            "\n",
            "avg / total       0.84      0.83      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 885    1    0    8    9   25   48    1    3    0]\n",
            " [   0 1120    0    4    0    1    4    0    5    1]\n",
            " [  45  137  602   43   60   12   39   45   47    2]\n",
            " [   4   10   12  893    4   45    4   23   10    5]\n",
            " [   0    5    2    1  904    4   11    2    0   53]\n",
            " [   7   12    4  135   19  688   20    4    0    3]\n",
            " [  15    6    0    1   60   15  861    0    0    0]\n",
            " [   2   34   13    2   19    2    1  906   12   37]\n",
            " [  16   42    7   95   40   60   21   15  651   27]\n",
            " [  17   11    2   13  169   14    2   15    3  763]]\n",
            "--------------------------------\n",
            "val predicted: (59675,) [0. 0. 6. ... 9. 9. 9.]\n",
            "probabilities: (59675, 10) \n",
            " [0 0 6 ... 9 9 9]\n",
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [29 46 27 34 42 34 33 48 25 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.124 s \n",
            "\n",
            "Accuracy rate for 84.280000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.89      0.90       980\n",
            "        1.0       0.84      0.98      0.91      1135\n",
            "        2.0       0.94      0.64      0.77      1032\n",
            "        3.0       0.78      0.87      0.82      1010\n",
            "        4.0       0.75      0.91      0.82       982\n",
            "        5.0       0.81      0.78      0.79       892\n",
            "        6.0       0.85      0.91      0.88       958\n",
            "        7.0       0.86      0.91      0.88      1028\n",
            "        8.0       0.88      0.74      0.80       974\n",
            "        9.0       0.86      0.78      0.82      1009\n",
            "\n",
            "avg / total       0.85      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 877    1    0    7    8   27   51    3    6    0]\n",
            " [   0 1117    0    5    0    1    3    3    6    0]\n",
            " [  34  105  665   36   46   10   33   50   48    5]\n",
            " [   5   11   10  879    2   45    6   27   17    8]\n",
            " [   0    7    1    0  892    4   10    2    1   65]\n",
            " [   5   12    2  119   21  693   24   11    2    3]\n",
            " [  13    7    0    0   42   17  875    2    2    0]\n",
            " [   2   25   20    3   12    4    1  931    8   22]\n",
            " [  12   36    5   59   34   44   22   24  716   22]\n",
            " [  15    9    2   15  132   13    3   32    5  783]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [29 47 30 42 46 36 34 52 26 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.215 s \n",
            "\n",
            "Accuracy rate for 84.150000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.88      0.89       980\n",
            "        1.0       0.86      0.98      0.92      1135\n",
            "        2.0       0.93      0.68      0.79      1032\n",
            "        3.0       0.73      0.91      0.81      1010\n",
            "        4.0       0.76      0.91      0.83       982\n",
            "        5.0       0.81      0.75      0.78       892\n",
            "        6.0       0.86      0.89      0.88       958\n",
            "        7.0       0.84      0.91      0.87      1028\n",
            "        8.0       0.91      0.70      0.79       974\n",
            "        9.0       0.88      0.78      0.83      1009\n",
            "\n",
            "avg / total       0.85      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 863    1    0   18    3   37   47    3    8    0]\n",
            " [   0 1117    1    2    1    1    4    6    3    0]\n",
            " [  29   93  703   47   43   11   22   46   34    4]\n",
            " [   4    3   13  920    2   21    3   28   10    6]\n",
            " [   1    6    1    1  895    4   12    8    2   52]\n",
            " [   6   11    2  151   11  665   26   16    1    3]\n",
            " [  11    6    1    0   64   20  853    2    1    0]\n",
            " [   3   23   23    1   12    4    1  932    7   22]\n",
            " [  18   32    7  101   25   42   19   30  678   22]\n",
            " [  16    5    1   16  117   17    2   42    4  789]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) [0. 0. 8. ... 9. 9. 7.]\n",
            "probabilities: (59625, 10) \n",
            " [0 0 8 ... 9 9 7]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [31 50 32 45 49 40 37 52 29 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.362 s \n",
            "\n",
            "Accuracy rate for 85.200000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.89      0.91       980\n",
            "        1.0       0.86      0.99      0.92      1135\n",
            "        2.0       0.93      0.72      0.81      1032\n",
            "        3.0       0.76      0.91      0.83      1010\n",
            "        4.0       0.77      0.92      0.84       982\n",
            "        5.0       0.83      0.77      0.80       892\n",
            "        6.0       0.86      0.91      0.89       958\n",
            "        7.0       0.87      0.89      0.88      1028\n",
            "        8.0       0.90      0.72      0.80       974\n",
            "        9.0       0.87      0.78      0.82      1009\n",
            "\n",
            "avg / total       0.86      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 873    1    1   20    4   27   38    2   14    0]\n",
            " [   0 1119    2    3    1    2    4    0    4    0]\n",
            " [  28   76  748   34   32    8   32   41   28    5]\n",
            " [   2    6   14  917    3   23    4   22   14    5]\n",
            " [   0    6    1    0  902    4   15    5    1   48]\n",
            " [   5   10    4  132   17  683   23   11    4    3]\n",
            " [  10    6    2    0   49   13  876    1    1    0]\n",
            " [   2   27   26    1   18    2    1  913    3   35]\n",
            " [  14   38    6   80   27   42   20   21  702   24]\n",
            " [  13   10    1   21  123   14    2   33    5  787]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 8. ... 9. 9. 7.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 8 ... 9 9 7]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [33 53 35 47 50 41 42 55 33 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.441 s \n",
            "\n",
            "Accuracy rate for 86.130000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.90      0.91       980\n",
            "        1.0       0.88      0.99      0.93      1135\n",
            "        2.0       0.93      0.75      0.83      1032\n",
            "        3.0       0.77      0.91      0.84      1010\n",
            "        4.0       0.78      0.92      0.84       982\n",
            "        5.0       0.84      0.76      0.80       892\n",
            "        6.0       0.86      0.92      0.89       958\n",
            "        7.0       0.90      0.89      0.89      1028\n",
            "        8.0       0.90      0.76      0.82       974\n",
            "        9.0       0.88      0.80      0.84      1009\n",
            "\n",
            "avg / total       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 884    1    1   11    5   23   45    1    9    0]\n",
            " [   0 1119    1    3    1    2    4    0    5    0]\n",
            " [  27   62  769   35   31    8   27   35   34    4]\n",
            " [   2    8   14  916    3   23    4   22   11    7]\n",
            " [   1    5    1    0  900    4   11    3    1   56]\n",
            " [   4   12    3  131   23  676   29    7    4    3]\n",
            " [  11    6    0    0   41   12  885    2    1    0]\n",
            " [   4   21   27    2   19    1    1  917    5   31]\n",
            " [  12   33    8   67   27   39   22   13  739   14]\n",
            " [  14   11    1   19  107   13    4   23    9  808]]\n",
            "--------------------------------\n",
            "val predicted: (59575,) [0. 0. 8. ... 9. 9. 7.]\n",
            "probabilities: (59575, 10) \n",
            " [0 0 8 ... 9 9 7]\n",
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [35 55 36 50 55 42 46 56 37 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.546 s \n",
            "\n",
            "Accuracy rate for 86.780000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.90      0.90       980\n",
            "        1.0       0.90      0.98      0.94      1135\n",
            "        2.0       0.94      0.78      0.85      1032\n",
            "        3.0       0.79      0.91      0.84      1010\n",
            "        4.0       0.78      0.93      0.85       982\n",
            "        5.0       0.87      0.77      0.82       892\n",
            "        6.0       0.87      0.93      0.90       958\n",
            "        7.0       0.90      0.89      0.89      1028\n",
            "        8.0       0.88      0.78      0.83       974\n",
            "        9.0       0.90      0.78      0.83      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 883    1    1   10    3   26   36    3   17    0]\n",
            " [   0 1117    2    2    2    1    4    0    7    0]\n",
            " [  34   37  804   33   35    6   22   33   27    1]\n",
            " [   4    6   14  917    3   18    5   18   20    5]\n",
            " [   0    6    1    0  915    2   13    3    2   40]\n",
            " [   5   13    2  117   26  687   25   10    5    2]\n",
            " [  13    7    1    0   31    9  894    2    1    0]\n",
            " [   4   21   26    2   19    2    1  911    9   33]\n",
            " [  15   28    6   65   23   30   24   10  762   11]\n",
            " [  16   11    2   17  122    9    4   27   13  788]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 8. ... 9. 9. 7.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 8 ... 9 9 7]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [37 59 38 51 57 43 48 62 39 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.624 s \n",
            "\n",
            "Accuracy rate for 86.950000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.90      0.91       980\n",
            "        1.0       0.89      0.98      0.93      1135\n",
            "        2.0       0.94      0.77      0.85      1032\n",
            "        3.0       0.78      0.91      0.84      1010\n",
            "        4.0       0.81      0.93      0.86       982\n",
            "        5.0       0.87      0.76      0.81       892\n",
            "        6.0       0.85      0.94      0.89       958\n",
            "        7.0       0.89      0.89      0.89      1028\n",
            "        8.0       0.89      0.78      0.83       974\n",
            "        9.0       0.90      0.81      0.85      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 882    1    0   16    2   24   43    1   11    0]\n",
            " [   0 1116    2    1    1    1    4    2    8    0]\n",
            " [  33   37  794   33   30    2   31   37   31    4]\n",
            " [   3    8   11  922    1   18    7   21   15    4]\n",
            " [   1    5    1    0  913    1   12    3    2   44]\n",
            " [   6   12    1  130   21  679   27    9    3    4]\n",
            " [  14    8    2    0   21   11  900    1    1    0]\n",
            " [   3   27   25    2   19    0    1  916    8   27]\n",
            " [  13   28    5   66   21   32   27   11  760   11]\n",
            " [  13   11    1   14  103    9    5   24   16  813]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59525,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59525, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [40 62 41 53 59 44 51 64 43 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.618 s \n",
            "\n",
            "Accuracy rate for 87.590000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.91      0.91       980\n",
            "        1.0       0.89      0.98      0.94      1135\n",
            "        2.0       0.94      0.78      0.85      1032\n",
            "        3.0       0.79      0.91      0.84      1010\n",
            "        4.0       0.83      0.91      0.87       982\n",
            "        5.0       0.89      0.78      0.83       892\n",
            "        6.0       0.86      0.95      0.90       958\n",
            "        7.0       0.91      0.90      0.90      1028\n",
            "        8.0       0.87      0.80      0.83       974\n",
            "        9.0       0.90      0.83      0.86      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 896    1    0   13    3   14   35    2   16    0]\n",
            " [   0 1115    1    3    1    1    4    0   10    0]\n",
            " [  31   41  801   36   22    1   28   35   34    3]\n",
            " [   2    7   11  916    2   20    7   18   23    4]\n",
            " [   1    6    2    0  895    3   13    2    5   55]\n",
            " [   5   11    2  122   18  693   27    6    6    2]\n",
            " [  11    7    1    0   20   10  906    1    2    0]\n",
            " [   4   22   26    1   17    2    1  922    9   24]\n",
            " [  12   26    6   56   25   26   24    9  781    9]\n",
            " [  18   10    1   12   81   12    6   22   13  834]]\n",
            "--------------------------------\n",
            "final active learning accuracies [51.64, 60.72, 65.45, 70.28999999999999, 72.94, 76.08, 77.51, 77.78, 79.35, 80.39, 81.6, 81.17, 82.73, 84.28, 84.15, 85.2, 86.13, 86.78, 86.95, 87.59]\n",
            "saved Active-learning-experiment-19.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 20, using model = RfModel, selection_function = RandomSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [2 3 1 1 1 0 0 1 0 1] [0 1 2 3 4 7 9]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n",
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.501 s \n",
            "\n",
            "Accuracy rate for 36.010000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.55      0.86      0.67       980\n",
            "        1.0       0.22      1.00      0.36      1135\n",
            "        2.0       0.73      0.22      0.34      1032\n",
            "        3.0       0.54      0.20      0.30      1010\n",
            "        4.0       0.45      0.20      0.28       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.00      0.00      0.00       958\n",
            "        7.0       0.56      0.42      0.48      1028\n",
            "        8.0       0.00      0.00      0.00       974\n",
            "        9.0       0.41      0.56      0.48      1009\n",
            "\n",
            "avg / total       0.35      0.36      0.30     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 842   56    0   42   29    0    0   10    0    1]\n",
            " [   0 1134    0    0    0    0    0    0    0    1]\n",
            " [  73  621  231    7   18    0    0   73    0    9]\n",
            " [  41  733    3  206    5    0    0   15    0    7]\n",
            " [  40  343   24    0  199    0    0   53    0  323]\n",
            " [ 262  502    1   70   14    0    0    9    0   34]\n",
            " [ 203  447   43    4  127    0    0    3    0  131]\n",
            " [   7  358    2    1    3    0    0  428    0  229]\n",
            " [  43  727   11   52   14    0    0   70    0   57]\n",
            " [  20  284    3    3   33    0    0  105    0  561]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59990,) [0. 0. 1. ... 7. 1. 1.]\n",
            "probabilities: (59990, 7) \n",
            " [0 0 1 ... 5 1 1]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [3 4 3 1 1 1 2 3 1 1] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.845 s \n",
            "\n",
            "Accuracy rate for 43.340000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.66      0.70       980\n",
            "        1.0       0.28      0.98      0.44      1135\n",
            "        2.0       0.64      0.45      0.53      1032\n",
            "        3.0       0.54      0.18      0.28      1010\n",
            "        4.0       0.37      0.19      0.26       982\n",
            "        5.0       0.91      0.09      0.16       892\n",
            "        6.0       0.68      0.49      0.57       958\n",
            "        7.0       0.36      0.84      0.51      1028\n",
            "        8.0       0.62      0.18      0.28       974\n",
            "        9.0       0.74      0.15      0.24      1009\n",
            "\n",
            "avg / total       0.58      0.43      0.40     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 643  103    0    7   52    0  110   53   12    0]\n",
            " [   0 1112   15    0    0    0    1    4    3    0]\n",
            " [  30  333  464    4   11    0   41  130   19    0]\n",
            " [  18  631   16  186   20    2    2   98   37    0]\n",
            " [  15  289   89    1  191    1   10  355    0   31]\n",
            " [  67  484    5   87   23   79   24   95   24    4]\n",
            " [  57  274   47    2   80    0  472   20    6    0]\n",
            " [   1  134   11    2    3    0    0  866    0   11]\n",
            " [  19  406   72   50   35    5   21  187  173    6]\n",
            " [  12  164    8    3   95    0   10  566    3  148]]\n",
            "--------------------------------\n",
            "val predicted: (59980,) [0. 0. 8. ... 7. 1. 1.]\n",
            "probabilities: (59980, 10) \n",
            " [0 0 8 ... 7 1 1]\n",
            "trainset before (20, 784) (20,)\n",
            "trainset after (30, 784) (30,)\n",
            "updated train set: (30, 784) (30,) unique(labels): [4 4 6 1 1 2 4 3 2 3] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59970, 784) (59970,)\n",
            "\n",
            "Train set: (30, 784) y: (30,)\n",
            "Val   set: (59970, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.078 s \n",
            "\n",
            "Accuracy rate for 53.940000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.87      0.81       980\n",
            "        1.0       0.42      0.96      0.58      1135\n",
            "        2.0       0.45      0.84      0.58      1032\n",
            "        3.0       0.69      0.15      0.24      1010\n",
            "        4.0       0.56      0.07      0.12       982\n",
            "        5.0       0.70      0.17      0.28       892\n",
            "        6.0       0.84      0.61      0.71       958\n",
            "        7.0       0.68      0.78      0.73      1028\n",
            "        8.0       0.49      0.15      0.23       974\n",
            "        9.0       0.43      0.69      0.53      1009\n",
            "\n",
            "avg / total       0.60      0.54      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 854   34   19    3    5    3   22   13   27    0]\n",
            " [   0 1087   46    0    0    0    1    0    0    1]\n",
            " [  20  113  864    0    0    0    8   20    1    6]\n",
            " [  49  403  291  149    8   24    2   19   30   35]\n",
            " [   4   81  169    1   64    8   50  130    6  469]\n",
            " [  98  328   17   43   11  153    9   39   63  131]\n",
            " [  43  176  112    0   13    2  583    3   14   12]\n",
            " [   3   84   76    2    1    8    0  800    4   50]\n",
            " [  40  214  289   18    3   12    6   13  148  231]\n",
            " [  13   72   58    0   10   10    9  139    6  692]]\n",
            "--------------------------------\n",
            "val predicted: (59970,) [0. 0. 8. ... 7. 7. 7.]\n",
            "probabilities: (59970, 10) \n",
            " [0 0 8 ... 7 7 7]\n",
            "trainset before (30, 784) (30,)\n",
            "trainset after (40, 784) (40,)\n",
            "updated train set: (40, 784) (40,) unique(labels): [5 6 7 2 2 3 5 4 2 4] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59960, 784) (59960,)\n",
            "\n",
            "Train set: (40, 784) y: (40,)\n",
            "Val   set: (59960, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.367 s \n",
            "\n",
            "Accuracy rate for 58.020000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.87      0.82       980\n",
            "        1.0       0.50      0.96      0.66      1135\n",
            "        2.0       0.46      0.82      0.59      1032\n",
            "        3.0       0.69      0.32      0.44      1010\n",
            "        4.0       0.90      0.19      0.32       982\n",
            "        5.0       0.64      0.26      0.36       892\n",
            "        6.0       0.81      0.64      0.72       958\n",
            "        7.0       0.64      0.83      0.73      1028\n",
            "        8.0       0.68      0.10      0.17       974\n",
            "        9.0       0.43      0.70      0.53      1009\n",
            "\n",
            "avg / total       0.65      0.58      0.54     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 854    8    3    9    0   30   48   21    4    3]\n",
            " [   0 1084   48    0    0    0    0    3    0    0]\n",
            " [  33   79  848    0    2    1    9   48   10    2]\n",
            " [  26  307  157  326    1   79    0   32    7   75]\n",
            " [  14   64  102    1  190    0   47  107    1  456]\n",
            " [  42  250   29  111    2  228   14   73   14  129]\n",
            " [  71   89  159    0    0    5  617   12    0    5]\n",
            " [  10   46   74   14    1    1    0  857    6   19]\n",
            " [  20  169  396   12    0   15   13   21   95  233]\n",
            " [  22   54   44    2   15    0   10  156    3  703]]\n",
            "--------------------------------\n",
            "val predicted: (59960,) [0. 0. 8. ... 7. 7. 7.]\n",
            "probabilities: (59960, 10) \n",
            " [0 0 8 ... 7 7 7]\n",
            "trainset before (40, 784) (40,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [5 7 8 3 3 3 6 6 3 6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.611 s \n",
            "\n",
            "Accuracy rate for 60.970000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.82      0.86       980\n",
            "        1.0       0.52      0.98      0.68      1135\n",
            "        2.0       0.48      0.82      0.61      1032\n",
            "        3.0       0.62      0.47      0.53      1010\n",
            "        4.0       0.83      0.30      0.44       982\n",
            "        5.0       0.88      0.12      0.21       892\n",
            "        6.0       0.80      0.74      0.77       958\n",
            "        7.0       0.71      0.80      0.76      1028\n",
            "        8.0       0.67      0.18      0.28       974\n",
            "        9.0       0.45      0.74      0.56      1009\n",
            "\n",
            "avg / total       0.68      0.61      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 808    6   58   11    6    4   60    8   16    3]\n",
            " [   0 1115   17    0    0    0    1    2    0    0]\n",
            " [  15   87  846    1    7    0   20   29   15   12]\n",
            " [   2  217  220  471    1    4   12   16    5   62]\n",
            " [   4   65   64    0  297    0   36   85    2  429]\n",
            " [  16  258   59  223    2  105   30   45   33  121]\n",
            " [  22   85  123    6   13    0  706    0    0    3]\n",
            " [  10   57   60   18    1    0    2  826    8   46]\n",
            " [   9  212  277   30    2    6   11   19  173  235]\n",
            " [  11   54   26    1   28    1    3  127    8  750]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 8. ... 7. 7. 7.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 8 ... 7 7 7]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (60, 784) (60,)\n",
            "updated train set: (60, 784) (60,) unique(labels): [7 9 8 4 5 3 7 7 4 6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59940, 784) (59940,)\n",
            "\n",
            "Train set: (60, 784) y: (60,)\n",
            "Val   set: (59940, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.746 s \n",
            "\n",
            "Accuracy rate for 66.440000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.86      0.87      0.86       980\n",
            "        1.0       0.49      0.96      0.65      1135\n",
            "        2.0       0.60      0.77      0.67      1032\n",
            "        3.0       0.59      0.52      0.55      1010\n",
            "        4.0       0.81      0.74      0.77       982\n",
            "        5.0       0.93      0.09      0.17       892\n",
            "        6.0       0.80      0.74      0.77       958\n",
            "        7.0       0.72      0.88      0.79      1028\n",
            "        8.0       0.79      0.30      0.44       974\n",
            "        9.0       0.62      0.66      0.64      1009\n",
            "\n",
            "avg / total       0.71      0.66      0.64     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 848    9   35   14    0    0   63    3    8    0]\n",
            " [   0 1094   33    0    0    0    1    4    3    0]\n",
            " [  27  101  791    7    8    0   18   42   30    8]\n",
            " [   9  302   90  528    3    4    7   29   13   25]\n",
            " [   1   50   15    0  724    0   40   49    0  103]\n",
            " [  45  278   27  288   12   84   29   34   17   78]\n",
            " [  24   97   77    6   35    0  712    3    2    2]\n",
            " [   5   44   36    3    6    0    0  903    6   25]\n",
            " [  11  203  202   42   10    1   11   26  297  171]\n",
            " [  14   42   12    5   93    1   10  167    2  663]]\n",
            "--------------------------------\n",
            "val predicted: (59940,) [0. 0. 3. ... 7. 7. 7.]\n",
            "probabilities: (59940, 10) \n",
            " [0 0 3 ... 7 7 7]\n",
            "trainset before (60, 784) (60,)\n",
            "trainset after (70, 784) (70,)\n",
            "updated train set: (70, 784) (70,) unique(labels): [ 8 11  8  6  5  3  9  7  6  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59930, 784) (59930,)\n",
            "\n",
            "Train set: (70, 784) y: (70,)\n",
            "Val   set: (59930, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.964 s \n",
            "\n",
            "Accuracy rate for 68.630000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.86      0.87      0.87       980\n",
            "        1.0       0.57      0.96      0.72      1135\n",
            "        2.0       0.76      0.66      0.71      1032\n",
            "        3.0       0.61      0.70      0.65      1010\n",
            "        4.0       0.76      0.65      0.70       982\n",
            "        5.0       0.85      0.07      0.13       892\n",
            "        6.0       0.73      0.87      0.79       958\n",
            "        7.0       0.83      0.82      0.82      1028\n",
            "        8.0       0.66      0.44      0.52       974\n",
            "        9.0       0.55      0.73      0.63      1009\n",
            "\n",
            "avg / total       0.71      0.69      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 855    3    9    6    1    0   85    2   18    1]\n",
            " [   0 1086    1    3    0    0    2    1   42    0]\n",
            " [  28  102  678   17   19    0   36   35  106   11]\n",
            " [   7  167   54  708    3    9    9   15   12   26]\n",
            " [   4   53    9    0  640    0   56   21    2  197]\n",
            " [  28  204   12  355   25   61   66   22   21   98]\n",
            " [  28   48   13    2   29    0  834    2    1    1]\n",
            " [  16   56   24    4   10    0    1  844   14   59]\n",
            " [   9  130   79   58    5    1   44   15  424  209]\n",
            " [  17   53    8   10  110    1   10   63    4  733]]\n",
            "--------------------------------\n",
            "val predicted: (59930,) [0. 0. 6. ... 7. 7. 7.]\n",
            "probabilities: (59930, 10) \n",
            " [0 0 6 ... 7 7 7]\n",
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [11 11  9  8  6  3  9  9  7  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.066 s \n",
            "\n",
            "Accuracy rate for 70.800000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.96      0.89       980\n",
            "        1.0       0.61      0.95      0.74      1135\n",
            "        2.0       0.83      0.66      0.73      1032\n",
            "        3.0       0.55      0.78      0.65      1010\n",
            "        4.0       0.75      0.69      0.72       982\n",
            "        5.0       0.96      0.03      0.06       892\n",
            "        6.0       0.84      0.85      0.84       958\n",
            "        7.0       0.80      0.84      0.82      1028\n",
            "        8.0       0.72      0.52      0.61       974\n",
            "        9.0       0.60      0.69      0.64      1009\n",
            "\n",
            "avg / total       0.74      0.71      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    1    3   12    3    0   14    1    5    0]\n",
            " [   0 1080    2    4    0    0    2    1   46    0]\n",
            " [  24  102  676   55   23    0   33   29   83    7]\n",
            " [  13  125   31  783    4    1    1   14   16   22]\n",
            " [   1   39    6    6  679    0   40   13    2  196]\n",
            " [  84  175   10  394   31   26   36   30   28   78]\n",
            " [  32   42   15   19   30    0  816    2    1    1]\n",
            " [  18   53   24   11   11    0    1  868    8   34]\n",
            " [   9  115   38  117   10    0   28   19  511  127]\n",
            " [  21   35    8   12  110    0    5  112    6  700]]\n",
            "--------------------------------\n",
            "val predicted: (59920,) [0. 0. 3. ... 7. 7. 7.]\n",
            "probabilities: (59920, 10) \n",
            " [0 0 3 ... 7 7 7]\n",
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [12 13 10  9  6  5 10  9  8  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.160 s \n",
            "\n",
            "Accuracy rate for 72.080000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.96      0.89       980\n",
            "        1.0       0.59      0.96      0.73      1135\n",
            "        2.0       0.82      0.67      0.74      1032\n",
            "        3.0       0.63      0.77      0.69      1010\n",
            "        4.0       0.77      0.65      0.71       982\n",
            "        5.0       0.97      0.20      0.33       892\n",
            "        6.0       0.85      0.85      0.85       958\n",
            "        7.0       0.80      0.82      0.81      1028\n",
            "        8.0       0.75      0.56      0.64       974\n",
            "        9.0       0.58      0.68      0.63      1009\n",
            "\n",
            "avg / total       0.75      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 939    3   10    2    3    4    7    1    9    2]\n",
            " [   0 1093    0    4    0    0    1    0   37    0]\n",
            " [  28  123  689   22   20    0   32   30   79    9]\n",
            " [  16  131   24  777    3    0    5   12   16   26]\n",
            " [   2   54   10    0  642    0   36   13    3  222]\n",
            " [  55  165   14  340    9  176   31   17   23   62]\n",
            " [  27   66   14    5   31    0  810    0    3    2]\n",
            " [  22   51   23    2    5    0    0  845   13   67]\n",
            " [  14  132   46   74    5    2   22   17  548  114]\n",
            " [  21   39    8    8  111    0    8  121    4  689]]\n",
            "--------------------------------\n",
            "val predicted: (59910,) [0. 0. 0. ... 7. 7. 7.]\n",
            "probabilities: (59910, 10) \n",
            " [0 0 0 ... 7 7 7]\n",
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [12 15 11  9  9  6 11 10  9  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.249 s \n",
            "\n",
            "Accuracy rate for 73.580000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.92      0.90       980\n",
            "        1.0       0.61      0.97      0.75      1135\n",
            "        2.0       0.76      0.69      0.72      1032\n",
            "        3.0       0.63      0.76      0.69      1010\n",
            "        4.0       0.72      0.86      0.79       982\n",
            "        5.0       0.90      0.21      0.33       892\n",
            "        6.0       0.85      0.85      0.85       958\n",
            "        7.0       0.81      0.83      0.82      1028\n",
            "        8.0       0.73      0.56      0.64       974\n",
            "        9.0       0.72      0.62      0.66      1009\n",
            "\n",
            "avg / total       0.76      0.74      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 906    2   23    5    1   13   19    1   10    0]\n",
            " [   0 1098    1    3    0    0    2    1   30    0]\n",
            " [  18  127  712   19   25    0   25   26   75    5]\n",
            " [   8  128   42  766    5    0    4   16   23   18]\n",
            " [   1   39   15    1  845    0   26    9    3   43]\n",
            " [  44  124   20  334   33  183   37   17   48   52]\n",
            " [  24   40   28    5   38    1  816    0    5    1]\n",
            " [  14   54   32    5   20    2    1  858    8   34]\n",
            " [  10  133   48   69   21    4   26   19  550   94]\n",
            " [  16   44   19    8  181    0    6  107    4  624]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59900,) [0. 0. 8. ... 7. 7. 7.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 8 ... 7 7 7]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [12 16 12  9 10  6 13 12 10 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.510 s \n",
            "\n",
            "Accuracy rate for 73.630000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.91      0.90       980\n",
            "        1.0       0.65      0.98      0.78      1135\n",
            "        2.0       0.85      0.67      0.75      1032\n",
            "        3.0       0.65      0.77      0.70      1010\n",
            "        4.0       0.70      0.81      0.75       982\n",
            "        5.0       0.88      0.18      0.30       892\n",
            "        6.0       0.79      0.88      0.83       958\n",
            "        7.0       0.82      0.82      0.82      1028\n",
            "        8.0       0.74      0.60      0.66       974\n",
            "        9.0       0.62      0.67      0.64      1009\n",
            "\n",
            "avg / total       0.76      0.74      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 891    2   15    7    5   15   32    2   10    1]\n",
            " [   0 1112    0    4    0    0    2    0   17    0]\n",
            " [  13  116  691   16   34    0   49   24   80    9]\n",
            " [  10  109   30  774    7    0   12   18   25   25]\n",
            " [   0   31    2    1  794    0   29    7    4  114]\n",
            " [  44  103    4  323   42  160   59   27   49   81]\n",
            " [  13   29   11    3   46    0  842    0   10    4]\n",
            " [   2   60   29    4   22    2    2  846    7   54]\n",
            " [  11  108   22   55    9    4   36   15  582  132]\n",
            " [  14   41    5    7  168    0    5   93    5  671]]\n",
            "--------------------------------\n",
            "val predicted: (59890,) [0. 0. 8. ... 7. 9. 7.]\n",
            "probabilities: (59890, 10) \n",
            " [0 0 8 ... 7 9 7]\n",
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [13 17 13 10 10  7 15 12 13 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.531 s \n",
            "\n",
            "Accuracy rate for 74.000000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.91      0.91       980\n",
            "        1.0       0.65      0.96      0.78      1135\n",
            "        2.0       0.81      0.64      0.71      1032\n",
            "        3.0       0.65      0.80      0.72      1010\n",
            "        4.0       0.72      0.79      0.75       982\n",
            "        5.0       0.91      0.24      0.39       892\n",
            "        6.0       0.81      0.90      0.85       958\n",
            "        7.0       0.83      0.82      0.82      1028\n",
            "        8.0       0.71      0.62      0.66       974\n",
            "        9.0       0.63      0.66      0.65      1009\n",
            "\n",
            "avg / total       0.76      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 890    2   24    4    4   12   30    2   11    1]\n",
            " [   0 1089    1    3    0    0    2    1   39    0]\n",
            " [  19  129  658   24   25    0   46   18  103   10]\n",
            " [   8   93   27  806    6    0    9   16   25   20]\n",
            " [   1   38    3    1  771    1   33    9    4  121]\n",
            " [  38   91   17  320   44  218   40   27   32   65]\n",
            " [   9   30   15    1   33    2  859    0    6    3]\n",
            " [   1   61   31    3   21    0    1  842   18   50]\n",
            " [   8   93   30   67    8    7   30   14  600  117]\n",
            " [  12   49   11    7  161    0    5   90    7  667]]\n",
            "--------------------------------\n",
            "val predicted: (59880,) [0. 0. 8. ... 7. 9. 7.]\n",
            "probabilities: (59880, 10) \n",
            " [0 0 8 ... 7 9 7]\n",
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [13 20 13 11 10  9 17 13 14 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.580 s \n",
            "\n",
            "Accuracy rate for 74.200000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.90      0.91       980\n",
            "        1.0       0.64      0.96      0.77      1135\n",
            "        2.0       0.86      0.62      0.72      1032\n",
            "        3.0       0.68      0.76      0.72      1010\n",
            "        4.0       0.74      0.78      0.76       982\n",
            "        5.0       0.84      0.31      0.45       892\n",
            "        6.0       0.78      0.93      0.85       958\n",
            "        7.0       0.77      0.82      0.80      1028\n",
            "        8.0       0.72      0.63      0.67       974\n",
            "        9.0       0.64      0.64      0.64      1009\n",
            "\n",
            "avg / total       0.76      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 883    2   19    3    5   20   32    4   12    0]\n",
            " [   0 1094    1    3    0    0    2    0   35    0]\n",
            " [  13  124  645   25   25    0   68   24  103    5]\n",
            " [   9  101   30  767    8   20   12   25   26   12]\n",
            " [   1   39    1    0  767    0   33   15    4  122]\n",
            " [  25  103    7  272   29  274   55   28   34   65]\n",
            " [   6   30    1    2   23    4  887    0    4    1]\n",
            " [   3   74   18    0   20    0    1  845   16   51]\n",
            " [   4   96   22   55    8    8   36   28  609  108]\n",
            " [  11   49    6    7  147    0    9  123    8  649]]\n",
            "--------------------------------\n",
            "val predicted: (59870,) [0. 0. 8. ... 7. 9. 1.]\n",
            "probabilities: (59870, 10) \n",
            " [0 0 8 ... 7 9 1]\n",
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [14 20 14 13 10 12 17 14 16 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.681 s \n",
            "\n",
            "Accuracy rate for 75.520000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.92      0.92       980\n",
            "        1.0       0.68      0.97      0.80      1135\n",
            "        2.0       0.88      0.61      0.72      1032\n",
            "        3.0       0.70      0.81      0.75      1010\n",
            "        4.0       0.73      0.77      0.75       982\n",
            "        5.0       0.80      0.37      0.51       892\n",
            "        6.0       0.81      0.89      0.85       958\n",
            "        7.0       0.76      0.83      0.79      1028\n",
            "        8.0       0.73      0.68      0.70       974\n",
            "        9.0       0.65      0.64      0.64      1009\n",
            "\n",
            "avg / total       0.77      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 898    1   17    0    3   20   29    3    8    1]\n",
            " [   0 1096    0    6    0    0    2    1   30    0]\n",
            " [  12  126  634   24   32    1   54   23  121    5]\n",
            " [   7   52   15  821    4   34   11   23   32   11]\n",
            " [   1   41    4    0  761    0   24   20    7  124]\n",
            " [  18   84    5  267   27  334   50   22   26   59]\n",
            " [   9   35    2    3   35    8  856    0    8    2]\n",
            " [   1   61   23    1   21    3    0  850   11   57]\n",
            " [   7   78   16   48    6   13   27   30  660   89]\n",
            " [  13   35    5   10  147    2    5  143    7  642]]\n",
            "--------------------------------\n",
            "val predicted: (59860,) [0. 0. 8. ... 7. 9. 7.]\n",
            "probabilities: (59860, 10) \n",
            " [0 0 8 ... 7 9 7]\n",
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [14 24 15 13 10 12 17 15 17 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.775 s \n",
            "\n",
            "Accuracy rate for 75.410000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.88      0.91       980\n",
            "        1.0       0.64      0.99      0.78      1135\n",
            "        2.0       0.84      0.59      0.69      1032\n",
            "        3.0       0.69      0.81      0.75      1010\n",
            "        4.0       0.79      0.73      0.76       982\n",
            "        5.0       0.87      0.36      0.51       892\n",
            "        6.0       0.78      0.91      0.84       958\n",
            "        7.0       0.81      0.84      0.83      1028\n",
            "        8.0       0.76      0.66      0.71       974\n",
            "        9.0       0.65      0.71      0.68      1009\n",
            "\n",
            "avg / total       0.77      0.75      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 862    2   35    1    3   16   46    3    9    3]\n",
            " [   0 1124    1    3    0    0    2    0    5    0]\n",
            " [  12  171  606   24   21    0   72   20   95   11]\n",
            " [   7   71   19  823    3   15   16   14   28   14]\n",
            " [   1   56    2    2  719    0   29    8    8  157]\n",
            " [  12  101    3  273   20  320   51   30   33   49]\n",
            " [   3   37    1    2   28    9  870    0    4    4]\n",
            " [   1   71   25    3   14    1    0  863   10   40]\n",
            " [   9   86   20   55    5    7   26   15  640  111]\n",
            " [  12   41    8   10  102    0    8  108    6  714]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 8. ... 7. 7. 7.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 8 ... 7 7 7]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [14 26 15 14 13 12 19 16 18 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.891 s \n",
            "\n",
            "Accuracy rate for 75.810000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.90      0.91       980\n",
            "        1.0       0.65      0.99      0.79      1135\n",
            "        2.0       0.86      0.58      0.70      1032\n",
            "        3.0       0.67      0.81      0.74      1010\n",
            "        4.0       0.72      0.82      0.77       982\n",
            "        5.0       0.88      0.30      0.45       892\n",
            "        6.0       0.77      0.91      0.84       958\n",
            "        7.0       0.81      0.86      0.84      1028\n",
            "        8.0       0.79      0.68      0.73       974\n",
            "        9.0       0.71      0.65      0.68      1009\n",
            "\n",
            "avg / total       0.78      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 880    3   19    1    4   15   46    4    6    2]\n",
            " [   0 1128    1    3    0    0    2    0    1    0]\n",
            " [  12  175  601   26   33    0   65   28   81   11]\n",
            " [   7   75   23  821    6    7   14    7   37   13]\n",
            " [   1   39    1    1  804    0   28    5    6   97]\n",
            " [  22   92    3  306   38  269   72   28   33   29]\n",
            " [   4   42    0    1   30    3  872    0    3    3]\n",
            " [   2   61   23    3   23    0    1  888    6   21]\n",
            " [   9   84   16   51   12    8   25   13  664   92]\n",
            " [  12   31    8   11  163    3    3  117    7  654]]\n",
            "--------------------------------\n",
            "val predicted: (59840,) [0. 0. 8. ... 7. 7. 7.]\n",
            "probabilities: (59840, 10) \n",
            " [0 0 8 ... 7 7 7]\n",
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [14 27 16 15 13 12 21 17 21 14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.988 s \n",
            "\n",
            "Accuracy rate for 75.980000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.88      0.91       980\n",
            "        1.0       0.65      0.99      0.79      1135\n",
            "        2.0       0.87      0.55      0.68      1032\n",
            "        3.0       0.66      0.81      0.73      1010\n",
            "        4.0       0.80      0.78      0.79       982\n",
            "        5.0       0.87      0.28      0.43       892\n",
            "        6.0       0.74      0.92      0.82       958\n",
            "        7.0       0.83      0.86      0.84      1028\n",
            "        8.0       0.77      0.69      0.73       974\n",
            "        9.0       0.71      0.76      0.73      1009\n",
            "\n",
            "avg / total       0.78      0.76      0.75     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 861    3   23    2    2   18   56    4    6    5]\n",
            " [   0 1125    1    3    0    0    2    1    3    0]\n",
            " [   9  174  572   17   30    0   97   33   90   10]\n",
            " [   8   72   20  815    2    8   15   16   43   11]\n",
            " [   1   45    1    0  762    0   34    4    6  129]\n",
            " [  15   94    2  324   27  254   75   30   31   40]\n",
            " [   3   36    0    1   24    4  883    1    3    3]\n",
            " [   1   67   19    2   12    0    1  884   14   28]\n",
            " [   7   74   15   57    6    7   29   19  676   84]\n",
            " [   9   32    7   10   90    0    6   78   11  766]]\n",
            "--------------------------------\n",
            "val predicted: (59830,) [0. 0. 8. ... 7. 7. 7.]\n",
            "probabilities: (59830, 10) \n",
            " [0 0 8 ... 7 7 7]\n",
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [14 28 18 15 15 12 22 18 22 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.054 s \n",
            "\n",
            "Accuracy rate for 77.970000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.87      0.91       980\n",
            "        1.0       0.71      0.99      0.83      1135\n",
            "        2.0       0.87      0.64      0.74      1032\n",
            "        3.0       0.68      0.82      0.74      1010\n",
            "        4.0       0.78      0.79      0.78       982\n",
            "        5.0       0.89      0.29      0.44       892\n",
            "        6.0       0.71      0.91      0.80       958\n",
            "        7.0       0.90      0.85      0.87      1028\n",
            "        8.0       0.80      0.74      0.77       974\n",
            "        9.0       0.72      0.83      0.77      1009\n",
            "\n",
            "avg / total       0.80      0.78      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 853    3   24    0    4   12   72    3    8    1]\n",
            " [   0 1127    1    3    0    0    2    1    1    0]\n",
            " [  10  120  664   13   31    0   91   29   63   11]\n",
            " [   8   55   26  826    7   12   18   11   30   17]\n",
            " [   0   33    1    0  772    0   29    3    7  137]\n",
            " [  12   73    5  303   31  258  106   23   40   41]\n",
            " [   4   30    5    1   36    3  873    0    2    4]\n",
            " [   1   63   17    3   19    0    5  873   12   35]\n",
            " [   5   58   16   57    7    5   26    8  717   75]\n",
            " [   8   21    5   11   89    0    5   22   14  834]]\n",
            "--------------------------------\n",
            "val predicted: (59820,) [0. 0. 8. ... 7. 9. 7.]\n",
            "probabilities: (59820, 10) \n",
            " [0 0 8 ... 7 9 7]\n",
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [15 28 19 16 16 12 23 19 24 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.220 s \n",
            "\n",
            "Accuracy rate for 77.500000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.89      0.91       980\n",
            "        1.0       0.72      0.99      0.83      1135\n",
            "        2.0       0.88      0.63      0.74      1032\n",
            "        3.0       0.65      0.80      0.72      1010\n",
            "        4.0       0.76      0.79      0.77       982\n",
            "        5.0       0.91      0.25      0.40       892\n",
            "        6.0       0.74      0.92      0.82       958\n",
            "        7.0       0.90      0.85      0.87      1028\n",
            "        8.0       0.78      0.74      0.76       974\n",
            "        9.0       0.70      0.82      0.76      1009\n",
            "\n",
            "avg / total       0.80      0.78      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 871    3   23    0    4    8   59    3    4    5]\n",
            " [   0 1123    2    2    0    0    2    1    5    0]\n",
            " [   9  138  650   16   31    0   75   36   64   13]\n",
            " [   9   54   27  805    9    7   18   12   54   15]\n",
            " [   0   22    1    0  771    0   25    7    6  150]\n",
            " [  19   72    4  327   33  225  101   16   44   51]\n",
            " [   5   29    0    2   29    3  882    0    5    3]\n",
            " [   3   58   14    3   19    0    2  869   10   50]\n",
            " [   4   44   10   74    9    4   28   11  722   68]\n",
            " [   9   18    5   10  105    0    6   12   12  832]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59810,) [0. 0. 8. ... 7. 9. 7.]\n",
            "probabilities: (59810, 10) \n",
            " [0 0 8 ... 7 9 7]\n",
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [15 30 20 17 17 15 24 19 25 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.302 s \n",
            "\n",
            "Accuracy rate for 80.150000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.88      0.91       980\n",
            "        1.0       0.76      0.99      0.86      1135\n",
            "        2.0       0.88      0.73      0.79      1032\n",
            "        3.0       0.68      0.82      0.74      1010\n",
            "        4.0       0.78      0.80      0.79       982\n",
            "        5.0       0.88      0.37      0.52       892\n",
            "        6.0       0.76      0.93      0.84       958\n",
            "        7.0       0.90      0.86      0.88      1028\n",
            "        8.0       0.81      0.76      0.79       974\n",
            "        9.0       0.76      0.82      0.79      1009\n",
            "\n",
            "avg / total       0.81      0.80      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 862    3   29    0    4   11   60    1    6    4]\n",
            " [   0 1123    2    2    0    0    2    0    6    0]\n",
            " [   7  101  750   14   25    1   48   31   45   10]\n",
            " [   6   38   23  827    8   18   21   17   41   11]\n",
            " [   1   26    1    0  785    0   27    2    8  132]\n",
            " [   9   67    2  293   30  326   97   14   34   20]\n",
            " [   5   22    3    2   18    7  894    1    4    2]\n",
            " [   2   53   19    1   24    0    1  881   13   34]\n",
            " [   5   29   18   64    9    7   27   21  742   52]\n",
            " [  10   14    9   12  103    1    6   16   13  825]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 8. ... 9. 7. 7.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 8 ... 9 7 7]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [15 35 21 19 18 15 24 19 26 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.333 s \n",
            "\n",
            "Accuracy rate for 79.810000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.90      0.92       980\n",
            "        1.0       0.73      0.99      0.84      1135\n",
            "        2.0       0.89      0.70      0.79      1032\n",
            "        3.0       0.64      0.84      0.73      1010\n",
            "        4.0       0.77      0.83      0.80       982\n",
            "        5.0       0.88      0.34      0.49       892\n",
            "        6.0       0.79      0.92      0.85       958\n",
            "        7.0       0.91      0.85      0.88      1028\n",
            "        8.0       0.82      0.75      0.78       974\n",
            "        9.0       0.77      0.80      0.79      1009\n",
            "\n",
            "avg / total       0.81      0.80      0.79     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 880    3   22    5    5   10   46    1    4    4]\n",
            " [   0 1120    0    3    0    0    2    0   10    0]\n",
            " [   9  112  726   15   29    0   48   34   52    7]\n",
            " [   7   43   22  851    8   13   12   11   35    8]\n",
            " [   1   22    3    1  817    0   22    1    6  109]\n",
            " [  15   81    3  344   26  304   68   13   26   12]\n",
            " [   5   31    3    2   21   11  877    0    4    4]\n",
            " [   1   63   17    3   28    0    1  871   11   33]\n",
            " [   3   32   11   88    9    6   28   10  727   60]\n",
            " [   8   18    8   14  124    1    4   14   10  808]]\n",
            "--------------------------------\n",
            "val predicted: (59790,) [0. 0. 8. ... 7. 9. 7.]\n",
            "probabilities: (59790, 10) \n",
            " [0 0 8 ... 7 9 7]\n",
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [17 36 21 20 19 17 24 21 27 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.318 s \n",
            "\n",
            "Accuracy rate for 81.130000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.91      0.92       980\n",
            "        1.0       0.75      0.99      0.85      1135\n",
            "        2.0       0.90      0.71      0.79      1032\n",
            "        3.0       0.70      0.84      0.76      1010\n",
            "        4.0       0.77      0.83      0.80       982\n",
            "        5.0       0.86      0.44      0.59       892\n",
            "        6.0       0.83      0.90      0.87       958\n",
            "        7.0       0.89      0.86      0.87      1028\n",
            "        8.0       0.81      0.76      0.79       974\n",
            "        9.0       0.78      0.81      0.79      1009\n",
            "\n",
            "avg / total       0.82      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 893    3   18    3    6   20   27    3    7    0]\n",
            " [   0 1125    1    3    0    0    2    0    4    0]\n",
            " [   8  110  735   16   31    0   29   39   59    5]\n",
            " [  11   37   23  848    7   17    9   17   34    7]\n",
            " [   1   16    1    0  816    0   22    3   10  113]\n",
            " [  16   78    5  249   31  396   59   15   30   13]\n",
            " [   8   36    5    2   24   10  860    0    8    5]\n",
            " [   1   53   15    4   21    0    0  882   12   40]\n",
            " [   7   31   11   78   10   15   19   15  745   43]\n",
            " [  11   14    7   17  115    2    3   17   10  813]]\n",
            "--------------------------------\n",
            "val predicted: (59780,) [0. 0. 8. ... 7. 9. 7.]\n",
            "probabilities: (59780, 10) \n",
            " [0 0 8 ... 7 9 7]\n",
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [17 37 21 22 21 19 25 23 27 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.435 s \n",
            "\n",
            "Accuracy rate for 80.870000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.90      0.92       980\n",
            "        1.0       0.76      0.99      0.86      1135\n",
            "        2.0       0.91      0.70      0.79      1032\n",
            "        3.0       0.69      0.85      0.76      1010\n",
            "        4.0       0.74      0.84      0.79       982\n",
            "        5.0       0.84      0.47      0.60       892\n",
            "        6.0       0.82      0.90      0.86       958\n",
            "        7.0       0.89      0.86      0.87      1028\n",
            "        8.0       0.83      0.74      0.78       974\n",
            "        9.0       0.78      0.79      0.78      1009\n",
            "\n",
            "avg / total       0.82      0.81      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 879    2   16    2    5   27   39    5    4    1]\n",
            " [   0 1122    1    3    0    0    2    1    6    0]\n",
            " [   8  115  725   12   39    1   38   43   44    7]\n",
            " [   6   36   22  861    8   19   10   11   27   10]\n",
            " [   1   15    1    0  826    1   22    2    7  107]\n",
            " [  11   55    3  269   32  416   47   15   33   11]\n",
            " [   6   30    7    3   32   13  859    0    6    2]\n",
            " [   1   49   14    4   23    0    1  884    9   43]\n",
            " [   5   29    8   86   15   18   25   18  721   49]\n",
            " [  11   16    4   14  138    3    4   17    8  794]]\n",
            "--------------------------------\n",
            "val predicted: (59770,) [0. 0. 8. ... 9. 9. 7.]\n",
            "probabilities: (59770, 10) \n",
            " [0 0 8 ... 9 9 7]\n",
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [19 37 21 24 21 19 27 23 28 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.478 s \n",
            "\n",
            "Accuracy rate for 80.590000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.89      0.92       980\n",
            "        1.0       0.77      0.99      0.86      1135\n",
            "        2.0       0.94      0.69      0.79      1032\n",
            "        3.0       0.68      0.86      0.76      1010\n",
            "        4.0       0.78      0.80      0.79       982\n",
            "        5.0       0.87      0.42      0.57       892\n",
            "        6.0       0.78      0.91      0.84       958\n",
            "        7.0       0.89      0.86      0.87      1028\n",
            "        8.0       0.82      0.76      0.79       974\n",
            "        9.0       0.74      0.83      0.78      1009\n",
            "\n",
            "avg / total       0.82      0.81      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 874    3    6    6    3   15   60    5    7    1]\n",
            " [   0 1120    1    3    0    0    2    1    8    0]\n",
            " [  10  118  711   19   26    1   49   43   48    7]\n",
            " [   4   35    9  871    5   16    7   16   35   12]\n",
            " [   1   15    1    0  781    0   28    3    5  148]\n",
            " [  13   53    1  277   27  376   74   15   34   22]\n",
            " [   5   27    2    2   34    8  872    1    4    3]\n",
            " [   1   44   16    7   19    0    2  884   10   45]\n",
            " [   4   30    6   82   10   15   24   14  736   53]\n",
            " [   8   11    5   16  100    1    6   16   12  834]]\n",
            "--------------------------------\n",
            "val predicted: (59760,) [0. 0. 8. ... 9. 9. 7.]\n",
            "probabilities: (59760, 10) \n",
            " [0 0 8 ... 9 9 7]\n",
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [19 38 21 27 22 19 29 23 31 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.567 s \n",
            "\n",
            "Accuracy rate for 80.860000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.88      0.92       980\n",
            "        1.0       0.79      0.99      0.88      1135\n",
            "        2.0       0.94      0.66      0.77      1032\n",
            "        3.0       0.66      0.88      0.75      1010\n",
            "        4.0       0.76      0.84      0.80       982\n",
            "        5.0       0.90      0.38      0.54       892\n",
            "        6.0       0.79      0.92      0.85       958\n",
            "        7.0       0.90      0.85      0.87      1028\n",
            "        8.0       0.78      0.79      0.79       974\n",
            "        9.0       0.79      0.83      0.81      1009\n",
            "\n",
            "avg / total       0.83      0.81      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 865    3   11   11    5   16   49    5   13    2]\n",
            " [   0 1123    0    4    0    0    2    0    6    0]\n",
            " [   9   99  680   24   42    0   57   39   78    4]\n",
            " [   4   29   10  888    6    6    8   14   35   10]\n",
            " [   1   12    1    0  820    0   25    2    7  114]\n",
            " [   9   54    1  310   39  341   66   14   37   21]\n",
            " [   5   23    0    1   31    5  883    0   10    0]\n",
            " [   1   46   11    6   24    0    3  878   16   43]\n",
            " [   2   23    4   92    8    8   18   11  774   34]\n",
            " [  10   12    5   15   98    1    6   16   12  834]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [20 38 23 30 23 21 29 24 31 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.536 s \n",
            "\n",
            "Accuracy rate for 81.260000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.88      0.92       980\n",
            "        1.0       0.80      0.99      0.89      1135\n",
            "        2.0       0.94      0.67      0.78      1032\n",
            "        3.0       0.67      0.89      0.76      1010\n",
            "        4.0       0.77      0.82      0.79       982\n",
            "        5.0       0.87      0.47      0.61       892\n",
            "        6.0       0.79      0.92      0.85       958\n",
            "        7.0       0.90      0.85      0.88      1028\n",
            "        8.0       0.80      0.77      0.78       974\n",
            "        9.0       0.76      0.82      0.79      1009\n",
            "\n",
            "avg / total       0.83      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 861    2    9   15    2   30   49    4    8    0]\n",
            " [   0 1119    0    4    0    0    3    0    8    1]\n",
            " [   9   94  691   39   27    0   54   40   72    6]\n",
            " [   2   24    9  899    6    8    9   14   26   13]\n",
            " [   1   12    2    1  803    0   26    1   10  126]\n",
            " [   5   40    1  265   32  418   61   12   37   21]\n",
            " [   4   22    3    4   32    7  877    1    7    1]\n",
            " [   1   42   14    5   22    0    3  876   14   51]\n",
            " [   2   25    3   93   13   14   22   11  752   39]\n",
            " [   8   13    5   16  110    2    7    9    9  830]]\n",
            "--------------------------------\n",
            "val predicted: (59740,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59740, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [22 39 23 30 24 22 31 25 32 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.691 s \n",
            "\n",
            "Accuracy rate for 82.260000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.89      0.92       980\n",
            "        1.0       0.80      0.99      0.88      1135\n",
            "        2.0       0.95      0.65      0.77      1032\n",
            "        3.0       0.76      0.87      0.81      1010\n",
            "        4.0       0.78      0.82      0.80       982\n",
            "        5.0       0.90      0.56      0.69       892\n",
            "        6.0       0.74      0.93      0.82       958\n",
            "        7.0       0.91      0.87      0.89      1028\n",
            "        8.0       0.80      0.80      0.80       974\n",
            "        9.0       0.77      0.83      0.80      1009\n",
            "\n",
            "avg / total       0.84      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 869    3    4    4    2   20   67    2    8    1]\n",
            " [   0 1119    0    4    0    0    2    1    9    0]\n",
            " [  10  101  671   23   27    0   77   45   75    3]\n",
            " [   3   32   11  877    5   16   11   11   32   12]\n",
            " [   1   13    0    0  802    0   28    0    5  133]\n",
            " [   7   40    2  162   28  496   93   10   34   20]\n",
            " [   8   22    1    0   25    4  889    1    6    2]\n",
            " [   1   42   10    3   25    2    3  890   11   41]\n",
            " [   5   20    3   64   13   10   25   12  779   43]\n",
            " [   9   13    3   15  107    2    8    8   10  834]]\n",
            "--------------------------------\n",
            "val predicted: (59730,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59730, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [23 39 23 33 24 23 33 25 34 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.688 s \n",
            "\n",
            "Accuracy rate for 82.440000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.87      0.91       980\n",
            "        1.0       0.81      0.99      0.89      1135\n",
            "        2.0       0.95      0.67      0.78      1032\n",
            "        3.0       0.74      0.89      0.81      1010\n",
            "        4.0       0.79      0.80      0.80       982\n",
            "        5.0       0.91      0.55      0.68       892\n",
            "        6.0       0.74      0.94      0.83       958\n",
            "        7.0       0.91      0.85      0.88      1028\n",
            "        8.0       0.80      0.81      0.80       974\n",
            "        9.0       0.77      0.83      0.80      1009\n",
            "\n",
            "avg / total       0.84      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 856    3    3    5    2   23   71    1   16    0]\n",
            " [   0 1118    0    4    0    0    3    1    9    0]\n",
            " [   8   93  689   27   22    0   76   35   79    3]\n",
            " [   2   23    8  902    3    9   15   13   24   11]\n",
            " [   1   11    3    0  790    0   34    2    9  132]\n",
            " [   6   42    1  192   27  487   72   10   33   22]\n",
            " [   7   10    1    2   24    3  904    1    5    1]\n",
            " [   1   46   15    3   22    1    4  878    7   51]\n",
            " [   9   21    4   67   11   10   28   11  785   28]\n",
            " [   8   15    3   15   96    4   11   10   12  835]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59720,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59720, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [23 39 24 34 25 24 34 28 35 24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.792 s \n",
            "\n",
            "Accuracy rate for 82.750000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.89      0.92       980\n",
            "        1.0       0.82      0.99      0.89      1135\n",
            "        2.0       0.94      0.67      0.78      1032\n",
            "        3.0       0.74      0.90      0.81      1010\n",
            "        4.0       0.77      0.82      0.79       982\n",
            "        5.0       0.92      0.55      0.69       892\n",
            "        6.0       0.77      0.93      0.84       958\n",
            "        7.0       0.90      0.86      0.88      1028\n",
            "        8.0       0.80      0.82      0.81       974\n",
            "        9.0       0.79      0.80      0.80      1009\n",
            "\n",
            "avg / total       0.84      0.83      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 868    2    3    6    3   19   60    3   16    0]\n",
            " [   0 1118    0    4    0    0    3    1    9    0]\n",
            " [   9   83  694   35   19    0   67   41   81    3]\n",
            " [   3   18   11  910    5   10   10   12   25    6]\n",
            " [   1   14    2    0  808    0   31    2   10  114]\n",
            " [   6   39    3  194   36  489   62   14   35   14]\n",
            " [   6   16    2    2   27    4  895    1    4    1]\n",
            " [   1   45   15    2   20    0    1  885   12   47]\n",
            " [   5   19    3   67    8    6   27   11  800   28]\n",
            " [   9   12    5   14  130    1    6   11   13  808]]\n",
            "--------------------------------\n",
            "val predicted: (59710,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59710, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [23 41 25 35 28 25 34 29 35 25] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.791 s \n",
            "\n",
            "Accuracy rate for 82.920000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.86      0.91       980\n",
            "        1.0       0.82      0.99      0.90      1135\n",
            "        2.0       0.94      0.70      0.81      1032\n",
            "        3.0       0.76      0.90      0.82      1010\n",
            "        4.0       0.76      0.83      0.80       982\n",
            "        5.0       0.90      0.56      0.69       892\n",
            "        6.0       0.76      0.92      0.84       958\n",
            "        7.0       0.91      0.86      0.88      1028\n",
            "        8.0       0.81      0.81      0.81       974\n",
            "        9.0       0.78      0.80      0.79      1009\n",
            "\n",
            "avg / total       0.84      0.83      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 843    2    4    5    4   31   71    5   14    1]\n",
            " [   0 1119    0    4    0    0    5    1    6    0]\n",
            " [  10   80  727   32   24    0   48   37   72    2]\n",
            " [   2   17   11  911    2    8   10   12   27   10]\n",
            " [   0   15    2    0  819    0   28    1    5  112]\n",
            " [   3   32    3  174   29  501   76   13   33   28]\n",
            " [   6   15    2    3   35    5  886    1    4    1]\n",
            " [   1   46   16    0   25    0    2  886   11   41]\n",
            " [   6   19    4   62   14   12   26    9  790   32]\n",
            " [   7   15    5   14  121    2    7   14   14  810]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 8. ... 9. 9. 7.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 8 ... 9 9 7]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [24 41 26 35 29 25 35 31 35 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.924 s \n",
            "\n",
            "Accuracy rate for 83.760000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.91      0.93       980\n",
            "        1.0       0.83      0.99      0.90      1135\n",
            "        2.0       0.92      0.74      0.82      1032\n",
            "        3.0       0.76      0.89      0.82      1010\n",
            "        4.0       0.78      0.81      0.80       982\n",
            "        5.0       0.93      0.60      0.73       892\n",
            "        6.0       0.78      0.93      0.85       958\n",
            "        7.0       0.91      0.86      0.88      1028\n",
            "        8.0       0.84      0.79      0.81       974\n",
            "        9.0       0.76      0.83      0.80      1009\n",
            "\n",
            "avg / total       0.85      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 891    2    2    4    3   11   53    4   10    0]\n",
            " [   0 1119    1    3    0    0    4    1    7    0]\n",
            " [   9   70  759   33   19    0   44   32   61    5]\n",
            " [   5   18   15  900    5   10   11   14   19   13]\n",
            " [   1   13    4    0  800    0   31    1    7  125]\n",
            " [   6   35    3  157   30  533   67   10   26   25]\n",
            " [   6   16    3    1   34    5  888    1    3    1]\n",
            " [   1   49   18    1   22    1    3  879    6   48]\n",
            " [   3   20    7   70   13   11   27   11  770   42]\n",
            " [   6   11    9   16   99    3    6   12   10  837]]\n",
            "--------------------------------\n",
            "val predicted: (59690,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59690, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [24 42 27 36 30 26 36 32 37 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.006 s \n",
            "\n",
            "Accuracy rate for 83.510000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.90      0.93       980\n",
            "        1.0       0.83      0.98      0.90      1135\n",
            "        2.0       0.92      0.74      0.82      1032\n",
            "        3.0       0.77      0.88      0.82      1010\n",
            "        4.0       0.80      0.80      0.80       982\n",
            "        5.0       0.93      0.58      0.71       892\n",
            "        6.0       0.78      0.92      0.84       958\n",
            "        7.0       0.90      0.85      0.88      1028\n",
            "        8.0       0.80      0.81      0.81       974\n",
            "        9.0       0.76      0.85      0.81      1009\n",
            "\n",
            "avg / total       0.84      0.84      0.83     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 878    2    7    3    1   12   60    5   12    0]\n",
            " [   0 1115    1    3    0    0    4    1   11    0]\n",
            " [   9   71  762   28   22    0   35   32   68    5]\n",
            " [   2   16   17  891    5    7   13   13   37    9]\n",
            " [   1   12    5    0  790    0   30    1    8  135]\n",
            " [   4   35    6  155   30  514   72   16   28   32]\n",
            " [   7   18    6    3   31    7  879    0    6    1]\n",
            " [   1   41   19    0   25    0    4  876   10   52]\n",
            " [   6   16    4   66   12   11   30   11  786   32]\n",
            " [  10   10    4   13   77    2    6   15   12  860]]\n",
            "--------------------------------\n",
            "val predicted: (59680,) [0. 0. 8. ... 9. 9. 7.]\n",
            "probabilities: (59680, 10) \n",
            " [0 0 8 ... 9 9 7]\n",
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [25 43 29 38 30 28 37 32 38 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.982 s \n",
            "\n",
            "Accuracy rate for 85.050000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.92      0.94       980\n",
            "        1.0       0.84      0.99      0.91      1135\n",
            "        2.0       0.93      0.77      0.84      1032\n",
            "        3.0       0.78      0.90      0.84      1010\n",
            "        4.0       0.81      0.81      0.81       982\n",
            "        5.0       0.94      0.65      0.77       892\n",
            "        6.0       0.80      0.93      0.86       958\n",
            "        7.0       0.92      0.86      0.89      1028\n",
            "        8.0       0.83      0.80      0.82       974\n",
            "        9.0       0.77      0.85      0.81      1009\n",
            "\n",
            "avg / total       0.86      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 905    3    3    2    1    8   46    4    8    0]\n",
            " [   0 1118    1    3    0    0    3    1    9    0]\n",
            " [   9   55  793   26   19    1   35   32   56    6]\n",
            " [   4   14   13  907    5    9   12   10   26   10]\n",
            " [   1   14    4    0  794    0   32    0    7  130]\n",
            " [   5   41    3  123   29  577   60    7   23   24]\n",
            " [   6   17    5    2   24    8  890    1    4    1]\n",
            " [   1   43   16    3   19    0    2  882   14   48]\n",
            " [   1   14    6   78   11   11   29    9  781   34]\n",
            " [   8   11    5   14   82    2    6    9   14  858]]\n",
            "--------------------------------\n",
            "val predicted: (59670,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59670, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [30 43 30 39 30 29 39 32 38 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.948 s \n",
            "\n",
            "Accuracy rate for 85.510000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.94      0.94       980\n",
            "        1.0       0.85      0.99      0.91      1135\n",
            "        2.0       0.94      0.78      0.85      1032\n",
            "        3.0       0.79      0.88      0.83      1010\n",
            "        4.0       0.82      0.81      0.82       982\n",
            "        5.0       0.93      0.65      0.77       892\n",
            "        6.0       0.82      0.93      0.87       958\n",
            "        7.0       0.91      0.86      0.89      1028\n",
            "        8.0       0.84      0.82      0.83       974\n",
            "        9.0       0.78      0.85      0.81      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 922    1    3    0    3   11   31    4    5    0]\n",
            " [   0 1119    1    3    0    0    3    1    8    0]\n",
            " [  13   47  809   24   21    0   41   34   39    4]\n",
            " [   6   15   17  893    3   12   11   10   33   10]\n",
            " [   1   15    3    0  798    0   33    2    8  122]\n",
            " [  15   35    2  130   25  579   44    9   30   23]\n",
            " [   9   15    1    1   24    8  891    2    4    3]\n",
            " [   1   42   20    2   17    1    2  882   11   50]\n",
            " [   7   15    4   65   10    7   27    8  796   35]\n",
            " [   7   11    4   17   72    2    8   12   14  862]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59660, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [30 44 30 40 30 31 40 33 40 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.038 s \n",
            "\n",
            "Accuracy rate for 85.130000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.94      0.94       980\n",
            "        1.0       0.84      0.99      0.91      1135\n",
            "        2.0       0.94      0.78      0.85      1032\n",
            "        3.0       0.81      0.87      0.84      1010\n",
            "        4.0       0.82      0.80      0.81       982\n",
            "        5.0       0.93      0.65      0.77       892\n",
            "        6.0       0.80      0.93      0.86       958\n",
            "        7.0       0.92      0.84      0.88      1028\n",
            "        8.0       0.84      0.81      0.83       974\n",
            "        9.0       0.75      0.87      0.80      1009\n",
            "\n",
            "avg / total       0.86      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 922    1    4    3    2    6   33    2    7    0]\n",
            " [   0 1119    1    3    0    0    3    0    9    0]\n",
            " [  11   48  801   26   24    0   43   31   41    7]\n",
            " [   7   20   17  883    2   17   12   14   26   12]\n",
            " [   1   14    2    0  787    0   29    1    9  139]\n",
            " [  13   36    1   97   27  580   65    9   31   33]\n",
            " [   9   17    2    2   22    7  893    0    6    0]\n",
            " [   1   47   18    1   24    0    2  861    7   67]\n",
            " [   4   18    6   57   14    7   29    8  791   40]\n",
            " [   7   11    4   15   63    4    7   10   12  876]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [33 44 30 41 31 32 40 33 42 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.115 s \n",
            "\n",
            "Accuracy rate for 86.020000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.95      0.95       980\n",
            "        1.0       0.86      0.99      0.92      1135\n",
            "        2.0       0.94      0.80      0.86      1032\n",
            "        3.0       0.83      0.88      0.85      1010\n",
            "        4.0       0.85      0.78      0.81       982\n",
            "        5.0       0.92      0.72      0.81       892\n",
            "        6.0       0.83      0.93      0.88       958\n",
            "        7.0       0.94      0.82      0.88      1028\n",
            "        8.0       0.83      0.82      0.82       974\n",
            "        9.0       0.73      0.89      0.80      1009\n",
            "\n",
            "avg / total       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 934    2    2    1    1   10   21    1    6    2]\n",
            " [   0 1118    2    2    0    0    4    0    9    0]\n",
            " [  11   37  823   26   20    1   31   31   45    7]\n",
            " [   7   12   21  886    1   17    9    8   35   14]\n",
            " [   1   12    2    0  766    1   32    2    7  159]\n",
            " [  12   35    1   77   21  646   47    4   23   26]\n",
            " [  14   16    3    1   18    8  888    0    9    1]\n",
            " [   1   40   15    1   18    3    2  848   17   83]\n",
            " [   5   16    4   57    9   14   25    6  798   40]\n",
            " [   6   11    5   13   49    5    7    6   12  895]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59640, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [34 46 31 41 33 32 41 34 42 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.192 s \n",
            "\n",
            "Accuracy rate for 86.020000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.95      0.94       980\n",
            "        1.0       0.85      0.99      0.91      1135\n",
            "        2.0       0.93      0.79      0.86      1032\n",
            "        3.0       0.83      0.87      0.85      1010\n",
            "        4.0       0.84      0.82      0.83       982\n",
            "        5.0       0.92      0.70      0.79       892\n",
            "        6.0       0.85      0.92      0.88       958\n",
            "        7.0       0.94      0.83      0.88      1028\n",
            "        8.0       0.82      0.82      0.82       974\n",
            "        9.0       0.75      0.89      0.81      1009\n",
            "\n",
            "avg / total       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 929    1    6    1    2   11   20    2    8    0]\n",
            " [   0 1121    2    2    0    0    2    0    8    0]\n",
            " [  10   41  815   19   24    0   29   30   54   10]\n",
            " [   9   20   19  878    1   20    7    6   37   13]\n",
            " [   1   11    2    0  804    0   23    0   10  131]\n",
            " [  14   40    2   90   25  623   39    7   29   23]\n",
            " [  14   20    3    1   23    6  881    0    9    1]\n",
            " [   3   39   18    2   20    3    1  856   11   75]\n",
            " [   4   16    3   56    8   13   26    5  800   43]\n",
            " [  11   11    4   13   50    2    6    5   12  895]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59630,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59630, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [34 47 31 43 33 33 43 35 42 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.208 s \n",
            "\n",
            "Accuracy rate for 86.500000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.95      0.95       980\n",
            "        1.0       0.86      0.99      0.92      1135\n",
            "        2.0       0.94      0.78      0.85      1032\n",
            "        3.0       0.83      0.89      0.86      1010\n",
            "        4.0       0.89      0.80      0.84       982\n",
            "        5.0       0.92      0.72      0.81       892\n",
            "        6.0       0.84      0.94      0.88       958\n",
            "        7.0       0.94      0.82      0.88      1028\n",
            "        8.0       0.86      0.81      0.83       974\n",
            "        9.0       0.73      0.92      0.81      1009\n",
            "\n",
            "avg / total       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 935    0    3    1    1   11   20    1    7    1]\n",
            " [   0 1118    2    2    0    0    4    0    9    0]\n",
            " [  10   42  808   29   19    0   41   25   46   12]\n",
            " [   7   11   18  903    1   15    8    8   28   11]\n",
            " [   1   13    2    0  788    1   24    0    5  148]\n",
            " [  16   37    4   77   14  642   44    9   17   32]\n",
            " [  11   16    2    1   18    8  898    0    4    0]\n",
            " [   1   42   15    2   10    3    1  848   10   96]\n",
            " [   3   16    5   62    8   11   28    6  786   49]\n",
            " [   7    9    4   17   25    6    5    7    5  924]]\n",
            "--------------------------------\n",
            "val predicted: (59620,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59620, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [36 47 31 47 34 33 44 37 42 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.198 s \n",
            "\n",
            "Accuracy rate for 86.090000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.95      0.94       980\n",
            "        1.0       0.87      0.99      0.92      1135\n",
            "        2.0       0.95      0.76      0.84      1032\n",
            "        3.0       0.80      0.89      0.85      1010\n",
            "        4.0       0.86      0.81      0.84       982\n",
            "        5.0       0.92      0.69      0.79       892\n",
            "        6.0       0.82      0.94      0.88       958\n",
            "        7.0       0.92      0.84      0.88      1028\n",
            "        8.0       0.85      0.81      0.83       974\n",
            "        9.0       0.74      0.90      0.81      1009\n",
            "\n",
            "avg / total       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 932    1    3    1    2   13   20    2    6    0]\n",
            " [   0 1120    1    3    0    0    5    0    6    0]\n",
            " [  13   39  787   36   21    1   48   34   42   11]\n",
            " [   8   12   12  903    2   18   10    8   24   13]\n",
            " [   1   11    1    0  799    0   28    2    6  134]\n",
            " [  16   35    2   97   25  612   44   10   25   26]\n",
            " [  11   13    3    1   17    6  899    0    8    0]\n",
            " [   1   35   15    3   16    2    0  863   11   82]\n",
            " [   5   11    5   65    8   10   28    6  790   46]\n",
            " [   8   10    3   18   38    1    8   12    7  904]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59610, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [39 48 31 48 34 35 45 37 42 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.193 s \n",
            "\n",
            "Accuracy rate for 85.830000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.96      0.94       980\n",
            "        1.0       0.85      0.99      0.91      1135\n",
            "        2.0       0.94      0.73      0.82      1032\n",
            "        3.0       0.79      0.89      0.84      1010\n",
            "        4.0       0.88      0.81      0.84       982\n",
            "        5.0       0.94      0.68      0.79       892\n",
            "        6.0       0.82      0.94      0.87       958\n",
            "        7.0       0.93      0.84      0.88      1028\n",
            "        8.0       0.86      0.80      0.83       974\n",
            "        9.0       0.74      0.92      0.82      1009\n",
            "\n",
            "avg / total       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    3    3    1    1    6   17    3    5    1]\n",
            " [   0 1121    1    3    0    0    4    0    6    0]\n",
            " [  12   62  750   40   22    0   54   26   56   10]\n",
            " [   9   13   14  900    2   15   15    6   21   15]\n",
            " [   1    9    1    0  798    0   26    2    5  140]\n",
            " [  17   38    4   99   25  607   48    6   18   30]\n",
            " [  15   10    2    2   18    6  899    0    5    1]\n",
            " [   3   41   13    4   13    2    1  864   11   76]\n",
            " [   7   15    4   67    7    9   30    6  780   49]\n",
            " [   8   10    4   17   22    1    6   13    4  924]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [39 49 32 49 36 35 45 40 43 42] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.295 s \n",
            "\n",
            "Accuracy rate for 86.900000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.96      0.94       980\n",
            "        1.0       0.87      0.99      0.92      1135\n",
            "        2.0       0.93      0.79      0.86      1032\n",
            "        3.0       0.82      0.88      0.85      1010\n",
            "        4.0       0.89      0.85      0.87       982\n",
            "        5.0       0.92      0.71      0.80       892\n",
            "        6.0       0.83      0.93      0.88       958\n",
            "        7.0       0.92      0.84      0.88      1028\n",
            "        8.0       0.86      0.80      0.83       974\n",
            "        9.0       0.76      0.91      0.83      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    1    3    1    0   10   17    1    5    1]\n",
            " [   0 1118    1    3    0    0    4    0    9    0]\n",
            " [  11   37  818   28   16    0   39   28   41   14]\n",
            " [  10   11   17  893    1   21   12   10   23   12]\n",
            " [   1    8    2    0  833    0   24    3    6  105]\n",
            " [  19   29    3   82   21  633   49    8   18   30]\n",
            " [  17   10    3    0   20    6  894    0    7    1]\n",
            " [   2   41   23    4   13    0    3  863    8   71]\n",
            " [   6   20    6   62    8   13   28    6  775   50]\n",
            " [   7    9    3   15   24    3    8   14    4  922]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59590, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [40 51 32 50 38 36 45 41 44 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.299 s \n",
            "\n",
            "Accuracy rate for 86.460000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.96      0.94       980\n",
            "        1.0       0.87      0.98      0.92      1135\n",
            "        2.0       0.94      0.78      0.85      1032\n",
            "        3.0       0.82      0.89      0.85      1010\n",
            "        4.0       0.86      0.81      0.84       982\n",
            "        5.0       0.93      0.71      0.81       892\n",
            "        6.0       0.84      0.94      0.89       958\n",
            "        7.0       0.93      0.84      0.88      1028\n",
            "        8.0       0.85      0.81      0.83       974\n",
            "        9.0       0.75      0.90      0.82      1009\n",
            "\n",
            "avg / total       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 939    2    2    1    2    8   17    3    5    1]\n",
            " [   0 1114    1    3    0    0    5    1   11    0]\n",
            " [  10   40  810   28   23    0   40   26   43   12]\n",
            " [  11   13   17  901    1   15   11    6   21   14]\n",
            " [   1    8    2    0  797    0   31    4   10  129]\n",
            " [  20   26    1   88   25  635   36   11   24   26]\n",
            " [  17   10    3    1   19    4  898    0    6    0]\n",
            " [   1   45   20    4   12    1    1  859   14   71]\n",
            " [   6   14    5   60    7   12   25    8  786   51]\n",
            " [   6   10    3   17   37    6    7   10    6  907]]\n",
            "--------------------------------\n",
            "val predicted: (59580,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59580, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [40 52 34 51 38 37 46 42 45 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.324 s \n",
            "\n",
            "Accuracy rate for 86.380000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.96      0.95       980\n",
            "        1.0       0.88      0.98      0.93      1135\n",
            "        2.0       0.95      0.78      0.85      1032\n",
            "        3.0       0.82      0.89      0.85      1010\n",
            "        4.0       0.87      0.81      0.84       982\n",
            "        5.0       0.93      0.72      0.81       892\n",
            "        6.0       0.82      0.94      0.88       958\n",
            "        7.0       0.92      0.84      0.88      1028\n",
            "        8.0       0.85      0.81      0.83       974\n",
            "        9.0       0.73      0.90      0.81      1009\n",
            "\n",
            "avg / total       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    1    2    1    2    8   17    4    7    1]\n",
            " [   0 1117    1    3    0    0    4    1    9    0]\n",
            " [   9   36  801   29   20    1   52   28   41   15]\n",
            " [   8   13   13  899    1   18   14    9   19   16]\n",
            " [   1    7    1    0  792    0   30    1   12  138]\n",
            " [  20   24    2   84   19  642   37    7   22   35]\n",
            " [  15    7    3    2   20    6  897    1    6    1]\n",
            " [   1   38   17    5   15    0    3  860   19   70]\n",
            " [   5   15    4   59    7   11   27    5  787   54]\n",
            " [   6    9    3   15   35    4    7   15    9  906]]\n",
            "--------------------------------\n",
            "val predicted: (59570,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59570, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [40 53 36 53 40 38 46 43 46 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.383 s \n",
            "\n",
            "Accuracy rate for 86.880000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.96      0.95       980\n",
            "        1.0       0.88      0.98      0.93      1135\n",
            "        2.0       0.93      0.79      0.86      1032\n",
            "        3.0       0.83      0.89      0.86      1010\n",
            "        4.0       0.86      0.83      0.85       982\n",
            "        5.0       0.92      0.73      0.82       892\n",
            "        6.0       0.85      0.94      0.89       958\n",
            "        7.0       0.92      0.84      0.88      1028\n",
            "        8.0       0.86      0.80      0.83       974\n",
            "        9.0       0.75      0.90      0.82      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    1    1    1    2   11   14    2    5    1]\n",
            " [   0 1116    1    3    0    0    4    1   10    0]\n",
            " [  11   33  818   33   21    1   37   29   34   15]\n",
            " [  12   13   16  896    2   15    9   10   21   16]\n",
            " [   1    8    2    0  818    0   28    3   10  112]\n",
            " [  19   21    1   76   21  652   35   10   21   36]\n",
            " [  17    8    4    1   20    5  897    1    5    0]\n",
            " [   1   38   26    2   13    2    2  860   12   72]\n",
            " [   3   18    5   57    9   14   24    8  779   57]\n",
            " [   4   10    3   14   40    5    6   12    5  910]]\n",
            "--------------------------------\n",
            "val predicted: (59560,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59560, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [40 54 37 53 41 39 47 44 48 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.461 s \n",
            "\n",
            "Accuracy rate for 87.090000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.96      0.95       980\n",
            "        1.0       0.88      0.99      0.93      1135\n",
            "        2.0       0.94      0.79      0.86      1032\n",
            "        3.0       0.84      0.89      0.87      1010\n",
            "        4.0       0.87      0.84      0.85       982\n",
            "        5.0       0.92      0.75      0.83       892\n",
            "        6.0       0.86      0.93      0.89       958\n",
            "        7.0       0.93      0.83      0.87      1028\n",
            "        8.0       0.83      0.82      0.83       974\n",
            "        9.0       0.75      0.89      0.82      1009\n",
            "\n",
            "avg / total       0.88      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    1    2    1    2    8   14    2    8    1]\n",
            " [   0 1120    1    3    0    0    3    0    8    0]\n",
            " [  12   37  813   28   14    1   41   28   44   14]\n",
            " [   8   11   13  900    2   24    5    9   23   15]\n",
            " [   1    9    2    0  821    0   27    2   12  108]\n",
            " [  16   24    2   68   20  670   31    6   25   30]\n",
            " [  19    8    3    1   19    7  894    0    6    1]\n",
            " [   1   36   23    2   14    2    2  850   22   76]\n",
            " [   2   22    5   51    7   13   21    5  798   50]\n",
            " [   6   10    3   13   40    3    7   14   11  902]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [44 54 40 53 41 40 47 46 48 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.464 s \n",
            "\n",
            "Accuracy rate for 87.870000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.96      0.94       980\n",
            "        1.0       0.89      0.98      0.93      1135\n",
            "        2.0       0.94      0.83      0.88      1032\n",
            "        3.0       0.84      0.89      0.87      1010\n",
            "        4.0       0.88      0.83      0.85       982\n",
            "        5.0       0.92      0.76      0.83       892\n",
            "        6.0       0.87      0.94      0.90       958\n",
            "        7.0       0.93      0.86      0.89      1028\n",
            "        8.0       0.86      0.82      0.84       974\n",
            "        9.0       0.77      0.90      0.83      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    1    2    1    1    8   13    2    7    1]\n",
            " [   0 1116    2    2    0    0    4    1   10    0]\n",
            " [  12   24  859   22   16    0   28   29   33    9]\n",
            " [  12    9   13  900    1   22    5   10   22   16]\n",
            " [   1   11    3    0  812    2   26    2   16  109]\n",
            " [  21   22    2   70   20  674   27    8   18   30]\n",
            " [  20   10    2    1   18    7  896    0    4    0]\n",
            " [   1   41   24    4   11    2    1  880    8   56]\n",
            " [   4   17    5   56    7   11   21    5  796   52]\n",
            " [   6   10    5   14   34    6    4   13    7  910]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59540,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59540, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [44 55 41 54 43 40 48 47 49 49] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.461 s \n",
            "\n",
            "Accuracy rate for 87.470000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.96      0.95       980\n",
            "        1.0       0.89      0.99      0.93      1135\n",
            "        2.0       0.93      0.83      0.88      1032\n",
            "        3.0       0.83      0.88      0.86      1010\n",
            "        4.0       0.86      0.84      0.85       982\n",
            "        5.0       0.92      0.73      0.82       892\n",
            "        6.0       0.88      0.92      0.90       958\n",
            "        7.0       0.94      0.84      0.89      1028\n",
            "        8.0       0.85      0.82      0.84       974\n",
            "        9.0       0.76      0.90      0.83      1009\n",
            "\n",
            "avg / total       0.88      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 945    0    2    1    2    7   13    1    7    2]\n",
            " [   0 1118    1    3    0    0    4    1    7    1]\n",
            " [  11   25  859   24   20    1   28   25   31    8]\n",
            " [  12    9   20  891    2   20    4   10   25   17]\n",
            " [   1   11    4    0  826    0   19    0   14  107]\n",
            " [  20   23    0   85   22  654   28    6   23   31]\n",
            " [  20    9    4    1   23    9  880    1   11    0]\n",
            " [   2   36   27    2   14    2    1  866   13   65]\n",
            " [   4   22    5   51    6   13   18    6  800   49]\n",
            " [   5    9    3   11   45    5    6    8    9  908]]\n",
            "--------------------------------\n",
            "val predicted: (59530,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59530, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [45 56 41 56 43 41 51 49 49 49] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.574 s \n",
            "\n",
            "Accuracy rate for 87.590000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.96      0.94       980\n",
            "        1.0       0.89      0.99      0.94      1135\n",
            "        2.0       0.93      0.83      0.88      1032\n",
            "        3.0       0.82      0.89      0.85      1010\n",
            "        4.0       0.88      0.82      0.85       982\n",
            "        5.0       0.91      0.75      0.82       892\n",
            "        6.0       0.87      0.93      0.89       958\n",
            "        7.0       0.92      0.85      0.89      1028\n",
            "        8.0       0.87      0.81      0.84       974\n",
            "        9.0       0.78      0.90      0.83      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    1    0    1    3   11   15    2    7    0]\n",
            " [   0 1120    2    2    0    0    4    1    6    0]\n",
            " [   9   21  856   34   16    0   31   29   27    9]\n",
            " [  12   10   15  903    1   19    5    8   22   15]\n",
            " [   1   10    3    1  810    1   31    4   11  110]\n",
            " [  19   23    2   89   20  665   26    9   19   20]\n",
            " [  17   10    3    1   15   12  887    2   11    0]\n",
            " [   4   32   29    2   13    2    1  877   11   57]\n",
            " [   4   17    6   57    7   11   21    8  790   53]\n",
            " [   5    8    5   14   39    6    4    9    8  911]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59520, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [46 57 41 58 44 42 52 51 49 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.524 s \n",
            "\n",
            "Accuracy rate for 87.740000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.96      0.95       980\n",
            "        1.0       0.90      0.99      0.94      1135\n",
            "        2.0       0.94      0.83      0.88      1032\n",
            "        3.0       0.81      0.90      0.85      1010\n",
            "        4.0       0.88      0.84      0.86       982\n",
            "        5.0       0.92      0.73      0.82       892\n",
            "        6.0       0.88      0.93      0.90       958\n",
            "        7.0       0.92      0.86      0.89      1028\n",
            "        8.0       0.86      0.81      0.84       974\n",
            "        9.0       0.78      0.89      0.83      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    1    1    1    1    4   17    3    9    1]\n",
            " [   0 1119    1    3    0    0    4    1    7    0]\n",
            " [  10   17  854   36   16    1   19   32   38    9]\n",
            " [   9    9   15  907    1   20    3    8   23   15]\n",
            " [   1    8    3    1  828    1   25    4   15   96]\n",
            " [  18   25    3   90   19  655   28   10   17   27]\n",
            " [  17    8    3    4   15    9  891    3    8    0]\n",
            " [   2   32   22    3   13    0    1  885    9   61]\n",
            " [   3   19    6   57    6   15   21    8  793   46]\n",
            " [   7    9    5   13   44    7    5   13    6  900]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59510, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [49 59 41 61 44 42 53 51 50 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.573 s \n",
            "\n",
            "Accuracy rate for 87.780000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.96      0.95       980\n",
            "        1.0       0.89      0.99      0.94      1135\n",
            "        2.0       0.94      0.81      0.87      1032\n",
            "        3.0       0.80      0.91      0.85      1010\n",
            "        4.0       0.88      0.86      0.87       982\n",
            "        5.0       0.94      0.73      0.82       892\n",
            "        6.0       0.87      0.93      0.90       958\n",
            "        7.0       0.92      0.87      0.89      1028\n",
            "        8.0       0.86      0.81      0.83       974\n",
            "        9.0       0.80      0.89      0.84      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    2    0    2    1    9   14    3    7    0]\n",
            " [   0 1121    1    3    0    0    4    1    5    0]\n",
            " [  10   27  835   39   14    0   31   33   35    8]\n",
            " [   6    8   14  917    1   12    4   11   25   12]\n",
            " [   1    9    2    0  843    0   26    3   13   85]\n",
            " [  19   24    2  103   21  651   27    5   16   24]\n",
            " [  18   10    2    3   20    7  890    2    5    1]\n",
            " [   2   28   22    4   12    0    2  891   11   56]\n",
            " [   4   24    6   61    9   11   21    6  787   45]\n",
            " [  10    8    3   13   41    4    4   17    8  901]]\n",
            "--------------------------------\n",
            "final active learning accuracies [36.01, 43.34, 53.94, 58.02, 60.97, 66.44, 68.63, 70.8, 72.08, 73.58, 73.63, 74.0, 74.2, 75.52, 75.41, 75.81, 75.98, 77.97, 77.5, 80.15, 79.81, 81.13, 80.87, 80.58999999999999, 80.86, 81.26, 82.26, 82.44, 82.75, 82.92, 83.76, 83.50999999999999, 85.05, 85.50999999999999, 85.13, 86.02, 86.02, 86.5, 86.09, 85.83, 86.9, 86.46000000000001, 86.38, 86.88, 87.09, 87.87, 87.47, 87.59, 87.74, 87.78]\n",
            "saved Active-learning-experiment-20.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "{\n",
            "  \"RfModel\": {\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          36.01,\n",
            "          43.34,\n",
            "          53.94,\n",
            "          58.02,\n",
            "          60.97,\n",
            "          66.44,\n",
            "          68.63,\n",
            "          70.8,\n",
            "          72.08,\n",
            "          73.58,\n",
            "          73.63,\n",
            "          74.0,\n",
            "          74.2,\n",
            "          75.52,\n",
            "          75.41,\n",
            "          75.81,\n",
            "          75.98,\n",
            "          77.97,\n",
            "          77.5,\n",
            "          80.15,\n",
            "          79.81,\n",
            "          81.13,\n",
            "          80.87,\n",
            "          80.58999999999999,\n",
            "          80.86,\n",
            "          81.26,\n",
            "          82.26,\n",
            "          82.44,\n",
            "          82.75,\n",
            "          82.92,\n",
            "          83.76,\n",
            "          83.50999999999999,\n",
            "          85.05,\n",
            "          85.50999999999999,\n",
            "          85.13,\n",
            "          86.02,\n",
            "          86.02,\n",
            "          86.5,\n",
            "          86.09,\n",
            "          85.83,\n",
            "          86.9,\n",
            "          86.46000000000001,\n",
            "          86.38,\n",
            "          86.88,\n",
            "          87.09,\n",
            "          87.87,\n",
            "          87.47,\n",
            "          87.59,\n",
            "          87.74,\n",
            "          87.78\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.64,\n",
            "          60.72,\n",
            "          65.45,\n",
            "          70.28999999999999,\n",
            "          72.94,\n",
            "          76.08,\n",
            "          77.51,\n",
            "          77.78,\n",
            "          79.35,\n",
            "          80.39,\n",
            "          81.6,\n",
            "          81.17,\n",
            "          82.73,\n",
            "          84.28,\n",
            "          84.15,\n",
            "          85.2,\n",
            "          86.13,\n",
            "          86.78,\n",
            "          86.95,\n",
            "          87.59\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          56.86,\n",
            "          69.43,\n",
            "          71.87,\n",
            "          75.68,\n",
            "          80.01,\n",
            "          82.06,\n",
            "          84.5,\n",
            "          85.92,\n",
            "          86.76,\n",
            "          87.32\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.5,\n",
            "          82.39,\n",
            "          85.76,\n",
            "          87.56\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.19,\n",
            "          88.14999999999999\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"SvmModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          35.93,\n",
            "          35.97,\n",
            "          40.33,\n",
            "          39.39,\n",
            "          41.349999999999994,\n",
            "          42.99,\n",
            "          46.23,\n",
            "          46.18,\n",
            "          47.260000000000005,\n",
            "          52.5,\n",
            "          52.400000000000006,\n",
            "          51.25999999999999,\n",
            "          51.690000000000005,\n",
            "          51.800000000000004,\n",
            "          53.18000000000001,\n",
            "          53.82,\n",
            "          55.88999999999999,\n",
            "          56.120000000000005,\n",
            "          57.269999999999996,\n",
            "          59.41,\n",
            "          59.95,\n",
            "          62.629999999999995,\n",
            "          61.339999999999996,\n",
            "          63.88,\n",
            "          65.34,\n",
            "          65.77,\n",
            "          66.9,\n",
            "          67.96,\n",
            "          68.27,\n",
            "          67.44,\n",
            "          68.45,\n",
            "          68.63,\n",
            "          68.0,\n",
            "          68.47,\n",
            "          68.77,\n",
            "          68.8,\n",
            "          69.17,\n",
            "          68.97,\n",
            "          69.33,\n",
            "          69.67999999999999,\n",
            "          69.95,\n",
            "          70.34,\n",
            "          70.47,\n",
            "          71.19,\n",
            "          71.97,\n",
            "          72.26,\n",
            "          72.06,\n",
            "          71.98,\n",
            "          72.55,\n",
            "          72.78999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          50.33,\n",
            "          51.59,\n",
            "          56.599999999999994,\n",
            "          60.24,\n",
            "          61.57,\n",
            "          63.5,\n",
            "          66.74,\n",
            "          68.19,\n",
            "          68.02,\n",
            "          69.8,\n",
            "          75.88000000000001,\n",
            "          77.24,\n",
            "          78.09,\n",
            "          79.38,\n",
            "          80.4,\n",
            "          80.99,\n",
            "          80.28999999999999,\n",
            "          80.12,\n",
            "          79.75999999999999,\n",
            "          80.36999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          64.55,\n",
            "          68.75,\n",
            "          71.34,\n",
            "          74.11999999999999,\n",
            "          75.96000000000001,\n",
            "          77.03999999999999,\n",
            "          76.85,\n",
            "          79.19,\n",
            "          80.51,\n",
            "          80.99\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          78.4,\n",
            "          78.21000000000001,\n",
            "          80.08,\n",
            "          81.0\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.11,\n",
            "          84.53\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.86,\n",
            "          37.6,\n",
            "          46.23,\n",
            "          58.41,\n",
            "          60.34,\n",
            "          65.98,\n",
            "          65.01,\n",
            "          69.86,\n",
            "          72.28999999999999,\n",
            "          74.65,\n",
            "          76.24,\n",
            "          77.37,\n",
            "          77.59,\n",
            "          78.7,\n",
            "          79.06,\n",
            "          80.06,\n",
            "          81.21000000000001,\n",
            "          82.32000000000001,\n",
            "          83.17,\n",
            "          83.78,\n",
            "          84.6,\n",
            "          84.58,\n",
            "          84.47,\n",
            "          85.07000000000001,\n",
            "          85.64,\n",
            "          85.75,\n",
            "          85.7,\n",
            "          86.18,\n",
            "          86.58,\n",
            "          86.50999999999999,\n",
            "          86.71,\n",
            "          87.09,\n",
            "          86.91,\n",
            "          87.13,\n",
            "          87.42999999999999,\n",
            "          87.75,\n",
            "          87.97,\n",
            "          88.23,\n",
            "          88.23,\n",
            "          88.22,\n",
            "          88.16000000000001,\n",
            "          88.03,\n",
            "          88.38000000000001,\n",
            "          88.39,\n",
            "          88.64,\n",
            "          88.98,\n",
            "          89.05999999999999,\n",
            "          89.34,\n",
            "          89.3,\n",
            "          89.52\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          50.160000000000004,\n",
            "          63.73,\n",
            "          70.14,\n",
            "          74.4,\n",
            "          78.99000000000001,\n",
            "          80.36999999999999,\n",
            "          82.76,\n",
            "          84.35000000000001,\n",
            "          85.78,\n",
            "          86.61999999999999,\n",
            "          87.46000000000001,\n",
            "          87.64,\n",
            "          88.08,\n",
            "          88.75,\n",
            "          88.68,\n",
            "          89.02,\n",
            "          89.39,\n",
            "          89.57000000000001,\n",
            "          89.66,\n",
            "          89.8\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          59.099999999999994,\n",
            "          69.91000000000001,\n",
            "          75.66000000000001,\n",
            "          81.41000000000001,\n",
            "          82.69,\n",
            "          85.07000000000001,\n",
            "          85.92,\n",
            "          86.89,\n",
            "          87.8,\n",
            "          87.6\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.45,\n",
            "          84.1,\n",
            "          86.36,\n",
            "          88.16000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.58,\n",
            "          87.38\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.009999999999998,\n",
            "          33.54,\n",
            "          48.67,\n",
            "          57.34,\n",
            "          61.68,\n",
            "          64.75999999999999,\n",
            "          69.28,\n",
            "          71.97,\n",
            "          73.2,\n",
            "          74.03,\n",
            "          75.08,\n",
            "          76.01,\n",
            "          76.55,\n",
            "          77.42999999999999,\n",
            "          77.75,\n",
            "          79.72,\n",
            "          80.78,\n",
            "          81.62,\n",
            "          81.8,\n",
            "          82.03,\n",
            "          81.82000000000001,\n",
            "          82.72,\n",
            "          82.94,\n",
            "          83.03,\n",
            "          83.72,\n",
            "          83.81,\n",
            "          83.72,\n",
            "          83.95,\n",
            "          84.38,\n",
            "          85.02,\n",
            "          85.36,\n",
            "          85.65,\n",
            "          85.26,\n",
            "          85.37,\n",
            "          85.37,\n",
            "          85.19,\n",
            "          85.18,\n",
            "          85.61999999999999,\n",
            "          85.47,\n",
            "          85.61999999999999,\n",
            "          85.78,\n",
            "          86.00999999999999,\n",
            "          86.05000000000001,\n",
            "          85.96000000000001,\n",
            "          85.96000000000001,\n",
            "          86.0,\n",
            "          86.24000000000001,\n",
            "          86.6,\n",
            "          86.66,\n",
            "          86.81\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.449999999999996,\n",
            "          67.88,\n",
            "          72.25,\n",
            "          77.82,\n",
            "          79.19,\n",
            "          80.32000000000001,\n",
            "          81.19,\n",
            "          81.91000000000001,\n",
            "          82.67999999999999,\n",
            "          82.89,\n",
            "          82.89,\n",
            "          83.05,\n",
            "          83.91999999999999,\n",
            "          84.69,\n",
            "          84.77,\n",
            "          84.66,\n",
            "          85.0,\n",
            "          85.3,\n",
            "          85.79,\n",
            "          86.08\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          56.38999999999999,\n",
            "          72.92999999999999,\n",
            "          78.44,\n",
            "          81.0,\n",
            "          82.73,\n",
            "          83.52000000000001,\n",
            "          84.35000000000001,\n",
            "          85.17,\n",
            "          86.17,\n",
            "          86.66\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          73.76,\n",
            "          83.52000000000001,\n",
            "          85.6,\n",
            "          86.44\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.02000000000001,\n",
            "          85.64\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 21, using model = RfModel, selection_function = MarginSamplingSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [36 33 21 26 21 19 21 19 26 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.553 s \n",
            "\n",
            "Accuracy rate for 81.260000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.98      0.85       980\n",
            "        1.0       0.80      0.99      0.89      1135\n",
            "        2.0       0.91      0.74      0.81      1032\n",
            "        3.0       0.66      0.87      0.75      1010\n",
            "        4.0       0.88      0.80      0.83       982\n",
            "        5.0       0.88      0.47      0.61       892\n",
            "        6.0       0.91      0.83      0.87       958\n",
            "        7.0       0.91      0.78      0.84      1028\n",
            "        8.0       0.86      0.77      0.81       974\n",
            "        9.0       0.73      0.84      0.78      1009\n",
            "\n",
            "avg / total       0.83      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 965    1    2    1    0    5    1    1    4    0]\n",
            " [   0 1123    3    1    0    3    1    0    4    0]\n",
            " [  76   62  759   41   10    2   19   10   42   11]\n",
            " [  22   21   13  881    2   20    6   11   22   12]\n",
            " [  15   21    1   17  781    1   21    1    3  121]\n",
            " [  66   26    8  271   12  418   14   11   30   36]\n",
            " [  84   14   18    4   21    9  798    0    9    1]\n",
            " [  14   79   14    7   19    0    3  803    4   85]\n",
            " [  22   34   11   72   11   13   10    3  749   49]\n",
            " [  20   20    2   31   36    3    1   42    5  849]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [43 36 49 41 50 72 44 48 54 63] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.951 s \n",
            "\n",
            "Accuracy rate for 87.980000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.98      0.94       980\n",
            "        1.0       0.92      0.97      0.94      1135\n",
            "        2.0       0.92      0.77      0.84      1032\n",
            "        3.0       0.93      0.77      0.84      1010\n",
            "        4.0       0.94      0.82      0.88       982\n",
            "        5.0       0.73      0.93      0.82       892\n",
            "        6.0       0.92      0.91      0.91       958\n",
            "        7.0       0.90      0.89      0.90      1028\n",
            "        8.0       0.87      0.83      0.85       974\n",
            "        9.0       0.81      0.92      0.86      1009\n",
            "\n",
            "avg / total       0.89      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 958    0    0    0    0   13    4    1    3    1]\n",
            " [   0 1099    7    2    0    6    4    0   17    0]\n",
            " [  27   47  796   18    3   16   21   43   55    6]\n",
            " [  11    2   23  780    0  132    3   19   27   13]\n",
            " [   4    5    9    0  810    7   12    2   10  123]\n",
            " [  17    4    3   15    1  830   11    4    2    5]\n",
            " [  23    3    3    1   23   33  868    0    4    0]\n",
            " [   1   24   18    3    6    5    0  918    3   50]\n",
            " [   6    5    6   13    7   78   16   10  811   22]\n",
            " [   6    9    3    5   11   22    1   19    5  928]]\n",
            "--------------------------------\n",
            "final active learning accuracies [81.26, 87.98]\n",
            "saved Active-learning-experiment-21.pkl /content ['datalab', '.forever', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 22, using model = RfModel, selection_function = MarginSamplingSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [10 13 12 19 16  9  8  9 15 14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.827 s \n",
            "\n",
            "Accuracy rate for 76.400000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.86      0.91      0.88       980\n",
            "        1.0       0.74      0.99      0.84      1135\n",
            "        2.0       0.91      0.71      0.80      1032\n",
            "        3.0       0.54      0.91      0.68      1010\n",
            "        4.0       0.68      0.93      0.79       982\n",
            "        5.0       0.88      0.29      0.43       892\n",
            "        6.0       0.93      0.70      0.80       958\n",
            "        7.0       0.95      0.68      0.79      1028\n",
            "        8.0       0.82      0.69      0.75       974\n",
            "        9.0       0.76      0.76      0.76      1009\n",
            "\n",
            "avg / total       0.80      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 889    1    7   35    6   14   15    2    9    2]\n",
            " [   0 1120    1    3    0    0    2    0    9    0]\n",
            " [  11  109  734   68   46    2   17   15   22    8]\n",
            " [   2   25   14  923    3    2    0    6   18   17]\n",
            " [   2   17    1    6  915    0    6    0    8   27]\n",
            " [  25   60    3  426   58  255    7    1   46   11]\n",
            " [  80   33   27   27  102    6  672    0   10    1]\n",
            " [   5   86   18   30   53    2    0  702    5  127]\n",
            " [   7   48    4  147   40    8    6    1  668   45]\n",
            " [  13   20    2   55  122    2    0   12   21  762]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59875, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [26 14 26 29 25 28 20 21 32 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.818 s \n",
            "\n",
            "Accuracy rate for 85.660000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.83      0.99      0.90       980\n",
            "        1.0       0.93      0.98      0.96      1135\n",
            "        2.0       0.89      0.84      0.86      1032\n",
            "        3.0       0.72      0.90      0.80      1010\n",
            "        4.0       0.86      0.86      0.86       982\n",
            "        5.0       0.89      0.55      0.68       892\n",
            "        6.0       0.93      0.89      0.91       958\n",
            "        7.0       0.94      0.80      0.86      1028\n",
            "        8.0       0.84      0.85      0.85       974\n",
            "        9.0       0.80      0.87      0.83      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 971    1    1    1    0    1    2    1    2    0]\n",
            " [   0 1109    5    7    0    1    4    0    9    0]\n",
            " [  30   12  863   25   10    3   22   14   47    6]\n",
            " [  25    1   19  909    2    4    5   15   17   13]\n",
            " [   8    3    6    2  841    4   18    2    7   91]\n",
            " [  53   19    5  262    7  493    5    2   36   10]\n",
            " [  47    5    9    2   14    8  856    0   17    0]\n",
            " [   7   23   50   10   34   12    0  819   10   63]\n",
            " [  15    6    5   34   14   17    6    3  832   42]\n",
            " [  16    8    7   14   54    9    1   15   12  873]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [28 15 40 36 42 46 34 44 44 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.672 s \n",
            "\n",
            "Accuracy rate for 90.220000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.98      0.95       980\n",
            "        1.0       0.95      0.98      0.96      1135\n",
            "        2.0       0.90      0.89      0.89      1032\n",
            "        3.0       0.87      0.86      0.86      1010\n",
            "        4.0       0.93      0.88      0.90       982\n",
            "        5.0       0.88      0.79      0.83       892\n",
            "        6.0       0.93      0.94      0.93       958\n",
            "        7.0       0.91      0.91      0.91      1028\n",
            "        8.0       0.89      0.88      0.89       974\n",
            "        9.0       0.84      0.89      0.87      1009\n",
            "\n",
            "avg / total       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 963    0    1    0    0    5    8    1    2    0]\n",
            " [   0 1107    7    4    0    1    5    1   10    0]\n",
            " [  18    6  916    5    4    9   11   20   34    9]\n",
            " [  12    1   30  871    0   40    4   18   24   10]\n",
            " [   3    2    5    0  860    3    7    5    5   92]\n",
            " [  20   12    5   97    6  707   17    9   14    5]\n",
            " [  23    3   12    1    9    9  897    2    2    0]\n",
            " [   2   19   36    3    1    2    0  940    5   20]\n",
            " [   7    4    7   13   16   15   16    5  860   31]\n",
            " [   8    7    2   10   30   14    1   30    6  901]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59625, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [31 20 51 58 63 72 37 50 59 59] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.380 s \n",
            "\n",
            "Accuracy rate for 92.130000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.98      0.96       980\n",
            "        1.0       0.97      0.98      0.97      1135\n",
            "        2.0       0.93      0.91      0.92      1032\n",
            "        3.0       0.92      0.88      0.90      1010\n",
            "        4.0       0.88      0.96      0.91       982\n",
            "        5.0       0.82      0.92      0.87       892\n",
            "        6.0       0.96      0.91      0.94       958\n",
            "        7.0       0.95      0.91      0.93      1028\n",
            "        8.0       0.93      0.89      0.91       974\n",
            "        9.0       0.91      0.88      0.89      1009\n",
            "\n",
            "avg / total       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 959    0    2    0    1   10    4    0    1    3]\n",
            " [   0 1111    4    7    1    2    2    1    7    0]\n",
            " [  17    1  937   14   13    9   11   13   16    1]\n",
            " [   6    0   11  890    1   70    1   10   17    4]\n",
            " [   2    0    4    0  938    0    3    2    4   29]\n",
            " [   7    7    1   20   13  820    7    5    5    7]\n",
            " [  21    3    8    1   23   22  876    0    4    0]\n",
            " [   3   12   35    3    5    3    0  934    6   27]\n",
            " [   2    3    3   27   12   40    7    4  863   13]\n",
            " [   5    7    0    7   65   20    1   10    9  885]]\n",
            "--------------------------------\n",
            "final active learning accuracies [76.4, 85.66, 90.22, 92.13]\n",
            "saved Active-learning-experiment-22.pkl /content ['datalab', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 23, using model = RfModel, selection_function = MarginSamplingSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [5 5 5 6 4 5 5 7 7 1] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.789 s \n",
            "\n",
            "Accuracy rate for 62.990000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.79      0.77       980\n",
            "        1.0       0.74      0.98      0.84      1135\n",
            "        2.0       0.80      0.57      0.67      1032\n",
            "        3.0       0.46      0.71      0.56      1010\n",
            "        4.0       0.75      0.50      0.60       982\n",
            "        5.0       0.37      0.34      0.36       892\n",
            "        6.0       0.84      0.69      0.76       958\n",
            "        7.0       0.52      0.89      0.65      1028\n",
            "        8.0       0.66      0.72      0.69       974\n",
            "        9.0       0.68      0.03      0.05      1009\n",
            "\n",
            "avg / total       0.66      0.63      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 770    5   25   39    3   85    8   37    8    0]\n",
            " [   0 1110    1   11    0    0    4    6    3    0]\n",
            " [  36  160  593   55   24    4   25   47   88    0]\n",
            " [  15   41   26  722    0  125   12   29   40    0]\n",
            " [  22   25   13  228  492   75   19   68   29   11]\n",
            " [  28   48    6  125   14  305   45  202  119    0]\n",
            " [ 102   31   52   15   37   38  660    4   19    0]\n",
            " [   3   46    2   37    7    5    1  918    8    1]\n",
            " [  15   29   12   36    8  118   13   41  701    1]\n",
            " [  33    9    7  314   70   63    2  428   55   28]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 0. ... 7. 7. 7.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 0 ... 7 7 7]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 9  5 11 11 13 10 15  9 13  4] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.739 s \n",
            "\n",
            "Accuracy rate for 75.070000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.92      0.92       980\n",
            "        1.0       0.94      0.91      0.93      1135\n",
            "        2.0       0.84      0.75      0.79      1032\n",
            "        3.0       0.80      0.72      0.76      1010\n",
            "        4.0       0.54      0.94      0.69       982\n",
            "        5.0       0.75      0.48      0.59       892\n",
            "        6.0       0.77      0.90      0.83       958\n",
            "        7.0       0.72      0.86      0.78      1028\n",
            "        8.0       0.62      0.83      0.71       974\n",
            "        9.0       0.91      0.16      0.27      1009\n",
            "\n",
            "avg / total       0.79      0.75      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 903    0    6    6    0   21   32    1   11    0]\n",
            " [   0 1038   28    2    4    0   48    2   13    0]\n",
            " [  13   16  774   41   39    8   30   14   95    2]\n",
            " [   0   10   12  727    6   38   15   37  165    0]\n",
            " [   0    2    7    2  927    1   36    2    3    2]\n",
            " [   4    7   22   87   83  429   56   69  129    6]\n",
            " [  38    6    8    4   19   15  864    0    4    0]\n",
            " [   4   12   46    1   47    2    4  879   30    3]\n",
            " [   7    5    8   35   25   46   24   14  808    2]\n",
            " [   9    3   12    9  560   13    6  197   42  158]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 8. ... 7. 4. 7.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 8 ... 7 4 7]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [12  5 29 11 15 19 16 15 15 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.246 s \n",
            "\n",
            "Accuracy rate for 75.380000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.91      0.93       980\n",
            "        1.0       0.99      0.66      0.79      1135\n",
            "        2.0       0.50      0.93      0.65      1032\n",
            "        3.0       0.93      0.48      0.63      1010\n",
            "        4.0       0.74      0.83      0.78       982\n",
            "        5.0       0.67      0.78      0.72       892\n",
            "        6.0       0.87      0.82      0.84       958\n",
            "        7.0       0.72      0.84      0.78      1028\n",
            "        8.0       0.82      0.67      0.74       974\n",
            "        9.0       0.79      0.64      0.70      1009\n",
            "\n",
            "avg / total       0.80      0.75      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[888   0  40   0   1  25  13   7   6   0]\n",
            " [  0 746 301   0  42   1  38   4   3   0]\n",
            " [  6   0 961   4  22   3  11   9   9   7]\n",
            " [  2   2 180 483   5 166   9  46 102  15]\n",
            " [  0   1  27   1 814   1  17  17   5  99]\n",
            " [ 10   0  57  17  16 695  13  70   9   5]\n",
            " [ 13   1  59   0  18  84 783   0   0   0]\n",
            " [  1   2 103   0  20   2   1 867   1  31]\n",
            " [  6   1 179  14  27  55  10   8 657  17]\n",
            " [  4   1  25   2 138   8   4 175   8 644]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 0. ... 7. 9. 9.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 0 ... 7 9 9]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [14 16 29 25 18 21 19 16 20 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.557 s \n",
            "\n",
            "Accuracy rate for 83.960000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.93      0.94       980\n",
            "        1.0       0.91      0.94      0.93      1135\n",
            "        2.0       0.73      0.90      0.81      1032\n",
            "        3.0       0.82      0.84      0.83      1010\n",
            "        4.0       0.90      0.70      0.79       982\n",
            "        5.0       0.79      0.74      0.76       892\n",
            "        6.0       0.92      0.87      0.89       958\n",
            "        7.0       0.86      0.80      0.83      1028\n",
            "        8.0       0.94      0.74      0.83       974\n",
            "        9.0       0.69      0.89      0.78      1009\n",
            "\n",
            "avg / total       0.85      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 910    1   20    7    1   17   12    6    4    2]\n",
            " [   0 1072   49    1    1    1    6    1    4    0]\n",
            " [   9   14  929   18   15    4    9   12    8   14]\n",
            " [   3    2   72  849    2   45    4   13   12    8]\n",
            " [   0    8    4   18  691    1   14    3    4  239]\n",
            " [   8   29   27   37   11  659   18   66    5   32]\n",
            " [  19    7   14    1   17   62  837    0    1    0]\n",
            " [   2   18  100    5    7    2    0  826    0   68]\n",
            " [   3   17   53   84    9   39   10    3  721   35]\n",
            " [   4    9    8   21   15    9    3   31    7  902]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [16 17 31 30 26 29 21 25 31 24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.007 s \n",
            "\n",
            "Accuracy rate for 87.890000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.93      0.94       980\n",
            "        1.0       0.94      0.98      0.96      1135\n",
            "        2.0       0.84      0.89      0.86      1032\n",
            "        3.0       0.83      0.86      0.84      1010\n",
            "        4.0       0.86      0.89      0.88       982\n",
            "        5.0       0.83      0.83      0.83       892\n",
            "        6.0       0.94      0.86      0.90       958\n",
            "        7.0       0.86      0.91      0.88      1028\n",
            "        8.0       0.87      0.87      0.87       974\n",
            "        9.0       0.88      0.76      0.82      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 913    1   11    5    0   28   10    3    8    1]\n",
            " [   0 1112    7    1    1    2    5    0    7    0]\n",
            " [  12    8  914   26   24    1    5   19   20    3]\n",
            " [   3    2   49  866    1   31    1   18   36    3]\n",
            " [   0    6    3   13  875    1   11    3    6   64]\n",
            " [   6   16   10   54    8  744   13   11   22    8]\n",
            " [  28    4   13    3   25   60  821    1    2    1]\n",
            " [   0   14   53    2    9    1    0  933    1   15]\n",
            " [   4   14   17   40   13   14    6   11  843   12]\n",
            " [   3    5    5   30   61   18    2   91   26  768]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 7. 9. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 7 9 9]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [18 19 33 35 32 37 26 29 37 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.374 s \n",
            "\n",
            "Accuracy rate for 89.620000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.93      0.94       980\n",
            "        1.0       0.95      0.98      0.97      1135\n",
            "        2.0       0.90      0.86      0.88      1032\n",
            "        3.0       0.87      0.89      0.88      1010\n",
            "        4.0       0.90      0.86      0.88       982\n",
            "        5.0       0.82      0.87      0.85       892\n",
            "        6.0       0.95      0.88      0.91       958\n",
            "        7.0       0.90      0.91      0.90      1028\n",
            "        8.0       0.88      0.88      0.88       974\n",
            "        9.0       0.84      0.88      0.86      1009\n",
            "\n",
            "avg / total       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 909    1    8    5    0   34   12    5    5    1]\n",
            " [   0 1115    3    4    0    2    5    1    5    0]\n",
            " [   9    9  890   37   20    7    6   21   23   10]\n",
            " [   0    0   23  897    1   27    1   23   32    6]\n",
            " [   1    7    2    1  849    4    9    3    4  102]\n",
            " [   3   13    2   35    6  780    9    8   21   15]\n",
            " [  18    4    6    2   14   64  844    0    6    0]\n",
            " [   0   11   45    2    6    1    0  935    1   27]\n",
            " [   3   10    9   40   11   22    4   10  853   12]\n",
            " [   3    4    3    9   35   11    2   35   17  890]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [20 19 44 35 39 47 26 29 50 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.696 s \n",
            "\n",
            "Accuracy rate for 89.700000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.95      0.96       980\n",
            "        1.0       0.96      0.98      0.97      1135\n",
            "        2.0       0.87      0.89      0.88      1032\n",
            "        3.0       0.95      0.80      0.87      1010\n",
            "        4.0       0.91      0.88      0.90       982\n",
            "        5.0       0.76      0.92      0.83       892\n",
            "        6.0       0.98      0.86      0.91       958\n",
            "        7.0       0.93      0.89      0.91      1028\n",
            "        8.0       0.82      0.91      0.86       974\n",
            "        9.0       0.86      0.88      0.87      1009\n",
            "\n",
            "avg / total       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 935    1    5    0    0   21    6    3    7    2]\n",
            " [   0 1112    3    2    1    4    3    2    8    0]\n",
            " [  12    8  917   15   13    8    2   10   43    4]\n",
            " [   3    0   34  808    1   81    0   19   55    9]\n",
            " [   0    1    8    0  865    9    7    1   11   80]\n",
            " [   3    5    7    8    3  821    3    3   31    8]\n",
            " [  14    3    7    0   17   80  825    0   12    0]\n",
            " [   0   11   56    1    8    2    0  916    4   30]\n",
            " [   2    8    6   12    8   39    0    5  882   12]\n",
            " [   3    4   10    6   34   15    0   27   21  889]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59650,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [25 20 53 48 41 49 30 32 56 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.951 s \n",
            "\n",
            "Accuracy rate for 91.480000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.98      0.97       980\n",
            "        1.0       0.97      0.98      0.97      1135\n",
            "        2.0       0.89      0.93      0.91      1032\n",
            "        3.0       0.90      0.90      0.90      1010\n",
            "        4.0       0.93      0.87      0.90       982\n",
            "        5.0       0.89      0.86      0.87       892\n",
            "        6.0       0.97      0.90      0.93       958\n",
            "        7.0       0.93      0.91      0.92      1028\n",
            "        8.0       0.84      0.94      0.89       974\n",
            "        9.0       0.87      0.88      0.88      1009\n",
            "\n",
            "avg / total       0.92      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 959    0    5    0    1    4    3    2    6    0]\n",
            " [   0 1111    4    3    0    2    4    1   10    0]\n",
            " [   9    5  955   14    6    1    1   12   28    1]\n",
            " [   0    0   18  910    1   22    0   18   35    6]\n",
            " [   1    1   13    0  855    5   10    1   19   77]\n",
            " [   5    5    7   54    3  763    4    5   36   10]\n",
            " [  14    4   11    1   12   44  860    0   11    1]\n",
            " [   1   10   42    2    7    3    0  933    4   26]\n",
            " [   2    6    9   15    7    9    1    4  911   10]\n",
            " [   5    3    9   10   29    9    0   30   23  891]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [27 21 56 55 50 59 33 36 63 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.194 s \n",
            "\n",
            "Accuracy rate for 91.840000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.97      0.97       980\n",
            "        1.0       0.97      0.98      0.97      1135\n",
            "        2.0       0.90      0.92      0.91      1032\n",
            "        3.0       0.90      0.91      0.91      1010\n",
            "        4.0       0.89      0.93      0.91       982\n",
            "        5.0       0.88      0.88      0.88       892\n",
            "        6.0       0.96      0.90      0.93       958\n",
            "        7.0       0.92      0.90      0.91      1028\n",
            "        8.0       0.86      0.94      0.90       974\n",
            "        9.0       0.93      0.85      0.89      1009\n",
            "\n",
            "avg / total       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    0    4    1    0    8    8    3    4    0]\n",
            " [   0 1108    3    4    1    0    4    2   13    0]\n",
            " [   9    3  953   15    9    1    5    8   28    1]\n",
            " [   0    0   16  919    1   23    0   19   28    4]\n",
            " [   2    0    9    0  916    1    5    3   14   32]\n",
            " [   5    6    2   50    7  782    8    5   23    4]\n",
            " [  12    3   12    2   13   47  859    0   10    0]\n",
            " [   1   11   53    0   12    1    1  925    5   19]\n",
            " [   1    4    4   19    9   10    1    4  913    9]\n",
            " [   3    4    8    6   60   12    2   32   25  857]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [29 21 60 63 58 63 41 38 69 58] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.490 s \n",
            "\n",
            "Accuracy rate for 92.490000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.97      0.97       980\n",
            "        1.0       0.98      0.97      0.97      1135\n",
            "        2.0       0.93      0.92      0.92      1032\n",
            "        3.0       0.90      0.90      0.90      1010\n",
            "        4.0       0.88      0.95      0.92       982\n",
            "        5.0       0.90      0.89      0.89       892\n",
            "        6.0       0.97      0.92      0.94       958\n",
            "        7.0       0.95      0.90      0.92      1028\n",
            "        8.0       0.88      0.94      0.90       974\n",
            "        9.0       0.91      0.88      0.89      1009\n",
            "\n",
            "avg / total       0.93      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 954    0    4    2    0    1    9    2    7    1]\n",
            " [   0 1102    2    6    1    1    4    2   17    0]\n",
            " [   9    3  954   16    8    3    4    9   23    3]\n",
            " [   0    0   18  907    2   30    0   18   28    7]\n",
            " [   1    0    6    0  937    1    5    2    7   23]\n",
            " [   3    5    1   43    8  794    5    2   21   10]\n",
            " [  12    4    6    1   12   32  880    0   10    1]\n",
            " [   1    8   31    3   24    3    0  923    3   32]\n",
            " [   3    4    5   16    9    7    0    4  911   15]\n",
            " [   3    3    4   11   61   11    1   14   14  887]]\n",
            "--------------------------------\n",
            "final active learning accuracies [62.99, 75.07000000000001, 75.38, 83.96000000000001, 87.89, 89.62, 89.7, 91.47999999999999, 91.84, 92.49000000000001]\n",
            "saved Active-learning-experiment-23.pkl /content ['datalab', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 24, using model = RfModel, selection_function = MarginSamplingSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [0 6 3 3 1 3 3 1 1 4] [1 2 3 4 5 6 7 8 9]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n",
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.774 s \n",
            "\n",
            "Accuracy rate for 39.050000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.00      0.00      0.00       980\n",
            "        1.0       0.36      0.98      0.53      1135\n",
            "        2.0       0.45      0.41      0.43      1032\n",
            "        3.0       0.62      0.42      0.50      1010\n",
            "        4.0       0.35      0.14      0.20       982\n",
            "        5.0       0.36      0.34      0.35       892\n",
            "        6.0       0.53      0.78      0.63       958\n",
            "        7.0       0.67      0.08      0.15      1028\n",
            "        8.0       0.56      0.01      0.03       974\n",
            "        9.0       0.26      0.64      0.37      1009\n",
            "\n",
            "avg / total       0.42      0.39      0.32     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[   0   21  289   70    1  316  178   13    0   92]\n",
            " [   0 1117    2    1    0    0    2    0    1   12]\n",
            " [   0  249  428    3    0   20  155    2    0  175]\n",
            " [   0  341   64  429    3  120   14    0    0   39]\n",
            " [   0  193    0    2  138    1   41    3    0  604]\n",
            " [   0  290   20  105   13  304   88    6    4   62]\n",
            " [   0   70   23    3    0   62  746    1    5   48]\n",
            " [   0  273    4    2   77    2    1   86    0  583]\n",
            " [   0  333  121   62   41   22  172    0   14  209]\n",
            " [   0  196    4   13  120    3   12   17    1  643]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59975,) [5. 5. 6. ... 9. 9. 9.]\n",
            "probabilities: (59975, 9) \n",
            " [4 4 5 ... 8 8 8]\n",
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [ 8  6  4  6  2 11  3  1  1  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.847 s \n",
            "\n",
            "Accuracy rate for 51.860000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.79      0.75       980\n",
            "        1.0       0.66      0.95      0.78      1135\n",
            "        2.0       0.82      0.51      0.63      1032\n",
            "        3.0       0.68      0.45      0.54      1010\n",
            "        4.0       0.85      0.16      0.27       982\n",
            "        5.0       0.32      0.84      0.46       892\n",
            "        6.0       0.83      0.60      0.70       958\n",
            "        7.0       0.93      0.01      0.02      1028\n",
            "        8.0       0.50      0.00      0.01       974\n",
            "        9.0       0.31      0.85      0.46      1009\n",
            "\n",
            "avg / total       0.66      0.52      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 778    0   10    4    0  164   11    0    0   13]\n",
            " [   0 1075    2    0    0   48    4    0    1    5]\n",
            " [  73  152  524   15    5   98   66    1    0   98]\n",
            " [  32   49   40  450    0  407    2    0    0   30]\n",
            " [  16   52    1    2  161  130    4    0    1  615]\n",
            " [  25   66    1   15    1  748    3    0    0   33]\n",
            " [  79   52    3    1   19  183  576    0    2   43]\n",
            " [  16   75    6   11    1   53    0   13    0  853]\n",
            " [  57   86   50  159    0  405   24    0    4  189]\n",
            " [  15   21    4    9    3  100    0    0    0  857]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [12  6  5  9  6 11  8  3  7  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.211 s \n",
            "\n",
            "Accuracy rate for 67.300000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.63      0.94      0.76       980\n",
            "        1.0       0.74      0.93      0.82      1135\n",
            "        2.0       0.93      0.42      0.58      1032\n",
            "        3.0       0.66      0.72      0.69      1010\n",
            "        4.0       0.78      0.64      0.71       982\n",
            "        5.0       0.70      0.57      0.62       892\n",
            "        6.0       0.73      0.89      0.80       958\n",
            "        7.0       0.89      0.25      0.39      1028\n",
            "        8.0       0.69      0.57      0.63       974\n",
            "        9.0       0.45      0.78      0.57      1009\n",
            "\n",
            "avg / total       0.72      0.67      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 919    1    5    0    1   25   29    0    0    0]\n",
            " [   0 1058    1   12    1    0    6    0   41   16]\n",
            " [ 117  118  435   24   21    5  138    4  122   48]\n",
            " [  92   58    9  724    2   82   16    2    8   17]\n",
            " [   5   36    0   32  632    1   47    0   18  211]\n",
            " [ 185   40    3   46   18  505   49    3   12   31]\n",
            " [  36    9    3    2   21   19  851    0   16    1]\n",
            " [  26   53    2   36   33    2    6  255   23  592]\n",
            " [  41   46    8  175   11   63   19    6  560   45]\n",
            " [  28   15    3   52   66   22   10   15    7  791]]\n",
            "--------------------------------\n",
            "val predicted: (59925,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59925, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [12  6 11  9  7 15 11  7 10 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.680 s \n",
            "\n",
            "Accuracy rate for 74.290000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.87      0.87       980\n",
            "        1.0       0.86      0.84      0.85      1135\n",
            "        2.0       0.66      0.78      0.71      1032\n",
            "        3.0       0.82      0.42      0.56      1010\n",
            "        4.0       0.89      0.67      0.77       982\n",
            "        5.0       0.57      0.84      0.68       892\n",
            "        6.0       0.75      0.89      0.82       958\n",
            "        7.0       0.86      0.61      0.72      1028\n",
            "        8.0       0.80      0.65      0.72       974\n",
            "        9.0       0.58      0.85      0.69      1009\n",
            "\n",
            "avg / total       0.77      0.74      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[852   0   9   0   0  62  43   4   4   6]\n",
            " [  0 957 121   5   1   5  12   1  33   0]\n",
            " [ 25  39 803   2  10   5  73  11  16  48]\n",
            " [ 22  13 184 428   2 300  18   6  17  20]\n",
            " [  2  25   2   0 662   8  52   8  23 200]\n",
            " [ 18   9   7  18   4 749  42  14  23   8]\n",
            " [ 21   7   3   0  14  44 856   1  12   0]\n",
            " [  6  29  43  13   9   1  13 629  20 265]\n",
            " [ 18  24  39  51   5 107  22   8 637  63]\n",
            " [ 17  12   5   5  33  24   4  46   7 856]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [15  7 14  9  8 19 11  8 17 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.027 s \n",
            "\n",
            "Accuracy rate for 74.430000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.86      0.96      0.90       980\n",
            "        1.0       0.89      0.86      0.87      1135\n",
            "        2.0       0.77      0.73      0.75      1032\n",
            "        3.0       0.84      0.42      0.56      1010\n",
            "        4.0       0.95      0.52      0.67       982\n",
            "        5.0       0.60      0.86      0.71       892\n",
            "        6.0       0.87      0.80      0.83       958\n",
            "        7.0       0.95      0.59      0.73      1028\n",
            "        8.0       0.62      0.81      0.70       974\n",
            "        9.0       0.53      0.90      0.67      1009\n",
            "\n",
            "avg / total       0.79      0.74      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[940   0   2   0   0  14  18   3   3   0]\n",
            " [  0 971  94   2   0   2   3   0  60   3]\n",
            " [ 31  61 756   2   5  12  58   7  59  41]\n",
            " [ 36   5  56 425   0 293   3   5 147  40]\n",
            " [  1  11   4   2 507  23  22   6  47 359]\n",
            " [ 26   4   5  30   0 769   8   3  30  17]\n",
            " [ 24   3   2   0  14  73 771   0  67   4]\n",
            " [ 10  23  54   6   1  10   1 604  27 292]\n",
            " [ 23  11   8  29   4  66   4   1 787  41]\n",
            " [  7   8   7   8   5  22   2   4  33 913]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59875, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [16  9 20 14 11 21 12 10 20 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.246 s \n",
            "\n",
            "Accuracy rate for 80.150000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.96      0.92       980\n",
            "        1.0       0.88      0.94      0.91      1135\n",
            "        2.0       0.79      0.82      0.80      1032\n",
            "        3.0       0.89      0.69      0.78      1010\n",
            "        4.0       0.90      0.65      0.75       982\n",
            "        5.0       0.67      0.88      0.76       892\n",
            "        6.0       0.94      0.74      0.83       958\n",
            "        7.0       0.95      0.63      0.76      1028\n",
            "        8.0       0.70      0.83      0.76       974\n",
            "        9.0       0.63      0.88      0.74      1009\n",
            "\n",
            "avg / total       0.82      0.80      0.80     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 936    0    6    0    0   24   11    1    2    0]\n",
            " [   0 1063   21    3    0    3    2    0   43    0]\n",
            " [  15   59  851    9    8   13   16   15   29   17]\n",
            " [  24    4   46  698    0  144    2    6   74   12]\n",
            " [   2   10   17    0  636   24    9    9   56  219]\n",
            " [  18    8   10   37    0  782    4    3   22    8]\n",
            " [  30    8   32    0   39   81  709    1   56    2]\n",
            " [   7   32   65   10    4    9    1  647   21  232]\n",
            " [  12   20   18   19    4   68    3    0  808   22]\n",
            " [  11    8   18    4   18   25    1    0   39  885]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [16  9 20 19 14 23 15 14 26 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.480 s \n",
            "\n",
            "Accuracy rate for 83.550000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.95      0.94       980\n",
            "        1.0       0.91      0.93      0.92      1135\n",
            "        2.0       0.86      0.79      0.82      1032\n",
            "        3.0       0.85      0.80      0.83      1010\n",
            "        4.0       0.88      0.72      0.79       982\n",
            "        5.0       0.75      0.82      0.78       892\n",
            "        6.0       0.93      0.82      0.87       958\n",
            "        7.0       0.93      0.84      0.88      1028\n",
            "        8.0       0.64      0.88      0.74       974\n",
            "        9.0       0.77      0.81      0.79      1009\n",
            "\n",
            "avg / total       0.85      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 929    0    7    0    0   25   10    1    8    0]\n",
            " [   0 1052   14    3    1    0    4    0   61    0]\n",
            " [  10   48  812   23   11    4   22   24   61   17]\n",
            " [   9    0   26  809    0   88    3   13   60    2]\n",
            " [   1    6    7    2  708    3    9    5   88  153]\n",
            " [  16    7    5   50    3  729   10    5   49   18]\n",
            " [  16    4   20    2   38   48  788    0   42    0]\n",
            " [   5   16   36    8    9    5    0  859   38   52]\n",
            " [   7   11    7   35    3   49    2    3  855    2]\n",
            " [   7    7   15   15   36   17    0   16   82  814]]\n",
            "--------------------------------\n",
            "val predicted: (59825,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59825, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [18  9 26 20 16 24 15 15 35 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.702 s \n",
            "\n",
            "Accuracy rate for 83.580000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.98      0.95       980\n",
            "        1.0       0.92      0.91      0.91      1135\n",
            "        2.0       0.83      0.79      0.81      1032\n",
            "        3.0       0.87      0.78      0.82      1010\n",
            "        4.0       0.87      0.72      0.79       982\n",
            "        5.0       0.84      0.76      0.80       892\n",
            "        6.0       0.94      0.77      0.85       958\n",
            "        7.0       0.95      0.81      0.87      1028\n",
            "        8.0       0.64      0.95      0.76       974\n",
            "        9.0       0.73      0.88      0.80      1009\n",
            "\n",
            "avg / total       0.85      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 957    0    8    0    0    3    6    1    5    0]\n",
            " [   0 1031   22    6    0    1    4    0   70    1]\n",
            " [  12   44  815   12    9    2   15   20   94    9]\n",
            " [  16    1   29  783    0   75    3    6   88    9]\n",
            " [   1    3   13    0  708    0    5    2   51  199]\n",
            " [  19    4    8   73    4  678   11    4   73   18]\n",
            " [  18    5   34    1   63   31  740    0   62    4]\n",
            " [   4   22   40    9   10    5    0  833   26   79]\n",
            " [   5    3    3    9    5    9    2    4  929    5]\n",
            " [   5    9   15    6   18    6    0    7   59  884]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [20 10 31 27 16 26 16 17 35 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.941 s \n",
            "\n",
            "Accuracy rate for 86.240000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.98      0.95       980\n",
            "        1.0       0.96      0.93      0.95      1135\n",
            "        2.0       0.88      0.91      0.89      1032\n",
            "        3.0       0.80      0.86      0.83      1010\n",
            "        4.0       0.94      0.70      0.80       982\n",
            "        5.0       0.83      0.74      0.78       892\n",
            "        6.0       0.95      0.82      0.88       958\n",
            "        7.0       0.95      0.84      0.89      1028\n",
            "        8.0       0.78      0.91      0.84       974\n",
            "        9.0       0.71      0.91      0.80      1009\n",
            "\n",
            "avg / total       0.87      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 961    0    5    0    0    4    4    1    5    0]\n",
            " [   0 1061    5    8    0    0    3    1   56    1]\n",
            " [  12    6  934   14    7    2   13   22   13    9]\n",
            " [   9    0   24  873    0   51    2   10   29   12]\n",
            " [   2    6    9    1  683    4    6    2   39  230]\n",
            " [  16    5    5  130    2  660   10    5   37   22]\n",
            " [  25    3   33    3   19   54  783    0   34    4]\n",
            " [   5   11   31   12    3    0    0  865   14   87]\n",
            " [   4    8    4   39    2   16    2    1  889    9]\n",
            " [   7    8   11   15   13    2    1    7   30  915]]\n",
            "--------------------------------\n",
            "val predicted: (59775,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59775, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [22 10 33 30 20 29 19 21 35 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.250 s \n",
            "\n",
            "Accuracy rate for 87.230000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.98      0.94       980\n",
            "        1.0       0.97      0.92      0.95      1135\n",
            "        2.0       0.88      0.89      0.89      1032\n",
            "        3.0       0.82      0.90      0.86      1010\n",
            "        4.0       0.92      0.70      0.80       982\n",
            "        5.0       0.90      0.76      0.83       892\n",
            "        6.0       0.94      0.86      0.90       958\n",
            "        7.0       0.92      0.88      0.90      1028\n",
            "        8.0       0.80      0.90      0.85       974\n",
            "        9.0       0.72      0.90      0.80      1009\n",
            "\n",
            "avg / total       0.88      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 965    0    5    0    0    1    2    1    5    1]\n",
            " [   0 1049    7   12    0    0    4    3   60    0]\n",
            " [   9    4  920   12    6    0   20   31   21    9]\n",
            " [  10    0   21  908    0   28    2   15   19    7]\n",
            " [   4    2   13    1  690    2    5    3   32  230]\n",
            " [  32    4    8  101    4  679   14    6   28   16]\n",
            " [  29    2   27    2   15   30  824    1   20    8]\n",
            " [   5   10   25    8    3    2    0  907   13   55]\n",
            " [   5    3    8   39    8    7    4    6  876   18]\n",
            " [   8    7   13   20   20    2    0   17   17  905]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [23 13 34 30 20 37 28 21 35 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.281 s \n",
            "\n",
            "Accuracy rate for 87.890000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.98      0.95       980\n",
            "        1.0       0.96      0.95      0.95      1135\n",
            "        2.0       0.92      0.89      0.90      1032\n",
            "        3.0       0.85      0.85      0.85      1010\n",
            "        4.0       0.94      0.69      0.80       982\n",
            "        5.0       0.80      0.85      0.83       892\n",
            "        6.0       0.93      0.93      0.93       958\n",
            "        7.0       0.94      0.87      0.90      1028\n",
            "        8.0       0.88      0.85      0.86       974\n",
            "        9.0       0.70      0.92      0.79      1009\n",
            "\n",
            "avg / total       0.89      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 962    1    0    0    0    5    7    1    4    0]\n",
            " [   0 1076    5   11    0    1    6    1   34    1]\n",
            " [  10    4  918   15    8    6   21   26   11   13]\n",
            " [   8    0   18  855    0   93    3    8    8   17]\n",
            " [   5    6    7    1  680    3    9    4   13  254]\n",
            " [  16    5    3   50    4  761   13    2   14   24]\n",
            " [  18    2    2    0    7   29  892    1    7    0]\n",
            " [   7   12   30   13    3    7    1  892    5   58]\n",
            " [   6   10    8   45    6   35    3    2  826   33]\n",
            " [  10    6    7   10   16    8    1   10   14  927]]\n",
            "--------------------------------\n",
            "val predicted: (59725,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59725, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [24 14 36 33 22 41 31 22 41 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.399 s \n",
            "\n",
            "Accuracy rate for 88.430000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.96      0.95       980\n",
            "        1.0       0.96      0.94      0.95      1135\n",
            "        2.0       0.92      0.90      0.91      1032\n",
            "        3.0       0.87      0.88      0.87      1010\n",
            "        4.0       0.96      0.67      0.79       982\n",
            "        5.0       0.84      0.86      0.85       892\n",
            "        6.0       0.92      0.94      0.93       958\n",
            "        7.0       0.94      0.86      0.90      1028\n",
            "        8.0       0.87      0.87      0.87       974\n",
            "        9.0       0.70      0.94      0.81      1009\n",
            "\n",
            "avg / total       0.89      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 945    1    3    0    0    6   18    1    6    0]\n",
            " [   0 1067    5    9    0    1    5    1   46    1]\n",
            " [  10    2  932   13    4    4   17   26   13   11]\n",
            " [   8    0   24  886    0   65    3   10    6    8]\n",
            " [   2    7    7    0  662    4   15    5   20  260]\n",
            " [  16    8    3   51    2  768   14    3   12   15]\n",
            " [  10    2    3    0   10   29  898    0    5    1]\n",
            " [   4   13   31   16    2    5    0  889    4   64]\n",
            " [   6    5    4   35    4   27    4    4  848   37]\n",
            " [   6    6    2   14    6    5    2    6   14  948]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [24 16 41 35 27 43 31 23 46 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.655 s \n",
            "\n",
            "Accuracy rate for 88.940000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.96      0.95       980\n",
            "        1.0       0.96      0.96      0.96      1135\n",
            "        2.0       0.89      0.93      0.91      1032\n",
            "        3.0       0.90      0.84      0.87      1010\n",
            "        4.0       0.95      0.73      0.82       982\n",
            "        5.0       0.81      0.88      0.84       892\n",
            "        6.0       0.93      0.91      0.92       958\n",
            "        7.0       0.95      0.85      0.90      1028\n",
            "        8.0       0.89      0.89      0.89       974\n",
            "        9.0       0.72      0.94      0.82      1009\n",
            "\n",
            "avg / total       0.90      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 939    1    7    0    0    6   23    1    3    0]\n",
            " [   0 1090    7    8    0    2    4    1   22    1]\n",
            " [   8    2  956   10    3    5   10   23    9    6]\n",
            " [   8    2   34  850    0   88    3   11    8    6]\n",
            " [   0    2    8    0  714    3   11    0   19  225]\n",
            " [  12    7    4   42    3  782    9    2   14   17]\n",
            " [  10    2    7    1   13   40  873    0   10    2]\n",
            " [   4   15   42    7    6    6    0  872    2   74]\n",
            " [   4    6    5   21    2   29    1    3  871   32]\n",
            " [   5    7    3    7   10    7    1    6   16  947]]\n",
            "--------------------------------\n",
            "val predicted: (59675,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59675, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [26 16 45 38 32 48 31 26 49 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.750 s \n",
            "\n",
            "Accuracy rate for 90.060000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.98      0.95       980\n",
            "        1.0       0.97      0.96      0.97      1135\n",
            "        2.0       0.90      0.93      0.91      1032\n",
            "        3.0       0.89      0.83      0.86      1010\n",
            "        4.0       0.93      0.82      0.87       982\n",
            "        5.0       0.83      0.88      0.85       892\n",
            "        6.0       0.96      0.92      0.94       958\n",
            "        7.0       0.96      0.87      0.91      1028\n",
            "        8.0       0.86      0.91      0.88       974\n",
            "        9.0       0.79      0.91      0.85      1009\n",
            "\n",
            "avg / total       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 959    0    5    0    0    4    6    1    5    0]\n",
            " [   0 1092    4    3    0    2    4    1   28    1]\n",
            " [  10    0  958   16    4    0    9   14   16    5]\n",
            " [  13    1   34  834    1   91    0   11   20    5]\n",
            " [   3    1   10    0  807    2    4    0   20  135]\n",
            " [  16    4    5   41    4  785    7    1   16   13]\n",
            " [  11    2    4    0   12   31  880    0   14    4]\n",
            " [   6   12   39    6    7    5    0  892    5   56]\n",
            " [   4    3    2   31    6   21    2    3  885   17]\n",
            " [   8    7    5    7   28    8    1   10   21  914]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [27 16 48 40 35 54 32 27 56 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.945 s \n",
            "\n",
            "Accuracy rate for 89.570000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.97      0.96       980\n",
            "        1.0       0.97      0.96      0.96      1135\n",
            "        2.0       0.90      0.94      0.92      1032\n",
            "        3.0       0.93      0.79      0.85      1010\n",
            "        4.0       0.92      0.82      0.87       982\n",
            "        5.0       0.75      0.91      0.82       892\n",
            "        6.0       0.96      0.90      0.93       958\n",
            "        7.0       0.96      0.84      0.90      1028\n",
            "        8.0       0.85      0.92      0.88       974\n",
            "        9.0       0.80      0.90      0.85      1009\n",
            "\n",
            "avg / total       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 947    1    4    0    0   15    9    0    3    1]\n",
            " [   0 1085    5    3    0    3    3    1   34    1]\n",
            " [   9    1  970    6    5    7    7   12   13    2]\n",
            " [   8    1   29  802    0  129    0   10   30    1]\n",
            " [   3    2   10    0  807    4    4    0   17  135]\n",
            " [  11    4    3   30    2  808    8    1   18    7]\n",
            " [   9    2    7    0   17   50  862    0   10    1]\n",
            " [   6   12   46    6   11    7    0  866   10   64]\n",
            " [   4    2    4   12    6   36    0    2  898   10]\n",
            " [   5    7    4    8   25   13    1    8   26  912]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59625, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [28 16 50 44 41 56 34 30 58 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.021 s \n",
            "\n",
            "Accuracy rate for 90.040000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.97      0.95       980\n",
            "        1.0       0.97      0.95      0.96      1135\n",
            "        2.0       0.92      0.93      0.92      1032\n",
            "        3.0       0.88      0.84      0.86      1010\n",
            "        4.0       0.91      0.89      0.90       982\n",
            "        5.0       0.77      0.90      0.83       892\n",
            "        6.0       0.96      0.90      0.93       958\n",
            "        7.0       0.96      0.85      0.91      1028\n",
            "        8.0       0.87      0.90      0.89       974\n",
            "        9.0       0.84      0.88      0.86      1009\n",
            "\n",
            "avg / total       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 946    1    2    0    0    9   18    1    3    0]\n",
            " [   0 1075    7    6    0    3    4    1   38    1]\n",
            " [   8    1  955   17    6   11    6   11   12    5]\n",
            " [   7    1   22  846    0  101    0    9   19    5]\n",
            " [   3    0    5    0  874    5    4    0   10   81]\n",
            " [  14    4    0   39    1  807    6    1   12    8]\n",
            " [  10    2    3    1   17   52  863    0    9    1]\n",
            " [   5   12   42    9    9    7    0  878    5   61]\n",
            " [   3    4    2   32    6   41    0    2  875    9]\n",
            " [   7    7    5   10   52   14    1    8   20  885]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [28 16 50 44 52 56 34 30 68 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.173 s \n",
            "\n",
            "Accuracy rate for 90.040000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.97      0.96       980\n",
            "        1.0       0.98      0.96      0.97      1135\n",
            "        2.0       0.90      0.92      0.91      1032\n",
            "        3.0       0.92      0.80      0.85      1010\n",
            "        4.0       0.83      0.95      0.88       982\n",
            "        5.0       0.82      0.87      0.84       892\n",
            "        6.0       0.96      0.90      0.93       958\n",
            "        7.0       0.96      0.84      0.90      1028\n",
            "        8.0       0.82      0.96      0.88       974\n",
            "        9.0       0.88      0.84      0.86      1009\n",
            "\n",
            "avg / total       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    1    3    0    0    6   14    1    3    0]\n",
            " [   0 1084    6    3    0    0    4    1   36    1]\n",
            " [   9    0  953   10   13    5    5   10   25    2]\n",
            " [   9    0   27  804    3  113    1   13   35    5]\n",
            " [   2    0    5    0  929    0    2    0    9   35]\n",
            " [  11    3    1   34    8  779    7    1   39    9]\n",
            " [   8    2    6    0   29   34  863    0   16    0]\n",
            " [   4   10   42    5   27    3    0  865   16   56]\n",
            " [   5    0    4    9   10    9    0    2  931    4]\n",
            " [   7    6    7    6  107    4    1    7   20  844]]\n",
            "--------------------------------\n",
            "val predicted: (59575,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59575, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [29 16 52 50 52 58 35 37 71 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.336 s \n",
            "\n",
            "Accuracy rate for 91.140000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.98      0.96       980\n",
            "        1.0       0.98      0.94      0.96      1135\n",
            "        2.0       0.92      0.93      0.92      1032\n",
            "        3.0       0.92      0.83      0.87      1010\n",
            "        4.0       0.87      0.95      0.91       982\n",
            "        5.0       0.84      0.88      0.86       892\n",
            "        6.0       0.96      0.90      0.93       958\n",
            "        7.0       0.95      0.89      0.92      1028\n",
            "        8.0       0.82      0.95      0.88       974\n",
            "        9.0       0.92      0.87      0.89      1009\n",
            "\n",
            "avg / total       0.91      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 957    0    2    0    1    4   10    1    5    0]\n",
            " [   0 1067    8    3    1    1    5    1   49    0]\n",
            " [  11    0  955   12    8    3    4   17   22    0]\n",
            " [  10    0   20  843    2   88    0   10   34    3]\n",
            " [   2    0    4    0  929    0    3    1   11   32]\n",
            " [  16    2    0   41    4  781    8    3   30    7]\n",
            " [  11    2    5    0   32   30  865    0   13    0]\n",
            " [   4   11   34    5   16    1    0  912   14   31]\n",
            " [   4    0    1   12    7   14    1    5  926    4]\n",
            " [   5    5    6    5   67    8    1   10   23  879]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [31 16 55 55 54 60 38 39 73 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.374 s \n",
            "\n",
            "Accuracy rate for 91.860000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.98      0.96       980\n",
            "        1.0       0.98      0.94      0.96      1135\n",
            "        2.0       0.93      0.92      0.92      1032\n",
            "        3.0       0.90      0.89      0.90      1010\n",
            "        4.0       0.90      0.94      0.92       982\n",
            "        5.0       0.89      0.86      0.88       892\n",
            "        6.0       0.97      0.91      0.94       958\n",
            "        7.0       0.96      0.89      0.92      1028\n",
            "        8.0       0.83      0.95      0.89       974\n",
            "        9.0       0.90      0.89      0.90      1009\n",
            "\n",
            "avg / total       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 959    0    2    0    0    5    7    1    6    0]\n",
            " [   0 1066    6    4    1    1    4    2   51    0]\n",
            " [   8    0  951   14   10    2    3   15   26    3]\n",
            " [   6    0   19  899    1   51    0    8   20    6]\n",
            " [   2    0    3    0  921    0    4    0    9   43]\n",
            " [  13    3    1   49    6  771    8    2   28   11]\n",
            " [  14    2    4    0   29   23  872    0   14    0]\n",
            " [   4    9   33    4   12    2    0  919   13   32]\n",
            " [   5    0    4   15    6    7    1    3  925    8]\n",
            " [   6    7    4    9   41    5    1   11   22  903]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59525,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59525, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [31 17 56 55 61 64 38 39 74 65] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.613 s \n",
            "\n",
            "Accuracy rate for 91.790000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.97      0.96       980\n",
            "        1.0       0.98      0.96      0.97      1135\n",
            "        2.0       0.94      0.93      0.93      1032\n",
            "        3.0       0.92      0.88      0.90      1010\n",
            "        4.0       0.88      0.93      0.91       982\n",
            "        5.0       0.86      0.89      0.87       892\n",
            "        6.0       0.97      0.91      0.94       958\n",
            "        7.0       0.97      0.87      0.91      1028\n",
            "        8.0       0.87      0.92      0.90       974\n",
            "        9.0       0.86      0.92      0.89      1009\n",
            "\n",
            "avg / total       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 955    0    2    1    1    8    6    1    5    1]\n",
            " [   0 1085    5    4    3    1    5    1   31    0]\n",
            " [   9    0  955   11   12    0    6   14   21    4]\n",
            " [   8    0   12  892    2   63    0    7   20    6]\n",
            " [   1    0    5    0  910    0    4    0    4   58]\n",
            " [  11    3    2   37    4  792    7    1   21   14]\n",
            " [  12    2    4    1   28   30  871    0   10    0]\n",
            " [   4   10   31    8   20    3    0  893    8   51]\n",
            " [   2    1    3   14   12   21    2    1  899   19]\n",
            " [   5    6    1    6   37    7    1    6   13  927]]\n",
            "--------------------------------\n",
            "final active learning accuracies [39.050000000000004, 51.85999999999999, 67.30000000000001, 74.29, 74.42999999999999, 80.15, 83.55, 83.58, 86.24000000000001, 87.22999999999999, 87.89, 88.42999999999999, 88.94, 90.06, 89.57000000000001, 90.03999999999999, 90.03999999999999, 91.14, 91.86, 91.79]\n",
            "saved Active-learning-experiment-24.pkl /content ['datalab', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 25, using model = RfModel, selection_function = MarginSamplingSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [2 2 1 2 0 1 1 0 1] [0 1 2 3 5 6 8]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n",
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.556 s \n",
            "\n",
            "Accuracy rate for 25.720000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.30      0.97      0.46       980\n",
            "        1.0       0.25      0.97      0.40      1135\n",
            "        2.0       0.17      0.04      0.06      1032\n",
            "        3.0       0.15      0.26      0.19      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.39      0.08      0.14       892\n",
            "        6.0       0.64      0.13      0.22       958\n",
            "        7.0       0.00      0.00      0.00      1028\n",
            "        8.0       0.24      0.03      0.05       974\n",
            "        9.0       0.00      0.00      0.00      1009\n",
            "\n",
            "avg / total       0.21      0.26      0.15     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 950   20    2    2    0    1    3    0    2    0]\n",
            " [   9 1097    4   15    0    7    0    0    3    0]\n",
            " [ 162  745   37   34    0    4   41    0    9    0]\n",
            " [ 247  464    2  258    0   37    0    0    2    0]\n",
            " [ 300  394   11  193    0   21   17    0   46    0]\n",
            " [ 490  235    0   88    0   75    4    0    0    0]\n",
            " [ 396  257  146   11    0    0  127    0   21    0]\n",
            " [ 335  253   16  397    0   27    0    0    0    0]\n",
            " [  62  712    0  154    0   16    2    0   28    0]\n",
            " [ 194  185    1  615    0    4    4    0    6    0]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59990,) [0. 0. 1. ... 0. 1. 1.]\n",
            "probabilities: (59990, 7) \n",
            " [0 0 1 ... 0 1 1]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [2 4 3 3 1 1 3 2 1] [0 1 2 3 4 5 6 7 8]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.525 s \n",
            "\n",
            "Accuracy rate for 38.830000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.67      0.74      0.70       980\n",
            "        1.0       0.23      1.00      0.37      1135\n",
            "        2.0       0.68      0.40      0.50      1032\n",
            "        3.0       0.48      0.50      0.49      1010\n",
            "        4.0       0.46      0.03      0.05       982\n",
            "        5.0       0.56      0.04      0.08       892\n",
            "        6.0       0.47      0.66      0.55       958\n",
            "        7.0       0.57      0.39      0.47      1028\n",
            "        8.0       0.41      0.01      0.03       974\n",
            "        9.0       0.00      0.00      0.00      1009\n",
            "\n",
            "avg / total       0.45      0.39      0.33     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 721   27   11   10   14    2  181   14    0    0]\n",
            " [   0 1135    0    0    0    0    0    0    0    0]\n",
            " [  27  507  408   14    3    3   46   11   13    0]\n",
            " [  30  423   35  503    0    7    2    6    4    0]\n",
            " [  29  522   29   41   26    1  273   61    0    0]\n",
            " [ 164  470    2  175    0   40   27   13    1    0]\n",
            " [  14  242   65    3    2    0  631    0    1    0]\n",
            " [  62  514   21   21    1    1    3  405    0    0]\n",
            " [   8  627   24  175    7   15   40   64   14    0]\n",
            " [  28  568    8  113    4    3  147  137    1    0]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59980,) [0. 0. 2. ... 7. 1. 1.]\n",
            "probabilities: (59980, 9) \n",
            " [0 0 2 ... 7 1 1]\n",
            "trainset before (20, 784) (20,)\n",
            "trainset after (30, 784) (30,)\n",
            "updated train set: (30, 784) (30,) unique(labels): [2 4 4 4 2 4 4 2 2 2] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59970, 784) (59970,)\n",
            "\n",
            "Train set: (30, 784) y: (30,)\n",
            "Val   set: (59970, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.172 s \n",
            "\n",
            "Accuracy rate for 53.990000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.70      0.79       980\n",
            "        1.0       0.36      0.99      0.52      1135\n",
            "        2.0       0.79      0.58      0.67      1032\n",
            "        3.0       0.53      0.65      0.58      1010\n",
            "        4.0       0.55      0.29      0.38       982\n",
            "        5.0       0.39      0.44      0.41       892\n",
            "        6.0       0.65      0.75      0.70       958\n",
            "        7.0       0.88      0.35      0.50      1028\n",
            "        8.0       0.76      0.20      0.32       974\n",
            "        9.0       0.49      0.38      0.43      1009\n",
            "\n",
            "avg / total       0.63      0.54      0.53     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 688   17   14   34   17   56  143    2    9    0]\n",
            " [   0 1125    5    0    0    0    0    0    5    0]\n",
            " [  14  313  597   31   27   16   28    3    2    1]\n",
            " [   2  227   45  655    2   61    2    2    6    8]\n",
            " [   5  206    8   36  289   92  119    3    4  220]\n",
            " [  24  295    6  138    6  394   20    3    6    0]\n",
            " [   9  120   20    2   30   43  717    0   16    1]\n",
            " [  11  321   30  141   26   21    0  358    0  120]\n",
            " [   1  329   30  117   11  227   17    7  197   38]\n",
            " [   8  216    3   91  118  101   50   30   13  379]]\n",
            "--------------------------------\n",
            "val predicted: (59970,) [0. 0. 8. ... 9. 1. 1.]\n",
            "probabilities: (59970, 10) \n",
            " [0 0 8 ... 9 1 1]\n",
            "trainset before (30, 784) (30,)\n",
            "trainset after (40, 784) (40,)\n",
            "updated train set: (40, 784) (40,) unique(labels): [6 4 5 4 2 4 4 6 2 3] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59960, 784) (59960,)\n",
            "\n",
            "Train set: (40, 784) y: (40,)\n",
            "Val   set: (59960, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.330 s \n",
            "\n",
            "Accuracy rate for 57.530000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.64      0.95      0.77       980\n",
            "        1.0       0.43      0.99      0.60      1135\n",
            "        2.0       0.56      0.52      0.54      1032\n",
            "        3.0       0.73      0.62      0.67      1010\n",
            "        4.0       0.68      0.13      0.22       982\n",
            "        5.0       0.53      0.40      0.45       892\n",
            "        6.0       0.87      0.61      0.71       958\n",
            "        7.0       0.50      0.76      0.60      1028\n",
            "        8.0       0.90      0.21      0.33       974\n",
            "        9.0       0.63      0.48      0.54      1009\n",
            "\n",
            "avg / total       0.64      0.58      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 935    4    0    1    1    1    9   29    0    0]\n",
            " [   0 1128    2    0    0    0    0    1    4    0]\n",
            " [  75  303  536   17   13    5   13   65    5    0]\n",
            " [  69  200   21  625    3   55    1   15    2   19]\n",
            " [  16  106  156   15  132   19   27  295    1  215]\n",
            " [ 171  205    9   85    1  353    9   55    1    3]\n",
            " [ 101   92  107    1    6   34  583   24   10    0]\n",
            " [  33  149   47    9    1    0    0  779    0   10]\n",
            " [  32  356   45   72    6  164   14   45  200   40]\n",
            " [  23   85   31   36   32   41   17  262    0  482]]\n",
            "--------------------------------\n",
            "val predicted: (59960,) [0. 0. 0. ... 7. 7. 7.]\n",
            "probabilities: (59960, 10) \n",
            " [0 0 0 ... 7 7 7]\n",
            "trainset before (40, 784) (40,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [6 4 6 4 3 5 5 6 5 6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.614 s \n",
            "\n",
            "Accuracy rate for 62.390000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.64      0.96      0.77       980\n",
            "        1.0       0.51      0.99      0.68      1135\n",
            "        2.0       0.67      0.59      0.63      1032\n",
            "        3.0       0.80      0.40      0.54      1010\n",
            "        4.0       0.77      0.15      0.25       982\n",
            "        5.0       0.43      0.41      0.42       892\n",
            "        6.0       0.90      0.66      0.76       958\n",
            "        7.0       0.74      0.73      0.74      1028\n",
            "        8.0       0.82      0.51      0.63       974\n",
            "        9.0       0.49      0.76      0.60      1009\n",
            "\n",
            "avg / total       0.68      0.62      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    2    9    1    1    0    5   16    2    0]\n",
            " [   0 1122    7    0    0    1    0    0    5    0]\n",
            " [  70  243  613   13    9    8   19   28   17   12]\n",
            " [  75  155   51  409    2  259    0   14   18   27]\n",
            " [  12   61   40    0  143    2   26   56   18  624]\n",
            " [ 224  158   24   44    3  366   13   32   10   18]\n",
            " [  73   53   91    0    9   76  632   10    7    7]\n",
            " [  30  144   47   11    3    1    0  752    2   38]\n",
            " [  32  177   34   28    5  116    7   20  493   62]\n",
            " [  17   65    4    8   10   17    3   90   30  765]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 0. ... 7. 7. 7.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 0 ... 7 7 7]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (60, 784) (60,)\n",
            "updated train set: (60, 784) (60,) unique(labels): [6 4 6 5 7 5 7 6 6 8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59940, 784) (59940,)\n",
            "\n",
            "Train set: (60, 784) y: (60,)\n",
            "Val   set: (59940, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.986 s \n",
            "\n",
            "Accuracy rate for 66.580000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.95      0.81       980\n",
            "        1.0       0.63      0.96      0.76      1135\n",
            "        2.0       0.82      0.50      0.62      1032\n",
            "        3.0       0.73      0.59      0.65      1010\n",
            "        4.0       0.54      0.39      0.46       982\n",
            "        5.0       0.61      0.37      0.46       892\n",
            "        6.0       0.84      0.80      0.82       958\n",
            "        7.0       0.84      0.62      0.72      1028\n",
            "        8.0       0.73      0.64      0.68       974\n",
            "        9.0       0.45      0.77      0.57      1009\n",
            "\n",
            "avg / total       0.69      0.67      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 928    2    5    3    4    0   23    7    1    7]\n",
            " [   0 1095    5    1    1    0    1    1   31    0]\n",
            " [  71  199  519   21   32    3   44   18   57   68]\n",
            " [  41  104   32  597   12  130   14    8   38   34]\n",
            " [   4   14    4    0  387    0   19    8   10  536]\n",
            " [ 168  102    6  118   64  328   35   25   19   27]\n",
            " [  33   36   30    0   46   32  763    0    7   11]\n",
            " [  26   73   14   22   53    0    0  642   25  173]\n",
            " [  19  102   16   44   28   41    7    8  627   82]\n",
            " [   9   19    1   13   89    8    3   50   45  772]]\n",
            "--------------------------------\n",
            "val predicted: (59940,) [0. 0. 0. ... 7. 4. 4.]\n",
            "probabilities: (59940, 10) \n",
            " [0 0 0 ... 7 4 4]\n",
            "trainset before (60, 784) (60,)\n",
            "trainset after (70, 784) (70,)\n",
            "updated train set: (70, 784) (70,) unique(labels): [ 6  4  6  5 15  5  7  6  8  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59930, 784) (59930,)\n",
            "\n",
            "Train set: (70, 784) y: (70,)\n",
            "Val   set: (59930, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.136 s \n",
            "\n",
            "Accuracy rate for 64.230000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.77      0.94      0.85       980\n",
            "        1.0       0.76      0.97      0.85      1135\n",
            "        2.0       0.85      0.50      0.63      1032\n",
            "        3.0       0.80      0.58      0.67      1010\n",
            "        4.0       0.33      0.96      0.49       982\n",
            "        5.0       0.63      0.33      0.43       892\n",
            "        6.0       0.92      0.55      0.69       958\n",
            "        7.0       0.94      0.44      0.60      1028\n",
            "        8.0       0.71      0.71      0.71       974\n",
            "        9.0       0.60      0.39      0.47      1009\n",
            "\n",
            "avg / total       0.73      0.64      0.64     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 918    1    3    1   33    1    7    8    3    5]\n",
            " [   0 1105    7    1    9    0    0    0   13    0]\n",
            " [  56  176  515   16  141    1   18    3   83   23]\n",
            " [  50   51   40  582   93  105    4    0   72   13]\n",
            " [   0    0    1    0  945    0    3    0    0   33]\n",
            " [  88   33    2   86  302  294   10    5   64    8]\n",
            " [  27   11    9    0  349   26  526    0    5    5]\n",
            " [  22   48   17    6  303    0    0  455   17  160]\n",
            " [  15   25   10   35  143   32    4    3  688   19]\n",
            " [   9    8    1    5  549    8    2   11   21  395]]\n",
            "--------------------------------\n",
            "val predicted: (59930,) [0. 0. 0. ... 9. 4. 4.]\n",
            "probabilities: (59930, 10) \n",
            " [0 0 0 ... 9 4 4]\n",
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [ 6  4  9  6 17  5  8  8  8  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.338 s \n",
            "\n",
            "Accuracy rate for 67.500000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.90      0.85       980\n",
            "        1.0       0.81      0.97      0.88      1135\n",
            "        2.0       0.86      0.56      0.68      1032\n",
            "        3.0       0.78      0.64      0.70      1010\n",
            "        4.0       0.35      0.99      0.52       982\n",
            "        5.0       0.67      0.30      0.42       892\n",
            "        6.0       0.89      0.68      0.77       958\n",
            "        7.0       0.83      0.61      0.70      1028\n",
            "        8.0       0.76      0.70      0.73       974\n",
            "        9.0       0.71      0.34      0.46      1009\n",
            "\n",
            "avg / total       0.75      0.68      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 882    0    7    2   57    0   22    2    4    4]\n",
            " [   0 1100    6    2   16    0    1    1    9    0]\n",
            " [  38  151  578   10  113    2   26   23   82    9]\n",
            " [  47   38   40  646   90   73    6    7   45   18]\n",
            " [   0    0    3    0  968    0    4    0    0    7]\n",
            " [  70   17    5  104  327  272   13   16   57   11]\n",
            " [  14    7   10    0  250   18  652    0    6    1]\n",
            " [  27   29   17    8  231    0    0  627    4   85]\n",
            " [  14   16    9   45  147   31    7   13  685    7]\n",
            " [   7    5    1   11  551    9    2   70   13  340]]\n",
            "--------------------------------\n",
            "val predicted: (59920,) [0. 0. 0. ... 7. 4. 4.]\n",
            "probabilities: (59920, 10) \n",
            " [0 0 0 ... 7 4 4]\n",
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [ 6  4 11  9 17  8 10  8  8  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.495 s \n",
            "\n",
            "Accuracy rate for 72.750000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.88      0.88       980\n",
            "        1.0       0.84      0.96      0.90      1135\n",
            "        2.0       0.76      0.72      0.74      1032\n",
            "        3.0       0.70      0.73      0.72      1010\n",
            "        4.0       0.47      0.96      0.63       982\n",
            "        5.0       0.66      0.45      0.53       892\n",
            "        6.0       0.91      0.78      0.84       958\n",
            "        7.0       0.81      0.69      0.75      1028\n",
            "        8.0       0.78      0.66      0.72       974\n",
            "        9.0       0.73      0.40      0.52      1009\n",
            "\n",
            "avg / total       0.76      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 866    4   33   13   22    2   27    5    4    4]\n",
            " [   0 1086   16    5    3    0    3    1   21    0]\n",
            " [  28   98  744   38   26    2   18   28   46    4]\n",
            " [  16   15   42  740   30  111    0   10   37    9]\n",
            " [   0    1    7    3  943    0   10    0    1   17]\n",
            " [  40   18    9  124  206  397   12   22   54   10]\n",
            " [   9    8   45    2  130   16  743    0    4    1]\n",
            " [  19   40   46   14  111    0    0  709    0   89]\n",
            " [   6   11   32   83   98   60    5   17  644   18]\n",
            " [   6    7    2   32  451   13    1   82   12  403]]\n",
            "--------------------------------\n",
            "val predicted: (59910,) [0. 0. 0. ... 9. 4. 4.]\n",
            "probabilities: (59910, 10) \n",
            " [0 0 0 ... 9 4 4]\n",
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 7  4 12 11 17 11 11  8  9 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.717 s \n",
            "\n",
            "Accuracy rate for 76.350000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.86      0.94      0.90       980\n",
            "        1.0       0.90      0.94      0.92      1135\n",
            "        2.0       0.79      0.73      0.76      1032\n",
            "        3.0       0.69      0.83      0.75      1010\n",
            "        4.0       0.52      0.96      0.67       982\n",
            "        5.0       0.74      0.56      0.64       892\n",
            "        6.0       0.92      0.81      0.86       958\n",
            "        7.0       0.84      0.67      0.74      1028\n",
            "        8.0       0.83      0.66      0.74       974\n",
            "        9.0       0.78      0.50      0.61      1009\n",
            "\n",
            "avg / total       0.79      0.76      0.76     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 922    0   13   10   11    4    8    4    6    2]\n",
            " [   0 1070   19    8   11    0    6    1   20    0]\n",
            " [  32   77  750   65   29    3   27   16   30    3]\n",
            " [   9    2   27  835   13   85    0    5   30    4]\n",
            " [   0    0    3    4  942    0    6    0    0   27]\n",
            " [  51    8    7   94  164  503   12   16   31    6]\n",
            " [  19    4   34    7  105   13  774    0    1    1]\n",
            " [  25   18   46   44  128    0    0  686    0   81]\n",
            " [   7   11   43   92   80   60    9   10  644   18]\n",
            " [   8    5    4   45  330   14    1   80   13  509]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 0. ... 7. 4. 4.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 0 ... 7 4 4]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [ 8  4 14 12 18 13 11  9  9 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.765 s \n",
            "\n",
            "Accuracy rate for 77.310000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.94      0.90       980\n",
            "        1.0       0.92      0.94      0.93      1135\n",
            "        2.0       0.80      0.80      0.80      1032\n",
            "        3.0       0.76      0.78      0.77      1010\n",
            "        4.0       0.52      0.90      0.66       982\n",
            "        5.0       0.65      0.60      0.63       892\n",
            "        6.0       0.94      0.73      0.82       958\n",
            "        7.0       0.86      0.74      0.80      1028\n",
            "        8.0       0.86      0.68      0.76       974\n",
            "        9.0       0.74      0.57      0.64      1009\n",
            "\n",
            "avg / total       0.79      0.77      0.77     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 926    0    9    7   13    3    7    5    5    5]\n",
            " [   0 1066   30    6    5    3    2    0   23    0]\n",
            " [  26   32  830   40   33    7   10   25   19   10]\n",
            " [  12    5   30  785   15  123    0    6   24   10]\n",
            " [   4    0    3    2  884    0   10    0    0   79]\n",
            " [  38   10    5   85  164  535    7   21   19    8]\n",
            " [  39    3   45    1  120   43  704    0    1    2]\n",
            " [  11   25   43   15   95    0    0  765    3   71]\n",
            " [   5    8   45   73   63   80    9   10  661   20]\n",
            " [   7    5    4   24  298   25    1   54   16  575]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59890,) [0. 0. 0. ... 7. 4. 4.]\n",
            "probabilities: (59890, 10) \n",
            " [0 0 0 ... 7 4 4]\n",
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [ 9  4 16 12 18 14 13 11 10 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.894 s \n",
            "\n",
            "Accuracy rate for 77.960000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.95      0.92       980\n",
            "        1.0       0.96      0.89      0.92      1135\n",
            "        2.0       0.69      0.89      0.78      1032\n",
            "        3.0       0.80      0.68      0.74      1010\n",
            "        4.0       0.61      0.86      0.71       982\n",
            "        5.0       0.66      0.63      0.64       892\n",
            "        6.0       0.91      0.83      0.87       958\n",
            "        7.0       0.79      0.78      0.78      1028\n",
            "        8.0       0.87      0.66      0.75       974\n",
            "        9.0       0.71      0.61      0.65      1009\n",
            "\n",
            "avg / total       0.79      0.78      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 929    0   18    3    8    4   10    2    5    1]\n",
            " [   0 1009   67    4    3    1    3   28   20    0]\n",
            " [  12    3  918   19   23    5   15   21   10    6]\n",
            " [   7    1   89  687    6  177    2   13   20    8]\n",
            " [   1    0    6    2  843    1   18    5    2  104]\n",
            " [  30    6   22   67  127  562   12   28   31    7]\n",
            " [  26    3   77    0   36   14  794    0    5    3]\n",
            " [   8   12   53    3   53    2    0  800    1   96]\n",
            " [  11    9   77   60   45   68   19   17  643   25]\n",
            " [   6    6    7   12  236   23    3  100    5  611]]\n",
            "--------------------------------\n",
            "val predicted: (59880,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59880, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [10  6 16 14 19 15 14 12 11 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.046 s \n",
            "\n",
            "Accuracy rate for 78.170000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.95      0.92       980\n",
            "        1.0       0.91      0.85      0.88      1135\n",
            "        2.0       0.78      0.83      0.80      1032\n",
            "        3.0       0.73      0.77      0.75      1010\n",
            "        4.0       0.59      0.88      0.71       982\n",
            "        5.0       0.70      0.63      0.66       892\n",
            "        6.0       0.93      0.82      0.87       958\n",
            "        7.0       0.79      0.83      0.81      1028\n",
            "        8.0       0.81      0.70      0.75       974\n",
            "        9.0       0.76      0.53      0.63      1009\n",
            "\n",
            "avg / total       0.79      0.78      0.78     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[929   0  15   2  13   3  10   1   6   1]\n",
            " [  0 965  14  12   2   1   3  59  79   0]\n",
            " [ 17  21 852  45  29   5  13  21  22   7]\n",
            " [  8   3  43 781   6 130   2  10  24   3]\n",
            " [  1   2   3   4 865   0  11   2   0  94]\n",
            " [ 39  18  16 106  94 563   7  21  18  10]\n",
            " [ 33   5  58   3  51  14 789   0   4   1]\n",
            " [  5  34  43   6  46   1   0 857   0  36]\n",
            " [  2   6  39  94  48  64  11  13 679  18]\n",
            " [  7   6   3  18 311  25   1  94   7 537]]\n",
            "--------------------------------\n",
            "val predicted: (59870,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59870, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [11  6 16 14 21 15 14 14 14 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.183 s \n",
            "\n",
            "Accuracy rate for 80.670000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.97      0.92       980\n",
            "        1.0       0.93      0.88      0.90      1135\n",
            "        2.0       0.84      0.82      0.83      1032\n",
            "        3.0       0.78      0.76      0.77      1010\n",
            "        4.0       0.64      0.91      0.75       982\n",
            "        5.0       0.73      0.60      0.66       892\n",
            "        6.0       0.94      0.84      0.89       958\n",
            "        7.0       0.81      0.89      0.85      1028\n",
            "        8.0       0.76      0.76      0.76       974\n",
            "        9.0       0.83      0.63      0.71      1009\n",
            "\n",
            "avg / total       0.81      0.81      0.81     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 946    2    8    1    7    2    7    1    5    1]\n",
            " [   0 1002    6    2    5    3    2   17   98    0]\n",
            " [  22   12  842   30   31    2   12   35   40    6]\n",
            " [  12    2   46  764    7  117    1   22   29   10]\n",
            " [   1    3    2    0  893    1   10    5    2   65]\n",
            " [  59   18   10   96   98  537    7   16   42    9]\n",
            " [  28    6   42    0   60    9  802    1    9    1]\n",
            " [   6   29   27    1   28    0    0  913    3   21]\n",
            " [   4    4   21   70   42   46   11   22  737   17]\n",
            " [   6    5    1   12  235   14    2   97    6  631]]\n",
            "--------------------------------\n",
            "val predicted: (59860,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59860, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [12  7 17 17 21 16 14 14 14 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.245 s \n",
            "\n",
            "Accuracy rate for 81.760000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.97      0.93       980\n",
            "        1.0       0.89      0.96      0.92      1135\n",
            "        2.0       0.84      0.80      0.82      1032\n",
            "        3.0       0.75      0.83      0.79      1010\n",
            "        4.0       0.62      0.91      0.74       982\n",
            "        5.0       0.77      0.61      0.68       892\n",
            "        6.0       0.96      0.78      0.86       958\n",
            "        7.0       0.92      0.83      0.87      1028\n",
            "        8.0       0.86      0.72      0.78       974\n",
            "        9.0       0.78      0.74      0.76      1009\n",
            "\n",
            "avg / total       0.83      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 954    1    4    3    7    0    5    0    4    2]\n",
            " [   0 1090    2    4    2    3    2    3   29    0]\n",
            " [  17   49  823   54   27    2   10   21   22    7]\n",
            " [   2    2   35  839    8   80    1   10   18   15]\n",
            " [   1    0    3    1  890    0    5    1    1   80]\n",
            " [  34   18   10  126  113  540    5    4   29   13]\n",
            " [  31   10   48    2   98   23  743    0    2    1]\n",
            " [  10   33   33    0   49    0    0  854    2   47]\n",
            " [   6   14   23   88   47   40    7   10  700   39]\n",
            " [   7    8    2    8  195   14    0   27    5  743]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [12  7 18 18 21 20 15 16 14 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.309 s \n",
            "\n",
            "Accuracy rate for 83.630000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.97      0.95       980\n",
            "        1.0       0.90      0.96      0.93      1135\n",
            "        2.0       0.87      0.79      0.83      1032\n",
            "        3.0       0.74      0.85      0.79      1010\n",
            "        4.0       0.72      0.86      0.78       982\n",
            "        5.0       0.78      0.74      0.76       892\n",
            "        6.0       0.93      0.81      0.87       958\n",
            "        7.0       0.86      0.90      0.88      1028\n",
            "        8.0       0.89      0.69      0.77       974\n",
            "        9.0       0.78      0.77      0.78      1009\n",
            "\n",
            "avg / total       0.84      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 947    2    6    4    7    3    6    0    4    1]\n",
            " [   0 1092    4    3    2    6    1    2   25    0]\n",
            " [  10   52  820   43   25    5   15   39   17    6]\n",
            " [   1    4   25  863    4   76    0   16   12    9]\n",
            " [   1    1    4    1  841    1    8   11    2  112]\n",
            " [  20    4    7  122   33  657   10   10   13   16]\n",
            " [  27    7   31    3   78   30  775    1    4    2]\n",
            " [   7   26   22    0   18    0    0  921    3   31]\n",
            " [   5   15   21  111   35   48   13   16  669   41]\n",
            " [   3    7    3   17  118   18    1   58    6  778]]\n",
            "--------------------------------\n",
            "val predicted: (59840,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59840, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [13  7 21 19 22 21 16 16 16 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.489 s \n",
            "\n",
            "Accuracy rate for 85.260000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.96      0.95       980\n",
            "        1.0       0.94      0.97      0.95      1135\n",
            "        2.0       0.85      0.86      0.85      1032\n",
            "        3.0       0.79      0.81      0.80      1010\n",
            "        4.0       0.76      0.89      0.82       982\n",
            "        5.0       0.75      0.77      0.76       892\n",
            "        6.0       0.95      0.84      0.89       958\n",
            "        7.0       0.88      0.87      0.87      1028\n",
            "        8.0       0.89      0.76      0.82       974\n",
            "        9.0       0.80      0.77      0.79      1009\n",
            "\n",
            "avg / total       0.86      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    2    9    1    4   10    6    1    4    2]\n",
            " [   0 1096    6    2    2    6    1    3   19    0]\n",
            " [   8   17  889   28   22    5    9   28   19    7]\n",
            " [   2    3   31  822    4   97    1   15   23   12]\n",
            " [   2    2    4    0  875    1   13    7    3   75]\n",
            " [  16    5    6  111   35  684    3   10   10   12]\n",
            " [  25    4   40    1   39   38  808    0    2    1]\n",
            " [   4   19   35    0   22    0    0  898    3   47]\n",
            " [   5   10   26   58   24   61    7   11  737   35]\n",
            " [   6    7    3   16  127   12    3   52    7  776]]\n",
            "--------------------------------\n",
            "val predicted: (59830,) [0. 0. 0. ... 9. 7. 7.]\n",
            "probabilities: (59830, 10) \n",
            " [0 0 0 ... 9 7 7]\n",
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [14  7 21 22 24 22 17 18 16 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.585 s \n",
            "\n",
            "Accuracy rate for 85.370000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.96      0.95       980\n",
            "        1.0       0.97      0.96      0.96      1135\n",
            "        2.0       0.88      0.87      0.87      1032\n",
            "        3.0       0.74      0.88      0.80      1010\n",
            "        4.0       0.71      0.95      0.81       982\n",
            "        5.0       0.78      0.76      0.77       892\n",
            "        6.0       0.95      0.82      0.88       958\n",
            "        7.0       0.87      0.91      0.89      1028\n",
            "        8.0       0.91      0.71      0.80       974\n",
            "        9.0       0.88      0.69      0.78      1009\n",
            "\n",
            "avg / total       0.86      0.85      0.85     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    1    9    7    5    4    6    0    3    2]\n",
            " [   0 1087    4    6    6    3    2    3   24    0]\n",
            " [  10    6  896   38   23    2    9   31   14    3]\n",
            " [   0    0   21  889    2   72    0   14   10    2]\n",
            " [   1    0    5    0  928    2    9    5    2   30]\n",
            " [  10    2    6  132   37  679    5    6    8    7]\n",
            " [  16    3   36    6   69   39  787    0    1    1]\n",
            " [   5   12   23    1   22    0    0  936    3   26]\n",
            " [  10    8   21  107   33   56    6   17  694   22]\n",
            " [   6    3    2   22  188   15    2   67    6  698]]\n",
            "--------------------------------\n",
            "val predicted: (59820,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59820, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [15  7 23 22 24 23 18 19 20 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.614 s \n",
            "\n",
            "Accuracy rate for 85.820000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.96      0.95       980\n",
            "        1.0       0.96      0.94      0.95      1135\n",
            "        2.0       0.88      0.84      0.86      1032\n",
            "        3.0       0.77      0.86      0.81      1010\n",
            "        4.0       0.74      0.92      0.82       982\n",
            "        5.0       0.78      0.79      0.78       892\n",
            "        6.0       0.94      0.84      0.89       958\n",
            "        7.0       0.87      0.92      0.89      1028\n",
            "        8.0       0.83      0.79      0.81       974\n",
            "        9.0       0.89      0.69      0.78      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    2    6    6    2    8    9    0    4    1]\n",
            " [   0 1070    4    4    3    5    2    2   45    0]\n",
            " [  10   23  871   33   18    6   11   26   32    2]\n",
            " [   0    1   21  872    2   67    2   17   25    3]\n",
            " [   5    1    5    0  907    2   11    7    7   37]\n",
            " [  12    2    6  113   31  702    4    6    9    7]\n",
            " [  18    3   31    4   62   26  809    0    4    1]\n",
            " [   4   11   24    1   15    2    0  941    7   23]\n",
            " [   2    1   13   72   27   61    7   13  769    9]\n",
            " [   6    5    4   27  156   20    2   71   19  699]]\n",
            "--------------------------------\n",
            "val predicted: (59810,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59810, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [15  8 23 24 24 25 19 19 22 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.759 s \n",
            "\n",
            "Accuracy rate for 85.760000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.97      0.96       980\n",
            "        1.0       0.95      0.96      0.95      1135\n",
            "        2.0       0.92      0.82      0.87      1032\n",
            "        3.0       0.77      0.85      0.81      1010\n",
            "        4.0       0.75      0.89      0.81       982\n",
            "        5.0       0.77      0.74      0.75       892\n",
            "        6.0       0.94      0.89      0.91       958\n",
            "        7.0       0.89      0.90      0.89      1028\n",
            "        8.0       0.81      0.81      0.81       974\n",
            "        9.0       0.84      0.74      0.79      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 950    0    1    2    3    7   10    1    5    1]\n",
            " [   0 1085    3    2    2    3    2    1   37    0]\n",
            " [   8   18  851   35   19    5    9   28   56    3]\n",
            " [   0    4   13  858    2   82    2   15   30    4]\n",
            " [   4    0    3    0  873    0   13    5    9   75]\n",
            " [  13    2    4  134   41  656    8    7   13   14]\n",
            " [  14    3   10    2   42   32  849    1    5    0]\n",
            " [   4   14   24    2   19    0    0  921   12   32]\n",
            " [   2    5   10   69   23   50    5   11  791    8]\n",
            " [   7    9    2   17  147   16    2   46   21  742]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59800,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [15  8 25 24 27 28 21 19 22 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.786 s \n",
            "\n",
            "Accuracy rate for 86.010000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.96      0.95       980\n",
            "        1.0       0.94      0.96      0.95      1135\n",
            "        2.0       0.91      0.82      0.86      1032\n",
            "        3.0       0.78      0.82      0.80      1010\n",
            "        4.0       0.77      0.92      0.84       982\n",
            "        5.0       0.72      0.81      0.76       892\n",
            "        6.0       0.92      0.91      0.92       958\n",
            "        7.0       0.88      0.91      0.90      1028\n",
            "        8.0       0.83      0.78      0.80       974\n",
            "        9.0       0.90      0.70      0.79      1009\n",
            "\n",
            "avg / total       0.86      0.86      0.86     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    0    3    2    2   11   16    1    5    0]\n",
            " [   0 1087    3    2    0    8    1    1   33    0]\n",
            " [   6   24  845   36   14   13   12   27   53    2]\n",
            " [   0    7   20  825    2  109    2   17   26    2]\n",
            " [   7    0    4    0  907    8   18    7    2   29]\n",
            " [  10    4    5  104   19  720    9    3    8   10]\n",
            " [  11    4    8    2   21   32  876    1    3    0]\n",
            " [   5   15   22    0   17    3    0  935    9   22]\n",
            " [   4    5   15   65   22   72    9   13  757   12]\n",
            " [   6    6    2   15  172   26    5   56   12  709]]\n",
            "--------------------------------\n",
            "val predicted: (59790,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59790, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [15  9 26 25 28 29 21 20 23 24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.937 s \n",
            "\n",
            "Accuracy rate for 87.010000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.97      0.96       980\n",
            "        1.0       0.95      0.94      0.95      1135\n",
            "        2.0       0.89      0.86      0.87      1032\n",
            "        3.0       0.81      0.84      0.82      1010\n",
            "        4.0       0.79      0.92      0.85       982\n",
            "        5.0       0.77      0.83      0.80       892\n",
            "        6.0       0.93      0.89      0.91       958\n",
            "        7.0       0.91      0.90      0.90      1028\n",
            "        8.0       0.83      0.80      0.82       974\n",
            "        9.0       0.88      0.74      0.81      1009\n",
            "\n",
            "avg / total       0.87      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 949    0    0    2    2   10   12    0    4    1]\n",
            " [   0 1068    4    2    1    8    2    0   49    1]\n",
            " [  10    9  885   25   13    5   12   28   42    3]\n",
            " [   0    6   20  849    3   74    2   11   40    5]\n",
            " [   6    1    4    0  899    6   15    2    2   47]\n",
            " [   9    2    6   95   17  739    8    2    9    5]\n",
            " [  17    4   26    3   16   33  857    0    1    1]\n",
            " [   5   15   32    1   20    3    0  921    8   23]\n",
            " [   3    5   15   59   17   56   11   10  783   15]\n",
            " [   4   10    5   16  150   23    3   38    9  751]]\n",
            "--------------------------------\n",
            "val predicted: (59780,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59780, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [15  9 26 27 28 31 23 22 24 25] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.004 s \n",
            "\n",
            "Accuracy rate for 87.450000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.95      0.95       980\n",
            "        1.0       0.97      0.95      0.96      1135\n",
            "        2.0       0.92      0.85      0.88      1032\n",
            "        3.0       0.79      0.88      0.84      1010\n",
            "        4.0       0.78      0.91      0.84       982\n",
            "        5.0       0.80      0.81      0.81       892\n",
            "        6.0       0.94      0.91      0.93       958\n",
            "        7.0       0.91      0.91      0.91      1028\n",
            "        8.0       0.83      0.81      0.82       974\n",
            "        9.0       0.87      0.74      0.80      1009\n",
            "\n",
            "avg / total       0.88      0.87      0.87     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 935    0    2    5    2   15   15    2    4    0]\n",
            " [   0 1077    2    2    1    4    2    0   46    1]\n",
            " [   9   10  876   32   18    5   11   25   44    2]\n",
            " [   0    3   15  890    1   52    1   15   27    6]\n",
            " [   8    0    4    1  897    3   13    3    4   49]\n",
            " [   7    3    1  108   18  723    9    6    8    9]\n",
            " [  12    3   14    2   18   30  876    1    2    0]\n",
            " [   0   11   25    2   11    1    0  937   13   28]\n",
            " [   4    1   15   60   17   55    5   11  786   20]\n",
            " [   7    6    2   19  173   14    3   26   11  748]]\n",
            "--------------------------------\n",
            "val predicted: (59770,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59770, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [16  9 27 27 29 31 25 24 25 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.091 s \n",
            "\n",
            "Accuracy rate for 87.830000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.96      0.96       980\n",
            "        1.0       0.97      0.93      0.95      1135\n",
            "        2.0       0.92      0.83      0.87      1032\n",
            "        3.0       0.80      0.86      0.83      1010\n",
            "        4.0       0.84      0.91      0.88       982\n",
            "        5.0       0.82      0.79      0.80       892\n",
            "        6.0       0.92      0.94      0.93       958\n",
            "        7.0       0.89      0.90      0.90      1028\n",
            "        8.0       0.81      0.83      0.82       974\n",
            "        9.0       0.85      0.81      0.83      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 939    0    6    1    2   10   16    1    5    0]\n",
            " [   0 1059    4    2    1    4    2    2   59    2]\n",
            " [  10   10  861   21   17    5   13   25   64    6]\n",
            " [   0    1   16  871    1   62    2   14   34    9]\n",
            " [   6    1    3    0  893    0   15    7    3   54]\n",
            " [   9    1    0  120   21  705   12    3   10   11]\n",
            " [   9    3   13    0    7   20  901    1    4    0]\n",
            " [   1    8   21    2   10    2    0  930    7   47]\n",
            " [   6    1   10   55   13   40   16   12  806   15]\n",
            " [   5    6    4   15   93   14    2   46    6  818]]\n",
            "--------------------------------\n",
            "val predicted: (59760,) [0. 0. 0. ... 9. 7. 7.]\n",
            "probabilities: (59760, 10) \n",
            " [0 0 0 ... 9 7 7]\n",
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [16 10 28 30 29 31 26 24 28 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.207 s \n",
            "\n",
            "Accuracy rate for 88.650000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.96      0.96       980\n",
            "        1.0       0.98      0.95      0.96      1135\n",
            "        2.0       0.92      0.86      0.89      1032\n",
            "        3.0       0.81      0.89      0.85      1010\n",
            "        4.0       0.85      0.88      0.87       982\n",
            "        5.0       0.85      0.80      0.82       892\n",
            "        6.0       0.91      0.95      0.93       958\n",
            "        7.0       0.90      0.92      0.91      1028\n",
            "        8.0       0.84      0.82      0.83       974\n",
            "        9.0       0.85      0.82      0.83      1009\n",
            "\n",
            "avg / total       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    0    2    1    2   14   13    1    6    0]\n",
            " [   0 1075    4    3    0    4    2    3   42    2]\n",
            " [  10    4  888   23   17    2   15   23   45    5]\n",
            " [   0    2   20  899    1   40    3   12   25    8]\n",
            " [   5    0    3    1  869    2   21    8    5   68]\n",
            " [   9    3    1  107   16  713   17    3   13   10]\n",
            " [  13    3    8    1    4   16  909    1    3    0]\n",
            " [   1    8   21    2   10    0    0  942    6   38]\n",
            " [   4    0   14   62   14   39   12   11  798   20]\n",
            " [   5    5    3   13   88   12    2   38   12  831]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [17 10 30 30 32 31 26 26 29 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.295 s \n",
            "\n",
            "Accuracy rate for 88.100000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.96      0.96       980\n",
            "        1.0       0.99      0.90      0.94      1135\n",
            "        2.0       0.90      0.88      0.89      1032\n",
            "        3.0       0.80      0.90      0.85      1010\n",
            "        4.0       0.83      0.94      0.88       982\n",
            "        5.0       0.86      0.76      0.81       892\n",
            "        6.0       0.94      0.92      0.93       958\n",
            "        7.0       0.85      0.91      0.88      1028\n",
            "        8.0       0.83      0.83      0.83       974\n",
            "        9.0       0.87      0.81      0.84      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 939    0    7    2    2    7   14    1    8    0]\n",
            " [   0 1017    7    2    1    4    2   61   40    1]\n",
            " [   6    1  903   20   20    3   11   26   38    4]\n",
            " [   0    0   21  912    1   31    0   13   26    6]\n",
            " [   3    0    4    2  919    1    8    8    4   33]\n",
            " [   7    1    6  123   23  676   13    5   23   15]\n",
            " [  16    2   16    1   12   21  884    0    6    0]\n",
            " [   0    6   19    2   11    0    0  938    6   46]\n",
            " [   6    0   15   67   15   27    9   11  806   18]\n",
            " [   4    5    3   14  104   12    1   37   13  816]]\n",
            "--------------------------------\n",
            "val predicted: (59740,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59740, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [17 10 31 31 34 34 27 26 30 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.392 s \n",
            "\n",
            "Accuracy rate for 87.930000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.96      0.96       980\n",
            "        1.0       0.99      0.89      0.93      1135\n",
            "        2.0       0.90      0.87      0.88      1032\n",
            "        3.0       0.83      0.89      0.86      1010\n",
            "        4.0       0.82      0.93      0.87       982\n",
            "        5.0       0.83      0.82      0.82       892\n",
            "        6.0       0.92      0.94      0.93       958\n",
            "        7.0       0.86      0.90      0.88      1028\n",
            "        8.0       0.83      0.82      0.82       974\n",
            "        9.0       0.86      0.78      0.82      1009\n",
            "\n",
            "avg / total       0.88      0.88      0.88     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 939    0    4    2    1    8   18    1    7    0]\n",
            " [   0 1008    7    4    0    2    3   44   66    1]\n",
            " [   7    2  900   27   18    1   11   24   41    1]\n",
            " [   0    0   20  900    1   53    0   12   19    5]\n",
            " [   1    0    4    3  909    0   14    8    3   40]\n",
            " [   9    2   11   82   18  729   11    4   13   13]\n",
            " [   6    2   17    2   10   21  896    0    4    0]\n",
            " [   0    4   24    7   10    0    0  930    3   50]\n",
            " [   3    1   12   50   14   48   15   13  799   19]\n",
            " [   3    4    3   13  134   14    1   41   13  783]]\n",
            "--------------------------------\n",
            "val predicted: (59730,) [0. 0. 0. ... 9. 7. 7.]\n",
            "probabilities: (59730, 10) \n",
            " [0 0 0 ... 9 7 7]\n",
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [19 13 32 33 34 35 27 26 30 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.414 s \n",
            "\n",
            "Accuracy rate for 89.210000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.97      0.96       980\n",
            "        1.0       0.97      0.98      0.97      1135\n",
            "        2.0       0.93      0.88      0.90      1032\n",
            "        3.0       0.83      0.91      0.87      1010\n",
            "        4.0       0.83      0.91      0.87       982\n",
            "        5.0       0.86      0.81      0.83       892\n",
            "        6.0       0.93      0.94      0.94       958\n",
            "        7.0       0.91      0.90      0.91      1028\n",
            "        8.0       0.87      0.81      0.84       974\n",
            "        9.0       0.85      0.80      0.82      1009\n",
            "\n",
            "avg / total       0.89      0.89      0.89     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 951    0    1    0    0    8   13    1    5    1]\n",
            " [   0 1107    3    6    1    1    3    0   13    1]\n",
            " [  11   11  906   22    9    0   11   25   34    3]\n",
            " [   0    1   13  920    2   38    2   12   17    5]\n",
            " [   7    0    4    1  894    1   12    5    9   49]\n",
            " [  11    6    2   93   15  723    9    5   14   14]\n",
            " [  10    3   13    1   10   14  901    1    5    0]\n",
            " [   2    9   18    5    9    0    0  928    4   53]\n",
            " [   6    4   11   53   23   47   13   13  788   16]\n",
            " [   9    6    4   13  118   12    1   27   16  803]]\n",
            "--------------------------------\n",
            "val predicted: (59720,) [0. 0. 0. ... 9. 7. 7.]\n",
            "probabilities: (59720, 10) \n",
            " [0 0 0 ... 9 7 7]\n",
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [19 13 32 35 35 37 27 27 32 33] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.476 s \n",
            "\n",
            "Accuracy rate for 89.570000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.97      0.96       980\n",
            "        1.0       0.97      0.97      0.97      1135\n",
            "        2.0       0.92      0.86      0.89      1032\n",
            "        3.0       0.85      0.88      0.87      1010\n",
            "        4.0       0.85      0.92      0.88       982\n",
            "        5.0       0.82      0.85      0.84       892\n",
            "        6.0       0.94      0.93      0.94       958\n",
            "        7.0       0.92      0.90      0.91      1028\n",
            "        8.0       0.87      0.83      0.85       974\n",
            "        9.0       0.86      0.83      0.84      1009\n",
            "\n",
            "avg / total       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 948    0    3    1    0    7   13    1    6    1]\n",
            " [   0 1098    3    3    1    5    1    1   22    1]\n",
            " [  11   12  890   15   15    6   12   28   39    4]\n",
            " [   0    0   14  892    3   65    0    9   21    6]\n",
            " [   4    1    4    2  904    1   11    3    3   49]\n",
            " [  10    2    4   66   15  761    8    2   11   13]\n",
            " [   8    3   11    1   12   28  892    0    2    1]\n",
            " [   1    8   18    2   15    2    0  930    5   47]\n",
            " [   5    5   14   42   25   37    8   12  808   18]\n",
            " [   6    7    4   20   79   13    1   29   16  834]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59710,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59710, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [20 14 34 35 35 38 28 29 32 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.482 s \n",
            "\n",
            "Accuracy rate for 90.340000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.98      0.96       980\n",
            "        1.0       0.97      0.99      0.98      1135\n",
            "        2.0       0.91      0.89      0.90      1032\n",
            "        3.0       0.85      0.91      0.88      1010\n",
            "        4.0       0.87      0.90      0.89       982\n",
            "        5.0       0.84      0.87      0.85       892\n",
            "        6.0       0.95      0.92      0.94       958\n",
            "        7.0       0.93      0.91      0.92      1028\n",
            "        8.0       0.91      0.79      0.85       974\n",
            "        9.0       0.85      0.86      0.85      1009\n",
            "\n",
            "avg / total       0.90      0.90      0.90     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 957    0    1    1    0    9    7    2    3    0]\n",
            " [   0 1118    2    3    1    5    0    0    5    1]\n",
            " [   8    8  921   26   10    2   11   19   24    3]\n",
            " [   0    0   16  919    3   44    1    8   13    6]\n",
            " [   6    1    6    2  887    2   11    4    4   59]\n",
            " [  11    4    4   51   11  774    6    6    9   16]\n",
            " [  12    3   20    1   11   23  886    0    2    0]\n",
            " [   1   10   24    5    5    2    0  935    3   43]\n",
            " [   9    4   16   54   23   49    8   10  772   29]\n",
            " [   6    7    6   16   68   10    2   20    9  865]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [20 14 35 35 36 39 30 29 33 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.568 s \n",
            "\n",
            "Accuracy rate for 91.120000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.98      0.97       980\n",
            "        1.0       0.97      0.99      0.98      1135\n",
            "        2.0       0.91      0.91      0.91      1032\n",
            "        3.0       0.86      0.90      0.88      1010\n",
            "        4.0       0.86      0.93      0.89       982\n",
            "        5.0       0.87      0.85      0.86       892\n",
            "        6.0       0.94      0.95      0.95       958\n",
            "        7.0       0.94      0.92      0.93      1028\n",
            "        8.0       0.92      0.82      0.87       974\n",
            "        9.0       0.87      0.86      0.86      1009\n",
            "\n",
            "avg / total       0.91      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 957    0    1    2    0    3   10    1    6    0]\n",
            " [   0 1118    3    2    1    3    2    0    4    2]\n",
            " [  10    7  941   12    8    1   11   19   17    6]\n",
            " [   0    0   19  908    1   46    3    9   16    8]\n",
            " [   3    0    6    3  912    3   14    3    3   35]\n",
            " [  11    2    4   66   17  759    7    3   11   12]\n",
            " [   9    3    7    2    8   14  911    1    3    0]\n",
            " [   0   11   22    4    8    0    0  942    5   36]\n",
            " [   4    5   22   43   23   33    8    9  796   31]\n",
            " [   6    8    4   12   80   13    1   13    4  868]]\n",
            "--------------------------------\n",
            "val predicted: (59690,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59690, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [20 14 36 38 37 40 30 29 36 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.662 s \n",
            "\n",
            "Accuracy rate for 90.860000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.97      0.96       980\n",
            "        1.0       0.96      0.98      0.97      1135\n",
            "        2.0       0.92      0.89      0.90      1032\n",
            "        3.0       0.89      0.90      0.89      1010\n",
            "        4.0       0.88      0.91      0.90       982\n",
            "        5.0       0.85      0.87      0.86       892\n",
            "        6.0       0.94      0.94      0.94       958\n",
            "        7.0       0.94      0.89      0.92      1028\n",
            "        8.0       0.91      0.83      0.87       974\n",
            "        9.0       0.84      0.89      0.86      1009\n",
            "\n",
            "avg / total       0.91      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 948    0    2    1    0    9   11    2    6    1]\n",
            " [   0 1117    3    2    1    3    1    0    6    2]\n",
            " [   7   10  919   18   12    2   15   17   29    3]\n",
            " [   1    2   13  906    2   50    2    6   17   11]\n",
            " [   5    0    6    0  897    1   10    5    3   55]\n",
            " [   9    6    2   50   19  773    9    5    9   10]\n",
            " [   9    4    9    2   10   18  900    3    3    0]\n",
            " [   2   10   25    3    7    0    0  916    5   60]\n",
            " [   2    3   19   28   17   46    7    6  812   34]\n",
            " [   8    8    3   11   51   11    1   12    6  898]]\n",
            "--------------------------------\n",
            "val predicted: (59680,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59680, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [21 14 38 39 38 42 31 30 37 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.721 s \n",
            "\n",
            "Accuracy rate for 91.170000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.97      0.97       980\n",
            "        1.0       0.97      0.98      0.98      1135\n",
            "        2.0       0.92      0.90      0.91      1032\n",
            "        3.0       0.90      0.88      0.89      1010\n",
            "        4.0       0.89      0.90      0.89       982\n",
            "        5.0       0.84      0.88      0.86       892\n",
            "        6.0       0.94      0.94      0.94       958\n",
            "        7.0       0.94      0.92      0.93      1028\n",
            "        8.0       0.90      0.85      0.87       974\n",
            "        9.0       0.86      0.88      0.87      1009\n",
            "\n",
            "avg / total       0.91      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    0    1    2    0    7   11    1    6    0]\n",
            " [   0 1116    3    4    1    4    1    0    5    1]\n",
            " [   6    5  924   12   11    3   17   20   30    4]\n",
            " [   0    2   17  890    0   65    2    9   20    5]\n",
            " [   5    1    4    1  885    0   14    3    4   65]\n",
            " [   9    2    2   34   13  784    9    6   16   17]\n",
            " [   7    3    8    2    8   23  905    0    2    0]\n",
            " [   1   10   22    3    6    1    0  949    5   31]\n",
            " [   5    3   16   33   18   36    6    7  824   26]\n",
            " [   6    8    5   13   55   10    2   16    6  888]]\n",
            "--------------------------------\n",
            "val predicted: (59670,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59670, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [21 15 38 40 38 42 32 30 44 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.775 s \n",
            "\n",
            "Accuracy rate for 91.540000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.96      0.96       980\n",
            "        1.0       0.97      0.98      0.97      1135\n",
            "        2.0       0.92      0.91      0.92      1032\n",
            "        3.0       0.92      0.87      0.89      1010\n",
            "        4.0       0.89      0.91      0.90       982\n",
            "        5.0       0.84      0.87      0.86       892\n",
            "        6.0       0.94      0.95      0.94       958\n",
            "        7.0       0.94      0.91      0.93      1028\n",
            "        8.0       0.90      0.89      0.89       974\n",
            "        9.0       0.86      0.88      0.87      1009\n",
            "\n",
            "avg / total       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    0    4    3    0   14   10    1    4    1]\n",
            " [   0 1113    2    5    1    2    2    0    9    1]\n",
            " [   6    4  942    6    9    2   15   14   32    2]\n",
            " [   0    0   24  879    0   67    2    8   22    8]\n",
            " [   4    0    6    1  896    2   13    3    5   52]\n",
            " [  11    4    2   41   14  779   12    4   12   13]\n",
            " [   6    3    6    0    9   21  906    0    6    1]\n",
            " [   1   13   24    3    8    1    0  938    5   35]\n",
            " [   2    5   11    9   13   25    7    8  866   28]\n",
            " [   7    8    5   10   53   12    1   17    4  892]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59660, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [21 15 39 44 38 44 32 30 46 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.862 s \n",
            "\n",
            "Accuracy rate for 91.840000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.96      0.97       980\n",
            "        1.0       0.97      0.98      0.98      1135\n",
            "        2.0       0.93      0.90      0.91      1032\n",
            "        3.0       0.92      0.90      0.91      1010\n",
            "        4.0       0.91      0.90      0.91       982\n",
            "        5.0       0.87      0.88      0.87       892\n",
            "        6.0       0.94      0.95      0.95       958\n",
            "        7.0       0.94      0.92      0.93      1028\n",
            "        8.0       0.86      0.90      0.88       974\n",
            "        9.0       0.86      0.89      0.88      1009\n",
            "\n",
            "avg / total       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    0    3    2    0    7   16    3    8    0]\n",
            " [   0 1111    4    2    1    4    1    1    9    2]\n",
            " [   7    3  925    6    8    1   12   17   46    7]\n",
            " [   0    0   18  907    1   49    2    7   22    4]\n",
            " [   3    1    7    1  887    0   12    6    3   62]\n",
            " [   6    1    2   43    6  781   10    4   27   12]\n",
            " [   4    3    8    1    6   16  912    0    8    0]\n",
            " [   2   11   17    3    7    2    0  943   10   33]\n",
            " [   1    5   11    8   12   22    5   10  876   24]\n",
            " [   5    8    5   13   45   12    2   14    4  901]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [22 15 39 44 40 48 32 31 48 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.907 s \n",
            "\n",
            "Accuracy rate for 91.760000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.96      0.97       980\n",
            "        1.0       0.98      0.98      0.98      1135\n",
            "        2.0       0.91      0.89      0.90      1032\n",
            "        3.0       0.92      0.88      0.90      1010\n",
            "        4.0       0.90      0.93      0.91       982\n",
            "        5.0       0.84      0.89      0.86       892\n",
            "        6.0       0.95      0.92      0.94       958\n",
            "        7.0       0.93      0.93      0.93      1028\n",
            "        8.0       0.88      0.90      0.89       974\n",
            "        9.0       0.89      0.88      0.88      1009\n",
            "\n",
            "avg / total       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    0    7    2    0   10   10    2    6    0]\n",
            " [   0 1113    2    3    1    7    1    0    7    1]\n",
            " [   6    2  923    8   10    4   11   18   47    3]\n",
            " [   0    0   17  889    1   56    2   10   29    6]\n",
            " [   5    0    5    3  913    3    8    4    3   38]\n",
            " [   6    4    4   30    7  794    8    9   14   16]\n",
            " [   5    3   15    2    8   36  884    0    5    0]\n",
            " [   1   10   23    5    8    1    0  951    6   23]\n",
            " [   0    3   10    9   14   22    5   10  878   23]\n",
            " [   6    6    6   14   55   12    3   17    2  888]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59640, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [22 15 41 45 41 50 33 31 49 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 9.954 s \n",
            "\n",
            "Accuracy rate for 91.070000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.96      0.96       980\n",
            "        1.0       0.97      0.97      0.97      1135\n",
            "        2.0       0.92      0.88      0.90      1032\n",
            "        3.0       0.93      0.87      0.90      1010\n",
            "        4.0       0.89      0.91      0.90       982\n",
            "        5.0       0.79      0.91      0.85       892\n",
            "        6.0       0.94      0.92      0.93       958\n",
            "        7.0       0.95      0.90      0.93      1028\n",
            "        8.0       0.88      0.89      0.89       974\n",
            "        9.0       0.87      0.87      0.87      1009\n",
            "\n",
            "avg / total       0.91      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    0    2    4    0   21    8    2    3    0]\n",
            " [   0 1104    3    3    1   10    1    0   12    1]\n",
            " [   6    7  909   11   12   10   12   16   46    3]\n",
            " [   0    0   17  883    0   70    1    9   25    5]\n",
            " [   5    0    5    1  894    5   15    1    6   50]\n",
            " [   6    2    2   26   10  816    6    4    9   11]\n",
            " [   6    1   12    0    8   44  886    0    1    0]\n",
            " [   0   17   22    4    9    4    0  929    7   36]\n",
            " [   2    4    7   11   11   31    7    5  865   31]\n",
            " [   8    8    5    9   63   16    4    9    6  881]]\n",
            "--------------------------------\n",
            "val predicted: (59630,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59630, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [22 17 41 46 42 50 33 33 49 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.146 s \n",
            "\n",
            "Accuracy rate for 91.360000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.95      0.96       980\n",
            "        1.0       0.97      0.98      0.98      1135\n",
            "        2.0       0.93      0.89      0.91      1032\n",
            "        3.0       0.91      0.89      0.90      1010\n",
            "        4.0       0.92      0.89      0.91       982\n",
            "        5.0       0.82      0.90      0.86       892\n",
            "        6.0       0.94      0.94      0.94       958\n",
            "        7.0       0.94      0.91      0.92      1028\n",
            "        8.0       0.91      0.86      0.89       974\n",
            "        9.0       0.82      0.91      0.86      1009\n",
            "\n",
            "avg / total       0.92      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 931    0    5    3    0   16   17    2    5    1]\n",
            " [   0 1114    1    3    1    7    1    0    7    1]\n",
            " [   5    6  915   13    9    4   13   21   38    8]\n",
            " [   0    0   12  902    1   60    1   12   13    9]\n",
            " [   5    1    5    0  878    3   10    0    1   79]\n",
            " [   6    2    0   33    4  801    8    3   10   25]\n",
            " [   3    3    7    2    6   35  900    0    2    0]\n",
            " [   0    8   19    3   10    2    0  931    5   50]\n",
            " [   1    4   13   15   14   37    7   10  841   32]\n",
            " [   6    6    4   12   33   14    2    9    0  923]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59620,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59620, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [22 17 41 49 43 50 36 33 50 49] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.098 s \n",
            "\n",
            "Accuracy rate for 91.220000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.98      0.94      0.96       980\n",
            "        1.0       0.97      0.98      0.98      1135\n",
            "        2.0       0.93      0.88      0.90      1032\n",
            "        3.0       0.90      0.92      0.91      1010\n",
            "        4.0       0.91      0.90      0.90       982\n",
            "        5.0       0.84      0.87      0.86       892\n",
            "        6.0       0.93      0.93      0.93       958\n",
            "        7.0       0.95      0.90      0.92      1028\n",
            "        8.0       0.89      0.89      0.89       974\n",
            "        9.0       0.83      0.91      0.86      1009\n",
            "\n",
            "avg / total       0.91      0.91      0.91     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 917    0    5    4    0   23   22    0    7    2]\n",
            " [   0 1114    3    5    1    5    1    0    5    1]\n",
            " [   5    7  907    9   11    4   14   24   47    4]\n",
            " [   0    0   14  925    0   33    3    8   16   11]\n",
            " [   2    0    5    1  885    3   12    1    3   70]\n",
            " [   4    2    3   54   12  776   10    2   11   18]\n",
            " [   4    3    6    1    4   40  893    1    5    1]\n",
            " [   0   11   18    4    6    3    0  926    5   55]\n",
            " [   2    4   13   11   12   24    6    7  863   32]\n",
            " [   1    9    4   13   43    9    2    9    3  916]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59610, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [23 17 42 51 44 52 36 34 51 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.135 s \n",
            "\n",
            "Accuracy rate for 91.880000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.98      0.95      0.97       980\n",
            "        1.0       0.97      0.98      0.98      1135\n",
            "        2.0       0.93      0.88      0.90      1032\n",
            "        3.0       0.91      0.92      0.92      1010\n",
            "        4.0       0.88      0.93      0.91       982\n",
            "        5.0       0.88      0.87      0.88       892\n",
            "        6.0       0.93      0.94      0.94       958\n",
            "        7.0       0.95      0.91      0.93      1028\n",
            "        8.0       0.89      0.90      0.89       974\n",
            "        9.0       0.86      0.89      0.87      1009\n",
            "\n",
            "avg / total       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 932    0    5    3    0   11   20    1    6    2]\n",
            " [   0 1113    3    4    1    5    1    0    6    2]\n",
            " [   4    3  906   14   16    4   16   19   44    6]\n",
            " [   0    0   17  931    1   24    3   12   19    3]\n",
            " [   1    0    4    0  915    0   11    1    3   47]\n",
            " [   4    2    3   37   15  777   12    6   16   20]\n",
            " [   4    3    4    1    8   26  903    0    9    0]\n",
            " [   0   10   23    2    8    1    0  936    6   42]\n",
            " [   2    4   10   15   12   18    5    7  877   24]\n",
            " [   1    8    4   15   60   12    2    7    2  898]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [25 17 43 51 46 53 36 34 53 52] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.154 s \n",
            "\n",
            "Accuracy rate for 92.000000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.97      0.97       980\n",
            "        1.0       0.97      0.98      0.98      1135\n",
            "        2.0       0.95      0.88      0.91      1032\n",
            "        3.0       0.91      0.92      0.91      1010\n",
            "        4.0       0.88      0.94      0.91       982\n",
            "        5.0       0.89      0.87      0.88       892\n",
            "        6.0       0.95      0.94      0.95       958\n",
            "        7.0       0.93      0.92      0.93      1028\n",
            "        8.0       0.89      0.90      0.89       974\n",
            "        9.0       0.86      0.88      0.87      1009\n",
            "\n",
            "avg / total       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 954    0    2    3    0    5    8    2    5    1]\n",
            " [   0 1113    1    6    1    5    1    0    7    1]\n",
            " [   3    2  906   14   18    5   15   29   38    2]\n",
            " [   0    1   15  929    0   28    2    9   18    8]\n",
            " [   8    0    2    0  920    0    8    2    3   39]\n",
            " [   7    2    1   42   16  774    6    6   21   17]\n",
            " [  11    3    5    1    8   19  902    1    8    0]\n",
            " [   0   11   17    6    7    0    0  944    2   41]\n",
            " [   4    2    4   11   15   18    5    7  875   33]\n",
            " [   6   10    4   11   65   12    1   12    5  883]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59590, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [26 17 46 51 46 57 36 34 54 53] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.239 s \n",
            "\n",
            "Accuracy rate for 91.970000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.96      0.96       980\n",
            "        1.0       0.97      0.98      0.97      1135\n",
            "        2.0       0.92      0.91      0.91      1032\n",
            "        3.0       0.93      0.90      0.92      1010\n",
            "        4.0       0.91      0.89      0.90       982\n",
            "        5.0       0.85      0.91      0.88       892\n",
            "        6.0       0.95      0.93      0.94       958\n",
            "        7.0       0.96      0.90      0.93      1028\n",
            "        8.0       0.91      0.88      0.90       974\n",
            "        9.0       0.83      0.92      0.87      1009\n",
            "\n",
            "avg / total       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 938    0    4    4    0   15   12    1    4    2]\n",
            " [   0 1108    5    4    1    5    1    1    9    1]\n",
            " [   5    2  937    5   15    3   12   19   28    6]\n",
            " [   1    0   18  913    1   45    1    7   14   10]\n",
            " [   6    0    4    0  877    0   11    1    3   80]\n",
            " [   7    3    4   24   10  811    8    1   10   14]\n",
            " [   5    3    8    1    8   31  893    1    8    0]\n",
            " [   1   10   22    4    6    2    0  930    3   50]\n",
            " [   4    4   12   11   10   28    4    7  860   34]\n",
            " [   3    8    5   11   33   10    1    5    3  930]]\n",
            "--------------------------------\n",
            "val predicted: (59580,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59580, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [28 17 47 52 46 57 41 35 54 53] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.300 s \n",
            "\n",
            "Accuracy rate for 91.700000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.96      0.97       980\n",
            "        1.0       0.97      0.98      0.97      1135\n",
            "        2.0       0.93      0.89      0.91      1032\n",
            "        3.0       0.94      0.90      0.92      1010\n",
            "        4.0       0.89      0.91      0.90       982\n",
            "        5.0       0.84      0.90      0.87       892\n",
            "        6.0       0.93      0.95      0.94       958\n",
            "        7.0       0.95      0.91      0.93      1028\n",
            "        8.0       0.91      0.87      0.89       974\n",
            "        9.0       0.85      0.90      0.87      1009\n",
            "\n",
            "avg / total       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    0    3    3    0   13   13    3    3    1]\n",
            " [   0 1110    3    3    1    6    2    0    9    1]\n",
            " [   4    4  918   10   14    7   18   22   33    2]\n",
            " [   0    0   19  904    1   56    1   10   12    7]\n",
            " [   5    1    8    0  892    2   11    1    3   59]\n",
            " [   7    2    2   24   12  805   12    2   11   15]\n",
            " [   6    2    4    1   12   19  912    0    2    0]\n",
            " [   1   12   24    2   10    2    0  932    2   43]\n",
            " [   4    4    6    8   14   36   11    7  845   39]\n",
            " [   2    8    4    9   46   17    1    7    4  911]]\n",
            "--------------------------------\n",
            "val predicted: (59570,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59570, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [28 18 50 53 46 58 42 36 55 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.388 s \n",
            "\n",
            "Accuracy rate for 92.120000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.96      0.96       980\n",
            "        1.0       0.97      0.98      0.97      1135\n",
            "        2.0       0.92      0.91      0.91      1032\n",
            "        3.0       0.94      0.90      0.92      1010\n",
            "        4.0       0.92      0.89      0.91       982\n",
            "        5.0       0.87      0.91      0.89       892\n",
            "        6.0       0.94      0.96      0.95       958\n",
            "        7.0       0.95      0.91      0.93      1028\n",
            "        8.0       0.91      0.89      0.90       974\n",
            "        9.0       0.83      0.91      0.87      1009\n",
            "\n",
            "avg / total       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    0    6    1    0   16   11    1    5    3]\n",
            " [   0 1107    4    5    1    3    1    1   12    1]\n",
            " [   3    6  934    2   11    5   12   17   36    6]\n",
            " [   0    0   22  906    0   52    1    8   14    7]\n",
            " [   6    0    7    1  872    1   10    3    3   79]\n",
            " [   4    3    1   26    6  808   11    2   10   21]\n",
            " [   5    4    5    0    3   13  922    1    4    1]\n",
            " [   0   13   22    2    5    0    0  935    4   47]\n",
            " [   4    3   12    9    9   22   11    8  870   26]\n",
            " [   4    7    4   11   37   12    2    9    2  921]]\n",
            "--------------------------------\n",
            "val predicted: (59560,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59560, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [29 19 51 54 49 58 42 37 57 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.393 s \n",
            "\n",
            "Accuracy rate for 92.280000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.96      0.97       980\n",
            "        1.0       0.97      0.98      0.97      1135\n",
            "        2.0       0.91      0.91      0.91      1032\n",
            "        3.0       0.93      0.91      0.92      1010\n",
            "        4.0       0.91      0.91      0.91       982\n",
            "        5.0       0.87      0.90      0.88       892\n",
            "        6.0       0.94      0.95      0.95       958\n",
            "        7.0       0.95      0.91      0.93      1028\n",
            "        8.0       0.91      0.90      0.91       974\n",
            "        9.0       0.85      0.90      0.88      1009\n",
            "\n",
            "avg / total       0.92      0.92      0.92     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    0    9    4    0   12   10    1    2    1]\n",
            " [   0 1111    4    5    1    4    2    0    7    1]\n",
            " [   5    4  937    2   15    3   13   15   34    4]\n",
            " [   0    0   21  915    0   47    2    9   12    4]\n",
            " [   5    0    6    2  896    2    9    1    2   59]\n",
            " [   5    3    4   29    8  799    9    7   13   15]\n",
            " [   7    3   10    2    7   18  907    0    4    0]\n",
            " [   0   10   21    3    9    1    0  935    4   45]\n",
            " [   1    4   13   11    8   22    7    7  874   27]\n",
            " [   3   10    4   11   42   11    1   10    4  913]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [31 20 51 54 50 59 42 39 60 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.362 s \n",
            "\n",
            "Accuracy rate for 92.570000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.97      0.97       980\n",
            "        1.0       0.97      0.98      0.98      1135\n",
            "        2.0       0.93      0.90      0.92      1032\n",
            "        3.0       0.94      0.89      0.92      1010\n",
            "        4.0       0.92      0.91      0.91       982\n",
            "        5.0       0.86      0.91      0.88       892\n",
            "        6.0       0.95      0.95      0.95       958\n",
            "        7.0       0.95      0.92      0.94      1028\n",
            "        8.0       0.92      0.90      0.91       974\n",
            "        9.0       0.86      0.91      0.88      1009\n",
            "\n",
            "avg / total       0.93      0.93      0.93     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 954    0    5    0    0    6   11    1    3    0]\n",
            " [   0 1117    3    3    0    5    1    0    5    1]\n",
            " [   3    3  933    4   13   11   12   18   31    4]\n",
            " [   1    0   19  902    1   55    1   10   18    3]\n",
            " [   7    0    5    1  889    3    8    2    3   64]\n",
            " [   6    3    3   27    8  809    9    2    6   19]\n",
            " [  14    3    5    0    7   14  910    0    5    0]\n",
            " [   1   10   21    4    5    1    0  950    6   30]\n",
            " [   3    5    9    6    9   23    9    7  878   25]\n",
            " [   2    9    4   11   38   14    1   13    2  915]]\n",
            "--------------------------------\n",
            "val predicted: (59540,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59540, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [31 20 51 56 51 60 44 41 61 55] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.476 s \n",
            "\n",
            "Accuracy rate for 92.630000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.97      0.96       980\n",
            "        1.0       0.97      0.98      0.98      1135\n",
            "        2.0       0.94      0.88      0.90      1032\n",
            "        3.0       0.92      0.92      0.92      1010\n",
            "        4.0       0.91      0.92      0.92       982\n",
            "        5.0       0.92      0.88      0.90       892\n",
            "        6.0       0.93      0.96      0.94       958\n",
            "        7.0       0.94      0.93      0.93      1028\n",
            "        8.0       0.89      0.92      0.91       974\n",
            "        9.0       0.88      0.90      0.89      1009\n",
            "\n",
            "avg / total       0.93      0.93      0.93     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 946    0    4    1    0    8   14    1    5    1]\n",
            " [   0 1117    4    2    1    2    2    1    4    2]\n",
            " [   5    8  904   15   17    1   18   21   40    3]\n",
            " [   0    0   13  928    0   33    2    8   23    3]\n",
            " [   5    0    4    1  903    0   12    1    3   53]\n",
            " [  11    3    2   34   11  788   11    6   16   10]\n",
            " [   9    3    5    2    4    9  917    0    9    0]\n",
            " [   1   12   20    1    5    0    0  956    7   26]\n",
            " [   2    4    7    7    8    7   10    9  898   22]\n",
            " [   3    9    3   13   41   11    1   17    5  906]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59530,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59530, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [31 20 52 58 51 63 44 41 64 56] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.547 s \n",
            "\n",
            "Accuracy rate for 92.550000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.96      0.97       980\n",
            "        1.0       0.97      0.98      0.97      1135\n",
            "        2.0       0.93      0.89      0.91      1032\n",
            "        3.0       0.94      0.89      0.91      1010\n",
            "        4.0       0.91      0.92      0.92       982\n",
            "        5.0       0.87      0.90      0.89       892\n",
            "        6.0       0.95      0.96      0.95       958\n",
            "        7.0       0.94      0.93      0.93      1028\n",
            "        8.0       0.90      0.92      0.91       974\n",
            "        9.0       0.88      0.89      0.89      1009\n",
            "\n",
            "avg / total       0.93      0.93      0.93     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    0    7    2    0   12    9    1    4    1]\n",
            " [   0 1115    4    2    1    4    2    1    5    1]\n",
            " [   4    7  922    9   15    2   15   19   36    3]\n",
            " [   0    0   19  899    2   53    1    9   24    3]\n",
            " [   4    1    5    0  905    1    8    1    3   54]\n",
            " [   8    2    2   31    9  804   10    6   11    9]\n",
            " [   5    2    2    1    4   20  919    0    5    0]\n",
            " [   0   13   21    0    5    0    0  951    5   33]\n",
            " [   3    2    7    8   12   11    7    9  893   22]\n",
            " [   3   11    5    8   43   13    1   15    7  903]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59520, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [31 20 53 59 56 64 44 41 66 56] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.547 s \n",
            "\n",
            "Accuracy rate for 92.800000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.97      0.97       980\n",
            "        1.0       0.97      0.98      0.97      1135\n",
            "        2.0       0.93      0.90      0.91      1032\n",
            "        3.0       0.94      0.92      0.93      1010\n",
            "        4.0       0.88      0.95      0.92       982\n",
            "        5.0       0.89      0.89      0.89       892\n",
            "        6.0       0.95      0.94      0.94       958\n",
            "        7.0       0.94      0.93      0.94      1028\n",
            "        8.0       0.91      0.92      0.92       974\n",
            "        9.0       0.90      0.87      0.88      1009\n",
            "\n",
            "avg / total       0.93      0.93      0.93     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 949    0    2    3    0   11   11    1    3    0]\n",
            " [   0 1117    5    1    1    5    2    0    3    1]\n",
            " [   4    6  930   10   19    5   13   16   26    3]\n",
            " [   0    0   17  925    0   36    1   10   18    3]\n",
            " [   3    0    4    1  932    0    5    2    3   32]\n",
            " [   5    2    6   32   11  794   10    2   20   10]\n",
            " [   9    3    7    1   11   20  902    0    5    0]\n",
            " [   0   12   21    0    5    0    0  956    7   27]\n",
            " [   1    5    9    5    8   10    8    9  897   22]\n",
            " [   4   12    4   11   68   11    1   17    3  878]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59510, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [31 20 53 59 57 65 44 41 70 60] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 10.657 s \n",
            "\n",
            "Accuracy rate for 92.760000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.97      0.97       980\n",
            "        1.0       0.98      0.98      0.98      1135\n",
            "        2.0       0.94      0.90      0.92      1032\n",
            "        3.0       0.95      0.89      0.92      1010\n",
            "        4.0       0.88      0.94      0.91       982\n",
            "        5.0       0.90      0.89      0.89       892\n",
            "        6.0       0.95      0.95      0.95       958\n",
            "        7.0       0.96      0.92      0.94      1028\n",
            "        8.0       0.87      0.94      0.90       974\n",
            "        9.0       0.89      0.89      0.89      1009\n",
            "\n",
            "avg / total       0.93      0.93      0.93     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 954    0    2    1    1    7    9    1    5    0]\n",
            " [   0 1113    3    2    1    3    2    1    9    1]\n",
            " [   4    2  926    4   19    4   13   17   38    5]\n",
            " [   0    0   16  903    2   39    2    7   35    6]\n",
            " [   3    0    2    0  922    0    7    1    5   42]\n",
            " [   6    3    3   25   17  791   11    4   20   12]\n",
            " [   9    3    4    0   12   12  909    0    9    0]\n",
            " [   0    8   22    2    9    1    0  942   12   32]\n",
            " [   4    2    4    4    8    8    6    7  915   16]\n",
            " [   3    6    4    7   62   12    1    6    7  901]]\n",
            "--------------------------------\n",
            "final active learning accuracies [25.72, 38.83, 53.99, 57.53, 62.39, 66.58, 64.23, 67.5, 72.75, 76.35, 77.31, 77.96, 78.17, 80.67, 81.76, 83.63000000000001, 85.26, 85.37, 85.82, 85.76, 86.00999999999999, 87.01, 87.45, 87.83, 88.64999999999999, 88.1, 87.92999999999999, 89.21, 89.57000000000001, 90.34, 91.12, 90.86, 91.17, 91.53999999999999, 91.84, 91.75999999999999, 91.07, 91.36, 91.22, 91.88, 92.0, 91.97, 91.7, 92.12, 92.28, 92.57, 92.63, 92.55, 92.80000000000001, 92.75999999999999]\n",
            "saved Active-learning-experiment-25.pkl /content ['datalab', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "{\n",
            "  \"RfModel\": {\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          25.72,\n",
            "          38.83,\n",
            "          53.99,\n",
            "          57.53,\n",
            "          62.39,\n",
            "          66.58,\n",
            "          64.23,\n",
            "          67.5,\n",
            "          72.75,\n",
            "          76.35,\n",
            "          77.31,\n",
            "          77.96,\n",
            "          78.17,\n",
            "          80.67,\n",
            "          81.76,\n",
            "          83.63000000000001,\n",
            "          85.26,\n",
            "          85.37,\n",
            "          85.82,\n",
            "          85.76,\n",
            "          86.00999999999999,\n",
            "          87.01,\n",
            "          87.45,\n",
            "          87.83,\n",
            "          88.64999999999999,\n",
            "          88.1,\n",
            "          87.92999999999999,\n",
            "          89.21,\n",
            "          89.57000000000001,\n",
            "          90.34,\n",
            "          91.12,\n",
            "          90.86,\n",
            "          91.17,\n",
            "          91.53999999999999,\n",
            "          91.84,\n",
            "          91.75999999999999,\n",
            "          91.07,\n",
            "          91.36,\n",
            "          91.22,\n",
            "          91.88,\n",
            "          92.0,\n",
            "          91.97,\n",
            "          91.7,\n",
            "          92.12,\n",
            "          92.28,\n",
            "          92.57,\n",
            "          92.63,\n",
            "          92.55,\n",
            "          92.80000000000001,\n",
            "          92.75999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          39.050000000000004,\n",
            "          51.85999999999999,\n",
            "          67.30000000000001,\n",
            "          74.29,\n",
            "          74.42999999999999,\n",
            "          80.15,\n",
            "          83.55,\n",
            "          83.58,\n",
            "          86.24000000000001,\n",
            "          87.22999999999999,\n",
            "          87.89,\n",
            "          88.42999999999999,\n",
            "          88.94,\n",
            "          90.06,\n",
            "          89.57000000000001,\n",
            "          90.03999999999999,\n",
            "          90.03999999999999,\n",
            "          91.14,\n",
            "          91.86,\n",
            "          91.79\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          62.99,\n",
            "          75.07000000000001,\n",
            "          75.38,\n",
            "          83.96000000000001,\n",
            "          87.89,\n",
            "          89.62,\n",
            "          89.7,\n",
            "          91.47999999999999,\n",
            "          91.84,\n",
            "          92.49000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          76.4,\n",
            "          85.66,\n",
            "          90.22,\n",
            "          92.13\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          81.26,\n",
            "          87.98\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          36.01,\n",
            "          43.34,\n",
            "          53.94,\n",
            "          58.02,\n",
            "          60.97,\n",
            "          66.44,\n",
            "          68.63,\n",
            "          70.8,\n",
            "          72.08,\n",
            "          73.58,\n",
            "          73.63,\n",
            "          74.0,\n",
            "          74.2,\n",
            "          75.52,\n",
            "          75.41,\n",
            "          75.81,\n",
            "          75.98,\n",
            "          77.97,\n",
            "          77.5,\n",
            "          80.15,\n",
            "          79.81,\n",
            "          81.13,\n",
            "          80.87,\n",
            "          80.58999999999999,\n",
            "          80.86,\n",
            "          81.26,\n",
            "          82.26,\n",
            "          82.44,\n",
            "          82.75,\n",
            "          82.92,\n",
            "          83.76,\n",
            "          83.50999999999999,\n",
            "          85.05,\n",
            "          85.50999999999999,\n",
            "          85.13,\n",
            "          86.02,\n",
            "          86.02,\n",
            "          86.5,\n",
            "          86.09,\n",
            "          85.83,\n",
            "          86.9,\n",
            "          86.46000000000001,\n",
            "          86.38,\n",
            "          86.88,\n",
            "          87.09,\n",
            "          87.87,\n",
            "          87.47,\n",
            "          87.59,\n",
            "          87.74,\n",
            "          87.78\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.64,\n",
            "          60.72,\n",
            "          65.45,\n",
            "          70.28999999999999,\n",
            "          72.94,\n",
            "          76.08,\n",
            "          77.51,\n",
            "          77.78,\n",
            "          79.35,\n",
            "          80.39,\n",
            "          81.6,\n",
            "          81.17,\n",
            "          82.73,\n",
            "          84.28,\n",
            "          84.15,\n",
            "          85.2,\n",
            "          86.13,\n",
            "          86.78,\n",
            "          86.95,\n",
            "          87.59\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          56.86,\n",
            "          69.43,\n",
            "          71.87,\n",
            "          75.68,\n",
            "          80.01,\n",
            "          82.06,\n",
            "          84.5,\n",
            "          85.92,\n",
            "          86.76,\n",
            "          87.32\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.5,\n",
            "          82.39,\n",
            "          85.76,\n",
            "          87.56\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.19,\n",
            "          88.14999999999999\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"SvmModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          35.93,\n",
            "          35.97,\n",
            "          40.33,\n",
            "          39.39,\n",
            "          41.349999999999994,\n",
            "          42.99,\n",
            "          46.23,\n",
            "          46.18,\n",
            "          47.260000000000005,\n",
            "          52.5,\n",
            "          52.400000000000006,\n",
            "          51.25999999999999,\n",
            "          51.690000000000005,\n",
            "          51.800000000000004,\n",
            "          53.18000000000001,\n",
            "          53.82,\n",
            "          55.88999999999999,\n",
            "          56.120000000000005,\n",
            "          57.269999999999996,\n",
            "          59.41,\n",
            "          59.95,\n",
            "          62.629999999999995,\n",
            "          61.339999999999996,\n",
            "          63.88,\n",
            "          65.34,\n",
            "          65.77,\n",
            "          66.9,\n",
            "          67.96,\n",
            "          68.27,\n",
            "          67.44,\n",
            "          68.45,\n",
            "          68.63,\n",
            "          68.0,\n",
            "          68.47,\n",
            "          68.77,\n",
            "          68.8,\n",
            "          69.17,\n",
            "          68.97,\n",
            "          69.33,\n",
            "          69.67999999999999,\n",
            "          69.95,\n",
            "          70.34,\n",
            "          70.47,\n",
            "          71.19,\n",
            "          71.97,\n",
            "          72.26,\n",
            "          72.06,\n",
            "          71.98,\n",
            "          72.55,\n",
            "          72.78999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          50.33,\n",
            "          51.59,\n",
            "          56.599999999999994,\n",
            "          60.24,\n",
            "          61.57,\n",
            "          63.5,\n",
            "          66.74,\n",
            "          68.19,\n",
            "          68.02,\n",
            "          69.8,\n",
            "          75.88000000000001,\n",
            "          77.24,\n",
            "          78.09,\n",
            "          79.38,\n",
            "          80.4,\n",
            "          80.99,\n",
            "          80.28999999999999,\n",
            "          80.12,\n",
            "          79.75999999999999,\n",
            "          80.36999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          64.55,\n",
            "          68.75,\n",
            "          71.34,\n",
            "          74.11999999999999,\n",
            "          75.96000000000001,\n",
            "          77.03999999999999,\n",
            "          76.85,\n",
            "          79.19,\n",
            "          80.51,\n",
            "          80.99\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          78.4,\n",
            "          78.21000000000001,\n",
            "          80.08,\n",
            "          81.0\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.11,\n",
            "          84.53\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.86,\n",
            "          37.6,\n",
            "          46.23,\n",
            "          58.41,\n",
            "          60.34,\n",
            "          65.98,\n",
            "          65.01,\n",
            "          69.86,\n",
            "          72.28999999999999,\n",
            "          74.65,\n",
            "          76.24,\n",
            "          77.37,\n",
            "          77.59,\n",
            "          78.7,\n",
            "          79.06,\n",
            "          80.06,\n",
            "          81.21000000000001,\n",
            "          82.32000000000001,\n",
            "          83.17,\n",
            "          83.78,\n",
            "          84.6,\n",
            "          84.58,\n",
            "          84.47,\n",
            "          85.07000000000001,\n",
            "          85.64,\n",
            "          85.75,\n",
            "          85.7,\n",
            "          86.18,\n",
            "          86.58,\n",
            "          86.50999999999999,\n",
            "          86.71,\n",
            "          87.09,\n",
            "          86.91,\n",
            "          87.13,\n",
            "          87.42999999999999,\n",
            "          87.75,\n",
            "          87.97,\n",
            "          88.23,\n",
            "          88.23,\n",
            "          88.22,\n",
            "          88.16000000000001,\n",
            "          88.03,\n",
            "          88.38000000000001,\n",
            "          88.39,\n",
            "          88.64,\n",
            "          88.98,\n",
            "          89.05999999999999,\n",
            "          89.34,\n",
            "          89.3,\n",
            "          89.52\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          50.160000000000004,\n",
            "          63.73,\n",
            "          70.14,\n",
            "          74.4,\n",
            "          78.99000000000001,\n",
            "          80.36999999999999,\n",
            "          82.76,\n",
            "          84.35000000000001,\n",
            "          85.78,\n",
            "          86.61999999999999,\n",
            "          87.46000000000001,\n",
            "          87.64,\n",
            "          88.08,\n",
            "          88.75,\n",
            "          88.68,\n",
            "          89.02,\n",
            "          89.39,\n",
            "          89.57000000000001,\n",
            "          89.66,\n",
            "          89.8\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          59.099999999999994,\n",
            "          69.91000000000001,\n",
            "          75.66000000000001,\n",
            "          81.41000000000001,\n",
            "          82.69,\n",
            "          85.07000000000001,\n",
            "          85.92,\n",
            "          86.89,\n",
            "          87.8,\n",
            "          87.6\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.45,\n",
            "          84.1,\n",
            "          86.36,\n",
            "          88.16000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.58,\n",
            "          87.38\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.009999999999998,\n",
            "          33.54,\n",
            "          48.67,\n",
            "          57.34,\n",
            "          61.68,\n",
            "          64.75999999999999,\n",
            "          69.28,\n",
            "          71.97,\n",
            "          73.2,\n",
            "          74.03,\n",
            "          75.08,\n",
            "          76.01,\n",
            "          76.55,\n",
            "          77.42999999999999,\n",
            "          77.75,\n",
            "          79.72,\n",
            "          80.78,\n",
            "          81.62,\n",
            "          81.8,\n",
            "          82.03,\n",
            "          81.82000000000001,\n",
            "          82.72,\n",
            "          82.94,\n",
            "          83.03,\n",
            "          83.72,\n",
            "          83.81,\n",
            "          83.72,\n",
            "          83.95,\n",
            "          84.38,\n",
            "          85.02,\n",
            "          85.36,\n",
            "          85.65,\n",
            "          85.26,\n",
            "          85.37,\n",
            "          85.37,\n",
            "          85.19,\n",
            "          85.18,\n",
            "          85.61999999999999,\n",
            "          85.47,\n",
            "          85.61999999999999,\n",
            "          85.78,\n",
            "          86.00999999999999,\n",
            "          86.05000000000001,\n",
            "          85.96000000000001,\n",
            "          85.96000000000001,\n",
            "          86.0,\n",
            "          86.24000000000001,\n",
            "          86.6,\n",
            "          86.66,\n",
            "          86.81\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.449999999999996,\n",
            "          67.88,\n",
            "          72.25,\n",
            "          77.82,\n",
            "          79.19,\n",
            "          80.32000000000001,\n",
            "          81.19,\n",
            "          81.91000000000001,\n",
            "          82.67999999999999,\n",
            "          82.89,\n",
            "          82.89,\n",
            "          83.05,\n",
            "          83.91999999999999,\n",
            "          84.69,\n",
            "          84.77,\n",
            "          84.66,\n",
            "          85.0,\n",
            "          85.3,\n",
            "          85.79,\n",
            "          86.08\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          56.38999999999999,\n",
            "          72.92999999999999,\n",
            "          78.44,\n",
            "          81.0,\n",
            "          82.73,\n",
            "          83.52000000000001,\n",
            "          84.35000000000001,\n",
            "          85.17,\n",
            "          86.17,\n",
            "          86.66\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          73.76,\n",
            "          83.52000000000001,\n",
            "          85.6,\n",
            "          86.44\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.02000000000001,\n",
            "          85.64\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 26, using model = RfModel, selection_function = EntropySelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [18 32 21 20 25 23 25 28 30 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.715 s \n",
            "\n",
            "Accuracy rate for 84.400000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.94      0.94       980\n",
            "        1.0       0.83      0.98      0.90      1135\n",
            "        2.0       0.92      0.72      0.81      1032\n",
            "        3.0       0.86      0.76      0.81      1010\n",
            "        4.0       0.85      0.80      0.82       982\n",
            "        5.0       0.83      0.72      0.77       892\n",
            "        6.0       0.85      0.91      0.88       958\n",
            "        7.0       0.90      0.85      0.87      1028\n",
            "        8.0       0.77      0.86      0.81       974\n",
            "        9.0       0.75      0.86      0.80      1009\n",
            "\n",
            "avg / total       0.85      0.84      0.84     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 924    0    2    1    3    5   26    3   11    5]\n",
            " [   0 1116    3    3    0    0    5    2    6    0]\n",
            " [   9   92  748   26   13    1   42   37   43   21]\n",
            " [   6   16   23  770    1   85    3   15   70   21]\n",
            " [   0   20    4    0  783    4   26    2   24  119]\n",
            " [  19   21    2   51   15  644   40   11   39   50]\n",
            " [  18    5    4    0   50    2  871    0    7    1]\n",
            " [   1   50   22    0   11    3    0  876    6   59]\n",
            " [   9   13    4   41   12   15   14    9  840   17]\n",
            " [   7   12    2    4   32   19    2   20   43  868]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59750,) [0. 0. 8. ... 7. 4. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 8 ... 7 4 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [ 18 269  21  20  25  23  25  33  30  36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.937 s \n",
            "\n",
            "Accuracy rate for 81.820000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.95      0.94       980\n",
            "        1.0       0.64      1.00      0.78      1135\n",
            "        2.0       0.92      0.67      0.77      1032\n",
            "        3.0       0.87      0.71      0.78      1010\n",
            "        4.0       0.89      0.73      0.80       982\n",
            "        5.0       0.87      0.71      0.78       892\n",
            "        6.0       0.86      0.91      0.89       958\n",
            "        7.0       0.92      0.82      0.87      1028\n",
            "        8.0       0.84      0.77      0.80       974\n",
            "        9.0       0.69      0.90      0.78      1009\n",
            "\n",
            "avg / total       0.84      0.82      0.82     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 927    2    1    1    0    1   29    5    8    6]\n",
            " [   0 1132    1    0    0    0    2    0    0    0]\n",
            " [  16  200  689   17    8    2   29   30   21   20]\n",
            " [   6  106   24  721    2   63    1    9   54   24]\n",
            " [   0   43    3    0  714    2   24    1   10  185]\n",
            " [  17   64    2   49   11  629   33    7   21   59]\n",
            " [  18   23    3    2   35    0  873    0    3    1]\n",
            " [   1   85   18    0    6    4    0  840    2   72]\n",
            " [  11   97    7   35    7   12   16    6  747   36]\n",
            " [   5   22    3    5   20    6    4   11   23  910]]\n",
            "--------------------------------\n",
            "final active learning accuracies [84.39999999999999, 81.82000000000001]\n",
            "saved Active-learning-experiment-26.pkl /content ['datalab', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 27, using model = RfModel, selection_function = EntropySelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [18 14 12 12 17 11  9 11  9 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.746 s \n",
            "\n",
            "Accuracy rate for 75.020000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.95      0.86       980\n",
            "        1.0       0.65      0.99      0.78      1135\n",
            "        2.0       0.84      0.70      0.77      1032\n",
            "        3.0       0.73      0.79      0.76      1010\n",
            "        4.0       0.66      0.90      0.76       982\n",
            "        5.0       0.84      0.48      0.61       892\n",
            "        6.0       0.87      0.76      0.81       958\n",
            "        7.0       0.70      0.85      0.77      1028\n",
            "        8.0       0.86      0.39      0.53       974\n",
            "        9.0       0.83      0.63      0.71      1009\n",
            "\n",
            "avg / total       0.77      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 929    2   14    0    3    3   19    9    1    0]\n",
            " [   0 1122    0    2    1    1    0    1    8    0]\n",
            " [  41  109  725   16   30    1   30   60   15    5]\n",
            " [  13   77   23  800    6   40    3   28    8   12]\n",
            " [   3   28    1    0  885    2   24   20    5   14]\n",
            " [  50   67    8  162   73  430   16   51   15   20]\n",
            " [  61   43   14    5   84   16  730    3    2    0]\n",
            " [   1   48   14    0   40    0    0  872    1   52]\n",
            " [  57  208   58  103   63   15   13   54  377   26]\n",
            " [  17   28    4    9  164    3    4  142    6  632]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) [0. 0. 0. ... 7. 7. 7.]\n",
            "probabilities: (59875, 10) \n",
            " [0 0 0 ... 7 7 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [57 17 14 24 34 12 17 39 10 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.283 s \n",
            "\n",
            "Accuracy rate for 74.360000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.70      0.97      0.81       980\n",
            "        1.0       0.73      0.98      0.83      1135\n",
            "        2.0       0.90      0.64      0.75      1032\n",
            "        3.0       0.61      0.86      0.71      1010\n",
            "        4.0       0.74      0.87      0.80       982\n",
            "        5.0       0.89      0.38      0.53       892\n",
            "        6.0       0.82      0.81      0.81       958\n",
            "        7.0       0.71      0.90      0.79      1028\n",
            "        8.0       0.86      0.32      0.47       974\n",
            "        9.0       0.81      0.62      0.70      1009\n",
            "\n",
            "avg / total       0.77      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 953    0    4    0    1    1   16    5    0    0]\n",
            " [   0 1107    0    3    3    1    3    1   17    0]\n",
            " [  95   94  664   32   26    0   45   41   14   21]\n",
            " [  22   20    7  873    3   17   10   30    3   25]\n",
            " [  17   22    1    6  851    0   30   14    4   37]\n",
            " [  63   46    5  250   52  339   31   73    8   25]\n",
            " [  89   23    6    7   36   11  780    5    1    0]\n",
            " [  12   39   15    2   13    0    0  928    5   14]\n",
            " [  91  150   30  229   44   10   36   48  315   21]\n",
            " [  28   20    2   37  118    1    6  170    1  626]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 7. 7. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 7 7 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [71 48 14 26 36 12 17 99 10 42] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.604 s \n",
            "\n",
            "Accuracy rate for 72.400000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.72      0.95      0.82       980\n",
            "        1.0       0.72      0.99      0.83      1135\n",
            "        2.0       0.92      0.62      0.74      1032\n",
            "        3.0       0.58      0.83      0.68      1010\n",
            "        4.0       0.82      0.82      0.82       982\n",
            "        5.0       0.90      0.30      0.45       892\n",
            "        6.0       0.85      0.80      0.83       958\n",
            "        7.0       0.56      0.93      0.70      1028\n",
            "        8.0       0.90      0.31      0.46       974\n",
            "        9.0       0.82      0.61      0.70      1009\n",
            "\n",
            "avg / total       0.77      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 934    1    5    0    1    2   17   19    1    0]\n",
            " [   0 1120    0    4    2    1    1    2    5    0]\n",
            " [  91  115  637   35   22    0   31   73    9   19]\n",
            " [  15   41    9  840    1   15    4   71    1   13]\n",
            " [  16   24    0    2  805    0   27   56    4   48]\n",
            " [  59   48    6  294   32  266   24  136    5   22]\n",
            " [  82   32    6    3   44    9  768   13    1    0]\n",
            " [   8   38    7    4    1    0    1  958    2    9]\n",
            " [  75  127   18  248   24    4   29  129  298   22]\n",
            " [  21   19    2   26   55    0    1  266    5  614]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) [0. 0. 0. ... 7. 7. 7.]\n",
            "probabilities: (59625, 10) \n",
            " [0 0 0 ... 7 7 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [ 71 134  14  28  43  12  17 120  10  51] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.898 s \n",
            "\n",
            "Accuracy rate for 72.080000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.95      0.81       980\n",
            "        1.0       0.69      0.99      0.81      1135\n",
            "        2.0       0.91      0.62      0.74      1032\n",
            "        3.0       0.60      0.81      0.69      1010\n",
            "        4.0       0.81      0.82      0.82       982\n",
            "        5.0       0.90      0.32      0.47       892\n",
            "        6.0       0.83      0.79      0.81       958\n",
            "        7.0       0.56      0.92      0.70      1028\n",
            "        8.0       0.88      0.29      0.44       974\n",
            "        9.0       0.80      0.61      0.69      1009\n",
            "\n",
            "avg / total       0.77      0.72      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 934    0    5    0    2    2   18   18    1    0]\n",
            " [   0 1121    0    3    1    1    1    2    6    0]\n",
            " [  82  122  644   33   22    0   38   62   10   19]\n",
            " [  18   56   11  819    3   15    6   62    1   19]\n",
            " [  18   26    1    3  809    0   26   52    4   43]\n",
            " [  61   55    5  245   38  288   27  135    9   29]\n",
            " [  85   39    8    4   46   11  753   11    1    0]\n",
            " [  13   42   10    2    2    0    1  941    4   13]\n",
            " [  80  137   20  233   37    4   35  109  286   33]\n",
            " [  23   21    2   25   39    0    2  282    2  613]]\n",
            "--------------------------------\n",
            "final active learning accuracies [75.02, 74.36, 72.39999999999999, 72.08]\n",
            "saved Active-learning-experiment-27.pkl /content ['datalab', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 28, using model = RfModel, selection_function = EntropySelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [3 6 6 8 5 3 4 5 5 5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.769 s \n",
            "\n",
            "Accuracy rate for 63.860000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.76      0.81       980\n",
            "        1.0       0.57      0.99      0.72      1135\n",
            "        2.0       0.75      0.65      0.70      1032\n",
            "        3.0       0.56      0.83      0.67      1010\n",
            "        4.0       0.50      0.63      0.56       982\n",
            "        5.0       0.63      0.13      0.22       892\n",
            "        6.0       0.74      0.66      0.70       958\n",
            "        7.0       0.82      0.75      0.78      1028\n",
            "        8.0       0.65      0.30      0.41       974\n",
            "        9.0       0.52      0.57      0.54      1009\n",
            "\n",
            "avg / total       0.66      0.64      0.62     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 741    4   36   31    9   15   71    2   54   17]\n",
            " [   0 1128    0    2    0    0    3    0    2    0]\n",
            " [   8  176  672  110    8    1   14   21   14    8]\n",
            " [   6   92   19  837    1    5   14   25    6    5]\n",
            " [   1   78   31    7  621    0   36   14    7  187]\n",
            " [  21  157   27  255   74  117   41   23   63  114]\n",
            " [  30   52   80   20  125    2  632    0    5   12]\n",
            " [   1   87    9    7   63    2    2  772    4   81]\n",
            " [  25  162   11  189   96   38   39    9  294  111]\n",
            " [   7   58   11   26  250    6    4   74    1  572]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 8 ... 9 9 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 3 53  6  8  6  3  5  6  5  5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.917 s \n",
            "\n",
            "Accuracy rate for 60.310000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.75      0.82       980\n",
            "        1.0       0.37      1.00      0.54      1135\n",
            "        2.0       0.81      0.55      0.66      1032\n",
            "        3.0       0.62      0.75      0.68      1010\n",
            "        4.0       0.52      0.71      0.60       982\n",
            "        5.0       0.73      0.13      0.23       892\n",
            "        6.0       0.78      0.66      0.72       958\n",
            "        7.0       0.89      0.69      0.78      1028\n",
            "        8.0       0.57      0.23      0.33       974\n",
            "        9.0       0.64      0.45      0.53      1009\n",
            "\n",
            "avg / total       0.68      0.60      0.59     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 736   18   28   26   16   11   56    3   74   12]\n",
            " [   0 1134    0    0    0    0    1    0    0    0]\n",
            " [   9  359  569   55    4    0   15    6   12    3]\n",
            " [   0  214    8  755    4    5    5   13    4    2]\n",
            " [   1  162   11    5  694    0   41    0    0   68]\n",
            " [   9  285    8  213   89  119   26   10   68   65]\n",
            " [  32  105   60   14  102    0  631    1    5    8]\n",
            " [   1  203    6    1   62    1    0  714    0   40]\n",
            " [  24  421    6  121   67   24   26    3  223   59]\n",
            " [  10  139    8   23  309    4    5   53    2  456]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 8. ... 9. 9. 1.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 8 ... 9 9 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 3 98  6  9  6  3  5  7  5  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.146 s \n",
            "\n",
            "Accuracy rate for 59.760000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.85      0.78      0.81       980\n",
            "        1.0       0.36      1.00      0.53      1135\n",
            "        2.0       0.82      0.48      0.61      1032\n",
            "        3.0       0.63      0.77      0.70      1010\n",
            "        4.0       0.54      0.64      0.59       982\n",
            "        5.0       0.70      0.12      0.20       892\n",
            "        6.0       0.80      0.67      0.73       958\n",
            "        7.0       0.90      0.65      0.76      1028\n",
            "        8.0       0.67      0.20      0.30       974\n",
            "        9.0       0.57      0.56      0.56      1009\n",
            "\n",
            "avg / total       0.68      0.60      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 763   26   21   35    7   18   61    2   40    7]\n",
            " [   0 1133    0    1    0    0    1    0    0    0]\n",
            " [  14  437  500   51    4    0   12    4    6    4]\n",
            " [   3  184   15  781    1    4    1   11    3    7]\n",
            " [   2  142    6    1  630    0   29    0    1  171]\n",
            " [  17  289    8  213   76  105   29    5   42  108]\n",
            " [  56  130   49   10   71    0  639    1    0    2]\n",
            " [   1  238    3    2   57    1    0  673    0   53]\n",
            " [  34  437    5  115   77   18   23    4  190   71]\n",
            " [  12   98    4   27  245    5    6   49    1  562]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 6. ... 9. 9. 9.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 6 ... 9 9 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [  3 144   6   9   6   3   6  10   5   8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.374 s \n",
            "\n",
            "Accuracy rate for 59.890000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.79      0.83       980\n",
            "        1.0       0.35      1.00      0.52      1135\n",
            "        2.0       0.77      0.47      0.58      1032\n",
            "        3.0       0.70      0.71      0.71      1010\n",
            "        4.0       0.56      0.63      0.59       982\n",
            "        5.0       0.75      0.12      0.20       892\n",
            "        6.0       0.87      0.63      0.73       958\n",
            "        7.0       0.87      0.75      0.80      1028\n",
            "        8.0       0.59      0.18      0.28       974\n",
            "        9.0       0.56      0.61      0.58      1009\n",
            "\n",
            "avg / total       0.68      0.60      0.59     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 776   35   27   19   14   13   33    2   47   14]\n",
            " [   0 1133    0    1    0    0    1    0    0    0]\n",
            " [  10  463  482   43    3    1    7   12    7    4]\n",
            " [   3  234   10  719    0    7    1   15    5   16]\n",
            " [   1  164   15    0  615    0   15    0    3  169]\n",
            " [  25  297   10  164   53  104   22   10   57  150]\n",
            " [  39  148   68    4   88    0  602    1    0    8]\n",
            " [   2  178    0    0   38    0    0  766    2   42]\n",
            " [  28  521    3   67   73   10   10    7  179   76]\n",
            " [  12   85    9   12  205    4    1   66    2  613]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 8. ... 9. 9. 1.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 8 ... 9 9 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [  3 191   6   9   6   3   6  10   5  11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.378 s \n",
            "\n",
            "Accuracy rate for 59.160000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.80      0.82       980\n",
            "        1.0       0.34      1.00      0.51      1135\n",
            "        2.0       0.86      0.44      0.58      1032\n",
            "        3.0       0.69      0.69      0.69      1010\n",
            "        4.0       0.59      0.58      0.58       982\n",
            "        5.0       0.76      0.12      0.21       892\n",
            "        6.0       0.86      0.64      0.73       958\n",
            "        7.0       0.89      0.71      0.79      1028\n",
            "        8.0       0.64      0.15      0.24       974\n",
            "        9.0       0.50      0.68      0.58      1009\n",
            "\n",
            "avg / total       0.69      0.59      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 785   38   12   25   19   10   42    1   29   19]\n",
            " [   0 1134    0    0    0    0    1    0    0    0]\n",
            " [  19  485  450   46    4    0    6   14    5    3]\n",
            " [   3  254    9  694    1    9    1   15    4   20]\n",
            " [   8  174    5    0  569    0   16    0    1  209]\n",
            " [  16  278    4  163   44  106   20    6   42  213]\n",
            " [  62  158   35    8   72    1  612    0    0   10]\n",
            " [   3  176    1    2   34    0    0  731    0   81]\n",
            " [  25  504    2   61   79   12   13    9  145  124]\n",
            " [  19   92    3   12  146    2    3   41    1  690]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 6. ... 9. 9. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 6 ... 9 9 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [  3 234   6   9   6   3   6  15   5  13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.501 s \n",
            "\n",
            "Accuracy rate for 59.520000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.85      0.80      0.82       980\n",
            "        1.0       0.34      1.00      0.51      1135\n",
            "        2.0       0.80      0.45      0.58      1032\n",
            "        3.0       0.69      0.67      0.68      1010\n",
            "        4.0       0.62      0.55      0.58       982\n",
            "        5.0       0.65      0.12      0.20       892\n",
            "        6.0       0.86      0.64      0.73       958\n",
            "        7.0       0.85      0.76      0.80      1028\n",
            "        8.0       0.63      0.16      0.26       974\n",
            "        9.0       0.53      0.69      0.60      1009\n",
            "\n",
            "avg / total       0.68      0.60      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 781   42   20   21    6   23   42    2   36    7]\n",
            " [   0 1132    0    1    0    0    1    0    0    1]\n",
            " [  18  464  469   34    0    2    6   31    3    5]\n",
            " [   4  268    9  680    2    7    1   16    3   20]\n",
            " [   1  177    9    2  536    0   19    2    1  235]\n",
            " [  21  280    5  169   50  103   17   10   48  189]\n",
            " [  46  157   66    3   69    1  612    0    0    4]\n",
            " [   2  167    0    0   20    0    0  786    0   53]\n",
            " [  30  515    1   58   58   19    8   13  160  112]\n",
            " [  11   83    4   11  130    3    2   70    2  693]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 6. ... 9. 9. 9.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 6 ... 9 9 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [  3 277   6   9   7   3   6  18   8  13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.715 s \n",
            "\n",
            "Accuracy rate for 57.900000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.79      0.81       980\n",
            "        1.0       0.34      1.00      0.51      1135\n",
            "        2.0       0.81      0.43      0.56      1032\n",
            "        3.0       0.68      0.64      0.66      1010\n",
            "        4.0       0.54      0.59      0.56       982\n",
            "        5.0       0.60      0.08      0.15       892\n",
            "        6.0       0.87      0.60      0.71       958\n",
            "        7.0       0.85      0.76      0.80      1028\n",
            "        8.0       0.66      0.17      0.27       974\n",
            "        9.0       0.50      0.60      0.55      1009\n",
            "\n",
            "avg / total       0.66      0.58      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 779   46   12   21   19   22   32    5   33   11]\n",
            " [   0 1134    0    0    0    0    1    0    0    0]\n",
            " [  21  494  446   27    3    0    7   22    8    4]\n",
            " [   2  288   11  649    0    6    3   25    6   20]\n",
            " [   8  167    5    1  581    0   11    2    0  207]\n",
            " [  24  288    5  188   58   75   16    8   33  197]\n",
            " [  46  159   69    3   99    0  573    1    2    6]\n",
            " [   2  154    0    1   33    0    0  782    0   56]\n",
            " [  53  493    1   57   63   19   11    9  166  102]\n",
            " [  16   80    4   12  219    3    1   67    2  605]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 1. ... 9. 9. 9.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 1 ... 9 9 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [  3 313   6  10   7   3   6  28  11  13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.869 s \n",
            "\n",
            "Accuracy rate for 59.740000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.83      0.81      0.82       980\n",
            "        1.0       0.38      1.00      0.55      1135\n",
            "        2.0       0.79      0.45      0.57      1032\n",
            "        3.0       0.72      0.66      0.69      1010\n",
            "        4.0       0.55      0.63      0.59       982\n",
            "        5.0       0.71      0.13      0.22       892\n",
            "        6.0       0.86      0.56      0.68       958\n",
            "        7.0       0.71      0.85      0.78      1028\n",
            "        8.0       0.69      0.23      0.34       974\n",
            "        9.0       0.49      0.56      0.52      1009\n",
            "\n",
            "avg / total       0.67      0.60      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 789   27   21   15   18   14   34   11   40   11]\n",
            " [   0 1132    0    0    0    0    1    1    0    1]\n",
            " [  14  428  465   34    4    1    7   70    7    2]\n",
            " [   3  261   12  664    1    9    3   35    3   19]\n",
            " [   1  120   11    0  615    0   13   27    9  186]\n",
            " [  22  266    6  147   64  114   16   22   30  205]\n",
            " [  53  154   71    1  114    0  537   11    4   13]\n",
            " [   1   97    0    0   25    0    0  873    1   31]\n",
            " [  51  412    0   57   65   20    9   25  221  114]\n",
            " [  19   51    5    7  208    3    1  148    3  564]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 8 ... 9 9 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [  3 352   6  11   7   4   6  37  11  13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.014 s \n",
            "\n",
            "Accuracy rate for 57.060000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.83      0.80      0.81       980\n",
            "        1.0       0.34      1.00      0.51      1135\n",
            "        2.0       0.82      0.39      0.53      1032\n",
            "        3.0       0.71      0.67      0.69      1010\n",
            "        4.0       0.50      0.61      0.55       982\n",
            "        5.0       0.85      0.09      0.17       892\n",
            "        6.0       0.86      0.59      0.70       958\n",
            "        7.0       0.74      0.83      0.79      1028\n",
            "        8.0       0.69      0.18      0.28       974\n",
            "        9.0       0.49      0.43      0.46      1009\n",
            "\n",
            "avg / total       0.68      0.57      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 782   53   13   10   18    7   42   12   37    6]\n",
            " [   0 1132    0    0    0    0    1    2    0    0]\n",
            " [  24  512  400   25    3    1    4   54    7    2]\n",
            " [   2  269   10  673    0    4    1   32    4   15]\n",
            " [   5  171    4    0  600    0   15   12    3  172]\n",
            " [  15  300    5  172   72   84   17   23   25  179]\n",
            " [  60  183   49    1   92    0  565    3    2    3]\n",
            " [   2  117    0    1   32    0    0  858    0   18]\n",
            " [  38  541    1   56   61    2   11   20  174   70]\n",
            " [  13   70    4    8  334    1    1  140    0  438]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 8. ... 9. 9. 1.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 8 ... 9 9 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [  3 390   7  11   8   4   8  38  12  19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.164 s \n",
            "\n",
            "Accuracy rate for 59.910000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.77      0.79       980\n",
            "        1.0       0.38      1.00      0.56      1135\n",
            "        2.0       0.74      0.41      0.53      1032\n",
            "        3.0       0.74      0.64      0.69      1010\n",
            "        4.0       0.69      0.58      0.63       982\n",
            "        5.0       0.79      0.10      0.18       892\n",
            "        6.0       0.87      0.64      0.74       958\n",
            "        7.0       0.73      0.80      0.76      1028\n",
            "        8.0       0.58      0.22      0.32       974\n",
            "        9.0       0.47      0.71      0.57      1009\n",
            "\n",
            "avg / total       0.67      0.60      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 757   29   23    6   10   12   41   12   63   27]\n",
            " [   0 1132    0    0    0    0    1    1    0    1]\n",
            " [  22  473  428   22    2    0    9   56   15    5]\n",
            " [   3  247   21  648    0   10    0   43    9   29]\n",
            " [  14   94    8    0  570    0   11   26    6  253]\n",
            " [  19  240   12  140   42   89   12   21   51  266]\n",
            " [  72  130   77    0   35    0  615    8    7   14]\n",
            " [   2  112    0    1   26    0    0  820    0   67]\n",
            " [  43  454    8   44   37    2   13   16  211  146]\n",
            " [  15   32    3    9  102    0    1  124    2  721]]\n",
            "--------------------------------\n",
            "final active learning accuracies [63.85999999999999, 60.309999999999995, 59.760000000000005, 59.89, 59.160000000000004, 59.519999999999996, 57.9, 59.74, 57.06, 59.91]\n",
            "saved Active-learning-experiment-28.pkl /content ['datalab', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 29, using model = RfModel, selection_function = EntropySelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [2 5 5 3 0 2 2 2 2 2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n",
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.803 s \n",
            "\n",
            "Accuracy rate for 44.210000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.54      0.64       980\n",
            "        1.0       0.30      0.98      0.46      1135\n",
            "        2.0       0.38      0.65      0.48      1032\n",
            "        3.0       0.43      0.52      0.47      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.57      0.22      0.31       892\n",
            "        6.0       0.74      0.31      0.43       958\n",
            "        7.0       0.60      0.47      0.53      1028\n",
            "        8.0       0.66      0.15      0.24       974\n",
            "        9.0       0.51      0.47      0.49      1009\n",
            "\n",
            "avg / total       0.49      0.44      0.41     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 533  131   46  180    0   14   28   30   18    0]\n",
            " [   0 1115   15    0    0    0    0    0    5    0]\n",
            " [   4  308  668   29    0    1    2   12    4    4]\n",
            " [   4  270  123  523    0   54   18   14    3    1]\n",
            " [  10  330  201    8    0   14    6   51   22  340]\n",
            " [  86  278   27  230    0  192   31    9   12   27]\n",
            " [  13  141  482    8    0   10  295    0    5    4]\n",
            " [  11  383   66   22    0    3    0  479    0   64]\n",
            " [  10  421  100  193    0   21   21   46  144   18]\n",
            " [  11  292   36   10    0   29    0  153    6  472]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59975,) [0. 0. 0. ... 7. 7. 1.]\n",
            "probabilities: (59975, 9) \n",
            " [0 0 0 ... 6 6 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [ 2 30  5  3  0  2  2  2  2  2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.929 s \n",
            "\n",
            "Accuracy rate for 39.200000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.61      0.70       980\n",
            "        1.0       0.22      0.99      0.36      1135\n",
            "        2.0       0.41      0.52      0.46      1032\n",
            "        3.0       0.51      0.47      0.49      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.62      0.19      0.29       892\n",
            "        6.0       0.73      0.30      0.42       958\n",
            "        7.0       0.69      0.33      0.44      1028\n",
            "        8.0       0.65      0.05      0.10       974\n",
            "        9.0       0.54      0.34      0.42      1009\n",
            "\n",
            "avg / total       0.51      0.39      0.37     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 595  152   32  115    0   34   30   14    8    0]\n",
            " [   0 1126    9    0    0    0    0    0    0    0]\n",
            " [   5  472  538    9    0    1    0    4    0    3]\n",
            " [   2  423   45  471    0   39   20    2    3    5]\n",
            " [   4  557  166    9    0    6    3   24    5  208]\n",
            " [  59  404   14  188    0  168   26    0    3   30]\n",
            " [  11  233  413    4    0    4  285    0    7    1]\n",
            " [  13  607   23   13    0    1    0  338    0   33]\n",
            " [  10  680   60  102    0    7   24   20   53   18]\n",
            " [  10  514   25    8    0   12    0   91    3  346]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59950,) [0. 0. 6. ... 7. 1. 1.]\n",
            "probabilities: (59950, 9) \n",
            " [0 0 5 ... 6 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [ 2 55  5  3  0  2  2  2  2  2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.975 s \n",
            "\n",
            "Accuracy rate for 37.570000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.65      0.69       980\n",
            "        1.0       0.21      0.99      0.34      1135\n",
            "        2.0       0.42      0.49      0.45      1032\n",
            "        3.0       0.51      0.40      0.45      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.72      0.12      0.20       892\n",
            "        6.0       0.78      0.26      0.39       958\n",
            "        7.0       0.64      0.30      0.41      1028\n",
            "        8.0       0.73      0.04      0.07       974\n",
            "        9.0       0.56      0.38      0.45      1009\n",
            "\n",
            "avg / total       0.52      0.38      0.35     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 641  189   27   76    0   15   12   14    6    0]\n",
            " [   0 1127    8    0    0    0    0    0    0    0]\n",
            " [   6  488  505   18    0    0    2    8    0    5]\n",
            " [   7  515   48  405    0   16   11    4    0    4]\n",
            " [  18  585  110    4    0    0    4   35    3  223]\n",
            " [ 106  461   12  157    0  105   26    1    1   23]\n",
            " [  15  255  425    7    0    2  248    0    4    2]\n",
            " [  42  638   12    4    0    0    0  309    0   23]\n",
            " [  19  681   45  120    0    5   15   34   38   17]\n",
            " [  21  500   19    6    0    3    0   81    0  379]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59925,) [0. 0. 0. ... 7. 1. 1.]\n",
            "probabilities: (59925, 9) \n",
            " [0 0 0 ... 6 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 2 80  5  3  0  2  2  2  2  2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.990 s \n",
            "\n",
            "Accuracy rate for 35.820000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.85      0.62      0.72       980\n",
            "        1.0       0.19      0.99      0.32      1135\n",
            "        2.0       0.42      0.49      0.45      1032\n",
            "        3.0       0.53      0.36      0.43      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.69      0.11      0.19       892\n",
            "        6.0       0.77      0.27      0.40       958\n",
            "        7.0       0.63      0.27      0.38      1028\n",
            "        8.0       0.76      0.05      0.10       974\n",
            "        9.0       0.55      0.28      0.37      1009\n",
            "\n",
            "avg / total       0.53      0.36      0.34     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 606  228   25   61    0   18   11   19   10    2]\n",
            " [   0 1129    6    0    0    0    0    0    0    0]\n",
            " [   5  507  506    8    0    0    2    4    0    0]\n",
            " [   1  574   36  362    0   15   15    2    0    5]\n",
            " [   3  634  148    4    0    3    4   29    3  154]\n",
            " [  61  514   11  159    0   99   25    0    1   22]\n",
            " [  16  279  395    2    0    0  262    0    2    2]\n",
            " [   9  686   13    4    0    0    0  281    0   35]\n",
            " [   8  723   48   79    0    6   20   20   53   17]\n",
            " [   6  592   30    5    0    2    1   88    1  284]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59900,) [0. 1. 0. ... 7. 1. 1.]\n",
            "probabilities: (59900, 9) \n",
            " [0 1 0 ... 6 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [  2 105   5   3   0   2   2   2   2   2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.029 s \n",
            "\n",
            "Accuracy rate for 36.120000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.81      0.63      0.71       980\n",
            "        1.0       0.19      0.99      0.33      1135\n",
            "        2.0       0.42      0.49      0.45      1032\n",
            "        3.0       0.52      0.31      0.39      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.71      0.13      0.22       892\n",
            "        6.0       0.72      0.28      0.40       958\n",
            "        7.0       0.65      0.30      0.41      1028\n",
            "        8.0       0.65      0.03      0.06       974\n",
            "        9.0       0.54      0.33      0.41      1009\n",
            "\n",
            "avg / total       0.51      0.36      0.34     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 615  237   23   40    0   10   21   15   18    1]\n",
            " [   0 1124   11    0    0    0    0    0    0    0]\n",
            " [   4  509  503    9    0    0    1    5    0    1]\n",
            " [   3  609   39  310    0   24   16    4    0    5]\n",
            " [  12  585  157    4    0    2    8   19    0  195]\n",
            " [  58  514   14  126    0  115   34    1    0   30]\n",
            " [  14  296  374    4    0    2  264    0    0    4]\n",
            " [  30  628   19    6    0    0    0  312    0   33]\n",
            " [  10  724   35   93    0    5   23   32   33   19]\n",
            " [   9  543   21    3    0    3    2   92    0  336]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59875,) [0. 1. 6. ... 7. 1. 1.]\n",
            "probabilities: (59875, 9) \n",
            " [0 1 5 ... 6 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [  2 130   5   3   0   2   2   2   2   2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.033 s \n",
            "\n",
            "Accuracy rate for 33.640000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.59      0.68       980\n",
            "        1.0       0.18      1.00      0.31      1135\n",
            "        2.0       0.40      0.45      0.42      1032\n",
            "        3.0       0.51      0.35      0.42      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.79      0.07      0.12       892\n",
            "        6.0       0.74      0.23      0.35       958\n",
            "        7.0       0.70      0.23      0.35      1028\n",
            "        8.0       0.62      0.04      0.08       974\n",
            "        9.0       0.53      0.27      0.36      1009\n",
            "\n",
            "avg / total       0.52      0.34      0.31     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 578  234   28   74    0    8   20   16   21    1]\n",
            " [   0 1132    3    0    0    0    0    0    0    0]\n",
            " [   4  549  466    6    0    0    0    6    0    1]\n",
            " [   5  598   37  353    0    4   10    2    0    1]\n",
            " [   6  651  133    2    0    3    4    8    1  174]\n",
            " [  65  546   18  150    0   59   28    1    0   25]\n",
            " [  14  297  421    2    0    0  221    0    3    0]\n",
            " [  25  709   13    8    0    0    0  240    0   33]\n",
            " [  15  760   28   86    0    0   16   17   41   11]\n",
            " [   9  644   22    6    0    1    1   52    0  274]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59850,) [0. 1. 6. ... 7. 1. 1.]\n",
            "probabilities: (59850, 9) \n",
            " [0 1 5 ... 6 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [  2 155   5   3   0   2   2   2   2   2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.062 s \n",
            "\n",
            "Accuracy rate for 32.090000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.56      0.69       980\n",
            "        1.0       0.17      1.00      0.30      1135\n",
            "        2.0       0.40      0.42      0.41      1032\n",
            "        3.0       0.53      0.29      0.37      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.56      0.10      0.17       892\n",
            "        6.0       0.67      0.21      0.32       958\n",
            "        7.0       0.66      0.23      0.34      1028\n",
            "        8.0       0.70      0.03      0.06       974\n",
            "        9.0       0.61      0.25      0.35      1009\n",
            "\n",
            "avg / total       0.51      0.32      0.30     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 544  289   31   36    0   17   36   17   10    0]\n",
            " [   0 1131    4    0    0    0    0    0    0    0]\n",
            " [   4  584  433    4    0    1    0    6    0    0]\n",
            " [   4  639   30  294    0   28   11    3    0    1]\n",
            " [   4  705  128    9    0    4    2   11    1  118]\n",
            " [  31  598   12  118    0   87   32    0    1   13]\n",
            " [   5  376  372    1    0    2  202    0    0    0]\n",
            " [   5  741   10    9    0    3    0  238    0   22]\n",
            " [   5  774   26   83    0    9   18   26   28    5]\n",
            " [   5  656   27    5    0    4    0   60    0  252]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59825,) [0. 1. 6. ... 1. 1. 1.]\n",
            "probabilities: (59825, 9) \n",
            " [0 1 5 ... 1 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [  2 180   5   3   0   2   2   2   2   2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.048 s \n",
            "\n",
            "Accuracy rate for 32.100000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.54      0.67       980\n",
            "        1.0       0.17      0.99      0.30      1135\n",
            "        2.0       0.44      0.43      0.43      1032\n",
            "        3.0       0.48      0.35      0.40      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.68      0.05      0.10       892\n",
            "        6.0       0.82      0.23      0.36       958\n",
            "        7.0       0.67      0.20      0.31      1028\n",
            "        8.0       0.48      0.02      0.03       974\n",
            "        9.0       0.54      0.27      0.36      1009\n",
            "\n",
            "avg / total       0.51      0.32      0.30     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 528  274   28   92    0   15   17   11   15    0]\n",
            " [   0 1129    6    0    0    0    0    0    0    0]\n",
            " [   4  575  440    6    0    0    1    3    0    3]\n",
            " [   2  612   35  351    0    2    3    2    0    3]\n",
            " [   2  704   86    3    0    1    4   11    1  170]\n",
            " [  42  582   15  173    0   46    8    0    1   25]\n",
            " [   5  388  342    5    0    0  218    0    0    0]\n",
            " [   7  774    7    6    0    0    0  205    0   29]\n",
            " [   8  782   33   87    0    3   14   21   16   10]\n",
            " [   5  652   17    3    0    1    0   54    0  277]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59800,) [0. 1. 0. ... 7. 1. 1.]\n",
            "probabilities: (59800, 9) \n",
            " [0 1 0 ... 6 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [  2 205   5   3   0   2   2   2   2   2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.124 s \n",
            "\n",
            "Accuracy rate for 32.280000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.85      0.60      0.70       980\n",
            "        1.0       0.17      1.00      0.29      1135\n",
            "        2.0       0.44      0.39      0.42      1032\n",
            "        3.0       0.51      0.30      0.38      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.68      0.10      0.18       892\n",
            "        6.0       0.85      0.22      0.35       958\n",
            "        7.0       0.73      0.20      0.32      1028\n",
            "        8.0       0.80      0.02      0.04       974\n",
            "        9.0       0.58      0.27      0.36      1009\n",
            "\n",
            "avg / total       0.55      0.32      0.31     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 589  278   20   53    0   15    9   11    5    0]\n",
            " [   0 1132    3    0    0    0    0    0    0    0]\n",
            " [   5  617  402    4    0    0    0    4    0    0]\n",
            " [   1  648   30  304    0   19    5    2    0    1]\n",
            " [   9  757   63    1    0    1    2   13    0  136]\n",
            " [  39  577   12  138    0   92   14    0    0   20]\n",
            " [  19  401  315    3    0    2  214    0    0    4]\n",
            " [  21  759    8    9    0    0    0  207    0   24]\n",
            " [   5  801   36   74    0    4    8   16   20   10]\n",
            " [   8  678   16    5    0    3    0   31    0  268]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59775,) [0. 0. 0. ... 7. 1. 1.]\n",
            "probabilities: (59775, 9) \n",
            " [0 0 0 ... 6 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [  2 230   5   3   0   2   2   2   2   2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.090 s \n",
            "\n",
            "Accuracy rate for 30.760000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.51      0.63       980\n",
            "        1.0       0.17      1.00      0.29      1135\n",
            "        2.0       0.44      0.38      0.40      1032\n",
            "        3.0       0.44      0.25      0.32      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.74      0.08      0.15       892\n",
            "        6.0       0.75      0.21      0.33       958\n",
            "        7.0       0.66      0.24      0.35      1028\n",
            "        8.0       0.54      0.02      0.04       974\n",
            "        9.0       0.55      0.25      0.35      1009\n",
            "\n",
            "avg / total       0.50      0.31      0.29     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 501  315   12   83    0   13   20   22   14    0]\n",
            " [   0 1132    3    0    0    0    0    0    0    0]\n",
            " [   4  623  390    8    0    0    0    7    0    0]\n",
            " [   3  707   19  255    0    9   12    2    0    3]\n",
            " [   4  707   94    4    0    0    3   18    1  151]\n",
            " [  51  595   10  122    0   75   20    0    0   19]\n",
            " [  11  416  321    3    0    0  205    0    1    1]\n",
            " [  11  735    9    6    0    1    0  242    0   24]\n",
            " [   7  785   23   89    0    1   15   23   19   12]\n",
            " [   7  668   14    7    0    2    0   54    0  257]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59750,) [0. 1. 6. ... 7. 1. 1.]\n",
            "probabilities: (59750, 9) \n",
            " [0 1 5 ... 6 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [  2 255   5   3   0   2   2   2   2   2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.112 s \n",
            "\n",
            "Accuracy rate for 31.230000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.83      0.54      0.65       980\n",
            "        1.0       0.17      1.00      0.29      1135\n",
            "        2.0       0.45      0.42      0.43      1032\n",
            "        3.0       0.52      0.27      0.36      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.71      0.09      0.16       892\n",
            "        6.0       0.82      0.23      0.35       958\n",
            "        7.0       0.65      0.20      0.30      1028\n",
            "        8.0       0.82      0.01      0.03       974\n",
            "        9.0       0.52      0.24      0.33      1009\n",
            "\n",
            "avg / total       0.54      0.31      0.29     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 526  323   24   56    0   13   20   13    3    2]\n",
            " [   0 1132    3    0    0    0    0    0    0    0]\n",
            " [   3  589  432    5    0    0    0    3    0    0]\n",
            " [   1  694   18  273    0   11    4    1    0    8]\n",
            " [   9  742   59    2    0    2    5   15    0  148]\n",
            " [  59  604    8   99    0   79   10    0    0   33]\n",
            " [  11  360  364    3    0    2  217    0    0    1]\n",
            " [  11  786    9    3    0    0    0  203    0   16]\n",
            " [  11  797   27   77    0    3    8   18   14   19]\n",
            " [   5  681   14    3    0    1    1   57    0  247]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59725,) [1. 1. 0. ... 7. 1. 1.]\n",
            "probabilities: (59725, 9) \n",
            " [1 1 0 ... 6 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [  2 280   5   3   0   2   2   2   2   2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.127 s \n",
            "\n",
            "Accuracy rate for 29.340000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.49      0.64       980\n",
            "        1.0       0.16      1.00      0.28      1135\n",
            "        2.0       0.47      0.37      0.42      1032\n",
            "        3.0       0.57      0.25      0.35      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.89      0.06      0.11       892\n",
            "        6.0       0.73      0.22      0.34       958\n",
            "        7.0       0.55      0.20      0.29      1028\n",
            "        8.0       0.80      0.01      0.02       974\n",
            "        9.0       0.52      0.22      0.31      1009\n",
            "\n",
            "avg / total       0.55      0.29      0.28     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 476  391   21   28    0    5   29   23    2    5]\n",
            " [   0 1132    3    0    0    0    0    0    0    0]\n",
            " [   3  631  385    5    0    0    1    7    0    0]\n",
            " [   1  724   18  250    0    1    6    5    0    5]\n",
            " [   2  791   37    2    0    0    1   27    0  122]\n",
            " [  24  670    9   91    0   50   23    0    0   25]\n",
            " [   5  441  300    2    0    0  208    0    0    2]\n",
            " [   1  793    9    3    0    0    0  205    0   17]\n",
            " [   5  800   27   55    0    0   15   39    8   25]\n",
            " [   2  707    9    3    0    0    0   68    0  220]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59700,) [1. 1. 6. ... 1. 1. 1.]\n",
            "probabilities: (59700, 9) \n",
            " [1 1 5 ... 1 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [  2 304   5   3   0   2   3   2   2   2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.282 s \n",
            "\n",
            "Accuracy rate for 26.420000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.50      0.64       980\n",
            "        1.0       0.15      1.00      0.26      1135\n",
            "        2.0       0.49      0.37      0.42      1032\n",
            "        3.0       0.50      0.20      0.28      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.82      0.03      0.05       892\n",
            "        6.0       0.97      0.09      0.17       958\n",
            "        7.0       0.71      0.16      0.26      1028\n",
            "        8.0       0.28      0.01      0.01       974\n",
            "        9.0       0.49      0.15      0.23      1009\n",
            "\n",
            "avg / total       0.52      0.26      0.24     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 494  380   14   51    0    4    2   16   18    1]\n",
            " [   0 1134    1    0    0    0    0    0    0    0]\n",
            " [   3  642  378    4    0    0    0    5    0    0]\n",
            " [   1  794   15  198    0    0    0    1    0    1]\n",
            " [   6  804   40    3    0    0    0   11    0  118]\n",
            " [  21  736    8   87    0   23    1    0    0   16]\n",
            " [  24  559  280    2    0    0   90    0    0    3]\n",
            " [   3  840    4    3    0    0    0  166    0   12]\n",
            " [   8  866   28   48    0    1    0    7    7    9]\n",
            " [   4  812    9    3    0    0    0   29    0  152]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59675,) [1. 1. 0. ... 7. 1. 1.]\n",
            "probabilities: (59675, 9) \n",
            " [1 1 0 ... 6 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [  2 329   5   3   0   2   3   2   2   2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.255 s \n",
            "\n",
            "Accuracy rate for 27.050000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.50      0.65       980\n",
            "        1.0       0.15      1.00      0.27      1135\n",
            "        2.0       0.45      0.37      0.41      1032\n",
            "        3.0       0.47      0.25      0.32      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.93      0.03      0.06       892\n",
            "        6.0       0.88      0.08      0.15       958\n",
            "        7.0       0.67      0.14      0.23      1028\n",
            "        8.0       0.20      0.00      0.00       974\n",
            "        9.0       0.56      0.20      0.29      1009\n",
            "\n",
            "avg / total       0.52      0.27      0.24     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 486  384   29   48    0    2   11   12    8    0]\n",
            " [   0 1134    1    0    0    0    0    0    0    0]\n",
            " [   0  636  384    8    0    0    0    4    0    0]\n",
            " [   0  747   13  248    0    0    0    1    0    1]\n",
            " [   3  811   56    3    0    0    0    4    0  105]\n",
            " [  14  708    7  119    0   26    0    0    0   18]\n",
            " [   9  522  340    5    0    0   80    0    0    2]\n",
            " [   2  857    4    3    0    0    0  145    0   17]\n",
            " [   3  831   16   89    0    0    0   21    2   12]\n",
            " [   2  764   10    4    0    0    0   29    0  200]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59650,) [1. 1. 6. ... 1. 1. 1.]\n",
            "probabilities: (59650, 9) \n",
            " [1 1 5 ... 1 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [  2 354   5   3   0   2   3   2   2   2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.358 s \n",
            "\n",
            "Accuracy rate for 26.580000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.44      0.59       980\n",
            "        1.0       0.15      1.00      0.26      1135\n",
            "        2.0       0.44      0.34      0.38      1032\n",
            "        3.0       0.46      0.18      0.26      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.74      0.04      0.08       892\n",
            "        6.0       0.97      0.13      0.22       958\n",
            "        7.0       0.66      0.17      0.27      1028\n",
            "        8.0       0.56      0.01      0.02       974\n",
            "        9.0       0.58      0.21      0.31      1009\n",
            "\n",
            "avg / total       0.54      0.27      0.24     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 427  450   25   47    0    6    3   13    7    2]\n",
            " [   0 1133    2    0    0    0    0    0    0    0]\n",
            " [   1  671  352    4    0    0    0    4    0    0]\n",
            " [   0  806   15  186    0    0    0    2    0    1]\n",
            " [   2  802   45    5    0    2    0   12    0  114]\n",
            " [  11  728    7   94    0   37    0    0    0   15]\n",
            " [   6  497  327    5    0    0  121    0    0    2]\n",
            " [   3  831    6    2    0    0    0  177    0    9]\n",
            " [   4  850   20   58    0    3    1   16    9   13]\n",
            " [   4  728   10    4    0    2    0   45    0  216]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59625,) [1. 1. 6. ... 7. 1. 1.]\n",
            "probabilities: (59625, 9) \n",
            " [1 1 5 ... 6 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [  2 377   5   3   0   2   3   4   2   2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.616 s \n",
            "\n",
            "Accuracy rate for 23.230000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.42      0.58       980\n",
            "        1.0       0.14      1.00      0.24      1135\n",
            "        2.0       0.51      0.31      0.38      1032\n",
            "        3.0       0.49      0.16      0.24      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       1.00      0.02      0.05       892\n",
            "        6.0       0.91      0.09      0.16       958\n",
            "        7.0       0.97      0.03      0.06      1028\n",
            "        8.0       0.61      0.01      0.02       974\n",
            "        9.0       0.53      0.15      0.23      1009\n",
            "\n",
            "avg / total       0.60      0.23      0.20     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 410  500   13   43    0    0    7    0    7    0]\n",
            " [   0 1134    1    0    0    0    0    0    0    0]\n",
            " [   0  710  319    3    0    0    0    0    0    0]\n",
            " [   0  845    3  161    0    0    0    0    0    1]\n",
            " [   1  856   14    6    0    0    0    0    0  105]\n",
            " [   7  787    6   60    0   21    1    0    0   10]\n",
            " [   7  610  254    2    0    0   85    0    0    0]\n",
            " [   1  985    0    1    0    0    0   34    0    7]\n",
            " [   1  895   10   48    0    0    0    1   11    8]\n",
            " [   3  849    6    3    0    0    0    0    0  148]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59600,) [1. 1. 1. ... 1. 1. 1.]\n",
            "probabilities: (59600, 9) \n",
            " [1 1 1 ... 1 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [  2 401   5   3   0   2   3   4   3   2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.697 s \n",
            "\n",
            "Accuracy rate for 24.000000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.42      0.58       980\n",
            "        1.0       0.14      1.00      0.25      1135\n",
            "        2.0       0.49      0.31      0.38      1032\n",
            "        3.0       0.47      0.23      0.31      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.90      0.02      0.04       892\n",
            "        6.0       0.90      0.07      0.13       958\n",
            "        7.0       1.00      0.05      0.09      1028\n",
            "        8.0       0.67      0.02      0.04       974\n",
            "        9.0       0.51      0.14      0.21      1009\n",
            "\n",
            "avg / total       0.59      0.24      0.21     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 413  465   23   60    0    2    7    0   10    0]\n",
            " [   0 1135    0    0    0    0    0    0    0    0]\n",
            " [   1  698  325    8    0    0    0    0    0    0]\n",
            " [   0  767   10  232    0    0    0    0    0    1]\n",
            " [   2  856   13    6    0    0    0    0    0  105]\n",
            " [   6  745    8  101    0   18    1    0    0   13]\n",
            " [   9  606  270    4    0    0   69    0    0    0]\n",
            " [   1  965    1    3    0    0    0   51    0    7]\n",
            " [   3  857    8   78    0    0    0    0   20    8]\n",
            " [   0  860    8    4    0    0    0    0    0  137]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59575,) [1. 1. 1. ... 1. 1. 1.]\n",
            "probabilities: (59575, 9) \n",
            " [1 1 1 ... 1 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [  2 426   5   3   0   2   3   4   3   2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.714 s \n",
            "\n",
            "Accuracy rate for 23.700000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.44      0.58       980\n",
            "        1.0       0.14      1.00      0.25      1135\n",
            "        2.0       0.51      0.28      0.36      1032\n",
            "        3.0       0.53      0.20      0.29      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.94      0.02      0.04       892\n",
            "        6.0       0.94      0.09      0.16       958\n",
            "        7.0       1.00      0.03      0.06      1028\n",
            "        8.0       0.67      0.02      0.05       974\n",
            "        9.0       0.54      0.16      0.24      1009\n",
            "\n",
            "avg / total       0.60      0.24      0.21     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 430  483   10   40    0    0    5    0   11    1]\n",
            " [   0 1135    0    0    0    0    0    0    0    0]\n",
            " [   1  739  287    5    0    0    0    0    0    0]\n",
            " [   1  795    9  203    0    0    0    0    0    2]\n",
            " [   3  874   12    4    0    0    0    0    0   89]\n",
            " [  21  754    7   79    0   16    0    0    0   15]\n",
            " [  18  632  220    3    0    0   83    0    1    1]\n",
            " [   1  986    1    0    0    0    0   33    0    7]\n",
            " [   8  860   12   47    0    1    0    0   24   22]\n",
            " [   8  836    4    2    0    0    0    0    0  159]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59550,) [1. 1. 1. ... 1. 1. 1.]\n",
            "probabilities: (59550, 9) \n",
            " [1 1 1 ... 1 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [  2 451   5   3   0   2   3   4   3   2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.724 s \n",
            "\n",
            "Accuracy rate for 21.580000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.35      0.51       980\n",
            "        1.0       0.14      1.00      0.24      1135\n",
            "        2.0       0.45      0.27      0.34      1032\n",
            "        3.0       0.43      0.19      0.26      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.88      0.02      0.03       892\n",
            "        6.0       0.95      0.06      0.11       958\n",
            "        7.0       1.00      0.03      0.06      1028\n",
            "        8.0       0.29      0.00      0.01       974\n",
            "        9.0       0.58      0.11      0.19      1009\n",
            "\n",
            "avg / total       0.56      0.22      0.18     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 339  529   22   76    0    1    3    0   10    0]\n",
            " [   0 1135    0    0    0    0    0    0    0    0]\n",
            " [   0  754  275    3    0    0    0    0    0    0]\n",
            " [   1  818    3  187    0    0    0    0    0    1]\n",
            " [   1  887   17    8    0    0    0    0    0   69]\n",
            " [   5  766    6   95    0   15    0    0    0    5]\n",
            " [   5  626  270    2    0    0   55    0    0    0]\n",
            " [   1  986    2    4    0    0    0   34    0    1]\n",
            " [   0  902    7   54    0    1    0    0    4    6]\n",
            " [   2  882    6    5    0    0    0    0    0  114]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59525,) [1. 1. 1. ... 1. 1. 1.]\n",
            "probabilities: (59525, 9) \n",
            " [1 1 1 ... 1 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [  2 473   5   3   0   4   3   4   4   2] [0 1 2 3 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.801 s \n",
            "\n",
            "Accuracy rate for 23.840000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.42      0.58       980\n",
            "        1.0       0.14      1.00      0.25      1135\n",
            "        2.0       0.50      0.33      0.39      1032\n",
            "        3.0       0.45      0.24      0.32      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.65      0.04      0.08       892\n",
            "        6.0       0.96      0.05      0.09       958\n",
            "        7.0       1.00      0.04      0.07      1028\n",
            "        8.0       0.60      0.01      0.02       974\n",
            "        9.0       0.52      0.12      0.19      1009\n",
            "\n",
            "avg / total       0.57      0.24      0.20     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 414  423   30   81    0   21    1    0    6    4]\n",
            " [   0 1135    0    0    0    0    0    0    0    0]\n",
            " [   2  688  337    5    0    0    0    0    0    0]\n",
            " [   0  752   11  246    0    0    0    0    0    1]\n",
            " [   1  873   21    5    0    0    0    0    0   82]\n",
            " [   6  710    6  123    0   39    1    0    0    7]\n",
            " [  10  643  252    7    0    0   46    0    0    0]\n",
            " [   1  978    0    4    0    0    0   40    0    5]\n",
            " [   2  868   12   74    0    0    0    0    9    9]\n",
            " [   4  875    7    5    0    0    0    0    0  118]]\n",
            "--------------------------------\n",
            "final active learning accuracies [44.21, 39.2, 37.57, 35.82, 36.120000000000005, 33.64, 32.09, 32.1, 32.28, 30.759999999999998, 31.230000000000004, 29.34, 26.419999999999998, 27.05, 26.58, 23.23, 24.0, 23.7, 21.58, 23.84]\n",
            "saved Active-learning-experiment-29.pkl /content ['datalab', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-29.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 30, using model = RfModel, selection_function = EntropySelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [2 2 1 2 1 0 0 2] [0 1 2 3 4 7]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.384 s \n",
            "\n",
            "Accuracy rate for 37.520000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.42      0.88      0.57       980\n",
            "        1.0       0.31      1.00      0.47      1135\n",
            "        2.0       0.65      0.16      0.26      1032\n",
            "        3.0       0.47      0.72      0.57      1010\n",
            "        4.0       0.47      0.22      0.30       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.00      0.00      0.00       958\n",
            "        7.0       0.32      0.63      0.43      1028\n",
            "        8.0       0.00      0.00      0.00       974\n",
            "        9.0       0.00      0.00      0.00      1009\n",
            "\n",
            "avg / total       0.27      0.38      0.27     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 858    9    0   13    3    0    0   97    0    0]\n",
            " [   0 1132    0    2    0    0    0    1    0    0]\n",
            " [ 198  440  169  161   13    0    0   51    0    0]\n",
            " [  42  179    3  731    0    0    0   55    0    0]\n",
            " [  88  338    0   14  217    0    0  325    0    0]\n",
            " [ 314  203    2  261   18    0    0   94    0    0]\n",
            " [ 179  422   87   36   69    0    0  165    0    0]\n",
            " [ 120  235    0    1   27    0    0  645    0    0]\n",
            " [ 137  401    1  325   43    0    0   67    0    0]\n",
            " [ 105  316    0   23   76    0    0  489    0    0]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59990,) [0. 0. 0. ... 0. 1. 1.]\n",
            "probabilities: (59990, 6) \n",
            " [0 0 0 ... 0 1 1]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [2 2 2 2 2 0 8 2] [0 1 2 3 4 6 7]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 4.961 s \n",
            "\n",
            "Accuracy rate for 42.530000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.37      0.45      0.41       980\n",
            "        1.0       0.45      0.98      0.62      1135\n",
            "        2.0       0.83      0.26      0.40      1032\n",
            "        3.0       0.65      0.47      0.55      1010\n",
            "        4.0       0.56      0.61      0.58       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.26      0.93      0.41       958\n",
            "        7.0       0.57      0.45      0.50      1028\n",
            "        8.0       0.00      0.00      0.00       974\n",
            "        9.0       0.00      0.00      0.00      1009\n",
            "\n",
            "avg / total       0.38      0.43      0.35     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 439    3   19    2    7    0  481   29    0    0]\n",
            " [   0 1114    0    2    0    0   19    0    0    0]\n",
            " [  98  292  270  108   73    0  176   15    0    0]\n",
            " [  66  184   11  477    8    0  220   44    0    0]\n",
            " [   3  100    1    0  602    0  251   25    0    0]\n",
            " [ 158  112    0   33   35    0  529   25    0    0]\n",
            " [   3   43   16    0    5    0  889    2    0    0]\n",
            " [ 160  293    4    5   40    0   64  462    0    0]\n",
            " [ 208  225    1  105   26    0  346   63    0    0]\n",
            " [  38  113    4    4  286    0  417  147    0    0]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59980,) [0. 0. 6. ... 6. 4. 1.]\n",
            "probabilities: (59980, 7) \n",
            " [0 0 5 ... 5 4 1]\n",
            "trainset before (20, 784) (20,)\n",
            "trainset after (30, 784) (30,)\n",
            "updated train set: (30, 784) (30,) unique(labels): [2 2 2 2 2 0 8 4 8] [0 1 2 3 4 6 7 8]\n",
            "val set: (59970, 784) (59970,)\n",
            "\n",
            "Train set: (30, 784) y: (30,)\n",
            "Val   set: (59970, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.511 s \n",
            "\n",
            "Accuracy rate for 51.420000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.64      0.44      0.52       980\n",
            "        1.0       0.63      0.98      0.77      1135\n",
            "        2.0       0.79      0.23      0.36      1032\n",
            "        3.0       0.65      0.44      0.52      1010\n",
            "        4.0       0.71      0.45      0.55       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.36      0.90      0.51       958\n",
            "        7.0       0.55      0.87      0.68      1028\n",
            "        8.0       0.38      0.74      0.50       974\n",
            "        9.0       0.00      0.00      0.00      1009\n",
            "\n",
            "avg / total       0.48      0.51      0.45     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 428    3   30    3    4    0  375   47   90    0]\n",
            " [   0 1109    0    2    0    0   17    2    5    0]\n",
            " [  59  162  239  185   23    0  106  119  139    0]\n",
            " [  14  100   11  444    0    0  159   88  194    0]\n",
            " [   0   58    0    3  438    0  226   83  174    0]\n",
            " [ 117  118    2   17   10    0  362   18  248    0]\n",
            " [   2   32   17    6    6    0  866   21    8    0]\n",
            " [   3   51    1    4   16    0   25  896   32    0]\n",
            " [  42   59    2   20    7    0  104   18  722    0]\n",
            " [   5   56    0    1  116    0  199  326  306    0]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59970,) [0. 0. 6. ... 4. 4. 8.]\n",
            "probabilities: (59970, 8) \n",
            " [0 0 5 ... 4 4 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (30, 784) (30,)\n",
            "trainset after (40, 784) (40,)\n",
            "updated train set: (40, 784) (40,) unique(labels): [ 2  2  2  2  3  0 15  4 10] [0 1 2 3 4 6 7 8]\n",
            "val set: (59960, 784) (59960,)\n",
            "\n",
            "Train set: (40, 784) y: (40,)\n",
            "Val   set: (59960, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 5.695 s \n",
            "\n",
            "Accuracy rate for 49.030000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.21      0.32       980\n",
            "        1.0       0.71      0.97      0.82      1135\n",
            "        2.0       0.88      0.15      0.25      1032\n",
            "        3.0       0.64      0.44      0.52      1010\n",
            "        4.0       0.70      0.51      0.59       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.29      0.95      0.45       958\n",
            "        7.0       0.65      0.81      0.72      1028\n",
            "        8.0       0.36      0.78      0.49       974\n",
            "        9.0       0.00      0.00      0.00      1009\n",
            "\n",
            "avg / total       0.50      0.49      0.42     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 202    5   13    4    9    0  570   44  133    0]\n",
            " [   0 1104    0    1    0    0   15    1   14    0]\n",
            " [  20  123  151  189   11    0  316   97  125    0]\n",
            " [  10   67    2  441    2    0  153   51  284    0]\n",
            " [   0   37    0    2  499    0  291   43  110    0]\n",
            " [  26   79    0   22   24    0  406    7  328    0]\n",
            " [   1   22    4    3    2    0  914    8    4    0]\n",
            " [   2   61    1    3   40    0   54  830   37    0]\n",
            " [  23   41    0   20    5    0  117    6  762    0]\n",
            " [   2   25    0    1  125    0  313  198  345    0]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59960,) [0. 0. 6. ... 4. 6. 1.]\n",
            "probabilities: (59960, 8) \n",
            " [0 0 5 ... 4 5 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (40, 784) (40,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [ 2  2  2  2  6  0 20  4 11  1] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.233 s \n",
            "\n",
            "Accuracy rate for 49.250000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.23      0.35       980\n",
            "        1.0       0.75      0.96      0.84      1135\n",
            "        2.0       0.99      0.08      0.15      1032\n",
            "        3.0       0.64      0.34      0.44      1010\n",
            "        4.0       0.48      0.72      0.58       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.35      0.93      0.51       958\n",
            "        7.0       0.74      0.76      0.75      1028\n",
            "        8.0       0.32      0.83      0.46       974\n",
            "        9.0       0.86      0.01      0.01      1009\n",
            "\n",
            "avg / total       0.60      0.49      0.42     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 225    4    0    4   25    0  509   31  182    0]\n",
            " [   0 1088    0    1    2    0    8    0   36    0]\n",
            " [  17  105   84  171   40    0  343   80  192    0]\n",
            " [  10   44    0  341    3    0  151   39  422    0]\n",
            " [   0   20    0    0  707    0  159   12   84    0]\n",
            " [  38   69    0    8  109    0  270    6  392    0]\n",
            " [   0   20    0    0   35    0  888    6    9    0]\n",
            " [   0   46    1    3  138    0   20  779   40    1]\n",
            " [  11   33    0    7   21    0   89    6  807    0]\n",
            " [   1   14    0    0  392    0  108   95  393    6]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59950,) [0. 0. 6. ... 4. 6. 4.]\n",
            "probabilities: (59950, 9) \n",
            " [0 0 5 ... 4 5 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (50, 784) (50,)\n",
            "trainset after (60, 784) (60,)\n",
            "updated train set: (60, 784) (60,) unique(labels): [ 2  2  4  2 11  0 23  4 11  1] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59940, 784) (59940,)\n",
            "\n",
            "Train set: (60, 784) y: (60,)\n",
            "Val   set: (59940, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.246 s \n",
            "\n",
            "Accuracy rate for 52.010000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.81      0.21      0.33       980\n",
            "        1.0       0.78      0.95      0.86      1135\n",
            "        2.0       0.80      0.41      0.55      1032\n",
            "        3.0       0.69      0.35      0.46      1010\n",
            "        4.0       0.41      0.79      0.54       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.34      0.89      0.50       958\n",
            "        7.0       0.76      0.73      0.74      1028\n",
            "        8.0       0.38      0.77      0.51       974\n",
            "        9.0       0.75      0.01      0.02      1009\n",
            "\n",
            "avg / total       0.59      0.52      0.46     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 204    1   31    4   38    0  541   34  127    0]\n",
            " [   0 1081    2    1    4    0   18    0   29    0]\n",
            " [   2   99  428  116   54    0  197   61   75    0]\n",
            " [   2   47   30  353   11    0  190   48  328    1]\n",
            " [   0   23    0    3  780    0  123    6   46    1]\n",
            " [  34   43    1   11  143    0  325    7  328    0]\n",
            " [   0   14    0    2   92    0  849    0    1    0]\n",
            " [   0   36   13    4  191    0   20  747   16    1]\n",
            " [  10   28   24   15   65    0   78    4  750    0]\n",
            " [   1   18    3    0  526    0  127   71  254    9]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59940,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59940, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (60, 784) (60,)\n",
            "trainset after (70, 784) (70,)\n",
            "updated train set: (70, 784) (70,) unique(labels): [ 2  2  5  2 16  0 27  4 11  1] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59930, 784) (59930,)\n",
            "\n",
            "Train set: (70, 784) y: (70,)\n",
            "Val   set: (59930, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.390 s \n",
            "\n",
            "Accuracy rate for 51.410000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.83      0.22      0.35       980\n",
            "        1.0       0.73      0.96      0.83      1135\n",
            "        2.0       0.74      0.42      0.54      1032\n",
            "        3.0       0.85      0.35      0.49      1010\n",
            "        4.0       0.37      0.82      0.51       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.35      0.88      0.50       958\n",
            "        7.0       0.78      0.62      0.69      1028\n",
            "        8.0       0.41      0.76      0.54       974\n",
            "        9.0       0.78      0.02      0.03      1009\n",
            "\n",
            "avg / total       0.59      0.51      0.46     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 214    3   29    1   79    0  525   29  100    0]\n",
            " [   0 1088   20    1    2    0   10    0   14    0]\n",
            " [   3  130  437   50   82    0  193   53   84    0]\n",
            " [   1   70   51  351   16    0  195   45  280    1]\n",
            " [   0   20    0    1  810    0  110    4   34    3]\n",
            " [  34   49    6    4  164    0  334    4  297    0]\n",
            " [   1   21    0    0   94    0  842    0    0    0]\n",
            " [   0   56   12    2  280    0   23  641   13    1]\n",
            " [   4   38   38    4   59    0   89    2  740    0]\n",
            " [   1   24    1    0  593    0  106   43  223   18]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59930,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59930, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [ 3  2  5  2 23  0 29  4 11  1] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.450 s \n",
            "\n",
            "Accuracy rate for 51.890000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.36      0.51       980\n",
            "        1.0       0.80      0.93      0.86      1135\n",
            "        2.0       0.75      0.40      0.52      1032\n",
            "        3.0       0.81      0.32      0.46      1010\n",
            "        4.0       0.34      0.82      0.48       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.37      0.88      0.52       958\n",
            "        7.0       0.76      0.62      0.68      1028\n",
            "        8.0       0.41      0.76      0.54       974\n",
            "        9.0       0.73      0.02      0.03      1009\n",
            "\n",
            "avg / total       0.60      0.52      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 353    1   18    0  133    0  346   26  103    0]\n",
            " [   0 1055   26    1    7    0   28    0   18    0]\n",
            " [  11   87  415   64  106    0  212   63   74    0]\n",
            " [   2   53   38  321   14    0  232   54  294    2]\n",
            " [   0   17    0    1  807    0  124    2   29    2]\n",
            " [  26   28    9    4  229    0  268    4  324    0]\n",
            " [   1   12    0    0  104    0  841    0    0    0]\n",
            " [   0   31   12    2  305    0   26  637   13    2]\n",
            " [   9   21   33    5   67    0   89    6  744    0]\n",
            " [   3   17    2    0  613    0  105   47  206   16]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59920,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59920, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [ 4  2 11  2 25  0 30  4 11  1] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.586 s \n",
            "\n",
            "Accuracy rate for 53.040000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.41      0.56       980\n",
            "        1.0       0.82      0.91      0.87      1135\n",
            "        2.0       0.64      0.63      0.64      1032\n",
            "        3.0       0.87      0.33      0.48      1010\n",
            "        4.0       0.32      0.84      0.47       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.41      0.84      0.55       958\n",
            "        7.0       0.87      0.50      0.63      1028\n",
            "        8.0       0.42      0.75      0.54       974\n",
            "        9.0       0.77      0.01      0.02      1009\n",
            "\n",
            "avg / total       0.61      0.53      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 401    1   52    1  123    0  320   10   72    0]\n",
            " [   0 1036   26    1    7    0   54    0   11    0]\n",
            " [   4   84  648   36   60    0  102   27   71    0]\n",
            " [  11   47  135  332   19    0  161   22  283    0]\n",
            " [   0   11    3    0  827    0  109    0   31    1]\n",
            " [  22   15   33    5  239    0  258    2  318    0]\n",
            " [   1    5    2    0  141    0  809    0    0    0]\n",
            " [   0   31   26    2  423    0   18  514   12    2]\n",
            " [   3   17   77    6   74    0   67    3  727    0]\n",
            " [   2   11    4    0  660    0   97   15  210   10]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59910,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59910, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 6  2 11  2 30  0 33  4 11  1] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.695 s \n",
            "\n",
            "Accuracy rate for 55.480000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.97      0.56      0.71       980\n",
            "        1.0       0.85      0.90      0.87      1135\n",
            "        2.0       0.69      0.61      0.65      1032\n",
            "        3.0       0.83      0.31      0.45      1010\n",
            "        4.0       0.37      0.80      0.51       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.36      0.92      0.52       958\n",
            "        7.0       0.79      0.63      0.70      1028\n",
            "        8.0       0.45      0.73      0.56       974\n",
            "        9.0       0.76      0.02      0.04      1009\n",
            "\n",
            "avg / total       0.62      0.55      0.51     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 544    1   19    0   74    0  277   20   45    0]\n",
            " [   0 1016   23    1   15    0   69    1   10    0]\n",
            " [   5   59  626   51   55    0  147   40   49    0]\n",
            " [   0   30  115  313   11    0  214   39  287    1]\n",
            " [   0   10    0    1  788    0  143    1   37    2]\n",
            " [  10   21   28    3  182    0  380    6  261    1]\n",
            " [   2    6    0    0   70    0  880    0    0    0]\n",
            " [   0   24   19    2  278    0   47  650    6    2]\n",
            " [   0   18   69    5   66    0  100    4  712    0]\n",
            " [   1    7    2    0  580    0  167   59  174   19]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59900,) [0. 0. 6. ... 4. 6. 4.]\n",
            "probabilities: (59900, 9) \n",
            " [0 0 5 ... 4 5 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [ 6  2 20  2 31  0 33  4 11  1] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.712 s \n",
            "\n",
            "Accuracy rate for 56.990000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.98      0.58      0.73       980\n",
            "        1.0       0.79      0.94      0.86      1135\n",
            "        2.0       0.67      0.67      0.67      1032\n",
            "        3.0       0.90      0.32      0.47      1010\n",
            "        4.0       0.35      0.84      0.49       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.48      0.90      0.63       958\n",
            "        7.0       0.82      0.60      0.69      1028\n",
            "        8.0       0.42      0.74      0.54       974\n",
            "        9.0       0.58      0.01      0.03      1009\n",
            "\n",
            "avg / total       0.61      0.57      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 570    1   20    1   82    0  234   17   55    0]\n",
            " [   0 1068   18    1   14    0   16    1   17    0]\n",
            " [   4   87  694   27   56    0   84   34   46    0]\n",
            " [   0   48  144  321   14    0  154   37  287    5]\n",
            " [   0   20    2    0  829    0   88    3   37    3]\n",
            " [   8   30   46    2  227    0  238    8  332    1]\n",
            " [   1   14    0    0   75    0  866    0    2    0]\n",
            " [   0   34   23    1  334    0   10  618    7    1]\n",
            " [   0   27   79    4   64    0   75    6  719    0]\n",
            " [   1   21    5    0  692    0   45   33  198   14]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59890,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59890, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [ 9  2 23  2 34  0 33  4 11  2] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.862 s \n",
            "\n",
            "Accuracy rate for 56.720000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.71      0.79       980\n",
            "        1.0       0.87      0.87      0.87      1135\n",
            "        2.0       0.60      0.70      0.65      1032\n",
            "        3.0       0.86      0.27      0.41      1010\n",
            "        4.0       0.33      0.88      0.48       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.47      0.91      0.62       958\n",
            "        7.0       0.87      0.53      0.66      1028\n",
            "        8.0       0.47      0.69      0.56       974\n",
            "        9.0       0.64      0.04      0.07      1009\n",
            "\n",
            "avg / total       0.61      0.57      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[699   1  18   0  66   0 166   4  26   0]\n",
            " [  0 985  36   1  20   0  76   0  17   0]\n",
            " [ 10  51 719  34  57   0  97  24  38   2]\n",
            " [ 12  27 206 276  29   0 176  31 242  11]\n",
            " [  0  11   5   1 868   0  73   0  22   2]\n",
            " [ 47   7  75   2 255   0 238   3 264   1]\n",
            " [  3   2   1   0  77   0 873   0   2   0]\n",
            " [  0  24  20   1 414   0  16 544   5   4]\n",
            " [  7  12 111   6  84   0  79   3 672   0]\n",
            " [  3  10   5   0 763   0  49  14 129  36]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59880,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59880, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [ 9  2 24  2 37  0 39  4 11  2] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.862 s \n",
            "\n",
            "Accuracy rate for 56.930000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.73      0.79       980\n",
            "        1.0       0.82      0.91      0.86      1135\n",
            "        2.0       0.64      0.68      0.66      1032\n",
            "        3.0       0.89      0.29      0.44      1010\n",
            "        4.0       0.34      0.85      0.48       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.47      0.91      0.62       958\n",
            "        7.0       0.87      0.53      0.66      1028\n",
            "        8.0       0.46      0.71      0.56       974\n",
            "        9.0       0.33      0.00      0.01      1009\n",
            "\n",
            "avg / total       0.58      0.57      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 713    1   14    0   59    0  167    3   23    0]\n",
            " [   0 1037   33    1    5    0   45    1   13    0]\n",
            " [  11   74  706   27   48    0   96   30   39    1]\n",
            " [  20   58  163  291   18    0  159   27  269    5]\n",
            " [   0   18    6    0  839    0   93    0   26    0]\n",
            " [  62   17   53    2  234    0  256    3  265    0]\n",
            " [   3    5    1    0   74    0  871    0    4    0]\n",
            " [   0   31   30    0  385    0   29  545    6    2]\n",
            " [   5   19   97    6   76    0   81    3  687    0]\n",
            " [   2   11    6    0  754    0   67   17  148    4]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59870,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59870, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [10  2 25  2 40  0 44  4 11  2] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 6.998 s \n",
            "\n",
            "Accuracy rate for 55.170000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.69      0.77       980\n",
            "        1.0       0.90      0.85      0.87      1135\n",
            "        2.0       0.57      0.69      0.62      1032\n",
            "        3.0       0.86      0.27      0.41      1010\n",
            "        4.0       0.34      0.85      0.48       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.41      0.93      0.57       958\n",
            "        7.0       0.88      0.51      0.65      1028\n",
            "        8.0       0.47      0.66      0.55       974\n",
            "        9.0       0.42      0.00      0.01      1009\n",
            "\n",
            "avg / total       0.58      0.55      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[674   1  20   0  67   0 186   3  29   0]\n",
            " [  0 968  47   1   6   0 100   0  13   0]\n",
            " [ 11  41 709  33  42   0 128  22  45   1]\n",
            " [ 19  20 196 268  17   0 218  32 234   6]\n",
            " [  0   4   6   0 836   0 119   0  17   0]\n",
            " [ 47   6  83   2 238   0 274   3 239   0]\n",
            " [  4   2   3   0  58   0 890   0   1   0]\n",
            " [  0  15  34   1 401   0  41 529   7   0]\n",
            " [  6  12 138   8  70   0  99   3 638   0]\n",
            " [  3   9   5   0 744   0 101  10 132   5]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59860,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59860, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [10  2 33  2 41  0 44  4 11  3] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.006 s \n",
            "\n",
            "Accuracy rate for 56.260000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.69      0.79       980\n",
            "        1.0       0.90      0.84      0.87      1135\n",
            "        2.0       0.55      0.72      0.62      1032\n",
            "        3.0       0.89      0.24      0.38      1010\n",
            "        4.0       0.37      0.83      0.51       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.39      0.94      0.55       958\n",
            "        7.0       0.88      0.53      0.67      1028\n",
            "        8.0       0.49      0.62      0.55       974\n",
            "        9.0       0.78      0.14      0.24      1009\n",
            "\n",
            "avg / total       0.63      0.56      0.53     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[680   1  36   0  46   0 179   5  33   0]\n",
            " [  0 956  53   1   5   0 118   0   2   0]\n",
            " [  9  37 738  22  36   0 141  20  28   1]\n",
            " [ 11  12 226 244  14   0 243  25 222  13]\n",
            " [  0   5   6   0 815   0 129   1  14  12]\n",
            " [ 41   9  78   2 194   0 333   3 232   0]\n",
            " [  3   2   3   0  49   0 901   0   0   0]\n",
            " [  0  21  33   1 360   0  46 549   4  14]\n",
            " [  3   9 170   5  58   0 124   3 602   0]\n",
            " [  2   9   9   0 646   0  93  16  93 141]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59850,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59850, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [10  2 33  2 46  0 49  4 11  3] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.056 s \n",
            "\n",
            "Accuracy rate for 55.640000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.73      0.82       980\n",
            "        1.0       0.89      0.86      0.87      1135\n",
            "        2.0       0.54      0.70      0.61      1032\n",
            "        3.0       0.85      0.22      0.35      1010\n",
            "        4.0       0.33      0.85      0.48       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.42      0.93      0.58       958\n",
            "        7.0       0.87      0.43      0.58      1028\n",
            "        8.0       0.52      0.62      0.57       974\n",
            "        9.0       0.73      0.14      0.24      1009\n",
            "\n",
            "avg / total       0.62      0.56      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[719   1  29   0  51   0 158   0  22   0]\n",
            " [  0 975  42   1   5   0 105   1   6   0]\n",
            " [  6  40 726  30  45   0 123  18  44   0]\n",
            " [ 16  32 236 222  24   0 220  32 206  22]\n",
            " [  0   4   6   0 837   0 120   0   7   8]\n",
            " [ 32   8  85   2 260   0 296   1 206   2]\n",
            " [  4   2   4   0  56   0 891   0   1   0]\n",
            " [  0  17  37   1 484   0  20 443   4  22]\n",
            " [  4  11 161   4  84   0 100   3 607   0]\n",
            " [  2   9   9   0 679   0  86   9  71 144]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59840,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59840, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [10  2 35  2 50  0 53  4 11  3] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.102 s \n",
            "\n",
            "Accuracy rate for 54.770000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.71      0.80       980\n",
            "        1.0       0.87      0.84      0.86      1135\n",
            "        2.0       0.56      0.70      0.62      1032\n",
            "        3.0       0.90      0.25      0.39      1010\n",
            "        4.0       0.32      0.89      0.47       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.42      0.94      0.58       958\n",
            "        7.0       0.88      0.38      0.53      1028\n",
            "        8.0       0.53      0.59      0.56       974\n",
            "        9.0       0.76      0.11      0.20      1009\n",
            "\n",
            "avg / total       0.63      0.55      0.51     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[692   1  24   0  50   0 199   4  10   0]\n",
            " [  0 953  43   1  10   0 124   0   4   0]\n",
            " [  6  40 723  17  52   0 139  15  39   1]\n",
            " [ 11  21 211 250  36   0 236  24 204  17]\n",
            " [  0  12   6   0 873   0  79   0   6   6]\n",
            " [ 36   5  81   5 286   0 285   1 191   2]\n",
            " [  2   3   2   0  48   0 903   0   0   0]\n",
            " [  0  28  31   1 540   0  18 395   4  11]\n",
            " [  2  16 162   5 101   0 112   3 573   0]\n",
            " [  2  13  10   0 760   0  55   9  45 115]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59830,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59830, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [10  2 44  2 51  0 53  4 11  3] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.305 s \n",
            "\n",
            "Accuracy rate for 54.980000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.67      0.78       980\n",
            "        1.0       0.90      0.84      0.87      1135\n",
            "        2.0       0.52      0.75      0.62      1032\n",
            "        3.0       0.86      0.24      0.37      1010\n",
            "        4.0       0.32      0.88      0.47       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.43      0.94      0.59       958\n",
            "        7.0       0.89      0.41      0.56      1028\n",
            "        8.0       0.53      0.60      0.56       974\n",
            "        9.0       0.66      0.09      0.16      1009\n",
            "\n",
            "avg / total       0.62      0.55      0.51     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[661   1  56   0  62   0 170   2  27   1]\n",
            " [  0 958  56   1   5   0 113   0   2   0]\n",
            " [  4  30 773  24  37   0 115  16  32   1]\n",
            " [  5  23 253 241  28   0 223  26 190  21]\n",
            " [  0   7   6   1 865   0  88   0   9   6]\n",
            " [ 38   6 102   6 263   0 275   1 200   1]\n",
            " [  2   2  11   0  47   0 896   0   0   0]\n",
            " [  0  16  34   1 504   0  27 426   2  18]\n",
            " [  3  15 176   6  82   0 105   3 584   0]\n",
            " [  2   9  12   0 781   0  53   6  52  94]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59820,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59820, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [11  2 44  2 59  0 53  4 12  3] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.240 s \n",
            "\n",
            "Accuracy rate for 54.070000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.67      0.78       980\n",
            "        1.0       0.93      0.80      0.86      1135\n",
            "        2.0       0.56      0.72      0.63      1032\n",
            "        3.0       0.86      0.27      0.41      1010\n",
            "        4.0       0.29      0.96      0.44       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.48      0.92      0.63       958\n",
            "        7.0       0.85      0.38      0.53      1028\n",
            "        8.0       0.56      0.60      0.58       974\n",
            "        9.0       0.53      0.02      0.05      1009\n",
            "\n",
            "avg / total       0.61      0.54      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[658   1  42   0  70   0 185   5  19   0]\n",
            " [  0 907  44   1 138   0  38   0   7   0]\n",
            " [  2  25 742  31  65   0 116  20  30   1]\n",
            " [ 11  14 227 272  72   0 210  32 159  13]\n",
            " [  0   0   5   0 940   0  33   0   2   2]\n",
            " [ 35   2  74   4 311   0 261   1 204   0]\n",
            " [  3   2   4   0  63   0 885   0   1   0]\n",
            " [  0   9  21   1 589   0   5 395   3   5]\n",
            " [  4   7 164   7 111   0  95   2 584   0]\n",
            " [  2   5  10   0 900   0  20   7  41  24]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59810,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59810, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [11  2 44  2 60  0 62  4 12  3] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.258 s \n",
            "\n",
            "Accuracy rate for 53.710000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.67      0.78       980\n",
            "        1.0       0.91      0.82      0.86      1135\n",
            "        2.0       0.54      0.72      0.61      1032\n",
            "        3.0       0.85      0.25      0.38      1010\n",
            "        4.0       0.30      0.92      0.46       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.43      0.94      0.59       958\n",
            "        7.0       0.85      0.38      0.52      1028\n",
            "        8.0       0.53      0.58      0.55       974\n",
            "        9.0       0.69      0.04      0.08      1009\n",
            "\n",
            "avg / total       0.62      0.54      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[655   1  49   0  67   0 175   6  27   0]\n",
            " [  0 928  57   1  43   0 103   0   3   0]\n",
            " [  4  24 740  32  54   0 132  20  25   1]\n",
            " [  7  19 236 250  51   0 229  38 170  10]\n",
            " [  0   3   6   0 907   0  61   0   2   3]\n",
            " [ 25   7  89   3 286   0 269   1 212   0]\n",
            " [  2   2   4   0  53   0 897   0   0   0]\n",
            " [  0  15  27   1 570   0  20 388   1   6]\n",
            " [  2   8 163   6 104   0 128   1 562   0]\n",
            " [  2  10  10   0 839   0  50   4  50  44]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59800,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59800, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [12  2 44  2 64  0 67  4 12  3] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.283 s \n",
            "\n",
            "Accuracy rate for 53.210000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.71      0.79       980\n",
            "        1.0       0.90      0.82      0.86      1135\n",
            "        2.0       0.56      0.70      0.62      1032\n",
            "        3.0       0.87      0.24      0.37      1010\n",
            "        4.0       0.28      0.95      0.43       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.48      0.93      0.63       958\n",
            "        7.0       0.89      0.34      0.50      1028\n",
            "        8.0       0.54      0.56      0.55       974\n",
            "        9.0       0.72      0.02      0.04      1009\n",
            "\n",
            "avg / total       0.63      0.53      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[694   1  30   0  84   0 152   0  19   0]\n",
            " [  0 926  49   1  89   0  69   0   1   0]\n",
            " [  4  24 724  28  70   0 133  16  33   0]\n",
            " [ 16  25 219 240  88   0 203  25 191   3]\n",
            " [  0   1   5   0 932   0  41   0   2   1]\n",
            " [ 44   4  72   4 358   0 235   1 174   0]\n",
            " [  2   2   3   0  62   0 889   0   0   0]\n",
            " [  0  14  25   0 624   0   3 353   5   4]\n",
            " [  5  15 156   3 132   0 120   1 542   0]\n",
            " [  1  12   9   0 912   0  17   2  35  21]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59790,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59790, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [13  2 47  2 67  0 70  4 12  3] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.343 s \n",
            "\n",
            "Accuracy rate for 52.800000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.69      0.78       980\n",
            "        1.0       0.91      0.79      0.85      1135\n",
            "        2.0       0.58      0.69      0.63      1032\n",
            "        3.0       0.86      0.28      0.42      1010\n",
            "        4.0       0.27      0.96      0.42       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.49      0.93      0.64       958\n",
            "        7.0       0.88      0.31      0.46      1028\n",
            "        8.0       0.56      0.55      0.56       974\n",
            "        9.0       0.69      0.02      0.04      1009\n",
            "\n",
            "avg / total       0.63      0.53      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[677   1  35   0  98   0 151   1  17   0]\n",
            " [  0 897  46   1 137   0  51   0   3   0]\n",
            " [  2  29 714  30  78   0 135  13  30   1]\n",
            " [ 13  17 205 281 110   0 192  26 159   7]\n",
            " [  0   0   5   0 940   0  34   0   2   1]\n",
            " [ 46   3  59   5 366   0 236   1 176   0]\n",
            " [  3   2   2   0  57   0 894   0   0   0]\n",
            " [  0  12  27   1 663   0   6 316   2   1]\n",
            " [  4  12 135   9 154   0 120   1 539   0]\n",
            " [  2   8   9   0 913   0  19   3  33  22]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59780,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59780, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [13  2 47  2 68  0 78  4 12  4] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.463 s \n",
            "\n",
            "Accuracy rate for 53.540000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.70      0.80       980\n",
            "        1.0       0.89      0.81      0.85      1135\n",
            "        2.0       0.53      0.71      0.61      1032\n",
            "        3.0       0.89      0.28      0.42      1010\n",
            "        4.0       0.28      0.94      0.43       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.48      0.94      0.64       958\n",
            "        7.0       0.89      0.34      0.49      1028\n",
            "        8.0       0.57      0.54      0.55       974\n",
            "        9.0       0.76      0.03      0.06      1009\n",
            "\n",
            "avg / total       0.64      0.54      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[686   1  51   0  83   0 144   1  14   0]\n",
            " [  0 920  53   1  54   0 104   0   3   0]\n",
            " [  4  34 734  25  63   0 124  16  32   0]\n",
            " [  8  28 227 278 102   0 197  23 141   6]\n",
            " [  0   1   6   0 926   0  46   0   2   1]\n",
            " [ 26   3  95   4 370   0 220   1 173   0]\n",
            " [  3   2   4   0  44   0 905   0   0   0]\n",
            " [  0  21  28   1 621   0   4 350   0   3]\n",
            " [  3  11 182   5 143   0 106   1 523   0]\n",
            " [  1  10   7   0 916   0  17   1  25  32]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59770,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59770, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [13  2 54  2 71  0 78  4 12  4] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.533 s \n",
            "\n",
            "Accuracy rate for 52.720000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.69      0.79       980\n",
            "        1.0       0.91      0.84      0.87      1135\n",
            "        2.0       0.52      0.71      0.60      1032\n",
            "        3.0       0.83      0.27      0.41      1010\n",
            "        4.0       0.27      0.95      0.42       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.50      0.92      0.65       958\n",
            "        7.0       0.88      0.26      0.40      1028\n",
            "        8.0       0.59      0.54      0.56       974\n",
            "        9.0       0.69      0.04      0.07      1009\n",
            "\n",
            "avg / total       0.62      0.53      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[679   1  50   1 105   0 132   0  12   0]\n",
            " [  0 954  50   1  92   0  36   0   2   0]\n",
            " [  3  40 730  40  67   0 118  11  23   0]\n",
            " [ 10  24 239 271 103   0 202  23 132   6]\n",
            " [  0   1   5   1 933   0  40   0   1   1]\n",
            " [ 45   2  85   5 376   0 217   1 161   0]\n",
            " [  3   2  19   0  54   0 880   0   0   0]\n",
            " [  0  12  37   1 698   0   5 264   2   9]\n",
            " [  4  10 178   7 135   0 114   1 525   0]\n",
            " [  1   6  12   0 906   0  18   1  29  36]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59760,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59760, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [13  2 54  2 75  0 84  4 12  4] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.583 s \n",
            "\n",
            "Accuracy rate for 52.650000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.71      0.79       980\n",
            "        1.0       0.90      0.78      0.83      1135\n",
            "        2.0       0.51      0.74      0.60      1032\n",
            "        3.0       0.89      0.24      0.38      1010\n",
            "        4.0       0.28      0.95      0.44       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.48      0.94      0.63       958\n",
            "        7.0       0.88      0.30      0.44      1028\n",
            "        8.0       0.57      0.53      0.55       974\n",
            "        9.0       0.69      0.03      0.06      1009\n",
            "\n",
            "avg / total       0.62      0.53      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[695   1  51   0  75   0 143   0  15   0]\n",
            " [  0 883  78   1  82   0  89   0   2   0]\n",
            " [  3  24 760  21  58   0 129  11  26   0]\n",
            " [ 16  35 239 240  83   0 213  27 151   6]\n",
            " [  0   1   6   0 936   0  36   0   1   2]\n",
            " [ 53   2 109   2 338   0 217   1 170   0]\n",
            " [  2   2   9   0  48   0 897   0   0   0]\n",
            " [  0  15  43   1 647   0  10 306   0   6]\n",
            " [  5   9 194   5 128   0 116   1 515   1]\n",
            " [  1   9  12   0 914   0  21   3  16  33]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59750,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59750, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [13  2 54  2 77  0 91  4 12  5] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.692 s \n",
            "\n",
            "Accuracy rate for 51.850000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.68      0.78       980\n",
            "        1.0       0.91      0.78      0.84      1135\n",
            "        2.0       0.53      0.69      0.60      1032\n",
            "        3.0       0.90      0.27      0.41      1010\n",
            "        4.0       0.28      0.94      0.43       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.44      0.95      0.61       958\n",
            "        7.0       0.87      0.25      0.38      1028\n",
            "        8.0       0.58      0.54      0.56       974\n",
            "        9.0       0.85      0.04      0.08      1009\n",
            "\n",
            "avg / total       0.64      0.52      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[664   1  61   0  93   0 151   0  10   0]\n",
            " [  0 888  48   1  47   0 149   0   2   0]\n",
            " [  3  41 715  18  59   0 153  14  29   0]\n",
            " [ 14  12 198 269  97   0 247  22 148   3]\n",
            " [  0   0   6   0 924   0  49   0   1   2]\n",
            " [ 43   4  89   7 341   0 239   1 168   0]\n",
            " [  2   2   5   0  40   0 909   0   0   0]\n",
            " [  0  12  34   0 707   0  15 254   4   2]\n",
            " [  4   7 183   4 137   0 116   1 522   0]\n",
            " [  1   7  12   0 914   0  16   1  18  40]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59740,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59740, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [13  2 54  2 80  0 98  4 12  5] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.693 s \n",
            "\n",
            "Accuracy rate for 51.670000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.69      0.79       980\n",
            "        1.0       0.93      0.76      0.83      1135\n",
            "        2.0       0.53      0.70      0.60      1032\n",
            "        3.0       0.90      0.24      0.38      1010\n",
            "        4.0       0.27      0.95      0.42       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.44      0.96      0.60       958\n",
            "        7.0       0.87      0.27      0.41      1028\n",
            "        8.0       0.61      0.52      0.56       974\n",
            "        9.0       0.77      0.02      0.03      1009\n",
            "\n",
            "avg / total       0.64      0.52      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[680   1  54   0  80   0 154   0  11   0]\n",
            " [  0 862  65   1  61   0 144   1   1   0]\n",
            " [  5  24 719  21  59   0 161  14  29   0]\n",
            " [ 11  18 216 247 112   0 252  24 128   2]\n",
            " [  0   0   6   0 937   0  36   0   1   2]\n",
            " [ 31   3  87   2 361   0 271   1 136   0]\n",
            " [  1   2   4   0  31   0 920   0   0   0]\n",
            " [  0  10  33   1 685   0  19 278   1   1]\n",
            " [  5   5 160   2 172   0 122   1 507   0]\n",
            " [  1   6  12   0 933   0  28   1  11  17]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59730,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59730, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [ 13   2  54   2  81   0 107   4  12   5] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.776 s \n",
            "\n",
            "Accuracy rate for 51.890000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.70      0.79       980\n",
            "        1.0       0.93      0.79      0.86      1135\n",
            "        2.0       0.52      0.69      0.59      1032\n",
            "        3.0       0.88      0.23      0.36      1010\n",
            "        4.0       0.28      0.94      0.43       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.43      0.96      0.59       958\n",
            "        7.0       0.87      0.28      0.43      1028\n",
            "        8.0       0.58      0.50      0.53       974\n",
            "        9.0       0.80      0.04      0.07      1009\n",
            "\n",
            "avg / total       0.63      0.52      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[684   1  47   0  67   0 169   0  12   0]\n",
            " [  0 900  70   1  54   0 108   1   0   1]\n",
            " [  2  31 717  23  56   0 163  11  29   0]\n",
            " [ 10   7 228 228  88   0 272  27 146   4]\n",
            " [  0   0   6   0 926   0  47   0   1   2]\n",
            " [ 46   2  95   2 321   0 279   1 146   0]\n",
            " [  3   2   5   0  28   0 920   0   0   0]\n",
            " [  0  12  33   1 673   0  13 292   1   3]\n",
            " [  3   6 171   4 161   0 145   1 483   0]\n",
            " [  2   6  13   0 906   0  28   1  14  39]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59720,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59720, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [ 13   2  54   3  82   0 113   4  12   7] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.697 s \n",
            "\n",
            "Accuracy rate for 52.540000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.67      0.78       980\n",
            "        1.0       0.92      0.79      0.85      1135\n",
            "        2.0       0.55      0.70      0.61      1032\n",
            "        3.0       0.85      0.27      0.41      1010\n",
            "        4.0       0.27      0.94      0.42       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.45      0.94      0.61       958\n",
            "        7.0       0.86      0.31      0.45      1028\n",
            "        8.0       0.59      0.49      0.54       974\n",
            "        9.0       0.72      0.08      0.14      1009\n",
            "\n",
            "avg / total       0.63      0.53      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[661   1  43   0 113   0 147   4  11   0]\n",
            " [  0 894  45   1  52   0 139   1   3   0]\n",
            " [  2  36 724  29  68   0 133  14  26   0]\n",
            " [ 15  13 215 274 120   0 212  27 128   6]\n",
            " [  0   0   6   0 924   0  49   0   1   2]\n",
            " [ 33   1  69   7 393   0 245   1 141   2]\n",
            " [  2   2  13   0  40   0 901   0   0   0]\n",
            " [  0  10  33   0 633   0  13 317   1  21]\n",
            " [  2  13 165  13 168   0 133   1 479   0]\n",
            " [  1   6  10   0 875   0  18   3  16  80]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59710,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59710, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [ 14   2  54   3  83   0 119   4  12   9] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.815 s \n",
            "\n",
            "Accuracy rate for 53.030000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.68      0.78       980\n",
            "        1.0       0.93      0.73      0.82      1135\n",
            "        2.0       0.53      0.71      0.61      1032\n",
            "        3.0       0.82      0.26      0.39      1010\n",
            "        4.0       0.30      0.93      0.45       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.41      0.96      0.57       958\n",
            "        7.0       0.86      0.31      0.45      1028\n",
            "        8.0       0.63      0.49      0.55       974\n",
            "        9.0       0.76      0.19      0.31      1009\n",
            "\n",
            "avg / total       0.63      0.53      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[665   1  38   0  83   0 187   2   4   0]\n",
            " [  0 827  71   1  18   0 216   0   1   1]\n",
            " [  3  20 736  33  47   0 157  14  21   1]\n",
            " [ 13  12 239 260  82   0 244  33 118   9]\n",
            " [  0   1   4   0 910   0  62   0   0   5]\n",
            " [ 29   1  88  11 357   0 280   1 122   3]\n",
            " [  2   2   6   0  30   0 918   0   0   0]\n",
            " [  0  13  34   1 609   0  17 314   1  39]\n",
            " [  1   8 167  13 153   0 147   2 479   4]\n",
            " [  2   8  11   0 753   0  29   0  12 194]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59700,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59700, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [ 14   2  56   3  88   0 120   6  12   9] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.897 s \n",
            "\n",
            "Accuracy rate for 56.060000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.69      0.80       980\n",
            "        1.0       0.94      0.79      0.86      1135\n",
            "        2.0       0.59      0.70      0.64      1032\n",
            "        3.0       0.88      0.28      0.42      1010\n",
            "        4.0       0.32      0.93      0.48       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.41      0.96      0.57       958\n",
            "        7.0       0.82      0.49      0.61      1028\n",
            "        8.0       0.59      0.50      0.54       974\n",
            "        9.0       0.84      0.20      0.32      1009\n",
            "\n",
            "avg / total       0.64      0.56      0.53     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[678   1  30   0  76   0 177   7  11   0]\n",
            " [  0 892  50   1  35   0 154   0   3   0]\n",
            " [  4  22 726  22  45   0 169  22  22   0]\n",
            " [  7  13 191 281  80   0 261  34 136   7]\n",
            " [  0   1   6   0 911   0  61   0   1   2]\n",
            " [ 26   2  49   7 333   0 291  23 158   3]\n",
            " [  2   2   5   0  28   0 921   0   0   0]\n",
            " [  0   7  18   1 447   0  21 507   1  26]\n",
            " [  2   7 151   9 137   0 162  15 490   1]\n",
            " [  2   4   7   0 729   0  40  14  13 200]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59690,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59690, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [ 15   2  60   3  91   0 120   6  13  10] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.885 s \n",
            "\n",
            "Accuracy rate for 56.260000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.67      0.78       980\n",
            "        1.0       0.94      0.81      0.87      1135\n",
            "        2.0       0.55      0.72      0.62      1032\n",
            "        3.0       0.88      0.25      0.39      1010\n",
            "        4.0       0.33      0.93      0.49       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.42      0.96      0.59       958\n",
            "        7.0       0.81      0.50      0.62      1028\n",
            "        8.0       0.58      0.51      0.54       974\n",
            "        9.0       0.76      0.20      0.31      1009\n",
            "\n",
            "avg / total       0.63      0.56      0.53     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[661   1  47   0  70   0 182   9   9   1]\n",
            " [  0 921  48   1  42   0 118   1   4   0]\n",
            " [  3  21 738  26  39   0 161  20  23   1]\n",
            " [  6   7 210 257  71   0 261  38 153   7]\n",
            " [  0   1   6   0 914   0  56   0   2   3]\n",
            " [ 32   2  79   4 303   0 288  25 154   5]\n",
            " [  1   2  10   0  26   0 918   0   1   0]\n",
            " [  0   9  19   0 422   0  17 519   1  41]\n",
            " [  3   9 169   4 125   0 145  16 500   3]\n",
            " [  1   6   9   0 739   0  22  15  19 198]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59680,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59680, 9) \n",
            " [0 0 5 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [ 15   2  60   3  98   0 120   6  13  13] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 7.944 s \n",
            "\n",
            "Accuracy rate for 55.670000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.69      0.79       980\n",
            "        1.0       0.93      0.78      0.85      1135\n",
            "        2.0       0.55      0.71      0.62      1032\n",
            "        3.0       0.87      0.24      0.38      1010\n",
            "        4.0       0.32      0.93      0.48       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.43      0.95      0.59       958\n",
            "        7.0       0.80      0.44      0.57      1028\n",
            "        8.0       0.60      0.50      0.55       974\n",
            "        9.0       0.72      0.26      0.38      1009\n",
            "\n",
            "avg / total       0.63      0.56      0.53     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[679   1  34   0  59   0 187  10   7   3]\n",
            " [  0 882  56   1  61   0 130   0   5   0]\n",
            " [  3  31 729  24  45   0 156  22  20   2]\n",
            " [ 16   7 221 247  86   0 244  40 141   8]\n",
            " [  0   0   5   0 918   0  54   0   1   4]\n",
            " [ 36   2  80   5 331   0 267  18 136  17]\n",
            " [  4   2   9   0  33   0 910   0   0   0]\n",
            " [  0   9  15   1 478   0  12 451   1  61]\n",
            " [  5   8 166   7 140   0 136  14 491   7]\n",
            " [  1   3   8   0 689   0  23  11  14 260]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59670,) [0. 0. 6. ... 4. 9. 9.]\n",
            "probabilities: (59670, 9) \n",
            " [0 0 5 ... 4 8 8]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [ 17   2  60   4  98   3 121   9  13  13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.226 s \n",
            "\n",
            "Accuracy rate for 60.170000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.72      0.81       980\n",
            "        1.0       0.91      0.79      0.84      1135\n",
            "        2.0       0.60      0.73      0.66      1032\n",
            "        3.0       0.92      0.33      0.49      1010\n",
            "        4.0       0.37      0.94      0.53       982\n",
            "        5.0       0.99      0.08      0.15       892\n",
            "        6.0       0.44      0.96      0.61       958\n",
            "        7.0       0.77      0.71      0.74      1028\n",
            "        8.0       0.60      0.53      0.56       974\n",
            "        9.0       0.86      0.18      0.29      1009\n",
            "\n",
            "avg / total       0.74      0.60      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[705   1  33   0  57   1 148  28   6   1]\n",
            " [  0 894  44   2  33   0 157   1   4   0]\n",
            " [  4  36 749  19  40   0 128  28  26   2]\n",
            " [ 16  20 181 338  64   0 203  51 133   4]\n",
            " [  0   1   5   0 920   0  51   0   2   3]\n",
            " [ 27   5  55   5 258  72 281  32 155   2]\n",
            " [  1   2   7   0  30   0 918   0   0   0]\n",
            " [  0  13  17   1 228   0  20 732   1  16]\n",
            " [  3  10 155   4 141   0 126  21 512   2]\n",
            " [  1   5   8   0 710   0  32  60  16 177]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) [0. 0. 6. ... 7. 4. 9.]\n",
            "probabilities: (59660, 10) \n",
            " [0 0 6 ... 7 4 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [ 19   2  64   4  98   3 125   9  13  13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.341 s \n",
            "\n",
            "Accuracy rate for 60.480000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.80      0.86       980\n",
            "        1.0       0.95      0.78      0.86      1135\n",
            "        2.0       0.58      0.74      0.65      1032\n",
            "        3.0       0.91      0.30      0.45      1010\n",
            "        4.0       0.37      0.94      0.53       982\n",
            "        5.0       0.97      0.07      0.12       892\n",
            "        6.0       0.46      0.95      0.62       958\n",
            "        7.0       0.75      0.69      0.72      1028\n",
            "        8.0       0.61      0.51      0.56       974\n",
            "        9.0       0.85      0.20      0.32      1009\n",
            "\n",
            "avg / total       0.74      0.60      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[786   1  33   0  38   2  87  25   8   0]\n",
            " [  0 888  47   1  32   0 162   1   4   0]\n",
            " [  6  10 768  17  40   0 144  22  21   4]\n",
            " [ 14   7 218 301  69   0 207  57 135   2]\n",
            " [  0   2   6   0 921   0  46   0   1   6]\n",
            " [ 30   5  48   5 306  59 259  42 133   5]\n",
            " [  3   2   9   0  30   0 913   0   1   0]\n",
            " [  0   7  18   1 264   0  11 713   2  12]\n",
            " [  4   7 178   4 130   0 119  27 500   5]\n",
            " [  4   5   8   0 693   0  17  70  13 199]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 6. ... 7. 9. 9.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 6 ... 7 9 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [ 19   2  64   4  98   3 135   9  13  13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.359 s \n",
            "\n",
            "Accuracy rate for 59.900000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.79      0.86       980\n",
            "        1.0       0.92      0.77      0.84      1135\n",
            "        2.0       0.60      0.74      0.66      1032\n",
            "        3.0       0.96      0.28      0.43      1010\n",
            "        4.0       0.38      0.93      0.54       982\n",
            "        5.0       0.94      0.09      0.16       892\n",
            "        6.0       0.41      0.97      0.58       958\n",
            "        7.0       0.79      0.67      0.72      1028\n",
            "        8.0       0.61      0.50      0.55       974\n",
            "        9.0       0.82      0.20      0.32      1009\n",
            "\n",
            "avg / total       0.74      0.60      0.57     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[779   1  20   0  19   2 128  22   8   1]\n",
            " [  0 872  51   1  18   0 188   1   4   0]\n",
            " [  9  22 762   5  31   0 160  15  25   3]\n",
            " [ 13  11 195 281  51   1 278  45 131   4]\n",
            " [  0   2   5   0 914   0  57   0   1   3]\n",
            " [ 21   5  50   5 241  78 323  33 127   9]\n",
            " [  1   2   4   0  21   0 930   0   0   0]\n",
            " [  0  12  20   0 259   0  26 688   3  20]\n",
            " [  1  15 166   0 123   2 156  21 488   2]\n",
            " [  3   6   7   0 701   0  27  51  16 198]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) [0. 0. 6. ... 7. 9. 4.]\n",
            "probabilities: (59640, 10) \n",
            " [0 0 6 ... 7 9 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [ 19   2  72   4 100   3 135   9  13  13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.393 s \n",
            "\n",
            "Accuracy rate for 58.970000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.79      0.86       980\n",
            "        1.0       0.95      0.74      0.83      1135\n",
            "        2.0       0.57      0.78      0.66      1032\n",
            "        3.0       0.96      0.28      0.43      1010\n",
            "        4.0       0.37      0.92      0.53       982\n",
            "        5.0       0.95      0.07      0.13       892\n",
            "        6.0       0.40      0.96      0.57       958\n",
            "        7.0       0.77      0.67      0.71      1028\n",
            "        8.0       0.62      0.46      0.53       974\n",
            "        9.0       0.88      0.17      0.29      1009\n",
            "\n",
            "avg / total       0.74      0.59      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[777   1  32   0  25   2 118  19   6   0]\n",
            " [  0 841  51   1  24   0 213   2   3   0]\n",
            " [  8  12 802   6  33   0 141  19  10   1]\n",
            " [ 13   8 222 281  64   0 264  46 110   2]\n",
            " [  0   1   8   0 906   0  64   0   1   2]\n",
            " [ 16   3  41   3 248  60 350  34 133   4]\n",
            " [  1   2   4   0  27   0 924   0   0   0]\n",
            " [  0   8  21   0 277   0  21 685   1  15]\n",
            " [  1   9 206   2 115   1 169  24 446   1]\n",
            " [  2   4   9   0 718   0  30  60  11 175]]\n",
            "--------------------------------\n",
            "val predicted: (59630,) [0. 0. 6. ... 7. 4. 4.]\n",
            "probabilities: (59630, 10) \n",
            " [0 0 6 ... 7 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [ 21   2  77   4 101   3 135   9  15  13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.424 s \n",
            "\n",
            "Accuracy rate for 60.020000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.80      0.87       980\n",
            "        1.0       0.93      0.79      0.85      1135\n",
            "        2.0       0.61      0.79      0.68      1032\n",
            "        3.0       0.97      0.25      0.40      1010\n",
            "        4.0       0.35      0.93      0.51       982\n",
            "        5.0       0.95      0.08      0.15       892\n",
            "        6.0       0.44      0.96      0.60       958\n",
            "        7.0       0.82      0.66      0.73      1028\n",
            "        8.0       0.62      0.53      0.57       974\n",
            "        9.0       0.87      0.16      0.27      1009\n",
            "\n",
            "avg / total       0.75      0.60      0.57     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[787   1  33   0  36   2  98  17   6   0]\n",
            " [  0 894  42   1  46   0 148   0   4   0]\n",
            " [  6  19 811   2  34   0 125  13  21   1]\n",
            " [ 14  19 202 253  68   0 271  41 138   4]\n",
            " [  0   0   6   0 913   0  60   0   1   2]\n",
            " [ 18   4  41   4 289  75 304  19 137   1]\n",
            " [  1   2   8   0  29   1 917   0   0   0]\n",
            " [  0  11  21   0 285   0  20 676   1  14]\n",
            " [  3  10 168   0 134   1 124  16 516   2]\n",
            " [  2   5   7   0 749   0  33  43  10 160]]\n",
            "--------------------------------\n",
            "val predicted: (59620,) [0. 0. 6. ... 7. 9. 9.]\n",
            "probabilities: (59620, 10) \n",
            " [0 0 6 ... 7 9 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [ 21   2  81   4 102   3 140   9  15  13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.539 s \n",
            "\n",
            "Accuracy rate for 59.820000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.81      0.87       980\n",
            "        1.0       0.95      0.74      0.84      1135\n",
            "        2.0       0.59      0.77      0.67      1032\n",
            "        3.0       0.98      0.29      0.44      1010\n",
            "        4.0       0.36      0.93      0.52       982\n",
            "        5.0       0.99      0.08      0.14       892\n",
            "        6.0       0.43      0.96      0.59       958\n",
            "        7.0       0.82      0.66      0.73      1028\n",
            "        8.0       0.59      0.52      0.56       974\n",
            "        9.0       0.86      0.16      0.27      1009\n",
            "\n",
            "avg / total       0.75      0.60      0.57     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[797   1  28   0  21   1 109  18   5   0]\n",
            " [  0 843  50   2  42   0 194   0   4   0]\n",
            " [  6  10 798   2  34   0 142  10  29   1]\n",
            " [ 15   9 201 288  62   0 244  38 148   5]\n",
            " [  0   1   5   0 918   0  57   0   0   1]\n",
            " [ 20   3  54   3 271  67 296  26 152   0]\n",
            " [  2   2  10   0  23   0 921   0   0   0]\n",
            " [  0   5  24   0 282   0  21 680   2  14]\n",
            " [  2   6 162   0 131   0 140  17 511   5]\n",
            " [  2   4  13   0 756   0  23  39  13 159]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59610, 10) \n",
            " [0 0 6 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [ 22   2  83   4 105   3 144   9  15  13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.488 s \n",
            "\n",
            "Accuracy rate for 59.860000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.93      0.82      0.87       980\n",
            "        1.0       0.95      0.74      0.83      1135\n",
            "        2.0       0.57      0.78      0.66      1032\n",
            "        3.0       0.97      0.26      0.41      1010\n",
            "        4.0       0.36      0.93      0.52       982\n",
            "        5.0       0.97      0.07      0.14       892\n",
            "        6.0       0.44      0.95      0.60       958\n",
            "        7.0       0.79      0.67      0.73      1028\n",
            "        8.0       0.61      0.54      0.57       974\n",
            "        9.0       0.86      0.15      0.25      1009\n",
            "\n",
            "avg / total       0.75      0.60      0.57     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[808   1  36   0  25   0  88  14   8   0]\n",
            " [  0 838  57   2  31   0 204   0   3   0]\n",
            " [  6   9 810   2  37   0 127  14  26   1]\n",
            " [ 19  13 218 265  57   1 235  54 144   4]\n",
            " [  0   1   6   0 918   0  51   0   1   5]\n",
            " [ 25   2  66   3 285  66 273  20 152   0]\n",
            " [  2   2  15   0  27   0 912   0   0   0]\n",
            " [  0   8  23   0 277   0  14 693   1  12]\n",
            " [  4   5 172   0 111   1 123  30 526   2]\n",
            " [  3   1   8   0 758   0  32  49   8 150]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 6 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [ 22   2  83   4 109   3 149  10  15  13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.565 s \n",
            "\n",
            "Accuracy rate for 59.950000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.83      0.88       980\n",
            "        1.0       0.95      0.78      0.86      1135\n",
            "        2.0       0.59      0.76      0.66      1032\n",
            "        3.0       0.96      0.20      0.33      1010\n",
            "        4.0       0.38      0.93      0.54       982\n",
            "        5.0       0.96      0.08      0.15       892\n",
            "        6.0       0.41      0.96      0.58       958\n",
            "        7.0       0.81      0.70      0.75      1028\n",
            "        8.0       0.59      0.52      0.55       974\n",
            "        9.0       0.90      0.17      0.29      1009\n",
            "\n",
            "avg / total       0.75      0.60      0.57     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[816   1  27   0  32   1  89  11   3   0]\n",
            " [  0 888  41   2  23   0 171   7   3   0]\n",
            " [  7  14 781   4  34   0 148  15  28   1]\n",
            " [ 18   6 208 201  58   1 302  46 170   0]\n",
            " [  0   1   5   0 909   0  64   0   1   2]\n",
            " [ 22   2  46   2 240  74 340  25 139   2]\n",
            " [  2   2  10   0  22   0 922   0   0   0]\n",
            " [  0   7  22   0 244   0  18 721   2  14]\n",
            " [  3  11 168   0 111   1 151  19 509   1]\n",
            " [  3   3  10   0 734   0  35  41   9 174]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59590, 10) \n",
            " [0 0 6 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [ 22   2  83   8 110   3 149  15  15  13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.568 s \n",
            "\n",
            "Accuracy rate for 62.970000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.84      0.88       980\n",
            "        1.0       0.98      0.72      0.83      1135\n",
            "        2.0       0.66      0.76      0.70      1032\n",
            "        3.0       0.85      0.57      0.68      1010\n",
            "        4.0       0.41      0.94      0.58       982\n",
            "        5.0       1.00      0.06      0.11       892\n",
            "        6.0       0.44      0.96      0.60       958\n",
            "        7.0       0.66      0.79      0.72      1028\n",
            "        8.0       0.67      0.47      0.55       974\n",
            "        9.0       0.88      0.15      0.25      1009\n",
            "\n",
            "avg / total       0.75      0.63      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[819   0  28   1  19   0  94  15   3   1]\n",
            " [  0 813  53   5  31   0 222  10   1   0]\n",
            " [  6   6 781  11  35   0 153  18  20   2]\n",
            " [ 12   1  71 571  56   0 172  43  81   3]\n",
            " [  0   0   5   0 920   0  53   3   0   1]\n",
            " [ 26   0  48  57 244  53 260  88 115   1]\n",
            " [  2   2  16   0  23   0 915   0   0   0]\n",
            " [  0   4  19   1 161   0  14 816   2  11]\n",
            " [  4   3 157  20 107   0 170  52 459   2]\n",
            " [  3   0   7   6 621   0  28 190   4 150]]\n",
            "--------------------------------\n",
            "val predicted: (59580,) [0. 0. 6. ... 7. 4. 4.]\n",
            "probabilities: (59580, 10) \n",
            " [0 0 6 ... 7 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [ 22   2  83   9 111   3 155  15  17  13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.645 s \n",
            "\n",
            "Accuracy rate for 63.700000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.82      0.88       980\n",
            "        1.0       0.96      0.78      0.86      1135\n",
            "        2.0       0.69      0.74      0.71      1032\n",
            "        3.0       0.80      0.60      0.69      1010\n",
            "        4.0       0.38      0.95      0.54       982\n",
            "        5.0       0.98      0.05      0.10       892\n",
            "        6.0       0.49      0.95      0.65       958\n",
            "        7.0       0.69      0.78      0.73      1028\n",
            "        8.0       0.69      0.50      0.58       974\n",
            "        9.0       0.90      0.13      0.22      1009\n",
            "\n",
            "avg / total       0.75      0.64      0.61     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[802   1  26   0  21   1  98  27   3   1]\n",
            " [  0 882  49   5  70   0 123   3   3   0]\n",
            " [  7  17 761  17  45   0 132  19  33   1]\n",
            " [ 10   4  48 610  82   0 142  38  75   1]\n",
            " [  0   0   5   0 933   0  40   2   1   1]\n",
            " [ 20   2  35  81 279  48 242  87  98   0]\n",
            " [  2   2  12   0  29   0 913   0   0   0]\n",
            " [  0   6  18   1 177   0  11 802   2  11]\n",
            " [  2   7 144  40 115   0 131  44 491   0]\n",
            " [  3   2   7   7 693   0  17 146   6 128]]\n",
            "--------------------------------\n",
            "val predicted: (59570,) [0. 0. 6. ... 7. 4. 4.]\n",
            "probabilities: (59570, 10) \n",
            " [0 0 6 ... 7 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [ 22   2  88   9 112   3 159  15  17  13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.663 s \n",
            "\n",
            "Accuracy rate for 62.940000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.82      0.88       980\n",
            "        1.0       0.97      0.69      0.81      1135\n",
            "        2.0       0.66      0.75      0.70      1032\n",
            "        3.0       0.81      0.57      0.67      1010\n",
            "        4.0       0.43      0.93      0.59       982\n",
            "        5.0       0.98      0.06      0.11       892\n",
            "        6.0       0.45      0.97      0.61       958\n",
            "        7.0       0.66      0.79      0.72      1028\n",
            "        8.0       0.64      0.52      0.57       974\n",
            "        9.0       0.92      0.14      0.24      1009\n",
            "\n",
            "avg / total       0.75      0.63      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[806   1  38   0  11   0  85  30   9   0]\n",
            " [  0 787  49  10  20   0 255  11   3   0]\n",
            " [  6  10 776  21  29   0 143  20  26   1]\n",
            " [  9   0  58 573  44   0 179  47  99   1]\n",
            " [  0   0   6   0 917   0  55   2   1   1]\n",
            " [ 20   1  52  62 204  53 264 101 135   0]\n",
            " [  2   2   5   0  19   0 930   0   0   0]\n",
            " [  0   3  22   2 157   0  24 808   3   9]\n",
            " [  3   4 164  37  91   1 125  43 506   0]\n",
            " [  3   1  10   5 651   0  25 167   9 138]]\n",
            "--------------------------------\n",
            "val predicted: (59560,) [0. 0. 2. ... 7. 4. 7.]\n",
            "probabilities: (59560, 10) \n",
            " [0 0 2 ... 7 4 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [ 22   2  88   9 112   3 168  15  17  14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.770 s \n",
            "\n",
            "Accuracy rate for 62.190000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.82      0.88       980\n",
            "        1.0       0.97      0.69      0.81      1135\n",
            "        2.0       0.66      0.72      0.69      1032\n",
            "        3.0       0.83      0.58      0.68      1010\n",
            "        4.0       0.40      0.93      0.56       982\n",
            "        5.0       1.00      0.05      0.10       892\n",
            "        6.0       0.44      0.97      0.60       958\n",
            "        7.0       0.66      0.77      0.71      1028\n",
            "        8.0       0.68      0.48      0.56       974\n",
            "        9.0       0.84      0.16      0.27      1009\n",
            "\n",
            "avg / total       0.75      0.62      0.59     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[804   1  30   0  19   0  92  27   6   1]\n",
            " [  0 788  45   4  64   0 231   2   1   0]\n",
            " [  7   8 742  19  37   0 167  21  30   1]\n",
            " [ 10   2  56 581  65   0 180  45  67   4]\n",
            " [  0   0   5   0 914   0  59   1   1   2]\n",
            " [ 16   0  39  54 265  47 277  84 105   5]\n",
            " [  2   1   8   0  20   0 927   0   0   0]\n",
            " [  0   4  18   2 180   0  18 788   1  17]\n",
            " [  2   4 163  33 110   0 145  50 466   1]\n",
            " [  3   1  11   5 632   0  20 171   4 162]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 6. ... 4. 7. 9.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 6 ... 4 7 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [ 22   2  89   9 117   3 172  15  17  14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.745 s \n",
            "\n",
            "Accuracy rate for 62.020000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.80      0.87       980\n",
            "        1.0       0.97      0.69      0.81      1135\n",
            "        2.0       0.69      0.71      0.70      1032\n",
            "        3.0       0.80      0.58      0.67      1010\n",
            "        4.0       0.43      0.93      0.59       982\n",
            "        5.0       0.97      0.07      0.13       892\n",
            "        6.0       0.40      0.97      0.57       958\n",
            "        7.0       0.67      0.78      0.72      1028\n",
            "        8.0       0.68      0.48      0.56       974\n",
            "        9.0       0.76      0.14      0.24      1009\n",
            "\n",
            "avg / total       0.73      0.62      0.59     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[784   1  37   0   8   1 118  27   3   1]\n",
            " [  0 782  44   9  21   0 276   2   1   0]\n",
            " [  5   7 731  24  26   0 194  17  25   3]\n",
            " [  9   2  44 586  40   1 201  41  80   6]\n",
            " [  0   0   4   0 911   0  64   0   1   2]\n",
            " [ 25   1  25  73 202  60 296 100 104   6]\n",
            " [  2   2   4   0  17   0 933   0   0   0]\n",
            " [  0   5  18   1 141   0  34 802   1  26]\n",
            " [  3   4 145  33  89   0 177  53 469   1]\n",
            " [  3   2   9   5 645   0  33 164   4 144]]\n",
            "--------------------------------\n",
            "val predicted: (59540,) [0. 0. 6. ... 4. 7. 9.]\n",
            "probabilities: (59540, 10) \n",
            " [0 0 6 ... 4 7 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [ 22   2  90   9 117   3 180  15  18  14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.840 s \n",
            "\n",
            "Accuracy rate for 63.890000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.82      0.88       980\n",
            "        1.0       0.97      0.72      0.83      1135\n",
            "        2.0       0.66      0.72      0.69      1032\n",
            "        3.0       0.79      0.60      0.69      1010\n",
            "        4.0       0.45      0.92      0.60       982\n",
            "        5.0       0.98      0.09      0.17       892\n",
            "        6.0       0.43      0.97      0.60       958\n",
            "        7.0       0.70      0.78      0.74      1028\n",
            "        8.0       0.67      0.55      0.60       974\n",
            "        9.0       0.78      0.17      0.27      1009\n",
            "\n",
            "avg / total       0.74      0.64      0.61     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[801   0  34   1  12   1 109  16   5   1]\n",
            " [  0 819  45  15  21   0 232   1   2   0]\n",
            " [  7   6 740  24  26   0 175  16  35   3]\n",
            " [ 14   3  52 610  40   0 174  34  77   6]\n",
            " [  0   0   5   0 905   0  67   2   1   2]\n",
            " [ 18   1  61  78 175  82 285  60 130   2]\n",
            " [  2   2   6   0  15   0 933   0   0   0]\n",
            " [  0   6  18   1 144   0  27 800   1  31]\n",
            " [  2   5 151  37  74   1 128  43 531   2]\n",
            " [  3   2  11   5 621   0  25 165   9 168]]\n",
            "--------------------------------\n",
            "val predicted: (59530,) [0. 0. 6. ... 9. 7. 9.]\n",
            "probabilities: (59530, 10) \n",
            " [0 0 6 ... 9 7 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [ 22   2  91   9 117   3 188  15  18  15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.852 s \n",
            "\n",
            "Accuracy rate for 62.150000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.96      0.80      0.87       980\n",
            "        1.0       0.98      0.66      0.79      1135\n",
            "        2.0       0.66      0.71      0.68      1032\n",
            "        3.0       0.81      0.58      0.67      1010\n",
            "        4.0       0.43      0.91      0.59       982\n",
            "        5.0       0.97      0.09      0.16       892\n",
            "        6.0       0.41      0.97      0.58       958\n",
            "        7.0       0.69      0.77      0.73      1028\n",
            "        8.0       0.67      0.51      0.58       974\n",
            "        9.0       0.74      0.17      0.27      1009\n",
            "\n",
            "avg / total       0.73      0.62      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[781   1  31   0  13   1 129  20   4   0]\n",
            " [  0 752  66   6  21   0 283   4   3   0]\n",
            " [  5   7 735  23  29   0 187  17  27   2]\n",
            " [  7   1  55 585  43   0 179  39  92   9]\n",
            " [  0   0   5   0 898   0  73   2   0   4]\n",
            " [ 16   0  33  62 187  77 309  81 119   8]\n",
            " [  2   2   8   0  15   0 931   0   0   0]\n",
            " [  0   5  20   1 148   0  31 792   1  30]\n",
            " [  1   3 157  40  93   1 133  44 497   5]\n",
            " [  2   0  12   7 639   0  25 153   4 167]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) [0. 0. 6. ... 9. 9. 7.]\n",
            "probabilities: (59520, 10) \n",
            " [0 0 6 ... 9 9 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [ 23   2  91   9 118   3 194  15  20  15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.883 s \n",
            "\n",
            "Accuracy rate for 60.170000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.95      0.81      0.88       980\n",
            "        1.0       0.99      0.59      0.74      1135\n",
            "        2.0       0.66      0.69      0.68      1032\n",
            "        3.0       0.86      0.51      0.64      1010\n",
            "        4.0       0.43      0.92      0.59       982\n",
            "        5.0       0.98      0.07      0.13       892\n",
            "        6.0       0.37      0.98      0.54       958\n",
            "        7.0       0.71      0.75      0.73      1028\n",
            "        8.0       0.59      0.51      0.55       974\n",
            "        9.0       0.78      0.16      0.26      1009\n",
            "\n",
            "avg / total       0.74      0.60      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[798   1  36   0   7   0 111  18   8   1]\n",
            " [  0 670  50   4  29   0 379   1   2   0]\n",
            " [  6   1 715  12  25   0 227  14  30   2]\n",
            " [ 10   2  57 511  39   0 219  36 134   2]\n",
            " [  0   0   5   0 902   0  70   1   1   3]\n",
            " [ 18   0  41  42 170  60 322  73 157   9]\n",
            " [  2   1   5   0  14   0 936   0   0   0]\n",
            " [  0   2  17   1 168   0  45 770   1  24]\n",
            " [  2   3 146  23  86   1 171  44 495   3]\n",
            " [  3   0  10   4 659   0  38 130   5 160]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) [0. 0. 6. ... 9. 9. 7.]\n",
            "probabilities: (59510, 10) \n",
            " [0 0 6 ... 9 9 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: divide by zero encountered in log2\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:278: RuntimeWarning: invalid value encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [ 24   2  91   9 118   3 203  15  20  15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training random forest...\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 8.882 s \n",
            "\n",
            "Accuracy rate for 62.390000 \n",
            "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
            "            criterion='gini', max_depth=None, max_features='auto',\n",
            "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
            "            min_impurity_split=None, min_samples_leaf=1,\n",
            "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
            "            verbose=0, warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.81      0.87       980\n",
            "        1.0       0.97      0.68      0.80      1135\n",
            "        2.0       0.68      0.71      0.70      1032\n",
            "        3.0       0.83      0.53      0.65      1010\n",
            "        4.0       0.46      0.89      0.60       982\n",
            "        5.0       1.00      0.10      0.17       892\n",
            "        6.0       0.39      0.97      0.56       958\n",
            "        7.0       0.68      0.76      0.72      1028\n",
            "        8.0       0.63      0.53      0.58       974\n",
            "        9.0       0.79      0.20      0.31      1009\n",
            "\n",
            "avg / total       0.74      0.62      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[798   0  37   1  12   0 102  23   6   1]\n",
            " [  0 772  47   3  14   0 295   3   1   0]\n",
            " [  6   8 735  19  25   0 191  16  28   4]\n",
            " [ 15   1  54 538  30   0 213  43 109   7]\n",
            " [  0   0   4   0 876   0  95   2   0   5]\n",
            " [ 25   1  30  48 150  85 335  61 153   4]\n",
            " [  2   2   5   0  15   0 934   0   0   0]\n",
            " [  0   5  18   2 157   0  37 782   1  26]\n",
            " [  2   6 135  30  70   0 158  47 521   5]\n",
            " [  3   0  13   4 568   0  44 172   7 198]]\n",
            "--------------------------------\n",
            "final active learning accuracies [37.519999999999996, 42.53, 51.42, 49.03, 49.25, 52.01, 51.41, 51.89, 53.04, 55.48, 56.989999999999995, 56.720000000000006, 56.93, 55.169999999999995, 56.26, 55.64, 54.769999999999996, 54.98, 54.06999999999999, 53.71, 53.21, 52.800000000000004, 53.54, 52.72, 52.65, 51.849999999999994, 51.67, 51.89, 52.54, 53.03, 56.06, 56.26, 55.669999999999995, 60.17, 60.480000000000004, 59.9, 58.97, 60.019999999999996, 59.81999999999999, 59.86, 59.95, 62.970000000000006, 63.7, 62.94, 62.19, 62.019999999999996, 63.89, 62.150000000000006, 60.17, 62.39]\n",
            "saved Active-learning-experiment-30.pkl /content ['datalab', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-29.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "{\n",
            "  \"RfModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          37.519999999999996,\n",
            "          42.53,\n",
            "          51.42,\n",
            "          49.03,\n",
            "          49.25,\n",
            "          52.01,\n",
            "          51.41,\n",
            "          51.89,\n",
            "          53.04,\n",
            "          55.48,\n",
            "          56.989999999999995,\n",
            "          56.720000000000006,\n",
            "          56.93,\n",
            "          55.169999999999995,\n",
            "          56.26,\n",
            "          55.64,\n",
            "          54.769999999999996,\n",
            "          54.98,\n",
            "          54.06999999999999,\n",
            "          53.71,\n",
            "          53.21,\n",
            "          52.800000000000004,\n",
            "          53.54,\n",
            "          52.72,\n",
            "          52.65,\n",
            "          51.849999999999994,\n",
            "          51.67,\n",
            "          51.89,\n",
            "          52.54,\n",
            "          53.03,\n",
            "          56.06,\n",
            "          56.26,\n",
            "          55.669999999999995,\n",
            "          60.17,\n",
            "          60.480000000000004,\n",
            "          59.9,\n",
            "          58.97,\n",
            "          60.019999999999996,\n",
            "          59.81999999999999,\n",
            "          59.86,\n",
            "          59.95,\n",
            "          62.970000000000006,\n",
            "          63.7,\n",
            "          62.94,\n",
            "          62.19,\n",
            "          62.019999999999996,\n",
            "          63.89,\n",
            "          62.150000000000006,\n",
            "          60.17,\n",
            "          62.39\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          44.21,\n",
            "          39.2,\n",
            "          37.57,\n",
            "          35.82,\n",
            "          36.120000000000005,\n",
            "          33.64,\n",
            "          32.09,\n",
            "          32.1,\n",
            "          32.28,\n",
            "          30.759999999999998,\n",
            "          31.230000000000004,\n",
            "          29.34,\n",
            "          26.419999999999998,\n",
            "          27.05,\n",
            "          26.58,\n",
            "          23.23,\n",
            "          24.0,\n",
            "          23.7,\n",
            "          21.58,\n",
            "          23.84\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          63.85999999999999,\n",
            "          60.309999999999995,\n",
            "          59.760000000000005,\n",
            "          59.89,\n",
            "          59.160000000000004,\n",
            "          59.519999999999996,\n",
            "          57.9,\n",
            "          59.74,\n",
            "          57.06,\n",
            "          59.91\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          75.02,\n",
            "          74.36,\n",
            "          72.39999999999999,\n",
            "          72.08\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.39999999999999,\n",
            "          81.82000000000001\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          25.72,\n",
            "          38.83,\n",
            "          53.99,\n",
            "          57.53,\n",
            "          62.39,\n",
            "          66.58,\n",
            "          64.23,\n",
            "          67.5,\n",
            "          72.75,\n",
            "          76.35,\n",
            "          77.31,\n",
            "          77.96,\n",
            "          78.17,\n",
            "          80.67,\n",
            "          81.76,\n",
            "          83.63000000000001,\n",
            "          85.26,\n",
            "          85.37,\n",
            "          85.82,\n",
            "          85.76,\n",
            "          86.00999999999999,\n",
            "          87.01,\n",
            "          87.45,\n",
            "          87.83,\n",
            "          88.64999999999999,\n",
            "          88.1,\n",
            "          87.92999999999999,\n",
            "          89.21,\n",
            "          89.57000000000001,\n",
            "          90.34,\n",
            "          91.12,\n",
            "          90.86,\n",
            "          91.17,\n",
            "          91.53999999999999,\n",
            "          91.84,\n",
            "          91.75999999999999,\n",
            "          91.07,\n",
            "          91.36,\n",
            "          91.22,\n",
            "          91.88,\n",
            "          92.0,\n",
            "          91.97,\n",
            "          91.7,\n",
            "          92.12,\n",
            "          92.28,\n",
            "          92.57,\n",
            "          92.63,\n",
            "          92.55,\n",
            "          92.80000000000001,\n",
            "          92.75999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          39.050000000000004,\n",
            "          51.85999999999999,\n",
            "          67.30000000000001,\n",
            "          74.29,\n",
            "          74.42999999999999,\n",
            "          80.15,\n",
            "          83.55,\n",
            "          83.58,\n",
            "          86.24000000000001,\n",
            "          87.22999999999999,\n",
            "          87.89,\n",
            "          88.42999999999999,\n",
            "          88.94,\n",
            "          90.06,\n",
            "          89.57000000000001,\n",
            "          90.03999999999999,\n",
            "          90.03999999999999,\n",
            "          91.14,\n",
            "          91.86,\n",
            "          91.79\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          62.99,\n",
            "          75.07000000000001,\n",
            "          75.38,\n",
            "          83.96000000000001,\n",
            "          87.89,\n",
            "          89.62,\n",
            "          89.7,\n",
            "          91.47999999999999,\n",
            "          91.84,\n",
            "          92.49000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          76.4,\n",
            "          85.66,\n",
            "          90.22,\n",
            "          92.13\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          81.26,\n",
            "          87.98\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          36.01,\n",
            "          43.34,\n",
            "          53.94,\n",
            "          58.02,\n",
            "          60.97,\n",
            "          66.44,\n",
            "          68.63,\n",
            "          70.8,\n",
            "          72.08,\n",
            "          73.58,\n",
            "          73.63,\n",
            "          74.0,\n",
            "          74.2,\n",
            "          75.52,\n",
            "          75.41,\n",
            "          75.81,\n",
            "          75.98,\n",
            "          77.97,\n",
            "          77.5,\n",
            "          80.15,\n",
            "          79.81,\n",
            "          81.13,\n",
            "          80.87,\n",
            "          80.58999999999999,\n",
            "          80.86,\n",
            "          81.26,\n",
            "          82.26,\n",
            "          82.44,\n",
            "          82.75,\n",
            "          82.92,\n",
            "          83.76,\n",
            "          83.50999999999999,\n",
            "          85.05,\n",
            "          85.50999999999999,\n",
            "          85.13,\n",
            "          86.02,\n",
            "          86.02,\n",
            "          86.5,\n",
            "          86.09,\n",
            "          85.83,\n",
            "          86.9,\n",
            "          86.46000000000001,\n",
            "          86.38,\n",
            "          86.88,\n",
            "          87.09,\n",
            "          87.87,\n",
            "          87.47,\n",
            "          87.59,\n",
            "          87.74,\n",
            "          87.78\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.64,\n",
            "          60.72,\n",
            "          65.45,\n",
            "          70.28999999999999,\n",
            "          72.94,\n",
            "          76.08,\n",
            "          77.51,\n",
            "          77.78,\n",
            "          79.35,\n",
            "          80.39,\n",
            "          81.6,\n",
            "          81.17,\n",
            "          82.73,\n",
            "          84.28,\n",
            "          84.15,\n",
            "          85.2,\n",
            "          86.13,\n",
            "          86.78,\n",
            "          86.95,\n",
            "          87.59\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          56.86,\n",
            "          69.43,\n",
            "          71.87,\n",
            "          75.68,\n",
            "          80.01,\n",
            "          82.06,\n",
            "          84.5,\n",
            "          85.92,\n",
            "          86.76,\n",
            "          87.32\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.5,\n",
            "          82.39,\n",
            "          85.76,\n",
            "          87.56\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.19,\n",
            "          88.14999999999999\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"SvmModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          35.93,\n",
            "          35.97,\n",
            "          40.33,\n",
            "          39.39,\n",
            "          41.349999999999994,\n",
            "          42.99,\n",
            "          46.23,\n",
            "          46.18,\n",
            "          47.260000000000005,\n",
            "          52.5,\n",
            "          52.400000000000006,\n",
            "          51.25999999999999,\n",
            "          51.690000000000005,\n",
            "          51.800000000000004,\n",
            "          53.18000000000001,\n",
            "          53.82,\n",
            "          55.88999999999999,\n",
            "          56.120000000000005,\n",
            "          57.269999999999996,\n",
            "          59.41,\n",
            "          59.95,\n",
            "          62.629999999999995,\n",
            "          61.339999999999996,\n",
            "          63.88,\n",
            "          65.34,\n",
            "          65.77,\n",
            "          66.9,\n",
            "          67.96,\n",
            "          68.27,\n",
            "          67.44,\n",
            "          68.45,\n",
            "          68.63,\n",
            "          68.0,\n",
            "          68.47,\n",
            "          68.77,\n",
            "          68.8,\n",
            "          69.17,\n",
            "          68.97,\n",
            "          69.33,\n",
            "          69.67999999999999,\n",
            "          69.95,\n",
            "          70.34,\n",
            "          70.47,\n",
            "          71.19,\n",
            "          71.97,\n",
            "          72.26,\n",
            "          72.06,\n",
            "          71.98,\n",
            "          72.55,\n",
            "          72.78999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          50.33,\n",
            "          51.59,\n",
            "          56.599999999999994,\n",
            "          60.24,\n",
            "          61.57,\n",
            "          63.5,\n",
            "          66.74,\n",
            "          68.19,\n",
            "          68.02,\n",
            "          69.8,\n",
            "          75.88000000000001,\n",
            "          77.24,\n",
            "          78.09,\n",
            "          79.38,\n",
            "          80.4,\n",
            "          80.99,\n",
            "          80.28999999999999,\n",
            "          80.12,\n",
            "          79.75999999999999,\n",
            "          80.36999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          64.55,\n",
            "          68.75,\n",
            "          71.34,\n",
            "          74.11999999999999,\n",
            "          75.96000000000001,\n",
            "          77.03999999999999,\n",
            "          76.85,\n",
            "          79.19,\n",
            "          80.51,\n",
            "          80.99\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          78.4,\n",
            "          78.21000000000001,\n",
            "          80.08,\n",
            "          81.0\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.11,\n",
            "          84.53\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.86,\n",
            "          37.6,\n",
            "          46.23,\n",
            "          58.41,\n",
            "          60.34,\n",
            "          65.98,\n",
            "          65.01,\n",
            "          69.86,\n",
            "          72.28999999999999,\n",
            "          74.65,\n",
            "          76.24,\n",
            "          77.37,\n",
            "          77.59,\n",
            "          78.7,\n",
            "          79.06,\n",
            "          80.06,\n",
            "          81.21000000000001,\n",
            "          82.32000000000001,\n",
            "          83.17,\n",
            "          83.78,\n",
            "          84.6,\n",
            "          84.58,\n",
            "          84.47,\n",
            "          85.07000000000001,\n",
            "          85.64,\n",
            "          85.75,\n",
            "          85.7,\n",
            "          86.18,\n",
            "          86.58,\n",
            "          86.50999999999999,\n",
            "          86.71,\n",
            "          87.09,\n",
            "          86.91,\n",
            "          87.13,\n",
            "          87.42999999999999,\n",
            "          87.75,\n",
            "          87.97,\n",
            "          88.23,\n",
            "          88.23,\n",
            "          88.22,\n",
            "          88.16000000000001,\n",
            "          88.03,\n",
            "          88.38000000000001,\n",
            "          88.39,\n",
            "          88.64,\n",
            "          88.98,\n",
            "          89.05999999999999,\n",
            "          89.34,\n",
            "          89.3,\n",
            "          89.52\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          50.160000000000004,\n",
            "          63.73,\n",
            "          70.14,\n",
            "          74.4,\n",
            "          78.99000000000001,\n",
            "          80.36999999999999,\n",
            "          82.76,\n",
            "          84.35000000000001,\n",
            "          85.78,\n",
            "          86.61999999999999,\n",
            "          87.46000000000001,\n",
            "          87.64,\n",
            "          88.08,\n",
            "          88.75,\n",
            "          88.68,\n",
            "          89.02,\n",
            "          89.39,\n",
            "          89.57000000000001,\n",
            "          89.66,\n",
            "          89.8\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          59.099999999999994,\n",
            "          69.91000000000001,\n",
            "          75.66000000000001,\n",
            "          81.41000000000001,\n",
            "          82.69,\n",
            "          85.07000000000001,\n",
            "          85.92,\n",
            "          86.89,\n",
            "          87.8,\n",
            "          87.6\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.45,\n",
            "          84.1,\n",
            "          86.36,\n",
            "          88.16000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.58,\n",
            "          87.38\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.009999999999998,\n",
            "          33.54,\n",
            "          48.67,\n",
            "          57.34,\n",
            "          61.68,\n",
            "          64.75999999999999,\n",
            "          69.28,\n",
            "          71.97,\n",
            "          73.2,\n",
            "          74.03,\n",
            "          75.08,\n",
            "          76.01,\n",
            "          76.55,\n",
            "          77.42999999999999,\n",
            "          77.75,\n",
            "          79.72,\n",
            "          80.78,\n",
            "          81.62,\n",
            "          81.8,\n",
            "          82.03,\n",
            "          81.82000000000001,\n",
            "          82.72,\n",
            "          82.94,\n",
            "          83.03,\n",
            "          83.72,\n",
            "          83.81,\n",
            "          83.72,\n",
            "          83.95,\n",
            "          84.38,\n",
            "          85.02,\n",
            "          85.36,\n",
            "          85.65,\n",
            "          85.26,\n",
            "          85.37,\n",
            "          85.37,\n",
            "          85.19,\n",
            "          85.18,\n",
            "          85.61999999999999,\n",
            "          85.47,\n",
            "          85.61999999999999,\n",
            "          85.78,\n",
            "          86.00999999999999,\n",
            "          86.05000000000001,\n",
            "          85.96000000000001,\n",
            "          85.96000000000001,\n",
            "          86.0,\n",
            "          86.24000000000001,\n",
            "          86.6,\n",
            "          86.66,\n",
            "          86.81\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.449999999999996,\n",
            "          67.88,\n",
            "          72.25,\n",
            "          77.82,\n",
            "          79.19,\n",
            "          80.32000000000001,\n",
            "          81.19,\n",
            "          81.91000000000001,\n",
            "          82.67999999999999,\n",
            "          82.89,\n",
            "          82.89,\n",
            "          83.05,\n",
            "          83.91999999999999,\n",
            "          84.69,\n",
            "          84.77,\n",
            "          84.66,\n",
            "          85.0,\n",
            "          85.3,\n",
            "          85.79,\n",
            "          86.08\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          56.38999999999999,\n",
            "          72.92999999999999,\n",
            "          78.44,\n",
            "          81.0,\n",
            "          82.73,\n",
            "          83.52000000000001,\n",
            "          84.35000000000001,\n",
            "          85.17,\n",
            "          86.17,\n",
            "          86.66\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          73.76,\n",
            "          83.52000000000001,\n",
            "          85.6,\n",
            "          86.44\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.02000000000001,\n",
            "          85.64\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 31, using model = LogModel, selection_function = RandomSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [30 27 22 21 26 34 27 14 23 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.458 s \n",
            "\n",
            "Accuracy rate for 73.110000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.81      0.91      0.85       980\n",
            "        1.0       0.72      0.97      0.82      1135\n",
            "        2.0       0.78      0.63      0.70      1032\n",
            "        3.0       0.66      0.78      0.71      1010\n",
            "        4.0       0.67      0.73      0.70       982\n",
            "        5.0       0.71      0.43      0.53       892\n",
            "        6.0       0.79      0.87      0.83       958\n",
            "        7.0       0.77      0.78      0.78      1028\n",
            "        8.0       0.68      0.63      0.66       974\n",
            "        9.0       0.74      0.52      0.61      1009\n",
            "\n",
            "avg / total       0.73      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 891    2   14    6    0    4   43   10    8    2]\n",
            " [   0 1104   12    7    0    1    4    1    6    0]\n",
            " [  63   94  654   38   42    2   59   48   27    5]\n",
            " [   8   25   61  786    9   22   12    9   49   29]\n",
            " [  15   49    3    8  720   41   21   43   32   50]\n",
            " [  23   49   25  181   30  382   45   17   95   45]\n",
            " [  27   11   25    2   22   18  832    4   17    0]\n",
            " [  39   93   16   18   27    2    4  802   11   16]\n",
            " [  15   75   33  114   20   28   32    6  618   33]\n",
            " [  24   41    0   33  206   39    4   95   45  522]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 7. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 7 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [54 63 40 49 54 57 49 35 54 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.531 s \n",
            "\n",
            "Accuracy rate for 74.560000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.81      0.89      0.85       980\n",
            "        1.0       0.75      0.98      0.85      1135\n",
            "        2.0       0.79      0.67      0.73      1032\n",
            "        3.0       0.64      0.79      0.71      1010\n",
            "        4.0       0.71      0.81      0.75       982\n",
            "        5.0       0.74      0.38      0.51       892\n",
            "        6.0       0.73      0.85      0.78       958\n",
            "        7.0       0.82      0.80      0.81      1028\n",
            "        8.0       0.72      0.62      0.67       974\n",
            "        9.0       0.80      0.59      0.68      1009\n",
            "\n",
            "avg / total       0.75      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 877    3   10    3    1    3   54   17   10    2]\n",
            " [   0 1108    0   16    0    1    4    1    5    0]\n",
            " [  51   82  693   43   24    0   74   28   32    5]\n",
            " [   9   22   58  802    9   21   15   15   40   19]\n",
            " [  23   42    8    6  794   31   37   10   11   20]\n",
            " [  22   41   21  197   51  343   53   39   84   41]\n",
            " [  41   11   29    3   33   15  811    2   12    1]\n",
            " [  19   60   28   19   23    3    4  822   12   38]\n",
            " [  17   75   27  133   14   17   53    5  607   26]\n",
            " [  25   42    4   34  173   31    7   59   35  599]]\n",
            "--------------------------------\n",
            "final active learning accuracies [73.11, 74.56]\n",
            "saved Active-learning-experiment-31.pkl /content ['datalab', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-29.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 32, using model = LogModel, selection_function = RandomSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [13 14 13 10 12  9 16  9 16 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.357 s \n",
            "\n",
            "Accuracy rate for 68.950000 \n",
            "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.93      0.85       980\n",
            "        1.0       0.70      0.99      0.82      1135\n",
            "        2.0       0.83      0.50      0.63      1032\n",
            "        3.0       0.64      0.70      0.67      1010\n",
            "        4.0       0.67      0.56      0.61       982\n",
            "        5.0       0.47      0.30      0.36       892\n",
            "        6.0       0.70      0.87      0.78       958\n",
            "        7.0       0.88      0.66      0.76      1028\n",
            "        8.0       0.67      0.59      0.63       974\n",
            "        9.0       0.55      0.73      0.63      1009\n",
            "\n",
            "avg / total       0.69      0.69      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 908    1    1    2    5   12   41    2    7    1]\n",
            " [   0 1119    0    2    0    1    7    0    6    0]\n",
            " [  43  160  518   51   53    6  124   14   58    5]\n",
            " [  26   26   26  708    1   99   34   10   56   24]\n",
            " [   1   41   15    2  554   40   13    3   24  289]\n",
            " [ 102   27    4  228   50  265   79   19   56   62]\n",
            " [  23   14   13   12   26   21  836    1    8    4]\n",
            " [  22   86   18    1   23    3    7  680   30  158]\n",
            " [  10   85   13   85    4   94   48    9  575   51]\n",
            " [   9   35   14    9  112   22    6   33   37  732]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) [0. 0. 8. ... 9. 9. 8.]\n",
            "probabilities: (59875, 10) \n",
            " [0 0 8 ... 9 9 8]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [24 32 27 26 27 25 23 19 24 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.426 s \n",
            "\n",
            "Accuracy rate for 68.530000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.85      0.82       980\n",
            "        1.0       0.73      0.98      0.84      1135\n",
            "        2.0       0.60      0.42      0.50      1032\n",
            "        3.0       0.68      0.78      0.73      1010\n",
            "        4.0       0.63      0.54      0.58       982\n",
            "        5.0       0.57      0.37      0.45       892\n",
            "        6.0       0.73      0.82      0.78       958\n",
            "        7.0       0.75      0.74      0.75      1028\n",
            "        8.0       0.73      0.63      0.68       974\n",
            "        9.0       0.56      0.65      0.60      1009\n",
            "\n",
            "avg / total       0.68      0.69      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 836    1    9    7   14    8   27    7   69    2]\n",
            " [   0 1113    8    2    0    1    5    2    4    0]\n",
            " [  58  167  437   99   40    0  125   43   59    4]\n",
            " [  20   30   56  789    4   27   16   38   16   14]\n",
            " [  20   20   17    3  526   58   11    8   17  302]\n",
            " [  45   22   36  189   70  328   56   28   39   79]\n",
            " [  52   20    5    2   27   32  789    3   20    8]\n",
            " [   7   44   99    2   18    6    3  762    5   82]\n",
            " [  18   89   31   52    4   57   39   32  618   34]\n",
            " [  11   20   30   17  127   55    3   87    4  655]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 8. ... 9. 5. 2.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 8 ... 9 5 2]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [39 47 40 36 42 35 40 28 31 37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.536 s \n",
            "\n",
            "Accuracy rate for 71.670000 \n",
            "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.81      0.87      0.84       980\n",
            "        1.0       0.71      0.98      0.82      1135\n",
            "        2.0       0.70      0.49      0.57      1032\n",
            "        3.0       0.71      0.76      0.73      1010\n",
            "        4.0       0.67      0.69      0.68       982\n",
            "        5.0       0.56      0.42      0.48       892\n",
            "        6.0       0.73      0.85      0.78       958\n",
            "        7.0       0.84      0.79      0.81      1028\n",
            "        8.0       0.71      0.64      0.68       974\n",
            "        9.0       0.67      0.62      0.64      1009\n",
            "\n",
            "avg / total       0.71      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 856    1   10    7    8    8   22    5   62    1]\n",
            " [   0 1116    1    1    0    1    6    2    8    0]\n",
            " [  53  149  501   89   30    1  111   31   62    5]\n",
            " [  15   42   48  772    5   44   23   26   22   13]\n",
            " [  13   25   14    0  676   73   30    4   22  125]\n",
            " [  47   27   53  155   70  372   59   19   36   54]\n",
            " [  45   16    8    2   24   25  813    2   23    0]\n",
            " [   9   53   35    1   25   10    6  813    7   69]\n",
            " [  13  113   27   57    5   43   37   17  626   36]\n",
            " [  12   29   15   10  160   90   11   51    9  622]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) [0. 0. 8. ... 5. 5. 5.]\n",
            "probabilities: (59625, 10) \n",
            " [0 0 8 ... 5 5 5]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [53 66 45 47 54 44 46 36 48 61] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.539 s \n",
            "\n",
            "Accuracy rate for 73.090000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.81      0.92      0.86       980\n",
            "        1.0       0.74      0.98      0.84      1135\n",
            "        2.0       0.71      0.49      0.58      1032\n",
            "        3.0       0.74      0.77      0.75      1010\n",
            "        4.0       0.65      0.75      0.69       982\n",
            "        5.0       0.57      0.44      0.50       892\n",
            "        6.0       0.73      0.85      0.79       958\n",
            "        7.0       0.86      0.81      0.83      1028\n",
            "        8.0       0.74      0.67      0.70       974\n",
            "        9.0       0.69      0.59      0.64      1009\n",
            "\n",
            "avg / total       0.73      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 897    1   10    0    5    6   19    2   39    1]\n",
            " [   0 1116    1    2    0    1    5    2    8    0]\n",
            " [  49  142  504   77   41    1  123   23   69    3]\n",
            " [  28   25   42  774    4   57   23   21   18   18]\n",
            " [   6   23   10    1  733   74   19    5   23   88]\n",
            " [  68   21   50  126   72  396   56   19   35   49]\n",
            " [  27   14   17    0   30   28  819    1   21    1]\n",
            " [   7   48   42    4   24   10    5  829    3   56]\n",
            " [  14   93   21   55   10   39   34   15  648   45]\n",
            " [   6   29   11    9  215   78   12   46   10  593]]\n",
            "--------------------------------\n",
            "final active learning accuracies [68.95, 68.53, 71.67, 73.09]\n",
            "saved Active-learning-experiment-32.pkl /content ['datalab', 'Active-learning-experiment-32.pkl', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-29.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 33, using model = LogModel, selection_function = RandomSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [6 3 3 5 4 3 5 4 9 8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.342 s \n",
            "\n",
            "Accuracy rate for 68.380000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.69      0.84      0.76       980\n",
            "        1.0       0.72      0.98      0.83      1135\n",
            "        2.0       0.78      0.54      0.64      1032\n",
            "        3.0       0.70      0.69      0.69      1010\n",
            "        4.0       0.72      0.62      0.67       982\n",
            "        5.0       0.61      0.17      0.26       892\n",
            "        6.0       0.72      0.78      0.75       958\n",
            "        7.0       0.75      0.74      0.75      1028\n",
            "        8.0       0.50      0.61      0.55       974\n",
            "        9.0       0.64      0.77      0.70      1009\n",
            "\n",
            "avg / total       0.69      0.68      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 828    1    9   16    1    4   14    4  100    3]\n",
            " [   0 1113    4   12    0    0    6    0    0    0]\n",
            " [  27   77  556  161    5   23   80   33   63    7]\n",
            " [  16   44   24  699    2   26   12   24  138   25]\n",
            " [   2   50   34    1  608   24   64   13    4  182]\n",
            " [ 184   45   11   64   21  148   35   49  270   65]\n",
            " [  67   13   55    2   60    8  752    0    0    1]\n",
            " [  10   76    7    5   46    1    1  762    8  112]\n",
            " [  48   81    7   35   44    4   75   48  594   38]\n",
            " [  13   41    4    9   55    4    5   81   19  778]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 0. ... 7. 9. 7.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 0 ... 7 9 7]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [10 10  9 12  8  6  9  9 14 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.358 s \n",
            "\n",
            "Accuracy rate for 66.150000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.86      0.78       980\n",
            "        1.0       0.72      0.99      0.83      1135\n",
            "        2.0       0.69      0.54      0.61      1032\n",
            "        3.0       0.69      0.82      0.75      1010\n",
            "        4.0       0.64      0.63      0.64       982\n",
            "        5.0       0.63      0.21      0.32       892\n",
            "        6.0       0.79      0.82      0.80       958\n",
            "        7.0       0.62      0.47      0.53      1028\n",
            "        8.0       0.54      0.51      0.52       974\n",
            "        9.0       0.54      0.69      0.61      1009\n",
            "\n",
            "avg / total       0.66      0.66      0.64     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 845    1   10   10    4    1   19    2   86    2]\n",
            " [   0 1122    0    4    0    1    6    0    2    0]\n",
            " [  26  103  561  149    6    4   85   31   56   11]\n",
            " [  29   18   43  824    1   10    7    4   42   32]\n",
            " [   2   35   45    2  622   53   14   77    0  132]\n",
            " [ 184   38   53   65   17  188   29   12  212   94]\n",
            " [  40   10   61    4   45    5  783    0   10    0]\n",
            " [  23   87    8    8  155    1    0  481    1  264]\n",
            " [  33  120   29  112   22   30   45   39  493   51]\n",
            " [  15   27    8   19   94    6    4  136    4  696]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 0. ... 7. 7. 7.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 0 ... 7 7 7]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [12 15 14 19 11 12 15 16 19 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.375 s \n",
            "\n",
            "Accuracy rate for 70.450000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.82      0.79       980\n",
            "        1.0       0.68      0.99      0.81      1135\n",
            "        2.0       0.72      0.55      0.62      1032\n",
            "        3.0       0.68      0.76      0.72      1010\n",
            "        4.0       0.75      0.74      0.75       982\n",
            "        5.0       0.70      0.27      0.39       892\n",
            "        6.0       0.75      0.84      0.79       958\n",
            "        7.0       0.80      0.66      0.72      1028\n",
            "        8.0       0.62      0.60      0.61       974\n",
            "        9.0       0.62      0.76      0.68      1009\n",
            "\n",
            "avg / total       0.71      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 800    2   15   33    3    1   33    6   87    0]\n",
            " [   0 1125    1    1    0    0    5    0    3    0]\n",
            " [  25  125  566  122    7    3   78   38   57   11]\n",
            " [  28   50   46  768    2   26   10   11   43   26]\n",
            " [   1   31   16    2  725   17   42   13    3  132]\n",
            " [ 134   38   49  116   27  242   51    5  136   94]\n",
            " [  19   17   45    3   35   15  800    1   22    1]\n",
            " [  12   89   19    4   64    0    3  675    2  160]\n",
            " [  24  136   26   60   14   28   39   22  580   45]\n",
            " [   7   39    5   13   86   16    4   70    5  764]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 0. ... 9. 7. 7.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 0 ... 9 7 7]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [15 24 19 22 13 20 19 21 25 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.393 s \n",
            "\n",
            "Accuracy rate for 72.680000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.81      0.89      0.85       980\n",
            "        1.0       0.73      0.99      0.84      1135\n",
            "        2.0       0.79      0.52      0.63      1032\n",
            "        3.0       0.70      0.80      0.75      1010\n",
            "        4.0       0.77      0.71      0.74       982\n",
            "        5.0       0.65      0.41      0.50       892\n",
            "        6.0       0.78      0.83      0.80       958\n",
            "        7.0       0.80      0.70      0.75      1028\n",
            "        8.0       0.65      0.62      0.63       974\n",
            "        9.0       0.61      0.74      0.67      1009\n",
            "\n",
            "avg / total       0.73      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 874    2   14    2    3    1   19    3   62    0]\n",
            " [   0 1121    1    4    0    1    3    0    5    0]\n",
            " [  23  130  534   66   10    2   94   58   86   29]\n",
            " [  25   28   33  812    2   35    7   16   25   27]\n",
            " [   2   16   19    2  701   51   41   13    7  130]\n",
            " [  83   26   20  148   17  363   27    6  105   97]\n",
            " [  32   17   25   12   27   18  791   10   25    1]\n",
            " [  17   75   13    4   50    1    1  720    5  142]\n",
            " [   8   95   16   89   10   50   26   15  602   63]\n",
            " [  12   30    1   16   90   38    3   63    6  750]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [21 29 23 29 21 22 22 27 30 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.437 s \n",
            "\n",
            "Accuracy rate for 72.310000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.81      0.90      0.85       980\n",
            "        1.0       0.73      0.99      0.84      1135\n",
            "        2.0       0.83      0.54      0.65      1032\n",
            "        3.0       0.70      0.78      0.74      1010\n",
            "        4.0       0.74      0.72      0.73       982\n",
            "        5.0       0.63      0.38      0.47       892\n",
            "        6.0       0.75      0.83      0.79       958\n",
            "        7.0       0.78      0.72      0.75      1028\n",
            "        8.0       0.65      0.62      0.63       974\n",
            "        9.0       0.61      0.69      0.65      1009\n",
            "\n",
            "avg / total       0.72      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 883    3    8    1    7    3   23    2   48    2]\n",
            " [   0 1122    1    1    0    1    5    1    4    0]\n",
            " [  32  118  555   52    8    3  106   55   84   19]\n",
            " [  31   42   39  791    1   39    8   18   19   22]\n",
            " [   2   13   10    0  711   46   48   16   31  105]\n",
            " [  64   19   11  179   26  338   39   17   77  122]\n",
            " [  33   17   11    8   27   21  794   13   30    4]\n",
            " [  20   70   13    2   54    0    1  737   15  116]\n",
            " [   8  102   19   80   11   52   29   15  601   57]\n",
            " [  16   34    2   13  120   36    5   72   12  699]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 8. ... 9. 9. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 8 ... 9 9 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [28 32 30 33 22 27 31 32 34 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.409 s \n",
            "\n",
            "Accuracy rate for 72.330000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.90      0.82       980\n",
            "        1.0       0.72      0.99      0.84      1135\n",
            "        2.0       0.82      0.52      0.64      1032\n",
            "        3.0       0.71      0.78      0.74      1010\n",
            "        4.0       0.71      0.75      0.73       982\n",
            "        5.0       0.62      0.33      0.43       892\n",
            "        6.0       0.71      0.86      0.78       958\n",
            "        7.0       0.80      0.79      0.80      1028\n",
            "        8.0       0.71      0.60      0.65       974\n",
            "        9.0       0.67      0.63      0.65      1009\n",
            "\n",
            "avg / total       0.72      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 886    3    7    3    2    3   22    5   47    2]\n",
            " [   0 1123    1    2    0    0    6    2    1    0]\n",
            " [  60  123  539   33   16    3  135   54   57   12]\n",
            " [  38   39   50  790    0   33    9   13   12   26]\n",
            " [   2   19    5    0  735   50   73   19   18   61]\n",
            " [ 103   16   10  197   21  294   43   19   73  116]\n",
            " [  46   11    4    2   25   13  826    9   22    0]\n",
            " [  23   70   13    2   42    1    4  815    6   52]\n",
            " [  20  117   25   73   11   39   45   10  589   45]\n",
            " [  11   31    1   10  189   37    8   76   10  636]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 0. ... 9. 7. 7.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 0 ... 9 7 7]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [34 41 31 38 26 33 34 35 39 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.423 s \n",
            "\n",
            "Accuracy rate for 73.440000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.90      0.84       980\n",
            "        1.0       0.75      0.98      0.85      1135\n",
            "        2.0       0.80      0.51      0.62      1032\n",
            "        3.0       0.77      0.71      0.74      1010\n",
            "        4.0       0.73      0.77      0.75       982\n",
            "        5.0       0.68      0.39      0.49       892\n",
            "        6.0       0.71      0.86      0.78       958\n",
            "        7.0       0.80      0.79      0.79      1028\n",
            "        8.0       0.61      0.70      0.65       974\n",
            "        9.0       0.69      0.67      0.68      1009\n",
            "\n",
            "avg / total       0.74      0.73      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 883    2    3    2    3    1   24    3   54    5]\n",
            " [   0 1116    1    2    0    0    4    2   10    0]\n",
            " [  46  104  526   19   17    3  138   49  112   18]\n",
            " [  29   39   66  717    3   52   16   11   43   34]\n",
            " [   3   14   10    0  758   33   51   24   36   53]\n",
            " [  75   18   15  126   32  347   52   15  118   94]\n",
            " [  35   12    7    1   26   17  825   11   24    0]\n",
            " [  18   69    9    2   34    0    3  810   12   71]\n",
            " [  14   79   18   54   10   31   39   11  681   37]\n",
            " [   7   27    2    7  151   29   11   74   20  681]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 8. ... 9. 7. 7.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 8 ... 9 7 7]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [39 45 33 46 29 40 44 38 41 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.470 s \n",
            "\n",
            "Accuracy rate for 71.790000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.88      0.81       980\n",
            "        1.0       0.72      0.98      0.83      1135\n",
            "        2.0       0.79      0.48      0.60      1032\n",
            "        3.0       0.71      0.72      0.72      1010\n",
            "        4.0       0.75      0.77      0.76       982\n",
            "        5.0       0.62      0.35      0.45       892\n",
            "        6.0       0.69      0.87      0.77       958\n",
            "        7.0       0.80      0.76      0.78      1028\n",
            "        8.0       0.65      0.61      0.63       974\n",
            "        9.0       0.66      0.69      0.68      1009\n",
            "\n",
            "avg / total       0.72      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 858    2   17    6    2    1   31    6   55    2]\n",
            " [   0 1117    1    2    0    0    5    3    7    0]\n",
            " [  60  109  499   50   15    2  147   56   71   23]\n",
            " [  25   51   61  732    4   45   14   11   26   41]\n",
            " [   9   22   13    2  752   40   44   23   19   58]\n",
            " [  78   24   10  147   35  312   67   14  101  104]\n",
            " [  32   13    6    1   34   16  833    8   15    0]\n",
            " [  35   71    4    3   31    3    3  779    8   91]\n",
            " [  19  111   20   78   13   40   46    7  598   42]\n",
            " [  15   28    0   12  121   42    9   69   14  699]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59600,) [0. 0. 8. ... 9. 7. 7.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 8 ... 9 7 7]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [48 52 34 50 34 46 47 48 44 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.449 s \n",
            "\n",
            "Accuracy rate for 73.120000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.85      0.83       980\n",
            "        1.0       0.73      0.98      0.84      1135\n",
            "        2.0       0.78      0.55      0.65      1032\n",
            "        3.0       0.71      0.75      0.73      1010\n",
            "        4.0       0.75      0.75      0.75       982\n",
            "        5.0       0.71      0.40      0.51       892\n",
            "        6.0       0.67      0.89      0.76       958\n",
            "        7.0       0.82      0.75      0.78      1028\n",
            "        8.0       0.68      0.63      0.65       974\n",
            "        9.0       0.65      0.71      0.68      1009\n",
            "\n",
            "avg / total       0.73      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 829    2   25    5    1    5   37   10   57    9]\n",
            " [   0 1117    1    3    0    0    3    1    9    1]\n",
            " [  43  109  567   30   16    1  146   38   65   17]\n",
            " [  15   41   68  759    7   34   15   12   22   37]\n",
            " [   8   21    6    2  741   31   67   19   21   66]\n",
            " [  37   22   14  181   35  354   71   13   68   97]\n",
            " [  34   13    7    0   26   12  849    5   12    0]\n",
            " [  20   72   11    2   29    2    5  770   15  102]\n",
            " [  10   97   25   80   17   23   56    7  611   48]\n",
            " [  14   29    2   13  112   34   18   59   13  715]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 8. ... 7. 9. 7.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 8 ... 7 9 7]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [54 58 39 53 40 52 52 51 51 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.534 s \n",
            "\n",
            "Accuracy rate for 70.840000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.83      0.84      0.84       980\n",
            "        1.0       0.71      0.98      0.83      1135\n",
            "        2.0       0.76      0.54      0.63      1032\n",
            "        3.0       0.71      0.73      0.72      1010\n",
            "        4.0       0.71      0.73      0.72       982\n",
            "        5.0       0.59      0.29      0.38       892\n",
            "        6.0       0.68      0.84      0.75       958\n",
            "        7.0       0.77      0.76      0.76      1028\n",
            "        8.0       0.65      0.62      0.63       974\n",
            "        9.0       0.63      0.67      0.65      1009\n",
            "\n",
            "avg / total       0.71      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 826    1   26    2    9    3   23   24   62    4]\n",
            " [   0 1117    1    3    0    0    5    2    6    1]\n",
            " [  34  115  557   26   17    1  157   41   60   24]\n",
            " [  12   50   79  740    2   31   17   12   37   30]\n",
            " [   6   24    9    1  719   43   42   40   26   72]\n",
            " [  31   30   19  191   73  255   63   26   84  120]\n",
            " [  40   14    9    6   34   22  809    6   18    0]\n",
            " [  19   69    6    1   25    4   10  777   21   96]\n",
            " [  11  114   22   65   14   30   60    9  603   46]\n",
            " [  18   33    3    9  119   44   12   76   14  681]]\n",
            "--------------------------------\n",
            "final active learning accuracies [68.38, 66.14999999999999, 70.45, 72.68, 72.31, 72.33000000000001, 73.44000000000001, 71.78999999999999, 73.11999999999999, 70.84]\n",
            "saved Active-learning-experiment-33.pkl /content ['datalab', 'Active-learning-experiment-32.pkl', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-33.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-29.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 34, using model = LogModel, selection_function = RandomSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [2 0 4 3 5 1 3 2 3 2] [0 2 3 4 5 6 7 8 9]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n",
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.316 s \n",
            "\n",
            "Accuracy rate for 46.630000 \n",
            "Classification report for classifier LogisticRegression(C=2.0, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.56      0.31      0.40       980\n",
            "        1.0       0.00      0.00      0.00      1135\n",
            "        2.0       0.54      0.56      0.55      1032\n",
            "        3.0       0.49      0.51      0.50      1010\n",
            "        4.0       0.46      0.91      0.61       982\n",
            "        5.0       0.40      0.45      0.42       892\n",
            "        6.0       0.54      0.64      0.59       958\n",
            "        7.0       0.53      0.52      0.52      1028\n",
            "        8.0       0.45      0.61      0.52       974\n",
            "        9.0       0.25      0.22      0.23      1009\n",
            "\n",
            "avg / total       0.42      0.47      0.43     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[304   0  84  31  13 149 277   0   5 117]\n",
            " [  0   0 116 322   0   0  19 269 408   1]\n",
            " [ 21   0 578  37 165  21  85  49  60  16]\n",
            " [ 21   0  76 520   8 261  20  12  86   6]\n",
            " [  3   0   3  16 890   5  10  16  15  24]\n",
            " [ 20   0  57  71  47 404  48  15  68 162]\n",
            " [153   0  62   3  82  11 612   1  30   4]\n",
            " [  7   0  17  10 134  24   7 535   7 287]\n",
            " [  6   0  79  37  36  91  45  14 594  72]\n",
            " [  4   0   4  18 543  51   8 103  52 226]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59975,) [9. 9. 6. ... 4. 9. 7.]\n",
            "probabilities: (59975, 9) \n",
            " [8 8 5 ... 3 8 6]\n",
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [4 2 7 7 5 1 6 7 6 5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.345 s \n",
            "\n",
            "Accuracy rate for 57.860000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.56      0.78      0.65       980\n",
            "        1.0       0.88      0.33      0.48      1135\n",
            "        2.0       0.54      0.59      0.57      1032\n",
            "        3.0       0.66      0.61      0.63      1010\n",
            "        4.0       0.70      0.79      0.74       982\n",
            "        5.0       0.58      0.17      0.27       892\n",
            "        6.0       0.79      0.39      0.52       958\n",
            "        7.0       0.44      0.86      0.58      1028\n",
            "        8.0       0.49      0.68      0.57       974\n",
            "        9.0       0.62      0.57      0.59      1009\n",
            "\n",
            "avg / total       0.63      0.58      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[760   1  93  18  10  26   8  33   5  26]\n",
            " [  0 378  10  22   0   0   3 361 361   0]\n",
            " [ 53  12 610  59  56   2  36 128  47  29]\n",
            " [ 77   0  97 619   1  70   8  90  34  14]\n",
            " [ 16   8   9   3 774   0   2  90  35  45]\n",
            " [110   6  70 115  70 155  32 126 126  82]\n",
            " [278   4 168   2  76   0 370   3  52   5]\n",
            " [ 16  17   4  12  11   4   0 885   5  74]\n",
            " [ 19   4  63  76  18   6  11  41 661  75]\n",
            " [ 26   2   1  18  90   5   0 260  33 574]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 6. ... 9. 9. 9.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 6 ... 9 9 9]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [ 7  4 10  8  6  6  8 10  9  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.358 s \n",
            "\n",
            "Accuracy rate for 62.020000 \n",
            "Classification report for classifier LogisticRegression(C=0.6666666666666666, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.82      0.79       980\n",
            "        1.0       0.87      0.35      0.50      1135\n",
            "        2.0       0.62      0.65      0.64      1032\n",
            "        3.0       0.64      0.60      0.62      1010\n",
            "        4.0       0.65      0.75      0.70       982\n",
            "        5.0       0.49      0.37      0.42       892\n",
            "        6.0       0.76      0.65      0.70       958\n",
            "        7.0       0.51      0.85      0.64      1028\n",
            "        8.0       0.55      0.63      0.59       974\n",
            "        9.0       0.54      0.55      0.55      1009\n",
            "\n",
            "avg / total       0.64      0.62      0.61     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[802   1  81   7   7  28  19  22   6   7]\n",
            " [  0 395   7 134   0   1  12 386 196   4]\n",
            " [ 34  23 671  27  63   2  41 107  61   3]\n",
            " [ 29   0 110 608   1 148  24  48  20  22]\n",
            " [  5   4  10   6 734  15   2  32  27 147]\n",
            " [ 68   7  49  94  60 332  67  31  72 112]\n",
            " [ 75   2  66   2  92  28 621   0  72   0]\n",
            " [  5  13   7   7   9  26   3 873   5  80]\n",
            " [ 15   6  76  49  15  68  22  22 615  86]\n",
            " [ 19   1   4  14 148  35   2 190  45 551]]\n",
            "--------------------------------\n",
            "val predicted: (59925,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59925, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 9  7 15 11  8  7 11 13 10  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.356 s \n",
            "\n",
            "Accuracy rate for 70.610000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.83      0.86      0.85       980\n",
            "        1.0       0.79      0.94      0.86      1135\n",
            "        2.0       0.65      0.65      0.65      1032\n",
            "        3.0       0.81      0.60      0.69      1010\n",
            "        4.0       0.59      0.78      0.67       982\n",
            "        5.0       0.52      0.52      0.52       892\n",
            "        6.0       0.84      0.65      0.73       958\n",
            "        7.0       0.74      0.84      0.79      1028\n",
            "        8.0       0.68      0.64      0.66       974\n",
            "        9.0       0.63      0.52      0.57      1009\n",
            "\n",
            "avg / total       0.71      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 843    2   22    0   21   34   18   32    4    4]\n",
            " [   0 1072   13   20    0    1    3    6   20    0]\n",
            " [  46   68  669   39   78    1   22   59   49    1]\n",
            " [  21   33   85  611    5  165   16   35   28   11]\n",
            " [   2   16   11    0  770   19    2    9   21  132]\n",
            " [  31   38   36   47   78  460   42   22   85   53]\n",
            " [  37   15  114    1  102   29  623    2   34    1]\n",
            " [   4   38   12    8   16   22    2  863    3   60]\n",
            " [  15   53   60   14   21  107   13   14  624   53]\n",
            " [  16   16    5   13  211   39    1  126   56  526]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 0. ... 7. 9. 7.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 0 ... 7 9 7]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [11  9 16 14 11 10 12 13 17 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.365 s \n",
            "\n",
            "Accuracy rate for 72.740000 \n",
            "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.92      0.86       980\n",
            "        1.0       0.73      0.94      0.82      1135\n",
            "        2.0       0.62      0.62      0.62      1032\n",
            "        3.0       0.76      0.68      0.72      1010\n",
            "        4.0       0.66      0.79      0.72       982\n",
            "        5.0       0.67      0.57      0.61       892\n",
            "        6.0       0.81      0.69      0.75       958\n",
            "        7.0       0.76      0.85      0.80      1028\n",
            "        8.0       0.75      0.61      0.68       974\n",
            "        9.0       0.70      0.55      0.62      1009\n",
            "\n",
            "avg / total       0.73      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 906    1   24    1    6    9   11   18    3    1]\n",
            " [   0 1064   17   39    0    0    5    4    6    0]\n",
            " [  51   89  642   54   74    0   31   40   48    3]\n",
            " [  20   50   71  686    6   79   17   34   30   17]\n",
            " [   5   32   12    2  778   14    7    8   12  112]\n",
            " [  58   53   41   54   37  504   51   30   33   31]\n",
            " [  28   14  116    0   87   36  662    3   12    0]\n",
            " [  12   41   15    6   12    8    3  876   17   38]\n",
            " [  29   78   87   43   13   57   27    9  598   33]\n",
            " [  18   29    6   15  172   42    2  130   37  558]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) [0. 0. 0. ... 7. 9. 9.]\n",
            "probabilities: (59875, 10) \n",
            " [0 0 0 ... 7 9 9]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [15 12 17 16 13 12 14 15 21 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.376 s \n",
            "\n",
            "Accuracy rate for 69.820000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.77      0.94      0.85       980\n",
            "        1.0       0.74      0.95      0.83      1135\n",
            "        2.0       0.59      0.60      0.59      1032\n",
            "        3.0       0.68      0.69      0.69      1010\n",
            "        4.0       0.62      0.82      0.70       982\n",
            "        5.0       0.58      0.53      0.55       892\n",
            "        6.0       0.79      0.68      0.73       958\n",
            "        7.0       0.87      0.75      0.80      1028\n",
            "        8.0       0.63      0.62      0.62       974\n",
            "        9.0       0.76      0.35      0.48      1009\n",
            "\n",
            "avg / total       0.70      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 920    2   15   14    1   16    9    0    3    0]\n",
            " [   0 1083   34    6    0    2    5    3    2    0]\n",
            " [  59   68  621  116   50    1   44   25   48    0]\n",
            " [  10   52   56  698    2  100   17   13   58    4]\n",
            " [  16   34   18    1  806   27   16    8   16   40]\n",
            " [  42   65   50   84   43  477   47    3   64   17]\n",
            " [  30   11  133    0   62   54  655    2   11    0]\n",
            " [  47   54   25    7   32   24    4  768   28   39]\n",
            " [  22   66   94   73   11   56   33   10  600    9]\n",
            " [  43   33   12   21  298   72    2   51  123  354]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59850,) [0. 0. 0. ... 0. 9. 9.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 0 ... 0 9 9]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [19 15 18 17 16 14 18 17 25 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.383 s \n",
            "\n",
            "Accuracy rate for 69.600000 \n",
            "Classification report for classifier LogisticRegression(C=0.2857142857142857, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.93      0.87       980\n",
            "        1.0       0.75      0.95      0.83      1135\n",
            "        2.0       0.57      0.59      0.58      1032\n",
            "        3.0       0.74      0.59      0.66      1010\n",
            "        4.0       0.65      0.84      0.73       982\n",
            "        5.0       0.47      0.55      0.50       892\n",
            "        6.0       0.80      0.64      0.71       958\n",
            "        7.0       0.76      0.84      0.80      1028\n",
            "        8.0       0.65      0.56      0.60       974\n",
            "        9.0       0.83      0.43      0.57      1009\n",
            "\n",
            "avg / total       0.71      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 914    2   11    7    0   34    9    1    2    0]\n",
            " [   0 1076   39    1    0    0    5    4   10    0]\n",
            " [  47   71  611   75   57    3   46   58   60    4]\n",
            " [   7   53   38  597    3  217   22   26   32   15]\n",
            " [  12   33   28    0  823   20    9   25   17   15]\n",
            " [  30   74   38   62   49  490   26   23   79   21]\n",
            " [  29   11  148    0   75   70  611    3   11    0]\n",
            " [  28   33   23    3   19   18    4  862   17   21]\n",
            " [  19   63  116   44   11  126   30   10  542   13]\n",
            " [  32   28   16   15  224   71    4  125   60  434]]\n",
            "--------------------------------\n",
            "val predicted: (59825,) [0. 0. 0. ... 7. 9. 7.]\n",
            "probabilities: (59825, 10) \n",
            " [0 0 0 ... 7 9 7]\n",
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [20 20 22 19 18 16 19 19 27 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.396 s \n",
            "\n",
            "Accuracy rate for 70.810000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.92      0.87       980\n",
            "        1.0       0.74      0.94      0.83      1135\n",
            "        2.0       0.55      0.61      0.58      1032\n",
            "        3.0       0.74      0.64      0.69      1010\n",
            "        4.0       0.70      0.82      0.76       982\n",
            "        5.0       0.52      0.50      0.51       892\n",
            "        6.0       0.75      0.68      0.71       958\n",
            "        7.0       0.76      0.85      0.80      1028\n",
            "        8.0       0.72      0.53      0.61       974\n",
            "        9.0       0.82      0.53      0.64      1009\n",
            "\n",
            "avg / total       0.71      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 898    2   19    7    1   31   18    1    2    1]\n",
            " [   0 1065   49    7    0    0    6    3    5    0]\n",
            " [  47   71  632   62   50    3   53   48   62    4]\n",
            " [   5   43   45  651    4  169   25   22   20   26]\n",
            " [   9   41   30    5  807   11   23   32    8   16]\n",
            " [  30   74   48   85   47  449   43   29   58   29]\n",
            " [  28   12  143    0   48   58  653    4   12    0]\n",
            " [  27   39   22    0   12   16    5  875   13   19]\n",
            " [  17   67  144   55   15   85   40   11  521   19]\n",
            " [  33   30   20   13  171   49    5  132   26  530]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 0. ... 7. 9. 7.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 7 9 7]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [24 26 22 22 20 18 22 21 28 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.409 s \n",
            "\n",
            "Accuracy rate for 70.820000 \n",
            "Classification report for classifier LogisticRegression(C=0.2222222222222222, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.81      0.92      0.86       980\n",
            "        1.0       0.75      0.94      0.83      1135\n",
            "        2.0       0.55      0.60      0.57      1032\n",
            "        3.0       0.71      0.68      0.69      1010\n",
            "        4.0       0.65      0.80      0.72       982\n",
            "        5.0       0.60      0.52      0.56       892\n",
            "        6.0       0.72      0.66      0.69       958\n",
            "        7.0       0.77      0.85      0.81      1028\n",
            "        8.0       0.75      0.57      0.65       974\n",
            "        9.0       0.79      0.50      0.61      1009\n",
            "\n",
            "avg / total       0.71      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 899    2   21    9    1   14   22    2    9    1]\n",
            " [   0 1067   46    8    0    3    5    3    3    0]\n",
            " [  59   91  617   95   42    0   48   44   30    6]\n",
            " [  12   40   42  682    3  112   22   24   36   37]\n",
            " [  11   41   28    5  787   20   39   25    6   20]\n",
            " [  26   47   46   91   56  468   51   23   60   24]\n",
            " [  30    8  153    0   65   52  628    4   18    0]\n",
            " [  26   41   23    0   20   11    5  872    7   23]\n",
            " [  17   62  116   65   15   62   46   14  557   20]\n",
            " [  33   30   26    8  227   34    7  120   19  505]]\n",
            "--------------------------------\n",
            "val predicted: (59775,) [0. 0. 0. ... 7. 9. 7.]\n",
            "probabilities: (59775, 10) \n",
            " [0 0 0 ... 7 9 7]\n",
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [26 28 25 23 24 19 24 24 31 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.403 s \n",
            "\n",
            "Accuracy rate for 69.490000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.89      0.85       980\n",
            "        1.0       0.73      0.94      0.82      1135\n",
            "        2.0       0.53      0.62      0.57      1032\n",
            "        3.0       0.69      0.61      0.65      1010\n",
            "        4.0       0.66      0.79      0.72       982\n",
            "        5.0       0.51      0.51      0.51       892\n",
            "        6.0       0.75      0.66      0.70       958\n",
            "        7.0       0.79      0.84      0.81      1028\n",
            "        8.0       0.73      0.50      0.59       974\n",
            "        9.0       0.78      0.55      0.64      1009\n",
            "\n",
            "avg / total       0.70      0.69      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 868    1   35   10   10   32   19    0    3    2]\n",
            " [   0 1065   53    4    0    3    5    2    3    0]\n",
            " [  55   84  642   75   61    1   44   35   30    5]\n",
            " [  10   44   53  612    6  153   19   24   46   43]\n",
            " [   9   46   23    7  780   37   35   22    6   17]\n",
            " [  18   55   55   97   56  455   35   26   51   44]\n",
            " [  26    7  168    0   58   61  631    2    5    0]\n",
            " [  26   50   24    0   21   18    3  859    8   19]\n",
            " [  15   81  140   71   13   91   42   11  483   27]\n",
            " [  28   27   23   10  174   47    8  109   29  554]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 7. 7. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 7 7 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [29 32 27 25 25 21 25 27 34 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.417 s \n",
            "\n",
            "Accuracy rate for 71.460000 \n",
            "Classification report for classifier LogisticRegression(C=0.18181818181818182, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.94      0.88       980\n",
            "        1.0       0.72      0.94      0.82      1135\n",
            "        2.0       0.58      0.64      0.61      1032\n",
            "        3.0       0.76      0.67      0.71      1010\n",
            "        4.0       0.65      0.78      0.71       982\n",
            "        5.0       0.58      0.51      0.54       892\n",
            "        6.0       0.72      0.67      0.69       958\n",
            "        7.0       0.81      0.82      0.81      1028\n",
            "        8.0       0.71      0.56      0.62       974\n",
            "        9.0       0.80      0.56      0.66      1009\n",
            "\n",
            "avg / total       0.72      0.71      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 923    2   16    4    4   13   17    0    1    0]\n",
            " [   0 1071   47    2    0    4    5    2    4    0]\n",
            " [  47  104  658   39   63    2   45   45   25    4]\n",
            " [  11   44   36  676    7  115   18   18   62   23]\n",
            " [   4   41   27    5  770   29   40   19   13   34]\n",
            " [  34   42   42   90   64  453   49   10   68   40]\n",
            " [  23   10  140    0   75   54  641    1   14    0]\n",
            " [  35   55   29    1   22   12    7  840    5   22]\n",
            " [  17   82  104   60   14   65   57   11  546   18]\n",
            " [  30   29   30   10  159   40   10   97   36  568]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59725,) [0. 0. 0. ... 7. 9. 7.]\n",
            "probabilities: (59725, 10) \n",
            " [0 0 0 ... 7 9 7]\n",
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [30 34 34 26 28 21 28 30 37 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.419 s \n",
            "\n",
            "Accuracy rate for 71.480000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.94      0.86       980\n",
            "        1.0       0.73      0.94      0.82      1135\n",
            "        2.0       0.58      0.62      0.60      1032\n",
            "        3.0       0.73      0.67      0.70      1010\n",
            "        4.0       0.69      0.77      0.73       982\n",
            "        5.0       0.57      0.51      0.54       892\n",
            "        6.0       0.71      0.67      0.69       958\n",
            "        7.0       0.80      0.82      0.81      1028\n",
            "        8.0       0.70      0.59      0.64       974\n",
            "        9.0       0.84      0.57      0.68      1009\n",
            "\n",
            "avg / total       0.72      0.71      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 923    2   18    3    3   11   16    0    4    0]\n",
            " [   0 1070   45    5    0    3    5    4    3    0]\n",
            " [  59   96  643   66   44    3   48   39   30    4]\n",
            " [  11   41   41  672    6  126   19   18   60   16]\n",
            " [  10   43   24    8  760   34   41   29   17   16]\n",
            " [  42   48   39   90   54  452   56   13   60   38]\n",
            " [  23   11  145    0   76   55  640    1    7    0]\n",
            " [  41   51   24    0   23   12    7  838    8   24]\n",
            " [  16   69  101   65   10   56   54   14  573   16]\n",
            " [  31   34   20    7  128   43   14   96   59  577]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 0. ... 0. 7. 7.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 0 ... 0 7 7]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [31 35 40 30 30 24 30 33 38 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.449 s \n",
            "\n",
            "Accuracy rate for 72.040000 \n",
            "Classification report for classifier LogisticRegression(C=0.15384615384615385, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.96      0.87       980\n",
            "        1.0       0.73      0.94      0.82      1135\n",
            "        2.0       0.59      0.62      0.60      1032\n",
            "        3.0       0.72      0.69      0.71      1010\n",
            "        4.0       0.70      0.76      0.73       982\n",
            "        5.0       0.61      0.53      0.57       892\n",
            "        6.0       0.72      0.72      0.72       958\n",
            "        7.0       0.80      0.83      0.82      1028\n",
            "        8.0       0.68      0.57      0.62       974\n",
            "        9.0       0.85      0.55      0.67      1009\n",
            "\n",
            "avg / total       0.72      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    2   13    4    2    8   12    0    2    0]\n",
            " [   0 1066   44   11    0    1    5    4    4    0]\n",
            " [  51   96  638   61   44    2   65   37   36    2]\n",
            " [  10   46   48  697    6   90   12   19   64   18]\n",
            " [  15   47   20    6  746   41   42   26   16   23]\n",
            " [  44   43   31   97   55  471   51   23   53   24]\n",
            " [  29   11  111    0   59   53  688    2    5    0]\n",
            " [  30   48   27    2   19    9   11  855    9   18]\n",
            " [  17   63  135   75   11   47   54   10  551   11]\n",
            " [  35   32   19   12  129   46   15   93   73  555]]\n",
            "--------------------------------\n",
            "val predicted: (59675,) [0. 0. 0. ... 7. 9. 7.]\n",
            "probabilities: (59675, 10) \n",
            " [0 0 0 ... 7 9 7]\n",
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [32 37 42 31 32 25 31 37 44 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.472 s \n",
            "\n",
            "Accuracy rate for 72.110000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.95      0.87       980\n",
            "        1.0       0.73      0.94      0.82      1135\n",
            "        2.0       0.60      0.63      0.61      1032\n",
            "        3.0       0.72      0.68      0.70      1010\n",
            "        4.0       0.69      0.76      0.72       982\n",
            "        5.0       0.61      0.51      0.56       892\n",
            "        6.0       0.71      0.72      0.72       958\n",
            "        7.0       0.80      0.83      0.81      1028\n",
            "        8.0       0.72      0.56      0.63       974\n",
            "        9.0       0.82      0.58      0.68      1009\n",
            "\n",
            "avg / total       0.72      0.72      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 927    2   16    4    2    9   14    0    5    1]\n",
            " [   0 1070   41    7    0    2    6    3    6    0]\n",
            " [  54   91  649   59   34    0   70   36   36    3]\n",
            " [  11   56   52  688    8   91   13   20   58   13]\n",
            " [  15   45   21    6  748   38   42   29   12   26]\n",
            " [  42   42   29   99   64  458   55   21   36   46]\n",
            " [  27   10  112    0   57   52  692    3    5    0]\n",
            " [  29   51   25    1   20    9   11  853   11   18]\n",
            " [  19   75  127   78    9   42   52   11  541   20]\n",
            " [  28   31   11   12  149   46   14   92   41  585]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [37 40 42 32 34 25 32 39 49 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.478 s \n",
            "\n",
            "Accuracy rate for 72.650000 \n",
            "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.95      0.87       980\n",
            "        1.0       0.73      0.95      0.82      1135\n",
            "        2.0       0.62      0.63      0.62      1032\n",
            "        3.0       0.74      0.70      0.72      1010\n",
            "        4.0       0.66      0.77      0.71       982\n",
            "        5.0       0.64      0.51      0.57       892\n",
            "        6.0       0.70      0.70      0.70       958\n",
            "        7.0       0.83      0.82      0.83      1028\n",
            "        8.0       0.73      0.60      0.66       974\n",
            "        9.0       0.81      0.60      0.69      1009\n",
            "\n",
            "avg / total       0.73      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 928    2    9    2    2    9   12    0   15    1]\n",
            " [   0 1073   41    5    0    2    7    3    4    0]\n",
            " [  52   93  648   55   36    2   69   32   41    4]\n",
            " [   9   51   48  705    8   80   15   15   62   17]\n",
            " [  18   43   19    8  756   29   44   23    9   33]\n",
            " [  46   44   31   98   65  456   48   19   52   33]\n",
            " [  42   11  111    0   59   55  669    1   10    0]\n",
            " [  24   51   25    2   21    8   16  845    8   28]\n",
            " [  16   66  111   67   10   28   62    8  583   23]\n",
            " [  27   34   10    9  182   41   15   69   20  602]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) [0. 0. 8. ... 9. 9. 7.]\n",
            "probabilities: (59625, 10) \n",
            " [0 0 8 ... 9 9 7]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [40 43 45 36 36 26 34 41 50 49] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.521 s \n",
            "\n",
            "Accuracy rate for 73.090000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.94      0.87       980\n",
            "        1.0       0.74      0.95      0.83      1135\n",
            "        2.0       0.62      0.63      0.63      1032\n",
            "        3.0       0.73      0.70      0.71      1010\n",
            "        4.0       0.69      0.78      0.73       982\n",
            "        5.0       0.64      0.53      0.58       892\n",
            "        6.0       0.71      0.74      0.73       958\n",
            "        7.0       0.81      0.82      0.82      1028\n",
            "        8.0       0.76      0.58      0.66       974\n",
            "        9.0       0.81      0.58      0.68      1009\n",
            "\n",
            "avg / total       0.73      0.73      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 925    2   19    3    3    6   14    0    8    0]\n",
            " [   0 1075   39    6    0    2    7    3    3    0]\n",
            " [  55   95  651   58   35    1   63   32   38    4]\n",
            " [  12   42   44  706    7   84   14   18   53   30]\n",
            " [  10   43   21    9  763   33   44   27    9   23]\n",
            " [  54   41   27   92   59  476   50   22   40   31]\n",
            " [  25   10   98    2   48   57  710    2    6    0]\n",
            " [  27   53   26    2   19    7   13  847    7   27]\n",
            " [  17   72  105   78   10   32   59    8  569   24]\n",
            " [  30   29   16   15  168   40   20   89   15  587]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [42 47 46 43 38 29 36 42 51 51] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.472 s \n",
            "\n",
            "Accuracy rate for 73.720000 \n",
            "Classification report for classifier LogisticRegression(C=0.11764705882352941, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.96      0.87       980\n",
            "        1.0       0.72      0.95      0.82      1135\n",
            "        2.0       0.65      0.65      0.65      1032\n",
            "        3.0       0.76      0.69      0.72      1010\n",
            "        4.0       0.68      0.77      0.72       982\n",
            "        5.0       0.64      0.56      0.59       892\n",
            "        6.0       0.72      0.75      0.73       958\n",
            "        7.0       0.81      0.83      0.82      1028\n",
            "        8.0       0.78      0.60      0.68       974\n",
            "        9.0       0.84      0.57      0.68      1009\n",
            "\n",
            "avg / total       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    2    8    1    3    9    9    0    6    1]\n",
            " [   0 1080   34    6    0    3    7    2    3    0]\n",
            " [  48  103  669   31   36    4   60   39   38    4]\n",
            " [  17   48   43  696    8   99   17   18   45   19]\n",
            " [  10   45   21    8  761   32   43   31    8   23]\n",
            " [  67   36   25   82   63  498   52   17   30   22]\n",
            " [  30    8   98    2   39   53  716    2   10    0]\n",
            " [  25   56   27    2   21    8   10  851    7   21]\n",
            " [  16   78   86   68   12   35   62    8  588   21]\n",
            " [  25   34   17   22  175   43   19   86   16  572]]\n",
            "--------------------------------\n",
            "val predicted: (59575,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59575, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [44 49 48 49 41 30 39 43 53 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.454 s \n",
            "\n",
            "Accuracy rate for 73.860000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.96      0.87       980\n",
            "        1.0       0.73      0.95      0.83      1135\n",
            "        2.0       0.65      0.64      0.65      1032\n",
            "        3.0       0.77      0.69      0.72      1010\n",
            "        4.0       0.69      0.78      0.73       982\n",
            "        5.0       0.63      0.55      0.58       892\n",
            "        6.0       0.73      0.77      0.75       958\n",
            "        7.0       0.82      0.83      0.83      1028\n",
            "        8.0       0.76      0.64      0.70       974\n",
            "        9.0       0.82      0.54      0.66      1009\n",
            "\n",
            "avg / total       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    2    5    1    3    5   12    0    9    0]\n",
            " [   0 1073   40    9    0    3    7    1    2    0]\n",
            " [  58  103  663   29   36    3   65   29   42    4]\n",
            " [  26   39   42  692    9  101   16   16   49   20]\n",
            " [   7   44   22    7  765   41   41   24   12   19]\n",
            " [  72   28   34   79   60  487   47   16   38   31]\n",
            " [  28    9   91    2   31   52  733    2   10    0]\n",
            " [  17   56   28    3   19    5   10  857    7   26]\n",
            " [  16   74   74   56   10   35   59    8  624   18]\n",
            " [  29   37   17   21  182   42   12   94   26  549]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [47 53 52 50 44 30 40 48 56 55] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.491 s \n",
            "\n",
            "Accuracy rate for 74.690000 \n",
            "Classification report for classifier LogisticRegression(C=0.10526315789473684, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.96      0.87       980\n",
            "        1.0       0.74      0.95      0.83      1135\n",
            "        2.0       0.70      0.68      0.69      1032\n",
            "        3.0       0.81      0.66      0.73      1010\n",
            "        4.0       0.71      0.78      0.74       982\n",
            "        5.0       0.59      0.59      0.59       892\n",
            "        6.0       0.74      0.74      0.74       958\n",
            "        7.0       0.80      0.83      0.82      1028\n",
            "        8.0       0.79      0.61      0.69       974\n",
            "        9.0       0.82      0.62      0.71      1009\n",
            "\n",
            "avg / total       0.75      0.75      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    2    2    0    4   10    9    0   10    0]\n",
            " [   0 1080   35    4    0    5    6    2    3    0]\n",
            " [  48   92  702   16   42    4   61   32   31    4]\n",
            " [  23   46   47  669    8  124   16   19   42   16]\n",
            " [   8   33   16    5  762   56   35   29    8   30]\n",
            " [  68   27   18   63   61  529   43   26   27   30]\n",
            " [  36   12   66    2   37   76  713    6   10    0]\n",
            " [  17   54   27    1   21    6   10  855    8   29]\n",
            " [  19   88   79   49   10   48   59    7  591   24]\n",
            " [  24   33   14   22  125   46   12   93   15  625]]\n",
            "--------------------------------\n",
            "val predicted: (59525,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59525, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [49 56 56 52 47 32 41 53 57 57] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.539 s \n",
            "\n",
            "Accuracy rate for 73.730000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.97      0.86       980\n",
            "        1.0       0.74      0.95      0.83      1135\n",
            "        2.0       0.71      0.63      0.67      1032\n",
            "        3.0       0.75      0.66      0.70      1010\n",
            "        4.0       0.69      0.78      0.73       982\n",
            "        5.0       0.59      0.58      0.58       892\n",
            "        6.0       0.73      0.77      0.75       958\n",
            "        7.0       0.80      0.80      0.80      1028\n",
            "        8.0       0.79      0.62      0.70       974\n",
            "        9.0       0.81      0.57      0.67      1009\n",
            "\n",
            "avg / total       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 946    2    1    1    3   10   11    1    4    1]\n",
            " [   0 1077   33    7    0    5    6    2    5    0]\n",
            " [  65  101  652   33   45    6   63   26   36    5]\n",
            " [  28   41   44  664    8  130   17   21   45   12]\n",
            " [  12   34   12    6  768   47   46   22    9   26]\n",
            " [  70   30   19   73   59  518   47   28   24   24]\n",
            " [  34   12   55    2   34   70  742    3    6    0]\n",
            " [  22   54   30    1   22    5   12  826    7   49]\n",
            " [  18   79   57   75   14   49   57    5  606   14]\n",
            " [  24   34   12   22  158   42   17  101   25  574]]\n",
            "--------------------------------\n",
            "final active learning accuracies [46.63, 57.86, 62.019999999999996, 70.61, 72.74000000000001, 69.82000000000001, 69.6, 70.81, 70.82000000000001, 69.49, 71.46000000000001, 71.48, 72.04, 72.11, 72.65, 73.09, 73.72, 73.86, 74.69, 73.72999999999999]\n",
            "saved Active-learning-experiment-34.pkl /content ['datalab', 'Active-learning-experiment-32.pkl', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-33.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-29.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 35, using model = LogModel, selection_function = RandomSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [2 2 1 0 0 0 0 3 2] [0 1 2 7 8]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.226 s \n",
            "\n",
            "Accuracy rate for 31.610000 \n",
            "Classification report for classifier LogisticRegression(C=5.0, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.45      0.81      0.58       980\n",
            "        1.0       0.47      0.77      0.58      1135\n",
            "        2.0       0.01      0.01      0.01      1032\n",
            "        3.0       0.00      0.00      0.00      1010\n",
            "        4.0       0.00      0.00      0.00       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.00      0.00      0.00       958\n",
            "        7.0       0.37      0.80      0.51      1028\n",
            "        8.0       0.21      0.68      0.32       974\n",
            "        9.0       0.00      0.00      0.00      1009\n",
            "\n",
            "avg / total       0.16      0.32      0.21     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[798  11  10   0   0   0   0   2 159   0]\n",
            " [  8 877   5   0   0   0   0 109 136   0]\n",
            " [215 320   7   0   0   0   0 104 386   0]\n",
            " [ 22  63  15   0   0   0   0  57 853   0]\n",
            " [112  49 281   0   0   0   0 376 164   0]\n",
            " [ 99 202  45   0   0   0   0  67 479   0]\n",
            " [414 226  12   0   0   0   0  61 245   0]\n",
            " [ 16  33 139   0   0   0   0 821  19   0]\n",
            " [ 34  92  32   0   0   0   0 158 658   0]\n",
            " [ 48   2 439   0   0   0   0 457  63   0]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59990,) [0. 0. 8. ... 7. 7. 7.]\n",
            "probabilities: (59990, 5) \n",
            " [0 0 4 ... 3 3 3]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [3 3 2 2 2 0 2 4 2] [0 1 2 3 4 6 7 8]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.316 s \n",
            "\n",
            "Accuracy rate for 50.360000 \n",
            "Classification report for classifier LogisticRegression(C=2.5, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.65      0.80      0.72       980\n",
            "        1.0       0.68      0.96      0.80      1135\n",
            "        2.0       0.33      0.25      0.28      1032\n",
            "        3.0       0.48      0.54      0.51      1010\n",
            "        4.0       0.46      0.54      0.50       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.43      0.58      0.50       958\n",
            "        7.0       0.46      0.85      0.60      1028\n",
            "        8.0       0.42      0.40      0.41       974\n",
            "        9.0       0.00      0.00      0.00      1009\n",
            "\n",
            "avg / total       0.40      0.50      0.44     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 782    1   43   40    0    0   60    2   52    0]\n",
            " [   0 1092    3    2    2    0   29    6    1    0]\n",
            " [ 134  228  256  178   36    0   77   77   46    0]\n",
            " [  34   15   49  547   15    0   55   62  233    0]\n",
            " [  46   40   52    6  534    0   90  206    8    0]\n",
            " [  54   89   16  205   50    0  215   67  196    0]\n",
            " [  96   39  239    7   15    0  560    2    0    0]\n",
            " [  11   36   26    3   67    0    3  874    8    0]\n",
            " [  14   46    3  134   70    0  195  121  391    0]\n",
            " [  34   18   87   20  372    0    7  465    6    0]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59980,) [0. 0. 6. ... 7. 7. 7.]\n",
            "probabilities: (59980, 8) \n",
            " [0 0 5 ... 6 6 6]\n",
            "trainset before (20, 784) (20,)\n",
            "trainset after (30, 784) (30,)\n",
            "updated train set: (30, 784) (30,) unique(labels): [4 4 5 2 2 0 4 4 4 1] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59970, 784) (59970,)\n",
            "\n",
            "Train set: (30, 784) y: (30,)\n",
            "Val   set: (59970, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.325 s \n",
            "\n",
            "Accuracy rate for 53.100000 \n",
            "Classification report for classifier LogisticRegression(C=1.6666666666666667, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.70      0.76      0.73       980\n",
            "        1.0       0.69      0.97      0.81      1135\n",
            "        2.0       0.48      0.46      0.47      1032\n",
            "        3.0       0.56      0.44      0.49      1010\n",
            "        4.0       0.49      0.41      0.44       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.50      0.60      0.55       958\n",
            "        7.0       0.64      0.76      0.69      1028\n",
            "        8.0       0.32      0.71      0.44       974\n",
            "        9.0       0.50      0.10      0.17      1009\n",
            "\n",
            "avg / total       0.50      0.53      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 741    1   52   18    0    0   76    2   90    0]\n",
            " [   0 1101    2    1    0    0   14    1   16    0]\n",
            " [  58  205  476   95    9    0   35   21  133    0]\n",
            " [   8   39   73  444    4    0   37   18  387    0]\n",
            " [  45   28   60    5  401    0   90   92  175   86]\n",
            " [  14   55   40  144   15    0  211   45  355   13]\n",
            " [ 149   32  183    3    6    0  578    0    7    0]\n",
            " [  14   36   15    3   86    0    2  779   91    2]\n",
            " [   5   82   21   63    6    0   88   20  689    0]\n",
            " [  26   12   69   15  294    0   14  245  233  101]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59970,) [0. 0. 6. ... 7. 7. 7.]\n",
            "probabilities: (59970, 9) \n",
            " [0 0 5 ... 6 6 6]\n",
            "trainset before (30, 784) (30,)\n",
            "trainset after (40, 784) (40,)\n",
            "updated train set: (40, 784) (40,) unique(labels): [5 4 7 3 3 0 5 6 5 2] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59960, 784) (59960,)\n",
            "\n",
            "Train set: (40, 784) y: (40,)\n",
            "Val   set: (59960, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.329 s \n",
            "\n",
            "Accuracy rate for 59.740000 \n",
            "Classification report for classifier LogisticRegression(C=1.25, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.84      0.79       980\n",
            "        1.0       0.67      0.97      0.79      1135\n",
            "        2.0       0.61      0.51      0.55      1032\n",
            "        3.0       0.57      0.61      0.59      1010\n",
            "        4.0       0.56      0.64      0.60       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.60      0.71      0.65       958\n",
            "        7.0       0.76      0.80      0.78      1028\n",
            "        8.0       0.38      0.61      0.47       974\n",
            "        9.0       0.41      0.19      0.26      1009\n",
            "\n",
            "avg / total       0.54      0.60      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 824    1   30   15    1    0   48    2   57    2]\n",
            " [   0 1102    3    5    0    0   14    0   11    0]\n",
            " [  38  223  523   44   29    0   59   15   98    3]\n",
            " [  10   23   85  613    7    0   14   21  237    0]\n",
            " [  19   18   16   11  632    0   86    6   36  158]\n",
            " [  38   88   46  208   24    0  105   33  300   50]\n",
            " [ 119   30   72    6   51    0  677    0    2    1]\n",
            " [  11   48   17    8   28    0   11  823   44   38]\n",
            " [   6   86   21  132   12    0   92   19  593   13]\n",
            " [  28   21   40   33  343    0   15  163  179  187]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59960,) [0. 0. 6. ... 7. 9. 9.]\n",
            "probabilities: (59960, 9) \n",
            " [0 0 5 ... 6 8 8]\n",
            "trainset before (40, 784) (40,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [7 5 8 5 4 0 5 8 5 3] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.326 s \n",
            "\n",
            "Accuracy rate for 62.700000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.90      0.83       980\n",
            "        1.0       0.71      0.99      0.82      1135\n",
            "        2.0       0.72      0.51      0.60      1032\n",
            "        3.0       0.60      0.73      0.66      1010\n",
            "        4.0       0.52      0.66      0.58       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.62      0.68      0.64       958\n",
            "        7.0       0.72      0.82      0.77      1028\n",
            "        8.0       0.44      0.57      0.50       974\n",
            "        9.0       0.50      0.30      0.38      1009\n",
            "\n",
            "avg / total       0.57      0.63      0.59     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 878    1   12   15    2    0   47    7   13    5]\n",
            " [   0 1119    2    6    0    0    6    1    1    0]\n",
            " [  46  160  531   73   40    0   61   26   83   12]\n",
            " [   7   14   54  736    2    0   11   51  135    0]\n",
            " [  10   27    5    8  647    0   69    3   53  160]\n",
            " [  64   84   28  232   27    0  104   73  190   90]\n",
            " [  97   16   27    3  166    0  649    0    0    0]\n",
            " [   1   45   31   10   33    0    2  845   44   17]\n",
            " [   8  102   24  116   18    0   95   30  558   23]\n",
            " [  12   16   19   21  298    0   11  135  190  307]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59950,) [0. 0. 6. ... 7. 9. 9.]\n",
            "probabilities: (59950, 9) \n",
            " [0 0 5 ... 6 8 8]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (60, 784) (60,)\n",
            "updated train set: (60, 784) (60,) unique(labels): [8 9 8 5 4 0 5 9 6 6] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59940, 784) (59940,)\n",
            "\n",
            "Train set: (60, 784) y: (60,)\n",
            "Val   set: (59940, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.326 s \n",
            "\n",
            "Accuracy rate for 64.040000 \n",
            "Classification report for classifier LogisticRegression(C=0.8333333333333334, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.89      0.82       980\n",
            "        1.0       0.63      0.99      0.77      1135\n",
            "        2.0       0.63      0.45      0.53      1032\n",
            "        3.0       0.59      0.75      0.66      1010\n",
            "        4.0       0.59      0.71      0.65       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.60      0.69      0.64       958\n",
            "        7.0       0.80      0.81      0.80      1028\n",
            "        8.0       0.54      0.49      0.52       974\n",
            "        9.0       0.63      0.51      0.56      1009\n",
            "\n",
            "avg / total       0.58      0.64      0.60     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 873    1   22   21    1    0   43    4   15    0]\n",
            " [   0 1119    1    7    0    0    7    1    0    0]\n",
            " [  59  223  469  124   23    0   49   18   46   21]\n",
            " [  15   34   61  761    2    0   13   34   80   10]\n",
            " [  11   54   12    4  696    0   71    1   20  113]\n",
            " [  66   55   43  241   32    0  136   55  169   95]\n",
            " [  98   27   49    1  126    0  657    0    0    0]\n",
            " [   5   73   22    7   37    0    3  834   14   33]\n",
            " [  19  161   38  109   13    0  111   18  482   23]\n",
            " [  16   30   33   21  241    0   12   80   63  513]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59940,) [0. 0. 6. ... 9. 9. 9.]\n",
            "probabilities: (59940, 9) \n",
            " [0 0 5 ... 8 8 8]\n",
            "trainset before (60, 784) (60,)\n",
            "trainset after (70, 784) (70,)\n",
            "updated train set: (70, 784) (70,) unique(labels): [ 9 10  8  6  4  0  5 11  9  8] [0 1 2 3 4 6 7 8 9]\n",
            "val set: (59930, 784) (59930,)\n",
            "\n",
            "Train set: (70, 784) y: (70,)\n",
            "Val   set: (59930, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.336 s \n",
            "\n",
            "Accuracy rate for 64.250000 \n",
            "Classification report for classifier LogisticRegression(C=0.7142857142857143, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.72      0.92      0.81       980\n",
            "        1.0       0.64      0.99      0.77      1135\n",
            "        2.0       0.65      0.57      0.61      1032\n",
            "        3.0       0.66      0.74      0.69      1010\n",
            "        4.0       0.60      0.62      0.61       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.69      0.69      0.69       958\n",
            "        7.0       0.78      0.78      0.78      1028\n",
            "        8.0       0.49      0.53      0.51       974\n",
            "        9.0       0.55      0.48      0.51      1009\n",
            "\n",
            "avg / total       0.58      0.64      0.61     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 897    1   14   29    1    0   20    6   12    0]\n",
            " [   0 1122    2    3    0    0    6    0    2    0]\n",
            " [  57  215  591   15   21    0   58   17   29   29]\n",
            " [  22   44   85  745    3    0   13   28   64    6]\n",
            " [  10   47    6    2  611    0   31    4   70  201]\n",
            " [ 137   59   33  242   33    0   75   76  153   84]\n",
            " [  84   19   45    0  147    0  659    2    1    1]\n",
            " [   4   72   49   10   30    0    3  803   16   41]\n",
            " [  19  159   60   66   14    0   81   21  515   39]\n",
            " [  18   27   29   25  162    0    3   79  184  482]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59930,) [0. 0. 6. ... 7. 9. 9.]\n",
            "probabilities: (59930, 9) \n",
            " [0 0 5 ... 6 8 8]\n",
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [ 9 12  8  6  6  1  5 12 12  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.358 s \n",
            "\n",
            "Accuracy rate for 61.630000 \n",
            "Classification report for classifier LogisticRegression(C=0.625, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.68      0.87      0.76       980\n",
            "        1.0       0.63      0.99      0.77      1135\n",
            "        2.0       0.69      0.45      0.55      1032\n",
            "        3.0       0.60      0.63      0.62      1010\n",
            "        4.0       0.56      0.58      0.57       982\n",
            "        5.0       0.54      0.02      0.03       892\n",
            "        6.0       0.65      0.70      0.68       958\n",
            "        7.0       0.80      0.77      0.79      1028\n",
            "        8.0       0.41      0.60      0.49       974\n",
            "        9.0       0.59      0.46      0.52      1009\n",
            "\n",
            "avg / total       0.62      0.62      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 849    1   18   46    1    3   40    4   14    4]\n",
            " [   0 1119    2    7    0    0    6    1    0    0]\n",
            " [  87  232  469   36   16    4   83   12   68   25]\n",
            " [  32   37   67  632    5    1   18   25  189    4]\n",
            " [  13   55    7    1  569    3   65    2   71  196]\n",
            " [ 116   45   21  190   60   14   63   61  273   49]\n",
            " [ 107   26   41    2  103    1  672    0    4    2]\n",
            " [   9   82   35   10   48    0    2  790   26   26]\n",
            " [  15  132   12  100   22    0   75   16  580   22]\n",
            " [  23   36   10   21  191    0    7   73  179  469]]\n",
            "--------------------------------\n",
            "val predicted: (59920,) [0. 0. 6. ... 7. 9. 9.]\n",
            "probabilities: (59920, 10) \n",
            " [0 0 6 ... 7 9 9]\n",
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [10 14  9  9  8  1  5 12 12 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.362 s \n",
            "\n",
            "Accuracy rate for 66.470000 \n",
            "Classification report for classifier LogisticRegression(C=0.5555555555555556, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.92      0.83       980\n",
            "        1.0       0.71      0.98      0.82      1135\n",
            "        2.0       0.67      0.55      0.60      1032\n",
            "        3.0       0.60      0.75      0.67      1010\n",
            "        4.0       0.59      0.70      0.64       982\n",
            "        5.0       0.68      0.03      0.06       892\n",
            "        6.0       0.73      0.74      0.73       958\n",
            "        7.0       0.79      0.80      0.80      1028\n",
            "        8.0       0.48      0.57      0.52       974\n",
            "        9.0       0.69      0.50      0.58      1009\n",
            "\n",
            "avg / total       0.67      0.66      0.63     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 899    1   10   18    0    3   21    8   18    2]\n",
            " [   0 1115    1   12    0    0    6    1    0    0]\n",
            " [  60  176  570   59   18    3   57   17   67    5]\n",
            " [  21   16   47  757   10    1   10   32  115    1]\n",
            " [  19   32   32    5  684    4   54    7   22  123]\n",
            " [  98   40   34  220  114   27   35   48  239   37]\n",
            " [  60   23   76    0   75    1  707    1    3   12]\n",
            " [  12   66   39   15   27    0    2  827   15   25]\n",
            " [  15   85   12  148   44    0   72   24  558   16]\n",
            " [  15   27   36   31  191    1    5   79  121  503]]\n",
            "--------------------------------\n",
            "val predicted: (59910,) [0. 0. 6. ... 7. 9. 9.]\n",
            "probabilities: (59910, 10) \n",
            " [0 0 6 ... 7 9 9]\n",
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [12 15 10 11  9  1  6 13 13 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.341 s \n",
            "\n",
            "Accuracy rate for 68.000000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.64      0.92      0.76       980\n",
            "        1.0       0.71      0.95      0.81      1135\n",
            "        2.0       0.65      0.52      0.58      1032\n",
            "        3.0       0.64      0.77      0.70      1010\n",
            "        4.0       0.70      0.81      0.75       982\n",
            "        5.0       0.64      0.04      0.07       892\n",
            "        6.0       0.70      0.62      0.65       958\n",
            "        7.0       0.85      0.73      0.79      1028\n",
            "        8.0       0.58      0.66      0.62       974\n",
            "        9.0       0.69      0.68      0.68      1009\n",
            "\n",
            "avg / total       0.68      0.68      0.65     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 904    1    2    9    0    9   39    5   11    0]\n",
            " [   0 1079    3   36    0    0    6    1   10    0]\n",
            " [  71  194  538   15   21    7   41    8  123   14]\n",
            " [  33    8   33  779    3    1   16   14  110   13]\n",
            " [  28   23   13    4  791    1   46    1   14   61]\n",
            " [ 199   26   21  257   44   35   60   43  134   73]\n",
            " [ 119   21  103    0  108    1  591    0   12    3]\n",
            " [  13   73   52    7   20    0    1  754    9   99]\n",
            " [  24   78   26   82   16    0   47   14  647   40]\n",
            " [  20   15   39   26  121    1    3   52   50  682]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 6. ... 7. 9. 9.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 6 ... 7 9 9]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [13 15 11 14 10  3  6 14 14 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.367 s \n",
            "\n",
            "Accuracy rate for 65.760000 \n",
            "Classification report for classifier LogisticRegression(C=0.45454545454545453, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.67      0.89      0.77       980\n",
            "        1.0       0.71      0.98      0.82      1135\n",
            "        2.0       0.73      0.51      0.60      1032\n",
            "        3.0       0.53      0.72      0.61      1010\n",
            "        4.0       0.62      0.72      0.66       982\n",
            "        5.0       0.60      0.21      0.31       892\n",
            "        6.0       0.76      0.64      0.70       958\n",
            "        7.0       0.83      0.78      0.80      1028\n",
            "        8.0       0.49      0.51      0.50       974\n",
            "        9.0       0.68      0.52      0.59      1009\n",
            "\n",
            "avg / total       0.66      0.66      0.64     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 875    1    6   10    0   12   23    8   32   13]\n",
            " [   0 1108    2   18    0    0    4    1    2    0]\n",
            " [ 109  156  531   33   15   23   37   13  112    3]\n",
            " [  69    9   24  731    8    5   11   17  132    4]\n",
            " [  15   35   20    8  707   30   33    6   13  115]\n",
            " [  90   23   18  278   52  184   36   22  129   60]\n",
            " [  92   25   58    0  158    1  613    1    4    6]\n",
            " [   9   71   29   23   24   24    3  800   20   25]\n",
            " [  29  111   10  193   35    8   41   20  500   27]\n",
            " [  12   28   33   82  147   18    3   81   78  527]]\n",
            "--------------------------------\n",
            "val predicted: (59890,) [0. 0. 0. ... 7. 9. 7.]\n",
            "probabilities: (59890, 10) \n",
            " [0 0 0 ... 7 9 7]\n",
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [13 19 11 15 12  4  7 14 15 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.372 s \n",
            "\n",
            "Accuracy rate for 65.000000 \n",
            "Classification report for classifier LogisticRegression(C=0.4166666666666667, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.69      0.85      0.76       980\n",
            "        1.0       0.71      0.97      0.82      1135\n",
            "        2.0       0.74      0.48      0.58      1032\n",
            "        3.0       0.55      0.69      0.61      1010\n",
            "        4.0       0.60      0.74      0.67       982\n",
            "        5.0       0.63      0.20      0.30       892\n",
            "        6.0       0.62      0.61      0.62       958\n",
            "        7.0       0.82      0.77      0.80      1028\n",
            "        8.0       0.48      0.56      0.52       974\n",
            "        9.0       0.71      0.54      0.61      1009\n",
            "\n",
            "avg / total       0.66      0.65      0.63     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 831    1    6   16    1   11   59    6   39   10]\n",
            " [   0 1102    2   23    0    0    6    1    1    0]\n",
            " [  99  164  497   31   18   17   66   11  124    5]\n",
            " [  63    7   24  698    9    6   13   25  160    5]\n",
            " [  23   37   18    7  729   26   37    6   14   85]\n",
            " [  60   20   12  257   45  177   91   29  145   56]\n",
            " [  85   26   52    0  183    1  587    1   18    5]\n",
            " [  10   76   34   16   29   24    2  795   15   27]\n",
            " [  21   88    7  155   25    7   77   22  544   28]\n",
            " [  10   31   24   64  171   14    9   73   73  540]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59880,) [0. 0. 6. ... 7. 7. 7.]\n",
            "probabilities: (59880, 10) \n",
            " [0 0 6 ... 7 7 7]\n",
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [13 20 12 18 13  4  8 17 15 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.377 s \n",
            "\n",
            "Accuracy rate for 65.270000 \n",
            "Classification report for classifier LogisticRegression(C=0.38461538461538464, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.86      0.79       980\n",
            "        1.0       0.70      0.97      0.81      1135\n",
            "        2.0       0.73      0.53      0.61      1032\n",
            "        3.0       0.53      0.72      0.61      1010\n",
            "        4.0       0.60      0.73      0.66       982\n",
            "        5.0       0.63      0.21      0.31       892\n",
            "        6.0       0.64      0.62      0.63       958\n",
            "        7.0       0.83      0.78      0.80      1028\n",
            "        8.0       0.49      0.55      0.52       974\n",
            "        9.0       0.69      0.48      0.56      1009\n",
            "\n",
            "avg / total       0.66      0.65      0.64     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 841    1    9    6    0   18   47   11   37   10]\n",
            " [   0 1101    2   25    0    0    4    1    2    0]\n",
            " [  95  152  542   15   20   24   64   11  106    3]\n",
            " [  38   10   20  724    7    6   13   21  168    3]\n",
            " [  26   40   16   14  718   26   37   10   11   84]\n",
            " [  45   26    9  289   49  186   72   18  145   53]\n",
            " [  72   22   71    2  179    1  598    2    5    6]\n",
            " [   7   74   43   18   27   14    2  799   14   30]\n",
            " [  13  104    9  157   18    8   84   14  536   31]\n",
            " [  17   38   26  106  174   14    7   80   65  482]]\n",
            "--------------------------------\n",
            "val predicted: (59870,) [0. 0. 6. ... 7. 7. 7.]\n",
            "probabilities: (59870, 10) \n",
            " [0 0 6 ... 7 7 7]\n",
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [13 21 15 19 14  4  9 18 15 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.363 s \n",
            "\n",
            "Accuracy rate for 66.460000 \n",
            "Classification report for classifier LogisticRegression(C=0.35714285714285715, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.74      0.87      0.80       980\n",
            "        1.0       0.69      0.97      0.81      1135\n",
            "        2.0       0.69      0.53      0.60      1032\n",
            "        3.0       0.52      0.75      0.62      1010\n",
            "        4.0       0.68      0.74      0.71       982\n",
            "        5.0       0.69      0.18      0.29       892\n",
            "        6.0       0.67      0.72      0.69       958\n",
            "        7.0       0.82      0.75      0.78      1028\n",
            "        8.0       0.50      0.49      0.50       974\n",
            "        9.0       0.71      0.55      0.62      1009\n",
            "\n",
            "avg / total       0.67      0.66      0.65     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 852    1    9    4    0   11   47   15   30   11]\n",
            " [   0 1106    2   20    0    0    5    1    1    0]\n",
            " [  83  161  544   19   17   15   82   12   94    5]\n",
            " [  33   10   35  756    5    4   10   19  133    5]\n",
            " [  28   43   17   16  724   18   41    5   14   76]\n",
            " [  48   26   17  304   48  165   61   25  133   65]\n",
            " [  61   26   65    2  109    1  691    0    2    1]\n",
            " [   9   83   52   20   26   12    4  773    5   44]\n",
            " [   9  107   22  209   17    7   86   18  476   23]\n",
            " [  24   41   23   92  115    6    9   80   60  559]]\n",
            "--------------------------------\n",
            "val predicted: (59860,) [0. 0. 6. ... 7. 7. 7.]\n",
            "probabilities: (59860, 10) \n",
            " [0 0 6 ... 7 7 7]\n",
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [13 21 18 22 15  5  9 18 15 14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.384 s \n",
            "\n",
            "Accuracy rate for 66.990000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.83      0.77       980\n",
            "        1.0       0.72      0.97      0.83      1135\n",
            "        2.0       0.72      0.52      0.61      1032\n",
            "        3.0       0.57      0.79      0.66      1010\n",
            "        4.0       0.66      0.75      0.70       982\n",
            "        5.0       0.68      0.27      0.39       892\n",
            "        6.0       0.64      0.72      0.68       958\n",
            "        7.0       0.84      0.76      0.80      1028\n",
            "        8.0       0.52      0.49      0.51       974\n",
            "        9.0       0.65      0.51      0.57      1009\n",
            "\n",
            "avg / total       0.67      0.67      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 818    1    6    3    0   20   48   12   43   29]\n",
            " [   0 1105    5   18    0    0    5    1    1    0]\n",
            " [ 124  135  540   36   25   13   98   11   46    4]\n",
            " [  23   10   37  799    6    9    8   17   97    4]\n",
            " [  36   37    2   16  734   23   46    4   11   73]\n",
            " [  25   27   24  268   34  241   52   17  135   69]\n",
            " [  80   24   15    1  116    5  690    0    3   24]\n",
            " [   9   72   66   22   28    5    4  779    7   36]\n",
            " [  11   95   45  150   13   21  107   14  479   39]\n",
            " [  25   34    9   81  153   15   13   73   92  514]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 6. ... 7. 7. 7.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 6 ... 7 7 7]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [13 22 21 24 16  5  9 18 16 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.400 s \n",
            "\n",
            "Accuracy rate for 66.860000 \n",
            "Classification report for classifier LogisticRegression(C=0.3125, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.74      0.87      0.80       980\n",
            "        1.0       0.73      0.98      0.83      1135\n",
            "        2.0       0.74      0.54      0.62      1032\n",
            "        3.0       0.56      0.77      0.65      1010\n",
            "        4.0       0.61      0.77      0.68       982\n",
            "        5.0       0.68      0.30      0.41       892\n",
            "        6.0       0.64      0.65      0.65       958\n",
            "        7.0       0.85      0.76      0.80      1028\n",
            "        8.0       0.50      0.46      0.48       974\n",
            "        9.0       0.67      0.51      0.58      1009\n",
            "\n",
            "avg / total       0.67      0.67      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 853    2    7    0    2   19   48    5   20   24]\n",
            " [   0 1109    4   15    0    0    4    1    2    0]\n",
            " [ 113  115  556   20   34   10   94   12   75    3]\n",
            " [  28    9   31  775    4    6   11   24  119    3]\n",
            " [  29   37    1   16  760   27   41    3   14   54]\n",
            " [  30   25   17  268   37  266   46   19  105   79]\n",
            " [  66   28   15    2  203    5  625    0    6    8]\n",
            " [  10   63   71   19   28   11    4  783    6   33]\n",
            " [  10   99   39  194   10   28   88   13  446   47]\n",
            " [  21   41   14   67  166   20   12   64   91  513]]\n",
            "--------------------------------\n",
            "val predicted: (59840,) [0. 0. 6. ... 7. 7. 7.]\n",
            "probabilities: (59840, 10) \n",
            " [0 0 6 ... 7 7 7]\n",
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [15 23 22 25 18  5 10 18 17 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.393 s \n",
            "\n",
            "Accuracy rate for 67.280000 \n",
            "Classification report for classifier LogisticRegression(C=0.29411764705882354, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.72      0.89      0.80       980\n",
            "        1.0       0.72      0.97      0.82      1135\n",
            "        2.0       0.77      0.58      0.66      1032\n",
            "        3.0       0.56      0.78      0.65      1010\n",
            "        4.0       0.57      0.81      0.67       982\n",
            "        5.0       0.75      0.28      0.41       892\n",
            "        6.0       0.68      0.61      0.64       958\n",
            "        7.0       0.84      0.77      0.80      1028\n",
            "        8.0       0.54      0.49      0.52       974\n",
            "        9.0       0.74      0.46      0.57      1009\n",
            "\n",
            "avg / total       0.69      0.67      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 871    2   21    1    6   13   34    9   13   10]\n",
            " [   0 1102    3   21    0    0    7    1    1    0]\n",
            " [ 127  120  603   33   34   12   58   10   33    2]\n",
            " [  29   13   33  785    5    6    9   23  101    6]\n",
            " [  29   42    3   14  796   18   31    2   15   32]\n",
            " [  38   30   16  278   49  248   40   21  115   57]\n",
            " [  47   19   25    5  262    6  587    0    4    3]\n",
            " [  16   84   46   15   27    1    3  793   17   26]\n",
            " [  23   93   21  188   24   15   88   13  480   29]\n",
            " [  29   36   15   67  201   11    6   72  109  463]]\n",
            "--------------------------------\n",
            "val predicted: (59830,) [0. 0. 0. ... 7. 0. 7.]\n",
            "probabilities: (59830, 10) \n",
            " [0 0 0 ... 7 0 7]\n",
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [16 26 23 25 19  5 12 18 17 19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.406 s \n",
            "\n",
            "Accuracy rate for 66.720000 \n",
            "Classification report for classifier LogisticRegression(C=0.2777777777777778, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.83      0.76       980\n",
            "        1.0       0.71      0.99      0.82      1135\n",
            "        2.0       0.78      0.54      0.64      1032\n",
            "        3.0       0.55      0.75      0.63      1010\n",
            "        4.0       0.58      0.82      0.68       982\n",
            "        5.0       0.77      0.31      0.45       892\n",
            "        6.0       0.66      0.70      0.68       958\n",
            "        7.0       0.82      0.77      0.79      1028\n",
            "        8.0       0.52      0.46      0.49       974\n",
            "        9.0       0.78      0.42      0.54      1009\n",
            "\n",
            "avg / total       0.69      0.67      0.65     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 813    2   18   10    9   10   66   16   28    8]\n",
            " [   0 1120    3    4    0    0    6    1    1    0]\n",
            " [ 127  122  561   32   25   11   88   15   44    7]\n",
            " [  27   20   45  762    6    7    8   28  103    4]\n",
            " [  30   40    2   17  808   20   38    4   11   12]\n",
            " [  32   32   12  267   58  280   34   23  135   19]\n",
            " [  55   17   13    2  192    3  668    0    8    0]\n",
            " [  13   86   45   17   31    4    3  788   10   31]\n",
            " [  12  107   20  209   15   21   88   14  451   37]\n",
            " [  37   41    4   73  258   10   13   77   75  421]]\n",
            "--------------------------------\n",
            "val predicted: (59820,) [0. 0. 6. ... 7. 0. 7.]\n",
            "probabilities: (59820, 10) \n",
            " [0 0 6 ... 7 0 7]\n",
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [16 26 24 25 20  5 14 21 18 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.399 s \n",
            "\n",
            "Accuracy rate for 67.100000 \n",
            "Classification report for classifier LogisticRegression(C=0.2631578947368421, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.74      0.87      0.80       980\n",
            "        1.0       0.71      0.99      0.82      1135\n",
            "        2.0       0.80      0.56      0.66      1032\n",
            "        3.0       0.55      0.79      0.65      1010\n",
            "        4.0       0.58      0.81      0.68       982\n",
            "        5.0       0.68      0.28      0.39       892\n",
            "        6.0       0.66      0.74      0.70       958\n",
            "        7.0       0.81      0.78      0.80      1028\n",
            "        8.0       0.54      0.47      0.50       974\n",
            "        9.0       0.79      0.35      0.49      1009\n",
            "\n",
            "avg / total       0.69      0.67      0.65     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 850    2   17    4    6   18   44   12   20    7]\n",
            " [   0 1122    2    3    0    0    6    1    1    0]\n",
            " [ 114  123  575   28   23   12  102   17   32    6]\n",
            " [  30   12   29  800    6    7    8   23   90    5]\n",
            " [  24   40    2   16  795   27   41   14    9   14]\n",
            " [  29   33    7  290   60  248   36   16  153   20]\n",
            " [  45   23   11    1  155    9  708    1    5    0]\n",
            " [  12   80   49   15   27    2    6  800   11   26]\n",
            " [  15  115   15  183   23   25  116   12  454   16]\n",
            " [  33   41   16  104  277   16    7   88   69  358]]\n",
            "--------------------------------\n",
            "val predicted: (59810,) [0. 0. 6. ... 7. 7. 7.]\n",
            "probabilities: (59810, 10) \n",
            " [0 0 6 ... 7 7 7]\n",
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [18 28 24 27 20  6 15 22 18 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.408 s \n",
            "\n",
            "Accuracy rate for 68.330000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.88      0.80       980\n",
            "        1.0       0.70      0.99      0.82      1135\n",
            "        2.0       0.79      0.54      0.64      1032\n",
            "        3.0       0.59      0.72      0.65      1010\n",
            "        4.0       0.58      0.81      0.67       982\n",
            "        5.0       0.78      0.40      0.53       892\n",
            "        6.0       0.67      0.79      0.73       958\n",
            "        7.0       0.83      0.77      0.80      1028\n",
            "        8.0       0.53      0.45      0.49       974\n",
            "        9.0       0.81      0.41      0.55      1009\n",
            "\n",
            "avg / total       0.70      0.68      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 866    2   16    1    7   17   48   12    8    3]\n",
            " [   0 1121    2    4    0    0    6    1    1    0]\n",
            " [ 115  129  559   24   30    6   98   17   46    8]\n",
            " [  43   16   22  726    8   19   18   26  123    9]\n",
            " [  26   40    4   25  793   12   40    7   12   23]\n",
            " [  33   43    8  189   92  358   39   18  110    2]\n",
            " [  36   15   19    2  118    6  757    0    4    1]\n",
            " [  14   79   45   13   25    3    3  796   17   33]\n",
            " [  28  125   18  172   32   20  106   11  440   22]\n",
            " [  33   36   12   78  266   17   10   72   68  417]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 0. ... 7. 7. 7.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 7 7 7]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [18 29 25 28 22  6 17 23 18 24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.408 s \n",
            "\n",
            "Accuracy rate for 69.250000 \n",
            "Classification report for classifier LogisticRegression(C=0.23809523809523808, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.89      0.81       980\n",
            "        1.0       0.70      0.99      0.82      1135\n",
            "        2.0       0.79      0.57      0.66      1032\n",
            "        3.0       0.60      0.76      0.67      1010\n",
            "        4.0       0.59      0.84      0.69       982\n",
            "        5.0       0.82      0.40      0.54       892\n",
            "        6.0       0.66      0.80      0.72       958\n",
            "        7.0       0.81      0.77      0.79      1028\n",
            "        8.0       0.60      0.47      0.53       974\n",
            "        9.0       0.79      0.38      0.51      1009\n",
            "\n",
            "avg / total       0.71      0.69      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 871    2   17    0    8    8   47   12    6    9]\n",
            " [   0 1120    2    5    0    0    6    1    1    0]\n",
            " [ 103  124  590   23   33    5   89   18   39    8]\n",
            " [  36   17   36  772    5   12   20   24   81    7]\n",
            " [  19   40    1   26  821   11   38    2    9   15]\n",
            " [  40   50   13  200   64  361   47   20   92    5]\n",
            " [  23   16   15    2  127    7  762    0    6    0]\n",
            " [  14   82   44   13   31    1    4  788   13   38]\n",
            " [  23  123   18  150   17   18  131   18  455   21]\n",
            " [  38   36    8   92  286   16    9   85   54  385]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59790,) [0. 0. 0. ... 7. 0. 9.]\n",
            "probabilities: (59790, 10) \n",
            " [0 0 0 ... 7 0 9]\n",
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [19 29 28 30 23  6 18 23 18 26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.386 s \n",
            "\n",
            "Accuracy rate for 69.700000 \n",
            "Classification report for classifier LogisticRegression(C=0.22727272727272727, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.90      0.82       980\n",
            "        1.0       0.68      0.98      0.80      1135\n",
            "        2.0       0.79      0.55      0.65      1032\n",
            "        3.0       0.59      0.80      0.68      1010\n",
            "        4.0       0.62      0.84      0.71       982\n",
            "        5.0       0.91      0.31      0.46       892\n",
            "        6.0       0.69      0.76      0.72       958\n",
            "        7.0       0.80      0.79      0.80      1028\n",
            "        8.0       0.58      0.47      0.52       974\n",
            "        9.0       0.80      0.50      0.62      1009\n",
            "\n",
            "avg / total       0.72      0.70      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 884    2   18    2    4    4   43   11    4    8]\n",
            " [   0 1117    2    8    0    0    6    1    1    0]\n",
            " [  90  139  567   28   41    3   86   23   51    4]\n",
            " [  48   17   24  803    7    3   15   25   62    6]\n",
            " [  14   41    4   21  825    1   38    3   18   17]\n",
            " [  43   62   11  228   64  278   39   29  113   25]\n",
            " [  34   16   21    3  147    2  728    1    6    0]\n",
            " [  11   82   40   12   22    0    3  809   18   31]\n",
            " [  19  130   19  171   27    9   97   16  453   33]\n",
            " [  28   36   13   74  197    4    5   89   57  506]]\n",
            "--------------------------------\n",
            "val predicted: (59780,) [0. 0. 0. ... 7. 9. 7.]\n",
            "probabilities: (59780, 10) \n",
            " [0 0 0 ... 7 9 7]\n",
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [19 31 29 31 24  7 19 23 20 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.416 s \n",
            "\n",
            "Accuracy rate for 69.320000 \n",
            "Classification report for classifier LogisticRegression(C=0.21739130434782608, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.89      0.82       980\n",
            "        1.0       0.69      0.98      0.81      1135\n",
            "        2.0       0.83      0.55      0.66      1032\n",
            "        3.0       0.60      0.77      0.68      1010\n",
            "        4.0       0.60      0.83      0.70       982\n",
            "        5.0       0.72      0.43      0.54       892\n",
            "        6.0       0.66      0.84      0.74       958\n",
            "        7.0       0.84      0.79      0.81      1028\n",
            "        8.0       0.55      0.46      0.50       974\n",
            "        9.0       0.86      0.35      0.50      1009\n",
            "\n",
            "avg / total       0.71      0.69      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 869    2    6    1    5   40   44    6    5    2]\n",
            " [   0 1111    3   12    0    0    7    1    1    0]\n",
            " [  94  139  563   30   37   12  102   17   32    6]\n",
            " [  41   16   13  774    5   29   31   23   73    5]\n",
            " [  17   41    2   23  818   13   41    1   18    8]\n",
            " [  34   38    5  165   57  385   66   20  116    6]\n",
            " [  24   16    7    1   99    8  801    0    2    0]\n",
            " [  13   75   47   15   27    0    3  811   25   12]\n",
            " [  14  125   16  176   18   38  111   12  444   20]\n",
            " [  31   36   19   86  298   11    8   76   88  356]]\n",
            "--------------------------------\n",
            "val predicted: (59770,) [0. 0. 0. ... 7. 0. 9.]\n",
            "probabilities: (59770, 10) \n",
            " [0 0 0 ... 7 0 9]\n",
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [20 32 29 33 25  8 22 23 20 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.399 s \n",
            "\n",
            "Accuracy rate for 67.720000 \n",
            "Classification report for classifier LogisticRegression(C=0.20833333333333334, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.92      0.84       980\n",
            "        1.0       0.69      0.99      0.81      1135\n",
            "        2.0       0.80      0.51      0.62      1032\n",
            "        3.0       0.54      0.80      0.65      1010\n",
            "        4.0       0.62      0.82      0.71       982\n",
            "        5.0       0.86      0.34      0.49       892\n",
            "        6.0       0.64      0.88      0.74       958\n",
            "        7.0       0.83      0.77      0.80      1028\n",
            "        8.0       0.53      0.44      0.48       974\n",
            "        9.0       0.77      0.24      0.37      1009\n",
            "\n",
            "avg / total       0.70      0.68      0.65     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 898    2    7    0    1   12   45    9    4    2]\n",
            " [   0 1120    3    4    0    1    6    0    1    0]\n",
            " [  82  148  526   20   27    4  156   15   47    7]\n",
            " [  36   18   22  813    6    6   25   22   56    6]\n",
            " [  10   43    1   31  809    6   45    5   22   10]\n",
            " [  42   43    5  244   47  304   56   19  124    8]\n",
            " [  28   18   13    2   50    3  843    0    1    0]\n",
            " [  17   80   51   15   25    1    5  788   19   27]\n",
            " [  16  119   14  229   21   13  112   13  425   12]\n",
            " [  28   37   19  148  324    5   18   83  101  246]]\n",
            "--------------------------------\n",
            "val predicted: (59760,) [0. 0. 0. ... 7. 0. 7.]\n",
            "probabilities: (59760, 10) \n",
            " [0 0 0 ... 7 0 7]\n",
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [21 34 29 33 26  8 22 25 22 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.390 s \n",
            "\n",
            "Accuracy rate for 69.870000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.88      0.82       980\n",
            "        1.0       0.70      0.99      0.82      1135\n",
            "        2.0       0.78      0.60      0.68      1032\n",
            "        3.0       0.58      0.80      0.67      1010\n",
            "        4.0       0.64      0.82      0.72       982\n",
            "        5.0       0.80      0.38      0.52       892\n",
            "        6.0       0.70      0.89      0.78       958\n",
            "        7.0       0.83      0.79      0.81      1028\n",
            "        8.0       0.59      0.52      0.55       974\n",
            "        9.0       0.80      0.25      0.38      1009\n",
            "\n",
            "avg / total       0.72      0.70      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 866    2   13    0    3   22   49    9   12    4]\n",
            " [   0 1120    4    5    0    1    5    0    0    0]\n",
            " [  93  129  616   20   30    2  103   13   22    4]\n",
            " [  36   26   27  813    3   23   20   22   35    5]\n",
            " [  17   42    2   34  808    6   42    4   14   13]\n",
            " [  35   36    7  206   32  343   46   16  169    2]\n",
            " [  31   18   13    1   38    5  850    0    2    0]\n",
            " [  17   68   65   18   14    3    4  813    6   20]\n",
            " [  14  132   18  163   15   13   90    9  504   16]\n",
            " [  26   31   23  143  325   11    9   94   93  254]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 7. 0. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 7 0 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [24 36 29 33 27 10 22 25 23 31] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.403 s \n",
            "\n",
            "Accuracy rate for 68.690000 \n",
            "Classification report for classifier LogisticRegression(C=0.19230769230769232, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.90      0.82       980\n",
            "        1.0       0.71      0.99      0.83      1135\n",
            "        2.0       0.78      0.54      0.64      1032\n",
            "        3.0       0.54      0.81      0.65      1010\n",
            "        4.0       0.61      0.81      0.70       982\n",
            "        5.0       0.77      0.45      0.57       892\n",
            "        6.0       0.63      0.85      0.72       958\n",
            "        7.0       0.84      0.78      0.81      1028\n",
            "        8.0       0.64      0.42      0.51       974\n",
            "        9.0       0.82      0.27      0.40      1009\n",
            "\n",
            "avg / total       0.71      0.69      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 883    2   10    0    5   11   49    8   10    2]\n",
            " [   0 1120    4    4    0    1    6    0    0    0]\n",
            " [  87  120  558   28   33    1  163   13   25    4]\n",
            " [  36   20   21  814    3   49   16   21   25    5]\n",
            " [  23   35    1   32  796    3   63    5   12   12]\n",
            " [  36   47    8  212   52  401   41   16   78    1]\n",
            " [  37   16    9    1   59   20  815    0    1    0]\n",
            " [  18   70   63   15   20    3    5  801    9   24]\n",
            " [  13  105   22  248   17   18  118    8  412   13]\n",
            " [  28   32   22  144  317   13   26   87   71  269]]\n",
            "--------------------------------\n",
            "val predicted: (59740,) [0. 0. 0. ... 7. 7. 7.]\n",
            "probabilities: (59740, 10) \n",
            " [0 0 0 ... 7 7 7]\n",
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [25 36 32 33 28 10 23 26 25 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.422 s \n",
            "\n",
            "Accuracy rate for 68.830000 \n",
            "Classification report for classifier LogisticRegression(C=0.18518518518518517, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.88      0.82       980\n",
            "        1.0       0.69      0.98      0.81      1135\n",
            "        2.0       0.77      0.55      0.64      1032\n",
            "        3.0       0.54      0.77      0.63      1010\n",
            "        4.0       0.69      0.80      0.74       982\n",
            "        5.0       0.63      0.43      0.52       892\n",
            "        6.0       0.64      0.86      0.74       958\n",
            "        7.0       0.84      0.79      0.81      1028\n",
            "        8.0       0.62      0.41      0.49       974\n",
            "        9.0       0.86      0.35      0.50      1009\n",
            "\n",
            "avg / total       0.70      0.69      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 862    2   17    0    4   21   56   12    5    1]\n",
            " [   0 1116    6    4    0    3    6    0    0    0]\n",
            " [  86  146  563   19   31    3  139   18   23    4]\n",
            " [  40   27   17  778    3   72   18   22   29    4]\n",
            " [  17   38    5   30  785   31   48    5    9   14]\n",
            " [  41   42   10  228   50  388   44   17   69    3]\n",
            " [  29   18   14    0   38   30  827    1    1    0]\n",
            " [  19   71   55    8   14    6    6  809   14   26]\n",
            " [  14  129   22  236   16   23  117    8  402    7]\n",
            " [  25   32   26  145  194   35   22   76  101  353]]\n",
            "--------------------------------\n",
            "val predicted: (59730,) [0. 0. 0. ... 7. 9. 9.]\n",
            "probabilities: (59730, 10) \n",
            " [0 0 0 ... 7 9 9]\n",
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [26 38 32 36 28 11 24 28 25 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.394 s \n",
            "\n",
            "Accuracy rate for 70.010000 \n",
            "Classification report for classifier LogisticRegression(C=0.17857142857142858, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.77      0.88      0.82       980\n",
            "        1.0       0.69      0.99      0.81      1135\n",
            "        2.0       0.81      0.54      0.65      1032\n",
            "        3.0       0.60      0.74      0.66      1010\n",
            "        4.0       0.70      0.82      0.76       982\n",
            "        5.0       0.74      0.45      0.56       892\n",
            "        6.0       0.67      0.89      0.76       958\n",
            "        7.0       0.76      0.80      0.78      1028\n",
            "        8.0       0.56      0.46      0.50       974\n",
            "        9.0       0.82      0.38      0.52      1009\n",
            "\n",
            "avg / total       0.71      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 861    2   12    0    3   13   53   22   13    1]\n",
            " [   0 1119    4    4    0    1    7    0    0    0]\n",
            " [  82  151  559   15   30    4  136   27   24    4]\n",
            " [  55   24   19  750    2   49   24   26   53    8]\n",
            " [  10   42    2   27  809   14   35   13   13   17]\n",
            " [  46   35    3  162   37  404   49   24  126    6]\n",
            " [  24   17   11    2   33   22  848    1    0    0]\n",
            " [  11   75   39    6   13    1    3  826   18   36]\n",
            " [  12  132   20  197   15   25  106   11  444   12]\n",
            " [  21   33   21   97  209   13    7  130   97  381]]\n",
            "--------------------------------\n",
            "val predicted: (59720,) [0. 0. 0. ... 7. 9. 7.]\n",
            "probabilities: (59720, 10) \n",
            " [0 0 0 ... 7 9 7]\n",
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [27 40 32 38 31 11 24 28 27 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.431 s \n",
            "\n",
            "Accuracy rate for 69.650000 \n",
            "Classification report for classifier LogisticRegression(C=0.1724137931034483, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.89      0.81       980\n",
            "        1.0       0.71      0.98      0.82      1135\n",
            "        2.0       0.77      0.56      0.65      1032\n",
            "        3.0       0.56      0.79      0.65      1010\n",
            "        4.0       0.66      0.82      0.73       982\n",
            "        5.0       0.68      0.41      0.51       892\n",
            "        6.0       0.65      0.85      0.74       958\n",
            "        7.0       0.85      0.77      0.81      1028\n",
            "        8.0       0.65      0.42      0.51       974\n",
            "        9.0       0.82      0.41      0.55      1009\n",
            "\n",
            "avg / total       0.71      0.70      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 872    3   15    0    3   12   57    8    9    1]\n",
            " [   0 1111    9    6    0    2    7    0    0    0]\n",
            " [  93  139  576   20   33    5  127   15   18    6]\n",
            " [  48   22   14  795    3   55   24   19   19   11]\n",
            " [  11   32    5   28  810   21   39    6   12   18]\n",
            " [  49   30    4  217   68  369   53   11   85    6]\n",
            " [  33   18    9    1   50   28  817    0    2    0]\n",
            " [  21   70   57   12   18    5    5  790   11   39]\n",
            " [  14  118   26  241   16   21  113    7  409    9]\n",
            " [  19   29   32  112  229   28    9   70   65  416]]\n",
            "--------------------------------\n",
            "val predicted: (59710,) [0. 0. 0. ... 7. 9. 9.]\n",
            "probabilities: (59710, 10) \n",
            " [0 0 0 ... 7 9 9]\n",
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [28 41 34 38 31 11 25 30 28 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.404 s \n",
            "\n",
            "Accuracy rate for 70.190000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.91      0.81       980\n",
            "        1.0       0.69      0.98      0.81      1135\n",
            "        2.0       0.79      0.57      0.67      1032\n",
            "        3.0       0.60      0.78      0.68      1010\n",
            "        4.0       0.63      0.80      0.71       982\n",
            "        5.0       0.82      0.35      0.49       892\n",
            "        6.0       0.68      0.84      0.75       958\n",
            "        7.0       0.82      0.80      0.81      1028\n",
            "        8.0       0.61      0.50      0.55       974\n",
            "        9.0       0.82      0.41      0.55      1009\n",
            "\n",
            "avg / total       0.72      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 891    3    8    0    3    1   52   12    7    3]\n",
            " [   0 1115    7    6    0    1    6    0    0    0]\n",
            " [  84  148  593   25   26    1  106   27   17    5]\n",
            " [  66   29   12  784    5   26   18   22   38   10]\n",
            " [  17   40    8   25  789    4   45    7   20   27]\n",
            " [  59   38    4  190   77  311   45   24  137    7]\n",
            " [  41   17   14    2   59   14  808    2    1    0]\n",
            " [  12   68   48   11   15    2    5  826   10   31]\n",
            " [  19  128   26  181   18   10   87    8  486   11]\n",
            " [  24   32   28   82  254    8   13   75   77  416]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59700,) [0. 0. 0. ... 7. 9. 9.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 0 ... 7 9 9]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [28 42 34 39 32 12 28 30 29 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.391 s \n",
            "\n",
            "Accuracy rate for 71.410000 \n",
            "Classification report for classifier LogisticRegression(C=0.16129032258064516, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.85      0.82       980\n",
            "        1.0       0.70      0.99      0.82      1135\n",
            "        2.0       0.80      0.57      0.67      1032\n",
            "        3.0       0.58      0.78      0.67      1010\n",
            "        4.0       0.72      0.81      0.76       982\n",
            "        5.0       0.70      0.44      0.54       892\n",
            "        6.0       0.66      0.88      0.76       958\n",
            "        7.0       0.80      0.84      0.82      1028\n",
            "        8.0       0.63      0.44      0.52       974\n",
            "        9.0       0.85      0.48      0.61      1009\n",
            "\n",
            "avg / total       0.73      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 831    2   18    0    4   32   68   16    7    2]\n",
            " [   0 1121    4    3    0    1    6    0    0    0]\n",
            " [  76  136  591   19   30    5  128   32   11    4]\n",
            " [  30   35   14  786    4   56   16   29   30   10]\n",
            " [   9   38    6   23  799   11   48   15   15   18]\n",
            " [  37   38    4  182   46  395   48   21  110   11]\n",
            " [  28   15    5    1   34   24  847    3    1    0]\n",
            " [   4   70   40   11    9    2    4  861    3   24]\n",
            " [   7  129   33  220   16   20  100    8  425   16]\n",
            " [  13   27   22  102  167   16   14   95   68  485]]\n",
            "--------------------------------\n",
            "val predicted: (59690,) [0. 0. 0. ... 7. 7. 7.]\n",
            "probabilities: (59690, 10) \n",
            " [0 0 0 ... 7 7 7]\n",
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [29 44 37 39 32 13 28 31 29 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.413 s \n",
            "\n",
            "Accuracy rate for 70.530000 \n",
            "Classification report for classifier LogisticRegression(C=0.15625, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.90      0.81       980\n",
            "        1.0       0.72      0.98      0.83      1135\n",
            "        2.0       0.76      0.57      0.65      1032\n",
            "        3.0       0.60      0.71      0.65      1010\n",
            "        4.0       0.72      0.80      0.76       982\n",
            "        5.0       0.68      0.44      0.53       892\n",
            "        6.0       0.65      0.86      0.74       958\n",
            "        7.0       0.86      0.76      0.80      1028\n",
            "        8.0       0.59      0.49      0.54       974\n",
            "        9.0       0.80      0.49      0.61      1009\n",
            "\n",
            "avg / total       0.71      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 879    2   13    0    3   22   49    6    5    1]\n",
            " [   0 1107   14    3    0    4    5    0    2    0]\n",
            " [  89  116  587   28   23    4  133   18   25    9]\n",
            " [  71   30   14  721    3   52   22   19   69    9]\n",
            " [  16   31    7   21  784   19   50    7   20   27]\n",
            " [  57   30   13  161   49  393   51    9  123    6]\n",
            " [  33   15   17    1   33   35  824    0    0    0]\n",
            " [  16   74   51   12   16    4    6  779   11   59]\n",
            " [  16  111   36  171   15   24  105    6  480   10]\n",
            " [  21   29   19   86  168   23   18   65   81  499]]\n",
            "--------------------------------\n",
            "val predicted: (59680,) [0. 0. 0. ... 7. 7. 7.]\n",
            "probabilities: (59680, 10) \n",
            " [0 0 0 ... 7 7 7]\n",
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [30 45 39 40 33 13 29 33 30 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.427 s \n",
            "\n",
            "Accuracy rate for 70.150000 \n",
            "Classification report for classifier LogisticRegression(C=0.15151515151515152, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.88      0.81       980\n",
            "        1.0       0.69      0.97      0.81      1135\n",
            "        2.0       0.76      0.58      0.65      1032\n",
            "        3.0       0.60      0.76      0.67      1010\n",
            "        4.0       0.67      0.81      0.73       982\n",
            "        5.0       0.67      0.45      0.54       892\n",
            "        6.0       0.65      0.85      0.74       958\n",
            "        7.0       0.84      0.79      0.81      1028\n",
            "        8.0       0.66      0.44      0.53       974\n",
            "        9.0       0.82      0.44      0.57      1009\n",
            "\n",
            "avg / total       0.71      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 859    2   17    0    3   26   56   12    4    1]\n",
            " [   0 1105   16    3    0    3    5    0    3    0]\n",
            " [  89  126  595   23   29    6  118   21   21    4]\n",
            " [  59   39   14  765    4   52   22   21   25    9]\n",
            " [   9   35    8   21  794   20   55    4   16   20]\n",
            " [  51   29   10  187   60  405   54   15   77    4]\n",
            " [  28   15   10    2   42   41  818    1    1    0]\n",
            " [  13   74   41   15   22    1    5  809    6   42]\n",
            " [  18  133   59  165   14   32  109    5  424   15]\n",
            " [  14   36   17   92  225   20   25   78   61  441]]\n",
            "--------------------------------\n",
            "val predicted: (59670,) [0. 0. 0. ... 7. 9. 9.]\n",
            "probabilities: (59670, 10) \n",
            " [0 0 0 ... 7 9 9]\n",
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [31 45 40 44 35 13 31 33 30 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.436 s \n",
            "\n",
            "Accuracy rate for 68.740000 \n",
            "Classification report for classifier LogisticRegression(C=0.14705882352941177, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.74      0.88      0.81       980\n",
            "        1.0       0.69      0.97      0.81      1135\n",
            "        2.0       0.72      0.52      0.60      1032\n",
            "        3.0       0.62      0.72      0.67      1010\n",
            "        4.0       0.62      0.79      0.70       982\n",
            "        5.0       0.67      0.43      0.53       892\n",
            "        6.0       0.64      0.87      0.73       958\n",
            "        7.0       0.84      0.78      0.81      1028\n",
            "        8.0       0.60      0.49      0.54       974\n",
            "        9.0       0.81      0.37      0.51      1009\n",
            "\n",
            "avg / total       0.70      0.69      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 865    3   12    0    5   19   62    8    5    1]\n",
            " [   0 1096   24    3    0    3    6    0    3    0]\n",
            " [  92  136  534   41   31    5  145   23   18    7]\n",
            " [  62   45   11  729    9   55   27   21   44    7]\n",
            " [  14   35   12   23  774   23   48   11   21   21]\n",
            " [  51   28    5  137   82  384   64   11  125    5]\n",
            " [  27   16    9    2   43   29  830    1    1    0]\n",
            " [  18   69   43   21   19    2    4  806    6   40]\n",
            " [  14  114   64  134   25   30   99    4  480   10]\n",
            " [  19   35   32   87  256   19   18   73   94  376]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59660, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [33 46 40 45 35 14 33 34 32 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.440 s \n",
            "\n",
            "Accuracy rate for 70.000000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.74      0.88      0.81       980\n",
            "        1.0       0.70      0.98      0.81      1135\n",
            "        2.0       0.75      0.55      0.64      1032\n",
            "        3.0       0.63      0.76      0.69      1010\n",
            "        4.0       0.63      0.80      0.71       982\n",
            "        5.0       0.71      0.47      0.57       892\n",
            "        6.0       0.64      0.86      0.73       958\n",
            "        7.0       0.85      0.77      0.81      1028\n",
            "        8.0       0.66      0.48      0.56       974\n",
            "        9.0       0.80      0.39      0.53      1009\n",
            "\n",
            "avg / total       0.71      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 864    3   14    2    3   18   65    7    3    1]\n",
            " [   0 1108   13    3    0    3    5    0    3    0]\n",
            " [  94  138  569   28   30    3  130   15   19    6]\n",
            " [  59   31   14  771    7   41   24   24   33    6]\n",
            " [  17   33    7   18  784   20   51    8   24   20]\n",
            " [  54   26    7  165   75  423   55   11   72    4]\n",
            " [  27   16   14    2   44   27  826    1    1    0]\n",
            " [  12   77   46   13   19    3    5  790    7   56]\n",
            " [  16  122   48  143   20   31  113    5  467    9]\n",
            " [  17   35   25   85  256   25   20   73   75  398]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59650,) [0. 0. 0. ... 7. 7. 7.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 7 7 7]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [35 48 40 47 37 14 33 36 32 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.447 s \n",
            "\n",
            "Accuracy rate for 68.240000 \n",
            "Classification report for classifier LogisticRegression(C=0.1388888888888889, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.86      0.80       980\n",
            "        1.0       0.70      0.97      0.81      1135\n",
            "        2.0       0.72      0.54      0.62      1032\n",
            "        3.0       0.62      0.77      0.68      1010\n",
            "        4.0       0.57      0.79      0.66       982\n",
            "        5.0       0.70      0.46      0.56       892\n",
            "        6.0       0.64      0.85      0.73       958\n",
            "        7.0       0.81      0.78      0.79      1028\n",
            "        8.0       0.67      0.47      0.55       974\n",
            "        9.0       0.78      0.29      0.42      1009\n",
            "\n",
            "avg / total       0.70      0.68      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 845    2   15    0    5   16   83    8    5    1]\n",
            " [   0 1097   25    3    0    2    5    0    3    0]\n",
            " [  88  136  560   44   27    4  128   35    7    3]\n",
            " [  53   34   12  775    8   42   27   25   27    7]\n",
            " [  14   31    9   14  775   24   49   21   31   14]\n",
            " [  49   26    5  169   95  409   57    9   68    5]\n",
            " [  30   17   13    2   46   28  817    0    5    0]\n",
            " [  16   80   42   15   21    3    5  798    7   41]\n",
            " [  12  106   69  154   26   38   97    7  454   11]\n",
            " [  18   35   33   81  356   15   18   86   73  294]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) [0. 0. 6. ... 7. 7. 7.]\n",
            "probabilities: (59640, 10) \n",
            " [0 0 6 ... 7 7 7]\n",
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [35 49 40 48 37 17 34 38 32 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.455 s \n",
            "\n",
            "Accuracy rate for 68.920000 \n",
            "Classification report for classifier LogisticRegression(C=0.13513513513513514, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.90      0.82       980\n",
            "        1.0       0.70      0.97      0.81      1135\n",
            "        2.0       0.71      0.52      0.60      1032\n",
            "        3.0       0.66      0.77      0.71      1010\n",
            "        4.0       0.61      0.80      0.69       982\n",
            "        5.0       0.65      0.52      0.58       892\n",
            "        6.0       0.63      0.84      0.72       958\n",
            "        7.0       0.82      0.77      0.79      1028\n",
            "        8.0       0.67      0.45      0.54       974\n",
            "        9.0       0.76      0.32      0.45      1009\n",
            "\n",
            "avg / total       0.70      0.69      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 880    3   10    2    5    6   65    6    2    1]\n",
            " [   0 1102   20    3    0    3    5    0    2    0]\n",
            " [  92  135  540   46   27    3  145   23   17    4]\n",
            " [  52   30    8  773    6   56   23   25   30    7]\n",
            " [  19   28   14    9  783   39   45    5   18   22]\n",
            " [  49   30    3  129   91  467   55   16   49    3]\n",
            " [  34   18   10    1   49   43  801    1    1    0]\n",
            " [  13   75   40   13   21   11    5  789    7   54]\n",
            " [  17  117   77  129   21   41  119    7  436   10]\n",
            " [  17   37   37   60  290   51   18   92   86  321]]\n",
            "--------------------------------\n",
            "val predicted: (59630,) [0. 0. 6. ... 7. 7. 7.]\n",
            "probabilities: (59630, 10) \n",
            " [0 0 6 ... 7 7 7]\n",
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [35 51 40 50 38 17 36 40 33 40] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.452 s \n",
            "\n",
            "Accuracy rate for 67.910000 \n",
            "Classification report for classifier LogisticRegression(C=0.13157894736842105, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.77      0.86      0.81       980\n",
            "        1.0       0.71      0.97      0.82      1135\n",
            "        2.0       0.71      0.52      0.60      1032\n",
            "        3.0       0.65      0.77      0.70      1010\n",
            "        4.0       0.57      0.78      0.66       982\n",
            "        5.0       0.67      0.48      0.56       892\n",
            "        6.0       0.59      0.86      0.70       958\n",
            "        7.0       0.82      0.78      0.80      1028\n",
            "        8.0       0.68      0.46      0.55       974\n",
            "        9.0       0.71      0.28      0.40      1009\n",
            "\n",
            "avg / total       0.69      0.68      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 838    3   12    3    5    7  100    4    5    3]\n",
            " [   0 1099   22    3    0    2    6    0    3    0]\n",
            " [  89  128  535   40   25    3  165   20   15   12]\n",
            " [  46   30    8  776    8   51   34   22   27    8]\n",
            " [  15   30   19   10  767   33   49    8   22   29]\n",
            " [  41   27    4  146   98  425   64   21   64    2]\n",
            " [  27   15    9    1   45   37  823    0    1    0]\n",
            " [  11   68   44   13   28    5    4  797    4   54]\n",
            " [  10  112   67  133   25   35  128    6  448   10]\n",
            " [  16   34   38   67  352   33   17   98   71  283]]\n",
            "--------------------------------\n",
            "val predicted: (59620,) [0. 0. 6. ... 7. 9. 9.]\n",
            "probabilities: (59620, 10) \n",
            " [0 0 6 ... 7 9 9]\n",
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [36 51 40 51 40 19 36 42 33 42] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.501 s \n",
            "\n",
            "Accuracy rate for 69.180000 \n",
            "Classification report for classifier LogisticRegression(C=0.1282051282051282, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.88      0.82       980\n",
            "        1.0       0.71      0.96      0.82      1135\n",
            "        2.0       0.68      0.54      0.60      1032\n",
            "        3.0       0.65      0.76      0.70      1010\n",
            "        4.0       0.62      0.77      0.69       982\n",
            "        5.0       0.66      0.50      0.57       892\n",
            "        6.0       0.64      0.84      0.73       958\n",
            "        7.0       0.83      0.77      0.80      1028\n",
            "        8.0       0.66      0.49      0.56       974\n",
            "        9.0       0.77      0.35      0.48      1009\n",
            "\n",
            "avg / total       0.70      0.69      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 860    3   18    2    4    8   71    7    6    1]\n",
            " [   0 1095   26    3    0    2    6    0    3    0]\n",
            " [  81  133  559   49   26    5  142   19   11    7]\n",
            " [  47   31    8  772    4   55   27   18   38   10]\n",
            " [  15   28   24   14  761   38   45    2   28   27]\n",
            " [  47   28    7  126   80  443   54   21   84    2]\n",
            " [  32   18   15    2   43   36  808    1    2    1]\n",
            " [  16   67   49   13   28    4    4  792    5   50]\n",
            " [  13  105   74  126   20   46   97    7  478    8]\n",
            " [  18   36   48   77  270   38   15   84   73  350]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) [0. 0. 6. ... 9. 9. 9.]\n",
            "probabilities: (59610, 10) \n",
            " [0 0 6 ... 9 9 9]\n",
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [36 52 41 52 40 19 39 44 33 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.470 s \n",
            "\n",
            "Accuracy rate for 68.870000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.77      0.89      0.83       980\n",
            "        1.0       0.72      0.96      0.83      1135\n",
            "        2.0       0.68      0.54      0.60      1032\n",
            "        3.0       0.65      0.78      0.71      1010\n",
            "        4.0       0.60      0.80      0.68       982\n",
            "        5.0       0.64      0.48      0.55       892\n",
            "        6.0       0.63      0.84      0.72       958\n",
            "        7.0       0.84      0.77      0.80      1028\n",
            "        8.0       0.65      0.49      0.56       974\n",
            "        9.0       0.76      0.30      0.42      1009\n",
            "\n",
            "avg / total       0.70      0.69      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 873    3   11    2    3    4   72    5    7    0]\n",
            " [   0 1089   32    4    0    2    5    0    3    0]\n",
            " [  84  125  556   40   34    7  142   23   16    5]\n",
            " [  48   22   10  785    4   48   24   19   38   12]\n",
            " [  12   29   16   11  786   42   47    2   23   14]\n",
            " [  45   27    2  135   84  424   59   19   93    4]\n",
            " [  33   19   12    2   48   34  806    0    3    1]\n",
            " [  11   66   50   15   23    9    4  793    6   51]\n",
            " [  11   93   82  128   14   49  106    5  477    9]\n",
            " [  16   32   50   84  322   41   17   78   71  298]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 2. ... 7. 9. 9.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 2 ... 7 9 9]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [36 53 45 54 41 19 39 45 34 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.496 s \n",
            "\n",
            "Accuracy rate for 69.020000 \n",
            "Classification report for classifier LogisticRegression(C=0.12195121951219512, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.77      0.88      0.82       980\n",
            "        1.0       0.72      0.97      0.82      1135\n",
            "        2.0       0.75      0.57      0.65      1032\n",
            "        3.0       0.65      0.75      0.70      1010\n",
            "        4.0       0.57      0.81      0.67       982\n",
            "        5.0       0.64      0.50      0.56       892\n",
            "        6.0       0.63      0.85      0.72       958\n",
            "        7.0       0.80      0.79      0.80      1028\n",
            "        8.0       0.70      0.50      0.59       974\n",
            "        9.0       0.76      0.24      0.36      1009\n",
            "\n",
            "avg / total       0.70      0.69      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 860    3   10    1    4   11   77    7    6    1]\n",
            " [   0 1098   23    4    0    2    5    0    3    0]\n",
            " [  77  126  592   29   30    5  141   19    8    5]\n",
            " [  43   29   18  761    4   59   29   20   38    9]\n",
            " [  16   27    6   13  795   39   42   10   17   17]\n",
            " [  45   25    3  139   87  449   61   16   66    1]\n",
            " [  27   18   10    2   48   36  812    0    5    0]\n",
            " [  18   68   45   15   26    8    3  808    4   33]\n",
            " [  13  104   60  121   23   50  100    5  488   10]\n",
            " [  19   33   21   89  372   40   18  119   59  239]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) [0. 0. 0. ... 7. 9. 9.]\n",
            "probabilities: (59590, 10) \n",
            " [0 0 0 ... 7 9 9]\n",
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [36 54 49 54 41 21 40 45 35 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.478 s \n",
            "\n",
            "Accuracy rate for 70.010000 \n",
            "Classification report for classifier LogisticRegression(C=0.11904761904761904, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.88      0.82       980\n",
            "        1.0       0.72      0.97      0.83      1135\n",
            "        2.0       0.77      0.60      0.67      1032\n",
            "        3.0       0.67      0.72      0.69      1010\n",
            "        4.0       0.61      0.80      0.69       982\n",
            "        5.0       0.66      0.45      0.53       892\n",
            "        6.0       0.63      0.85      0.72       958\n",
            "        7.0       0.79      0.79      0.79      1028\n",
            "        8.0       0.69      0.56      0.62       974\n",
            "        9.0       0.74      0.33      0.46      1009\n",
            "\n",
            "avg / total       0.71      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 862    2   11    2    3    5   78    6   11    0]\n",
            " [   0 1101   23    3    0    1    4    0    3    0]\n",
            " [  79  106  618   26   27    4  131   22   12    7]\n",
            " [  58   39   14  728    6   52   28   22   53   10]\n",
            " [   9   29   10   11  784   36   51    8   20   24]\n",
            " [  56   30    3  132   87  397   62   26   92    7]\n",
            " [  28   18   11    2   42   37  816    0    4    0]\n",
            " [  12   66   39   11   21    4    3  814    3   55]\n",
            " [  10  101   55   89   23   30  101    7  546   12]\n",
            " [  15   33   18   81  290   37   20  131   49  335]]\n",
            "--------------------------------\n",
            "val predicted: (59580,) [0. 0. 6. ... 7. 9. 9.]\n",
            "probabilities: (59580, 10) \n",
            " [0 0 6 ... 7 9 9]\n",
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [37 55 50 56 42 22 42 45 36 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.487 s \n",
            "\n",
            "Accuracy rate for 70.470000 \n",
            "Classification report for classifier LogisticRegression(C=0.11627906976744186, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.87      0.83       980\n",
            "        1.0       0.70      0.96      0.81      1135\n",
            "        2.0       0.77      0.58      0.66      1032\n",
            "        3.0       0.70      0.71      0.71      1010\n",
            "        4.0       0.60      0.80      0.68       982\n",
            "        5.0       0.60      0.52      0.56       892\n",
            "        6.0       0.64      0.84      0.73       958\n",
            "        7.0       0.84      0.79      0.82      1028\n",
            "        8.0       0.72      0.56      0.63       974\n",
            "        9.0       0.77      0.37      0.50      1009\n",
            "\n",
            "avg / total       0.71      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 851    3    5    1    3    9   86    5   16    1]\n",
            " [   0 1091   33    3    0    2    4    0    2    0]\n",
            " [  73  125  599   22   32    7  136   23    7    8]\n",
            " [  30   41   15  720    3  108   28   13   38   14]\n",
            " [  16   28    7   10  786   38   43   11   20   23]\n",
            " [  40   28    2  100   90  465   60   10   89    8]\n",
            " [  26   17   11    1   47   43  807    0    6    0]\n",
            " [  13   72   41    5   21    9    2  816    2   47]\n",
            " [   9  112   47  102   22   44   78    6  542   12]\n",
            " [  21   33   16   63  316   47   17   90   36  370]]\n",
            "--------------------------------\n",
            "val predicted: (59570,) [0. 0. 8. ... 7. 9. 7.]\n",
            "probabilities: (59570, 10) \n",
            " [0 0 8 ... 7 9 7]\n",
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [38 56 50 57 43 23 43 45 37 48] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.446 s \n",
            "\n",
            "Accuracy rate for 71.830000 \n",
            "Classification report for classifier LogisticRegression(C=0.11363636363636363, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.87      0.84       980\n",
            "        1.0       0.70      0.98      0.82      1135\n",
            "        2.0       0.82      0.56      0.66      1032\n",
            "        3.0       0.71      0.76      0.73      1010\n",
            "        4.0       0.62      0.81      0.71       982\n",
            "        5.0       0.64      0.51      0.57       892\n",
            "        6.0       0.65      0.86      0.74       958\n",
            "        7.0       0.84      0.80      0.82      1028\n",
            "        8.0       0.71      0.62      0.66       974\n",
            "        9.0       0.80      0.37      0.50      1009\n",
            "\n",
            "avg / total       0.73      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 853    3    6    2    3    6   81    5   20    1]\n",
            " [   0 1114   10    3    0    1    4    0    3    0]\n",
            " [  63  153  575   22   31    4  138   24   14    8]\n",
            " [  33   39   12  768    4   66   25   12   44    7]\n",
            " [  14   28    2    8  798   50   44    2   13   23]\n",
            " [  39   27    2  132   62  453   59   18   94    6]\n",
            " [  23   18   11    1   37   39  826    0    3    0]\n",
            " [  12   72   40   10   20    6    3  821    4   40]\n",
            " [   8  108   32   83   17   33   73    6  606    8]\n",
            " [  18   34   11   59  307   52   19   85   55  369]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59560,) [0. 0. 8. ... 7. 5. 5.]\n",
            "probabilities: (59560, 10) \n",
            " [0 0 8 ... 7 5 5]\n",
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [38 56 51 57 44 26 44 47 39 48] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.459 s \n",
            "\n",
            "Accuracy rate for 70.780000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.88      0.83       980\n",
            "        1.0       0.70      0.97      0.81      1135\n",
            "        2.0       0.78      0.61      0.68      1032\n",
            "        3.0       0.63      0.79      0.70      1010\n",
            "        4.0       0.65      0.81      0.72       982\n",
            "        5.0       0.67      0.40      0.50       892\n",
            "        6.0       0.65      0.87      0.75       958\n",
            "        7.0       0.83      0.76      0.79      1028\n",
            "        8.0       0.70      0.55      0.62       974\n",
            "        9.0       0.76      0.39      0.51      1009\n",
            "\n",
            "avg / total       0.72      0.71      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 860    3   11    2    3    1   81    4   13    2]\n",
            " [   0 1103   19    3    0    1    4    0    5    0]\n",
            " [  71  130  626   30   30    2  112   15    9    7]\n",
            " [  31   37   14  794    4   55   24   15   29    7]\n",
            " [  10   33    7   14  796   31   55    1   17   18]\n",
            " [  45   36    7  194   65  360   59   36   84    6]\n",
            " [  23   17   10    4   32   20  833    0   19    0]\n",
            " [  14   73   47   13   18    7    3  781    3   69]\n",
            " [  11  110   42  140   17   15   84    6  535   14]\n",
            " [  21   35   23   73  264   48   22   88   45  390]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [40 58 51 59 45 27 46 47 39 48] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.456 s \n",
            "\n",
            "Accuracy rate for 70.610000 \n",
            "Classification report for classifier LogisticRegression(C=0.10869565217391304, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.87      0.82       980\n",
            "        1.0       0.70      0.97      0.82      1135\n",
            "        2.0       0.78      0.63      0.70      1032\n",
            "        3.0       0.64      0.79      0.71      1010\n",
            "        4.0       0.63      0.80      0.70       982\n",
            "        5.0       0.70      0.43      0.53       892\n",
            "        6.0       0.66      0.87      0.75       958\n",
            "        7.0       0.80      0.79      0.79      1028\n",
            "        8.0       0.69      0.55      0.61       974\n",
            "        9.0       0.78      0.31      0.44      1009\n",
            "\n",
            "avg / total       0.72      0.71      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 850    2   15    2    4    3   79    7   17    1]\n",
            " [   0 1103   20    3    0    1    4    0    4    0]\n",
            " [  77  125  649   18   23    2  103   24    6    5]\n",
            " [  28   38   20  801    3   39   23   21   30    7]\n",
            " [  18   31    4   11  784   28   60    5   24   17]\n",
            " [  42   35    5  193   63  380   54   29   87    4]\n",
            " [  26   18   14    2   24   24  835    0   15    0]\n",
            " [  19   68   43    9   17    5    4  816    6   41]\n",
            " [  13  113   43  135   16   17   82    8  535   12]\n",
            " [  23   33   16   78  314   42   26  116   53  308]]\n",
            "--------------------------------\n",
            "val predicted: (59540,) [0. 0. 8. ... 7. 9. 9.]\n",
            "probabilities: (59540, 10) \n",
            " [0 0 8 ... 7 9 9]\n",
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [40 59 52 62 46 27 47 48 39 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.457 s \n",
            "\n",
            "Accuracy rate for 71.330000 \n",
            "Classification report for classifier LogisticRegression(C=0.10638297872340426, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.88      0.83       980\n",
            "        1.0       0.70      0.98      0.82      1135\n",
            "        2.0       0.79      0.60      0.68      1032\n",
            "        3.0       0.68      0.78      0.73      1010\n",
            "        4.0       0.66      0.80      0.72       982\n",
            "        5.0       0.64      0.49      0.55       892\n",
            "        6.0       0.64      0.87      0.74       958\n",
            "        7.0       0.78      0.81      0.80      1028\n",
            "        8.0       0.70      0.55      0.61       974\n",
            "        9.0       0.85      0.34      0.48      1009\n",
            "\n",
            "avg / total       0.73      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 865    3    5    2    3    2   79    8   13    0]\n",
            " [   0 1109   16    3    0    1    4    0    2    0]\n",
            " [  72  131  616   21   27    2  128   24    7    4]\n",
            " [  33   31   13  783    2   68   25   23   29    3]\n",
            " [  11   28    6    9  787   41   58    7   18   17]\n",
            " [  51   28    5  148   64  434   56   22   78    6]\n",
            " [  23   18   11    2   30   37  830    1    6    0]\n",
            " [  12   73   47    6   18    6    5  836    5   20]\n",
            " [  11  122   42  118   17   29   83   11  531   10]\n",
            " [  19   34   14   55  250   55   29  136   75  342]]\n",
            "--------------------------------\n",
            "val predicted: (59530,) [0. 0. 8. ... 7. 9. 9.]\n",
            "probabilities: (59530, 10) \n",
            " [0 0 8 ... 7 9 9]\n",
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [41 59 53 65 46 28 47 49 39 53] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.473 s \n",
            "\n",
            "Accuracy rate for 70.910000 \n",
            "Classification report for classifier LogisticRegression(C=0.10416666666666667, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.86      0.82       980\n",
            "        1.0       0.71      0.97      0.82      1135\n",
            "        2.0       0.80      0.56      0.66      1032\n",
            "        3.0       0.70      0.71      0.70      1010\n",
            "        4.0       0.68      0.79      0.73       982\n",
            "        5.0       0.62      0.52      0.57       892\n",
            "        6.0       0.59      0.88      0.71       958\n",
            "        7.0       0.80      0.82      0.81      1028\n",
            "        8.0       0.70      0.55      0.61       974\n",
            "        9.0       0.84      0.39      0.53      1009\n",
            "\n",
            "avg / total       0.72      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 841    3    6    0    3    3  103    9   12    0]\n",
            " [   0 1104   19    3    0    1    4    0    4    0]\n",
            " [  77  128  578   19   36    1  157   22    5    9]\n",
            " [  42   45   13  714    2  110   26   21   30    7]\n",
            " [  10   24    3   11  779   46   70    5   20   14]\n",
            " [  52   29    4  113   58  466   67   17   78    8]\n",
            " [  21   18    8    1   26   33  846    0    5    0]\n",
            " [  10   71   34   11   21    6    6  839    3   27]\n",
            " [  15  111   42   95   16   25  119    9  531   11]\n",
            " [  14   32   14   59  207   65   37  122   66  393]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) [0. 0. 8. ... 7. 9. 9.]\n",
            "probabilities: (59520, 10) \n",
            " [0 0 8 ... 7 9 9]\n",
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [41 60 54 68 47 29 47 49 40 55] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.522 s \n",
            "\n",
            "Accuracy rate for 71.000000 \n",
            "Classification report for classifier LogisticRegression(C=0.10204081632653061, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.87      0.83       980\n",
            "        1.0       0.71      0.96      0.81      1135\n",
            "        2.0       0.74      0.57      0.64      1032\n",
            "        3.0       0.68      0.77      0.73      1010\n",
            "        4.0       0.69      0.78      0.74       982\n",
            "        5.0       0.61      0.48      0.54       892\n",
            "        6.0       0.64      0.86      0.73       958\n",
            "        7.0       0.77      0.80      0.78      1028\n",
            "        8.0       0.71      0.55      0.62       974\n",
            "        9.0       0.82      0.40      0.53      1009\n",
            "\n",
            "avg / total       0.72      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 857    3   13    2    4    4   79    6   10    2]\n",
            " [   0 1090   35    3    0    1    3    0    3    0]\n",
            " [  79  131  585   19   38    3  140   23   11    3]\n",
            " [  33   34   15  782    0   65   20   21   37    3]\n",
            " [  12   24    6    8  770   68   55    6   21   12]\n",
            " [  46   33    6  158   48  430   53   36   68   14]\n",
            " [  22   18   15    1   30   42  826    1    1    2]\n",
            " [  16   72   44    9   17    5    6  822    4   33]\n",
            " [  12  106   57  105   16   31   80   11  539   17]\n",
            " [  17   30   18   58  185   57   36  143   66  399]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59510, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [43 61 55 68 50 29 47 49 42 56] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.435 s \n",
            "\n",
            "Accuracy rate for 71.790000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.87      0.83       980\n",
            "        1.0       0.72      0.97      0.83      1135\n",
            "        2.0       0.75      0.62      0.68      1032\n",
            "        3.0       0.69      0.76      0.73      1010\n",
            "        4.0       0.61      0.82      0.70       982\n",
            "        5.0       0.62      0.52      0.57       892\n",
            "        6.0       0.65      0.85      0.73       958\n",
            "        7.0       0.84      0.81      0.82      1028\n",
            "        8.0       0.80      0.56      0.66       974\n",
            "        9.0       0.82      0.36      0.50      1009\n",
            "\n",
            "avg / total       0.73      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 856    2    5    1    3    5   92    3   12    1]\n",
            " [   0 1098   29    2    0    1    4    0    1    0]\n",
            " [  76  113  637   18   32    3  120   26    4    3]\n",
            " [  37   38   14  768    1   84   23   19   23    3]\n",
            " [  10   23   14   10  801   50   50    3   12    9]\n",
            " [  50   29    5  144   61  468   59   15   47   14]\n",
            " [  22   17    9    1   46   42  811    1    8    1]\n",
            " [   8   73   46    7   20    5    3  830    2   34]\n",
            " [  14  105   63  103   21   30   67    6  550   15]\n",
            " [  11   28   28   53  326   66   21   89   27  360]]\n",
            "--------------------------------\n",
            "final active learning accuracies [31.61, 50.36000000000001, 53.1, 59.74, 62.7, 64.03999999999999, 64.25, 61.629999999999995, 66.47, 68.0, 65.75999999999999, 65.0, 65.27, 66.46, 66.99000000000001, 66.86, 67.28, 66.72, 67.10000000000001, 68.33, 69.25, 69.69999999999999, 69.32000000000001, 67.72, 69.87, 68.69, 68.83, 70.00999999999999, 69.65, 70.19, 71.41, 70.53, 70.15, 68.74, 70.0, 68.24, 68.92, 67.91, 69.17999999999999, 68.87, 69.02000000000001, 70.00999999999999, 70.47, 71.83, 70.78, 70.61, 71.33, 70.91, 71.0, 71.78999999999999]\n",
            "saved Active-learning-experiment-35.pkl /content ['datalab', 'Active-learning-experiment-32.pkl', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-33.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-29.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "{\n",
            "  \"LogModel\": {\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.61,\n",
            "          50.36000000000001,\n",
            "          53.1,\n",
            "          59.74,\n",
            "          62.7,\n",
            "          64.03999999999999,\n",
            "          64.25,\n",
            "          61.629999999999995,\n",
            "          66.47,\n",
            "          68.0,\n",
            "          65.75999999999999,\n",
            "          65.0,\n",
            "          65.27,\n",
            "          66.46,\n",
            "          66.99000000000001,\n",
            "          66.86,\n",
            "          67.28,\n",
            "          66.72,\n",
            "          67.10000000000001,\n",
            "          68.33,\n",
            "          69.25,\n",
            "          69.69999999999999,\n",
            "          69.32000000000001,\n",
            "          67.72,\n",
            "          69.87,\n",
            "          68.69,\n",
            "          68.83,\n",
            "          70.00999999999999,\n",
            "          69.65,\n",
            "          70.19,\n",
            "          71.41,\n",
            "          70.53,\n",
            "          70.15,\n",
            "          68.74,\n",
            "          70.0,\n",
            "          68.24,\n",
            "          68.92,\n",
            "          67.91,\n",
            "          69.17999999999999,\n",
            "          68.87,\n",
            "          69.02000000000001,\n",
            "          70.00999999999999,\n",
            "          70.47,\n",
            "          71.83,\n",
            "          70.78,\n",
            "          70.61,\n",
            "          71.33,\n",
            "          70.91,\n",
            "          71.0,\n",
            "          71.78999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          46.63,\n",
            "          57.86,\n",
            "          62.019999999999996,\n",
            "          70.61,\n",
            "          72.74000000000001,\n",
            "          69.82000000000001,\n",
            "          69.6,\n",
            "          70.81,\n",
            "          70.82000000000001,\n",
            "          69.49,\n",
            "          71.46000000000001,\n",
            "          71.48,\n",
            "          72.04,\n",
            "          72.11,\n",
            "          72.65,\n",
            "          73.09,\n",
            "          73.72,\n",
            "          73.86,\n",
            "          74.69,\n",
            "          73.72999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          68.38,\n",
            "          66.14999999999999,\n",
            "          70.45,\n",
            "          72.68,\n",
            "          72.31,\n",
            "          72.33000000000001,\n",
            "          73.44000000000001,\n",
            "          71.78999999999999,\n",
            "          73.11999999999999,\n",
            "          70.84\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          68.95,\n",
            "          68.53,\n",
            "          71.67,\n",
            "          73.09\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          73.11,\n",
            "          74.56\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"RfModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          37.519999999999996,\n",
            "          42.53,\n",
            "          51.42,\n",
            "          49.03,\n",
            "          49.25,\n",
            "          52.01,\n",
            "          51.41,\n",
            "          51.89,\n",
            "          53.04,\n",
            "          55.48,\n",
            "          56.989999999999995,\n",
            "          56.720000000000006,\n",
            "          56.93,\n",
            "          55.169999999999995,\n",
            "          56.26,\n",
            "          55.64,\n",
            "          54.769999999999996,\n",
            "          54.98,\n",
            "          54.06999999999999,\n",
            "          53.71,\n",
            "          53.21,\n",
            "          52.800000000000004,\n",
            "          53.54,\n",
            "          52.72,\n",
            "          52.65,\n",
            "          51.849999999999994,\n",
            "          51.67,\n",
            "          51.89,\n",
            "          52.54,\n",
            "          53.03,\n",
            "          56.06,\n",
            "          56.26,\n",
            "          55.669999999999995,\n",
            "          60.17,\n",
            "          60.480000000000004,\n",
            "          59.9,\n",
            "          58.97,\n",
            "          60.019999999999996,\n",
            "          59.81999999999999,\n",
            "          59.86,\n",
            "          59.95,\n",
            "          62.970000000000006,\n",
            "          63.7,\n",
            "          62.94,\n",
            "          62.19,\n",
            "          62.019999999999996,\n",
            "          63.89,\n",
            "          62.150000000000006,\n",
            "          60.17,\n",
            "          62.39\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          44.21,\n",
            "          39.2,\n",
            "          37.57,\n",
            "          35.82,\n",
            "          36.120000000000005,\n",
            "          33.64,\n",
            "          32.09,\n",
            "          32.1,\n",
            "          32.28,\n",
            "          30.759999999999998,\n",
            "          31.230000000000004,\n",
            "          29.34,\n",
            "          26.419999999999998,\n",
            "          27.05,\n",
            "          26.58,\n",
            "          23.23,\n",
            "          24.0,\n",
            "          23.7,\n",
            "          21.58,\n",
            "          23.84\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          63.85999999999999,\n",
            "          60.309999999999995,\n",
            "          59.760000000000005,\n",
            "          59.89,\n",
            "          59.160000000000004,\n",
            "          59.519999999999996,\n",
            "          57.9,\n",
            "          59.74,\n",
            "          57.06,\n",
            "          59.91\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          75.02,\n",
            "          74.36,\n",
            "          72.39999999999999,\n",
            "          72.08\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.39999999999999,\n",
            "          81.82000000000001\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          25.72,\n",
            "          38.83,\n",
            "          53.99,\n",
            "          57.53,\n",
            "          62.39,\n",
            "          66.58,\n",
            "          64.23,\n",
            "          67.5,\n",
            "          72.75,\n",
            "          76.35,\n",
            "          77.31,\n",
            "          77.96,\n",
            "          78.17,\n",
            "          80.67,\n",
            "          81.76,\n",
            "          83.63000000000001,\n",
            "          85.26,\n",
            "          85.37,\n",
            "          85.82,\n",
            "          85.76,\n",
            "          86.00999999999999,\n",
            "          87.01,\n",
            "          87.45,\n",
            "          87.83,\n",
            "          88.64999999999999,\n",
            "          88.1,\n",
            "          87.92999999999999,\n",
            "          89.21,\n",
            "          89.57000000000001,\n",
            "          90.34,\n",
            "          91.12,\n",
            "          90.86,\n",
            "          91.17,\n",
            "          91.53999999999999,\n",
            "          91.84,\n",
            "          91.75999999999999,\n",
            "          91.07,\n",
            "          91.36,\n",
            "          91.22,\n",
            "          91.88,\n",
            "          92.0,\n",
            "          91.97,\n",
            "          91.7,\n",
            "          92.12,\n",
            "          92.28,\n",
            "          92.57,\n",
            "          92.63,\n",
            "          92.55,\n",
            "          92.80000000000001,\n",
            "          92.75999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          39.050000000000004,\n",
            "          51.85999999999999,\n",
            "          67.30000000000001,\n",
            "          74.29,\n",
            "          74.42999999999999,\n",
            "          80.15,\n",
            "          83.55,\n",
            "          83.58,\n",
            "          86.24000000000001,\n",
            "          87.22999999999999,\n",
            "          87.89,\n",
            "          88.42999999999999,\n",
            "          88.94,\n",
            "          90.06,\n",
            "          89.57000000000001,\n",
            "          90.03999999999999,\n",
            "          90.03999999999999,\n",
            "          91.14,\n",
            "          91.86,\n",
            "          91.79\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          62.99,\n",
            "          75.07000000000001,\n",
            "          75.38,\n",
            "          83.96000000000001,\n",
            "          87.89,\n",
            "          89.62,\n",
            "          89.7,\n",
            "          91.47999999999999,\n",
            "          91.84,\n",
            "          92.49000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          76.4,\n",
            "          85.66,\n",
            "          90.22,\n",
            "          92.13\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          81.26,\n",
            "          87.98\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          36.01,\n",
            "          43.34,\n",
            "          53.94,\n",
            "          58.02,\n",
            "          60.97,\n",
            "          66.44,\n",
            "          68.63,\n",
            "          70.8,\n",
            "          72.08,\n",
            "          73.58,\n",
            "          73.63,\n",
            "          74.0,\n",
            "          74.2,\n",
            "          75.52,\n",
            "          75.41,\n",
            "          75.81,\n",
            "          75.98,\n",
            "          77.97,\n",
            "          77.5,\n",
            "          80.15,\n",
            "          79.81,\n",
            "          81.13,\n",
            "          80.87,\n",
            "          80.58999999999999,\n",
            "          80.86,\n",
            "          81.26,\n",
            "          82.26,\n",
            "          82.44,\n",
            "          82.75,\n",
            "          82.92,\n",
            "          83.76,\n",
            "          83.50999999999999,\n",
            "          85.05,\n",
            "          85.50999999999999,\n",
            "          85.13,\n",
            "          86.02,\n",
            "          86.02,\n",
            "          86.5,\n",
            "          86.09,\n",
            "          85.83,\n",
            "          86.9,\n",
            "          86.46000000000001,\n",
            "          86.38,\n",
            "          86.88,\n",
            "          87.09,\n",
            "          87.87,\n",
            "          87.47,\n",
            "          87.59,\n",
            "          87.74,\n",
            "          87.78\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.64,\n",
            "          60.72,\n",
            "          65.45,\n",
            "          70.28999999999999,\n",
            "          72.94,\n",
            "          76.08,\n",
            "          77.51,\n",
            "          77.78,\n",
            "          79.35,\n",
            "          80.39,\n",
            "          81.6,\n",
            "          81.17,\n",
            "          82.73,\n",
            "          84.28,\n",
            "          84.15,\n",
            "          85.2,\n",
            "          86.13,\n",
            "          86.78,\n",
            "          86.95,\n",
            "          87.59\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          56.86,\n",
            "          69.43,\n",
            "          71.87,\n",
            "          75.68,\n",
            "          80.01,\n",
            "          82.06,\n",
            "          84.5,\n",
            "          85.92,\n",
            "          86.76,\n",
            "          87.32\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.5,\n",
            "          82.39,\n",
            "          85.76,\n",
            "          87.56\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.19,\n",
            "          88.14999999999999\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"SvmModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          35.93,\n",
            "          35.97,\n",
            "          40.33,\n",
            "          39.39,\n",
            "          41.349999999999994,\n",
            "          42.99,\n",
            "          46.23,\n",
            "          46.18,\n",
            "          47.260000000000005,\n",
            "          52.5,\n",
            "          52.400000000000006,\n",
            "          51.25999999999999,\n",
            "          51.690000000000005,\n",
            "          51.800000000000004,\n",
            "          53.18000000000001,\n",
            "          53.82,\n",
            "          55.88999999999999,\n",
            "          56.120000000000005,\n",
            "          57.269999999999996,\n",
            "          59.41,\n",
            "          59.95,\n",
            "          62.629999999999995,\n",
            "          61.339999999999996,\n",
            "          63.88,\n",
            "          65.34,\n",
            "          65.77,\n",
            "          66.9,\n",
            "          67.96,\n",
            "          68.27,\n",
            "          67.44,\n",
            "          68.45,\n",
            "          68.63,\n",
            "          68.0,\n",
            "          68.47,\n",
            "          68.77,\n",
            "          68.8,\n",
            "          69.17,\n",
            "          68.97,\n",
            "          69.33,\n",
            "          69.67999999999999,\n",
            "          69.95,\n",
            "          70.34,\n",
            "          70.47,\n",
            "          71.19,\n",
            "          71.97,\n",
            "          72.26,\n",
            "          72.06,\n",
            "          71.98,\n",
            "          72.55,\n",
            "          72.78999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          50.33,\n",
            "          51.59,\n",
            "          56.599999999999994,\n",
            "          60.24,\n",
            "          61.57,\n",
            "          63.5,\n",
            "          66.74,\n",
            "          68.19,\n",
            "          68.02,\n",
            "          69.8,\n",
            "          75.88000000000001,\n",
            "          77.24,\n",
            "          78.09,\n",
            "          79.38,\n",
            "          80.4,\n",
            "          80.99,\n",
            "          80.28999999999999,\n",
            "          80.12,\n",
            "          79.75999999999999,\n",
            "          80.36999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          64.55,\n",
            "          68.75,\n",
            "          71.34,\n",
            "          74.11999999999999,\n",
            "          75.96000000000001,\n",
            "          77.03999999999999,\n",
            "          76.85,\n",
            "          79.19,\n",
            "          80.51,\n",
            "          80.99\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          78.4,\n",
            "          78.21000000000001,\n",
            "          80.08,\n",
            "          81.0\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.11,\n",
            "          84.53\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.86,\n",
            "          37.6,\n",
            "          46.23,\n",
            "          58.41,\n",
            "          60.34,\n",
            "          65.98,\n",
            "          65.01,\n",
            "          69.86,\n",
            "          72.28999999999999,\n",
            "          74.65,\n",
            "          76.24,\n",
            "          77.37,\n",
            "          77.59,\n",
            "          78.7,\n",
            "          79.06,\n",
            "          80.06,\n",
            "          81.21000000000001,\n",
            "          82.32000000000001,\n",
            "          83.17,\n",
            "          83.78,\n",
            "          84.6,\n",
            "          84.58,\n",
            "          84.47,\n",
            "          85.07000000000001,\n",
            "          85.64,\n",
            "          85.75,\n",
            "          85.7,\n",
            "          86.18,\n",
            "          86.58,\n",
            "          86.50999999999999,\n",
            "          86.71,\n",
            "          87.09,\n",
            "          86.91,\n",
            "          87.13,\n",
            "          87.42999999999999,\n",
            "          87.75,\n",
            "          87.97,\n",
            "          88.23,\n",
            "          88.23,\n",
            "          88.22,\n",
            "          88.16000000000001,\n",
            "          88.03,\n",
            "          88.38000000000001,\n",
            "          88.39,\n",
            "          88.64,\n",
            "          88.98,\n",
            "          89.05999999999999,\n",
            "          89.34,\n",
            "          89.3,\n",
            "          89.52\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          50.160000000000004,\n",
            "          63.73,\n",
            "          70.14,\n",
            "          74.4,\n",
            "          78.99000000000001,\n",
            "          80.36999999999999,\n",
            "          82.76,\n",
            "          84.35000000000001,\n",
            "          85.78,\n",
            "          86.61999999999999,\n",
            "          87.46000000000001,\n",
            "          87.64,\n",
            "          88.08,\n",
            "          88.75,\n",
            "          88.68,\n",
            "          89.02,\n",
            "          89.39,\n",
            "          89.57000000000001,\n",
            "          89.66,\n",
            "          89.8\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          59.099999999999994,\n",
            "          69.91000000000001,\n",
            "          75.66000000000001,\n",
            "          81.41000000000001,\n",
            "          82.69,\n",
            "          85.07000000000001,\n",
            "          85.92,\n",
            "          86.89,\n",
            "          87.8,\n",
            "          87.6\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.45,\n",
            "          84.1,\n",
            "          86.36,\n",
            "          88.16000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.58,\n",
            "          87.38\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.009999999999998,\n",
            "          33.54,\n",
            "          48.67,\n",
            "          57.34,\n",
            "          61.68,\n",
            "          64.75999999999999,\n",
            "          69.28,\n",
            "          71.97,\n",
            "          73.2,\n",
            "          74.03,\n",
            "          75.08,\n",
            "          76.01,\n",
            "          76.55,\n",
            "          77.42999999999999,\n",
            "          77.75,\n",
            "          79.72,\n",
            "          80.78,\n",
            "          81.62,\n",
            "          81.8,\n",
            "          82.03,\n",
            "          81.82000000000001,\n",
            "          82.72,\n",
            "          82.94,\n",
            "          83.03,\n",
            "          83.72,\n",
            "          83.81,\n",
            "          83.72,\n",
            "          83.95,\n",
            "          84.38,\n",
            "          85.02,\n",
            "          85.36,\n",
            "          85.65,\n",
            "          85.26,\n",
            "          85.37,\n",
            "          85.37,\n",
            "          85.19,\n",
            "          85.18,\n",
            "          85.61999999999999,\n",
            "          85.47,\n",
            "          85.61999999999999,\n",
            "          85.78,\n",
            "          86.00999999999999,\n",
            "          86.05000000000001,\n",
            "          85.96000000000001,\n",
            "          85.96000000000001,\n",
            "          86.0,\n",
            "          86.24000000000001,\n",
            "          86.6,\n",
            "          86.66,\n",
            "          86.81\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.449999999999996,\n",
            "          67.88,\n",
            "          72.25,\n",
            "          77.82,\n",
            "          79.19,\n",
            "          80.32000000000001,\n",
            "          81.19,\n",
            "          81.91000000000001,\n",
            "          82.67999999999999,\n",
            "          82.89,\n",
            "          82.89,\n",
            "          83.05,\n",
            "          83.91999999999999,\n",
            "          84.69,\n",
            "          84.77,\n",
            "          84.66,\n",
            "          85.0,\n",
            "          85.3,\n",
            "          85.79,\n",
            "          86.08\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          56.38999999999999,\n",
            "          72.92999999999999,\n",
            "          78.44,\n",
            "          81.0,\n",
            "          82.73,\n",
            "          83.52000000000001,\n",
            "          84.35000000000001,\n",
            "          85.17,\n",
            "          86.17,\n",
            "          86.66\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          73.76,\n",
            "          83.52000000000001,\n",
            "          85.6,\n",
            "          86.44\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.02000000000001,\n",
            "          85.64\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 36, using model = LogModel, selection_function = MarginSamplingSelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [33 26 25 24 25 23 24 20 22 28] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.409 s \n",
            "\n",
            "Accuracy rate for 73.760000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.81      0.87      0.84       980\n",
            "        1.0       0.73      0.96      0.83      1135\n",
            "        2.0       0.78      0.69      0.73      1032\n",
            "        3.0       0.68      0.75      0.71      1010\n",
            "        4.0       0.66      0.81      0.73       982\n",
            "        5.0       0.82      0.36      0.50       892\n",
            "        6.0       0.70      0.88      0.78       958\n",
            "        7.0       0.78      0.80      0.79      1028\n",
            "        8.0       0.77      0.60      0.67       974\n",
            "        9.0       0.74      0.59      0.65      1009\n",
            "\n",
            "avg / total       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 855    2   13    8    8    3   67   19    4    1]\n",
            " [   0 1086   36    1    0    0    4    2    6    0]\n",
            " [  45   68  711   36   38    2   74   26   22   10]\n",
            " [  27   40   20  762    3   35   26   20   36   41]\n",
            " [   9   38    5    5  797    1   35   12   16   64]\n",
            " [  35   65    3  161  106  325   79   45   57   16]\n",
            " [  22   15   30    0   28    6  841    2   13    1]\n",
            " [  30   63   39    4   12    1    2  821    7   49]\n",
            " [  12   88   35  128   12   18   57    9  583   32]\n",
            " [  22   27   16   17  202    7   12   95   16  595]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [43 32 45 49 44 78 42 38 53 76] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.432 s \n",
            "\n",
            "Accuracy rate for 73.760000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.97      0.87       980\n",
            "        1.0       0.71      0.98      0.82      1135\n",
            "        2.0       0.81      0.70      0.75      1032\n",
            "        3.0       0.58      0.80      0.67      1010\n",
            "        4.0       0.72      0.75      0.73       982\n",
            "        5.0       0.78      0.30      0.44       892\n",
            "        6.0       0.76      0.91      0.82       958\n",
            "        7.0       0.91      0.68      0.78      1028\n",
            "        8.0       0.74      0.59      0.66       974\n",
            "        9.0       0.72      0.63      0.67      1009\n",
            "\n",
            "avg / total       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 951    2    1    1    1    0   19    1    4    0]\n",
            " [   0 1111    5    5    2    0    6    0    6    0]\n",
            " [  45  130  724    9   18    1   61   10   30    4]\n",
            " [  43   25   16  808    5   41   21    2   42    7]\n",
            " [   6   33   33   24  738    5   40    3   17   83]\n",
            " [  54   45    7  256   76  272   68   18   62   34]\n",
            " [  23   14   19    4   19    7  867    1    4    0]\n",
            " [  45   80   39   25   59    0    2  697   10   71]\n",
            " [  14  103   20  128   32   12   48    1  572   44]\n",
            " [  17   26   27  141   81   10   12   35   24  636]]\n",
            "--------------------------------\n",
            "final active learning accuracies [73.76, 73.76]\n",
            "saved Active-learning-experiment-36.pkl /content ['datalab', 'Active-learning-experiment-32.pkl', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-33.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-29.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 37, using model = LogModel, selection_function = MarginSamplingSelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [11 21 13 12 11 14 12  4 15 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.372 s \n",
            "\n",
            "Accuracy rate for 71.110000 \n",
            "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.89      0.88       980\n",
            "        1.0       0.78      0.98      0.86      1135\n",
            "        2.0       0.63      0.64      0.63      1032\n",
            "        3.0       0.59      0.64      0.61      1010\n",
            "        4.0       0.63      0.83      0.72       982\n",
            "        5.0       0.70      0.57      0.63       892\n",
            "        6.0       0.78      0.82      0.80       958\n",
            "        7.0       0.88      0.67      0.76      1028\n",
            "        8.0       0.76      0.50      0.60       974\n",
            "        9.0       0.56      0.54      0.55      1009\n",
            "\n",
            "avg / total       0.72      0.71      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 869    2   47    2    4    6   24   11   14    1]\n",
            " [   0 1107    0   18    0    2    6    0    2    0]\n",
            " [  27   64  656   33   44    1   95   27   27   58]\n",
            " [   3    2  202  644    1   76    9   11   25   37]\n",
            " [   2   33    0   11  815    7   29    4    2   79]\n",
            " [  33   49   20  110   42  512   38   16   68    4]\n",
            " [  25    8   48   11   30   40  787    5    4    0]\n",
            " [   9   55    6   25   44    1    7  688    3  190]\n",
            " [  14   91   60  177   14   61   11    3  486   57]\n",
            " [  16   14    5   61  303   28    7   20    8  547]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59875, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [16 22 30 25 22 27 24 14 41 29] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.409 s \n",
            "\n",
            "Accuracy rate for 72.420000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.92      0.86       980\n",
            "        1.0       0.70      0.98      0.81      1135\n",
            "        2.0       0.77      0.65      0.70      1032\n",
            "        3.0       0.68      0.73      0.71      1010\n",
            "        4.0       0.64      0.81      0.72       982\n",
            "        5.0       0.82      0.46      0.59       892\n",
            "        6.0       0.74      0.84      0.79       958\n",
            "        7.0       0.76      0.73      0.74      1028\n",
            "        8.0       0.79      0.44      0.56       974\n",
            "        9.0       0.66      0.63      0.64      1009\n",
            "\n",
            "avg / total       0.73      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 903    2   11    2    5    2   27    6   22    0]\n",
            " [   0 1109   12    3    0    1    5    2    3    0]\n",
            " [  58  131  666   22   46    4   59   28    5   13]\n",
            " [  33   65   59  742   15   29    9   16   23   19]\n",
            " [   7   16    2    7  799    8   57   13   12   61]\n",
            " [  52   34   21  150   55  409   45   26   27   73]\n",
            " [  24   17   34    4   60   12  800    0    7    0]\n",
            " [  18   40   27    9   64    3    2  751    2  112]\n",
            " [  19  164   32  134   52   10   64   22  427   50]\n",
            " [  16   17    5   20  144   23    8  130   10  636]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 8. ... 7. 7. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 8 ... 7 7 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [18 23 45 38 29 50 31 22 69 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.456 s \n",
            "\n",
            "Accuracy rate for 72.000000 \n",
            "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.74      0.96      0.83       980\n",
            "        1.0       0.63      0.98      0.77      1135\n",
            "        2.0       0.72      0.61      0.66      1032\n",
            "        3.0       0.76      0.65      0.70      1010\n",
            "        4.0       0.66      0.80      0.73       982\n",
            "        5.0       0.77      0.34      0.47       892\n",
            "        6.0       0.74      0.87      0.80       958\n",
            "        7.0       0.84      0.77      0.80      1028\n",
            "        8.0       0.88      0.41      0.55       974\n",
            "        9.0       0.68      0.74      0.71      1009\n",
            "\n",
            "avg / total       0.74      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 941    2    7    0    3    0   14    4    7    2]\n",
            " [   1 1116    8    1    0    1    4    1    1    2]\n",
            " [  52  179  633   18   48    2   52   17    2   29]\n",
            " [  58   86   58  660   14   46   19   20   15   34]\n",
            " [   1   17    3    3  790    2   54   15    2   95]\n",
            " [ 144   42   21  109  102  302   57   24   17   74]\n",
            " [  18   24   24    1   38   11  832    5    4    1]\n",
            " [  24   41   66    1   24    2    4  788    1   77]\n",
            " [  26  243   48   63   47   19   83   11  395   39]\n",
            " [  15   22   17   10  127    9    9   51    6  743]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59625, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [21 24 65 58 37 66 34 32 98 65] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.476 s \n",
            "\n",
            "Accuracy rate for 72.810000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.72      0.97      0.83       980\n",
            "        1.0       0.62      0.99      0.76      1135\n",
            "        2.0       0.78      0.56      0.65      1032\n",
            "        3.0       0.72      0.69      0.71      1010\n",
            "        4.0       0.74      0.80      0.77       982\n",
            "        5.0       0.78      0.47      0.58       892\n",
            "        6.0       0.72      0.91      0.80       958\n",
            "        7.0       0.81      0.82      0.81      1028\n",
            "        8.0       0.89      0.36      0.51       974\n",
            "        9.0       0.72      0.67      0.70      1009\n",
            "\n",
            "avg / total       0.75      0.73      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 955    2    3    2    1    1   10    5    1    0]\n",
            " [   0 1119    6    0    0    1    6    2    0    1]\n",
            " [  68  188  573   45   30    1   88   20    1   18]\n",
            " [  65   80   49  699    4   38   11   20   19   25]\n",
            " [   1   22    1    3  783   13   64   13    2   80]\n",
            " [ 162   53    8  102   47  415   41   23   12   29]\n",
            " [  25   28    5    0   12    8  870   10    0    0]\n",
            " [  16   46   38    0   26    6    5  838    0   53]\n",
            " [  22  245   42  108   32   21   91    9  349   55]\n",
            " [  13   31    8   12  120   29   19   90    7  680]]\n",
            "--------------------------------\n",
            "final active learning accuracies [71.11, 72.42, 72.0, 72.81]\n",
            "saved Active-learning-experiment-37.pkl /content ['datalab', 'Active-learning-experiment-32.pkl', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-33.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-29.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 38, using model = LogModel, selection_function = MarginSamplingSelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [6 7 6 1 6 2 6 5 7 4] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.344 s \n",
            "\n",
            "Accuracy rate for 62.800000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.61      0.80      0.69       980\n",
            "        1.0       0.71      0.98      0.82      1135\n",
            "        2.0       0.67      0.41      0.51      1032\n",
            "        3.0       0.61      0.22      0.32      1010\n",
            "        4.0       0.75      0.73      0.74       982\n",
            "        5.0       0.46      0.28      0.35       892\n",
            "        6.0       0.59      0.85      0.70       958\n",
            "        7.0       0.80      0.76      0.78      1028\n",
            "        8.0       0.44      0.63      0.52       974\n",
            "        9.0       0.61      0.57      0.59      1009\n",
            "\n",
            "avg / total       0.63      0.63      0.61     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 781    1   18    7    3  107   39    1    1   22]\n",
            " [   0 1115    0    9    1    0    6    2    2    0]\n",
            " [  50   97  419   35   55   22  261   20   64    9]\n",
            " [ 165   26   15  222    3   77   45   11  424   22]\n",
            " [   0   38   20    8  718   13   51    7   28   99]\n",
            " [ 196   57   20   44   29  250   77   20  117   82]\n",
            " [  27   11   75    3   12   18  810    0    1    1]\n",
            " [  17   86    3   16   22    1    7  778   32   66]\n",
            " [  29  114   21   10   17   46   55    7  609   66]\n",
            " [  12   33   32    7   94    7   11  126  109  578]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 0. ... 9. 8. 8.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 0 ... 9 8 8]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 9  8  8  5  9 12 11 11 14 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.358 s \n",
            "\n",
            "Accuracy rate for 70.190000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.93      0.82       980\n",
            "        1.0       0.72      0.97      0.82      1135\n",
            "        2.0       0.77      0.52      0.62      1032\n",
            "        3.0       0.64      0.65      0.65      1010\n",
            "        4.0       0.76      0.63      0.69       982\n",
            "        5.0       0.55      0.29      0.39       892\n",
            "        6.0       0.67      0.90      0.77       958\n",
            "        7.0       0.81      0.76      0.78      1028\n",
            "        8.0       0.60      0.70      0.65       974\n",
            "        9.0       0.74      0.61      0.67      1009\n",
            "\n",
            "avg / total       0.70      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 911    0   23   12    1    1   22    2    8    0]\n",
            " [   0 1098    0    1    0    1    5    2   28    0]\n",
            " [  46   60  532   30   28    0  199   64   70    3]\n",
            " [  50   79   29  656    2   43   22   17   97   15]\n",
            " [   0   33   17    5  619   70   63   23   27  125]\n",
            " [ 110   63   11  199   27  263   60    3  126   30]\n",
            " [  26    9   14    9    6    9  864    4   17    0]\n",
            " [  69   53    5   27   12    5   13  780   38   26]\n",
            " [  25   96   16   76    3   21   33    8  685   11]\n",
            " [  15   39   41    7  121   61   13   58   43  611]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [10  9 10 10 18 19 16 15 20 23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.382 s \n",
            "\n",
            "Accuracy rate for 68.390000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.93      0.82       980\n",
            "        1.0       0.70      0.98      0.82      1135\n",
            "        2.0       0.69      0.62      0.65      1032\n",
            "        3.0       0.58      0.66      0.62      1010\n",
            "        4.0       0.73      0.70      0.72       982\n",
            "        5.0       0.58      0.09      0.16       892\n",
            "        6.0       0.67      0.86      0.75       958\n",
            "        7.0       0.82      0.69      0.75      1028\n",
            "        8.0       0.57      0.66      0.61       974\n",
            "        9.0       0.72      0.55      0.63      1009\n",
            "\n",
            "avg / total       0.68      0.68      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 915    1   16   19    1    0   21    0    7    0]\n",
            " [   0 1112    3    3    0    1    8    2    6    0]\n",
            " [  32   72  640   46   29    0  131   28   47    7]\n",
            " [  38   27   86  666    3   21   22   13  127    7]\n",
            " [   4   50   11    6  692    9   46   10   16  138]\n",
            " [  64   56   51  323   34   83   86    5  179   11]\n",
            " [  21   13   51    4   25    0  820    8   16    0]\n",
            " [ 146   84    5    6   12    3    4  709   16   43]\n",
            " [  15  117   41   61    7    2   65   12  645    9]\n",
            " [  24   50   23   13  144   25   16   75   82  557]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [11 10 16 13 21 29 17 19 29 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.395 s \n",
            "\n",
            "Accuracy rate for 71.650000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.94      0.86       980\n",
            "        1.0       0.65      0.99      0.78      1135\n",
            "        2.0       0.78      0.58      0.67      1032\n",
            "        3.0       0.64      0.68      0.66      1010\n",
            "        4.0       0.79      0.77      0.78       982\n",
            "        5.0       0.88      0.17      0.29       892\n",
            "        6.0       0.68      0.89      0.77       958\n",
            "        7.0       0.83      0.81      0.82      1028\n",
            "        8.0       0.56      0.59      0.58       974\n",
            "        9.0       0.77      0.66      0.71      1009\n",
            "\n",
            "avg / total       0.74      0.72      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 919    1    5   11    2    0   26    2   14    0]\n",
            " [   0 1124    1    0    0    1    4    2    3    0]\n",
            " [  47  123  602   24   13    1  119   40   48   15]\n",
            " [  21   56   70  682    3   10   16   18  116   18]\n",
            " [   8   48    8    1  753    2   55   13   21   73]\n",
            " [  41   52    9  280   44  156   71    9  188   42]\n",
            " [  42   13   12    3   17    3  852   10    6    0]\n",
            " [  36   71   13    5   23    2    6  829   11   32]\n",
            " [  16  185   36   37   12    1   80   11  579   17]\n",
            " [  29   58   12   20   84    2   16   68   51  669]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [12 10 21 21 30 39 18 23 35 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.457 s \n",
            "\n",
            "Accuracy rate for 69.440000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.93      0.84       980\n",
            "        1.0       0.64      0.99      0.78      1135\n",
            "        2.0       0.69      0.55      0.61      1032\n",
            "        3.0       0.59      0.71      0.65      1010\n",
            "        4.0       0.77      0.74      0.76       982\n",
            "        5.0       0.97      0.14      0.24       892\n",
            "        6.0       0.70      0.89      0.79       958\n",
            "        7.0       0.82      0.75      0.78      1028\n",
            "        8.0       0.54      0.60      0.57       974\n",
            "        9.0       0.80      0.56      0.66      1009\n",
            "\n",
            "avg / total       0.73      0.69      0.67     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 911    1    0   21    2    0   22    6   17    0]\n",
            " [   0 1121    0    1    0    0    7    3    3    0]\n",
            " [  63  157  564   39   15    1  111   34   46    2]\n",
            " [  27   56   13  718    2    0   18   12  143   21]\n",
            " [  13   59   54    4  731    1   37   14   12   57]\n",
            " [  38   50    6  323   44  122   69   21  197   22]\n",
            " [  32   10   15   13   11    0  857   12    8    0]\n",
            " [  63   81   48    2   26    0    5  767    9   27]\n",
            " [  18  146   36   65   12    0   83   10  589   15]\n",
            " [  29   57   79   24  106    2   15   57   76  564]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [13 10 27 28 36 45 18 25 44 54] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.441 s \n",
            "\n",
            "Accuracy rate for 70.940000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.97      0.82       980\n",
            "        1.0       0.67      0.99      0.80      1135\n",
            "        2.0       0.76      0.55      0.64      1032\n",
            "        3.0       0.62      0.73      0.67      1010\n",
            "        4.0       0.79      0.74      0.76       982\n",
            "        5.0       0.91      0.15      0.25       892\n",
            "        6.0       0.68      0.88      0.77       958\n",
            "        7.0       0.86      0.76      0.80      1028\n",
            "        8.0       0.57      0.60      0.58       974\n",
            "        9.0       0.82      0.64      0.72      1009\n",
            "\n",
            "avg / total       0.74      0.71      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 953    3    2    3    0    0   12    1    6    0]\n",
            " [   0 1122    0    2    0    0    8    3    0    0]\n",
            " [  77  149  570   46   10    0  121   28   30    1]\n",
            " [  40   41   14  741    5    1   23   15  120   10]\n",
            " [  11   51   40    6  725    5   45    3   11   85]\n",
            " [  71   47    2  285   58  132   68   16  202   11]\n",
            " [  47    7   18   16   15    3  840    6    6    0]\n",
            " [  84   65   32    2   23    0    6  779    8   29]\n",
            " [  23  127   19   85   12    1  100   11  586   10]\n",
            " [  36   58   52   17   74    3   14   48   61  646]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 0. ... 9. 0. 7.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 0 ... 9 0 7]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [14 11 29 37 45 48 21 29 48 68] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.477 s \n",
            "\n",
            "Accuracy rate for 70.700000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.97      0.86       980\n",
            "        1.0       0.59      0.99      0.74      1135\n",
            "        2.0       0.79      0.58      0.67      1032\n",
            "        3.0       0.61      0.73      0.66      1010\n",
            "        4.0       0.80      0.70      0.75       982\n",
            "        5.0       0.93      0.24      0.38       892\n",
            "        6.0       0.66      0.90      0.76       958\n",
            "        7.0       0.90      0.74      0.81      1028\n",
            "        8.0       0.61      0.56      0.58       974\n",
            "        9.0       0.76      0.59      0.67      1009\n",
            "\n",
            "avg / total       0.74      0.71      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 955    2    2    2    0    0   10    1    8    0]\n",
            " [   0 1125    1    1    0    0    7    1    0    0]\n",
            " [  55  181  598   35   14    1  110   12   22    4]\n",
            " [  48   69   16  735    0    3   19    5  106    9]\n",
            " [   1   90   10    8  687    2   71    9   16   88]\n",
            " [  55   88    4  287   35  211   65   12  126    9]\n",
            " [  43   14   14    8   11    0  861    4    1    2]\n",
            " [  46   81   38    6   15    0    9  759   13   61]\n",
            " [  21  163   22   78    8    4  123    1  541   13]\n",
            " [  26   84   49   43   90    5   21   39   54  598]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [14 13 33 42 49 61 22 38 53 75] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.545 s \n",
            "\n",
            "Accuracy rate for 70.140000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.97      0.87       980\n",
            "        1.0       0.60      0.99      0.75      1135\n",
            "        2.0       0.80      0.59      0.68      1032\n",
            "        3.0       0.64      0.72      0.68      1010\n",
            "        4.0       0.78      0.65      0.71       982\n",
            "        5.0       0.90      0.23      0.37       892\n",
            "        6.0       0.66      0.89      0.76       958\n",
            "        7.0       0.80      0.79      0.79      1028\n",
            "        8.0       0.58      0.55      0.57       974\n",
            "        9.0       0.75      0.55      0.63      1009\n",
            "\n",
            "avg / total       0.73      0.70      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 953    3    2    1    0    1   11    3    6    0]\n",
            " [   0 1123    3    1    0    0    7    0    1    0]\n",
            " [  52  192  608   21   13    0  100   22   20    4]\n",
            " [  40   67   28  723    0   11   19   13  100    9]\n",
            " [   2   74    6    8  641    2   79   36   19  115]\n",
            " [  60   56    7  246   30  207   83   26  170    7]\n",
            " [  33   16   16    6   10    2  855   14    1    5]\n",
            " [  31   85   36    3   11    0    5  813   11   33]\n",
            " [  17  149   30   85    7    4  123    8  538   13]\n",
            " [  20   99   28   38  105    3   23   86   54  553]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59600,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [15 13 39 47 57 75 25 41 59 79] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.458 s \n",
            "\n",
            "Accuracy rate for 71.170000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.96      0.88       980\n",
            "        1.0       0.60      0.99      0.75      1135\n",
            "        2.0       0.83      0.62      0.71      1032\n",
            "        3.0       0.64      0.73      0.68      1010\n",
            "        4.0       0.76      0.74      0.75       982\n",
            "        5.0       0.86      0.16      0.27       892\n",
            "        6.0       0.68      0.89      0.77       958\n",
            "        7.0       0.76      0.79      0.78      1028\n",
            "        8.0       0.61      0.53      0.56       974\n",
            "        9.0       0.82      0.62      0.71      1009\n",
            "\n",
            "avg / total       0.74      0.71      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    4   10    1    0    0    6    8    8    0]\n",
            " [   0 1124    1    1    0    0    7    0    2    0]\n",
            " [  36  178  640   28   18    1   85   27   12    7]\n",
            " [  36   72   20  738    3    6   21   15   84   15]\n",
            " [   2   65    8    4  724    1   68   59    7   44]\n",
            " [  47   51    3  259   56  144  105   31  182   14]\n",
            " [  44   16    9   11   16    3  848    9    2    0]\n",
            " [  16   90   30    2   28    1    5  817    8   31]\n",
            " [  14  168   28   92   21    8   96   11  513   23]\n",
            " [  16   90   24   26   84    3   12  100   28  626]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [16 13 41 54 66 83 25 46 67 89] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.534 s \n",
            "\n",
            "Accuracy rate for 70.210000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.95      0.84       980\n",
            "        1.0       0.59      0.99      0.74      1135\n",
            "        2.0       0.81      0.62      0.70      1032\n",
            "        3.0       0.58      0.71      0.64      1010\n",
            "        4.0       0.84      0.62      0.71       982\n",
            "        5.0       0.85      0.29      0.43       892\n",
            "        6.0       0.65      0.87      0.75       958\n",
            "        7.0       0.75      0.80      0.77      1028\n",
            "        8.0       0.68      0.49      0.57       974\n",
            "        9.0       0.80      0.61      0.69      1009\n",
            "\n",
            "avg / total       0.73      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 935    4   18    0    0    0   10    5    8    0]\n",
            " [   0 1121    3    1    0    1    8    0    1    0]\n",
            " [  53  168  643    8   11    1   97   24   22    5]\n",
            " [  40   83   46  716    0   20   24    9   62   10]\n",
            " [   8   76    7    4  605    3   74   91   30   84]\n",
            " [  49   67    5  313   22  257   99   25   49    6]\n",
            " [  61   19   13    6    5    4  836   13    1    0]\n",
            " [  36   89   24    4   12    0    4  818   12   29]\n",
            " [  25  172   20  125    8    8  115   10  474   17]\n",
            " [  28   87   16   48   54    7   19   98   36  616]]\n",
            "--------------------------------\n",
            "final active learning accuracies [62.8, 70.19, 68.39, 71.65, 69.44, 70.94, 70.7, 70.14, 71.17, 70.21]\n",
            "saved Active-learning-experiment-38.pkl /content ['datalab', 'Active-learning-experiment-32.pkl', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-38.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-33.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-29.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 39, using model = LogModel, selection_function = MarginSamplingSelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [4 4 3 1 1 3 0 5 3 1] [0 1 2 3 4 5 7 8 9]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n",
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.307 s \n",
            "\n",
            "Accuracy rate for 41.980000 \n",
            "Classification report for classifier LogisticRegression(C=2.0, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.42      0.74      0.53       980\n",
            "        1.0       0.82      0.90      0.86      1135\n",
            "        2.0       0.37      0.68      0.48      1032\n",
            "        3.0       0.36      0.24      0.29      1010\n",
            "        4.0       0.39      0.31      0.35       982\n",
            "        5.0       0.49      0.26      0.34       892\n",
            "        6.0       0.00      0.00      0.00       958\n",
            "        7.0       0.60      0.38      0.47      1028\n",
            "        8.0       0.25      0.40      0.31       974\n",
            "        9.0       0.19      0.19      0.19      1009\n",
            "\n",
            "avg / total       0.40      0.42      0.39     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 726    0  159   36    0   22    0    0   29    8]\n",
            " [  30 1019    3    7    2    1    0    1   39   33]\n",
            " [ 197   33  703   20    6    3    0    6   46   18]\n",
            " [  82   47  384  238    4   18    0   15  178   44]\n",
            " [  80   18   71  103  308   57    0   42  177  126]\n",
            " [ 184   22  106   81   28  234    0   10  156   71]\n",
            " [ 302   29  368    2   13   56    0    0  172   16]\n",
            " [  10   16    9    3   89    5    0  392  106  398]\n",
            " [ 101   53   96  147   23   78    0   21  390   65]\n",
            " [  25    7   27   20  319    3    0  161  259  188]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59975,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59975, 9) \n",
            " [0 0 0 ... 8 8 8]\n",
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [ 5  4  3  1  8  7  3  6 11  2] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.346 s \n",
            "\n",
            "Accuracy rate for 52.120000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.53      0.77      0.63       980\n",
            "        1.0       0.84      0.89      0.87      1135\n",
            "        2.0       0.32      0.50      0.39      1032\n",
            "        3.0       0.00      0.00      0.00      1010\n",
            "        4.0       0.47      0.79      0.59       982\n",
            "        5.0       0.84      0.17      0.29       892\n",
            "        6.0       0.83      0.71      0.76       958\n",
            "        7.0       0.76      0.31      0.44      1028\n",
            "        8.0       0.45      0.74      0.56       974\n",
            "        9.0       0.26      0.28      0.27      1009\n",
            "\n",
            "avg / total       0.53      0.52      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 757    0  151    0    2    1   34   14   13    8]\n",
            " [   2 1010    3    0    0    1    3    0   91   25]\n",
            " [ 189   51  512    0   72    1   54   13   59   81]\n",
            " [ 138   42  508    0   22   12    8    2  232   46]\n",
            " [   0    8   11    0  779    0   20   25   32  107]\n",
            " [ 222    9  144    0   69  154   14    2  198   80]\n",
            " [  82    6  108    0   35    2  678    6   40    1]\n",
            " [   5   46    7    0  112    4    2  317  103  432]\n",
            " [  22   16  117    0   36    6    3    9  719   46]\n",
            " [  14   12   15    0  540    2    5   29  106  286]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59950,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [ 5  7  7  3 10 11  5 10 12  5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.349 s \n",
            "\n",
            "Accuracy rate for 65.400000 \n",
            "Classification report for classifier LogisticRegression(C=0.6666666666666666, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.68      0.83      0.75       980\n",
            "        1.0       0.73      0.97      0.84      1135\n",
            "        2.0       0.64      0.73      0.68      1032\n",
            "        3.0       0.70      0.39      0.50      1010\n",
            "        4.0       0.54      0.80      0.64       982\n",
            "        5.0       0.82      0.33      0.47       892\n",
            "        6.0       0.88      0.63      0.74       958\n",
            "        7.0       0.83      0.65      0.73      1028\n",
            "        8.0       0.49      0.78      0.60       974\n",
            "        9.0       0.51      0.36      0.42      1009\n",
            "\n",
            "avg / total       0.68      0.65      0.64     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 813    1   75   15    6   11    6   13   28   12]\n",
            " [   1 1102    0    1    0    0    3    0   26    2]\n",
            " [  45  109  754   20   19    1   14   24   33   13]\n",
            " [  66   81   52  393   21   10    3   21  349   14]\n",
            " [   1   24   41    0  786    0   12    7   25   86]\n",
            " [ 148   23   15  101   61  297   14   16  202   15]\n",
            " [  83   15  194    1   47    5  603    0   10    0]\n",
            " [  12   63   20    0   43    5    1  671   30  183]\n",
            " [  13   67   16   29   23   17   26    7  761   15]\n",
            " [  11   19   15    1  459   17    0   49   78  360]]\n",
            "--------------------------------\n",
            "val predicted: (59925,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59925, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 5  7  7 10 11 19  6 11 14 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.357 s \n",
            "\n",
            "Accuracy rate for 64.840000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.62      0.81      0.70       980\n",
            "        1.0       0.74      0.97      0.84      1135\n",
            "        2.0       0.62      0.69      0.65      1032\n",
            "        3.0       0.63      0.60      0.61      1010\n",
            "        4.0       0.56      0.61      0.58       982\n",
            "        5.0       0.72      0.15      0.25       892\n",
            "        6.0       0.82      0.65      0.72       958\n",
            "        7.0       0.80      0.79      0.80      1028\n",
            "        8.0       0.54      0.73      0.62       974\n",
            "        9.0       0.51      0.39      0.44      1009\n",
            "\n",
            "avg / total       0.66      0.65      0.63     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 794    1   76   26    0   23    5   23   29    3]\n",
            " [   0 1098    0    7    0    0    4    1   23    2]\n",
            " [  57  126  713   21    9    2   22   48   29    5]\n",
            " [  65   33   57  607    3    1    9   19  205   11]\n",
            " [   1   29   49    0  597    4   21   12   22  247]\n",
            " [ 227   26   16  223   27  132   25    9  196   11]\n",
            " [  89   17  183    4   12    4  619    6    7   17]\n",
            " [  17   52   15    2   32    4    2  817   13   74]\n",
            " [  12   70   32   61    8    5   44   13  713   16]\n",
            " [  11   23   10   16  384    8    2   76   85  394]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 0. ... 4. 9. 3.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 0 ... 4 9 3]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [ 7  7  9 13 15 24  6 13 15 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.373 s \n",
            "\n",
            "Accuracy rate for 65.100000 \n",
            "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.68      0.82      0.74       980\n",
            "        1.0       0.73      0.97      0.83      1135\n",
            "        2.0       0.58      0.65      0.61      1032\n",
            "        3.0       0.64      0.56      0.60      1010\n",
            "        4.0       0.58      0.69      0.63       982\n",
            "        5.0       0.60      0.22      0.32       892\n",
            "        6.0       0.86      0.57      0.69       958\n",
            "        7.0       0.87      0.63      0.73      1028\n",
            "        8.0       0.50      0.76      0.61       974\n",
            "        9.0       0.60      0.56      0.58      1009\n",
            "\n",
            "avg / total       0.67      0.65      0.64     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 801    1    5   18    1   87    4   10   49    4]\n",
            " [   0 1098    2    5    0    0    3    0   27    0]\n",
            " [  46  183  671   18   19    0   22   15   56    2]\n",
            " [  30   50   26  566   18    1    6   16  293    4]\n",
            " [   2   16   97    2  676    2    9    5   19  154]\n",
            " [ 127   14   31  219   61  192   12   14  204   18]\n",
            " [ 129   14  177    3   36    4  548    3   18   26]\n",
            " [  23   59   82    2   53    8    2  649   15  135]\n",
            " [   9   54   35   31   22   13   27    1  742   40]\n",
            " [  10   17   34   14  271   14    1   29   52  567]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) [0. 0. 8. ... 9. 9. 3.]\n",
            "probabilities: (59875, 10) \n",
            " [0 0 8 ... 9 9 3]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 8  7 14 14 17 29  8 15 18 20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.366 s \n",
            "\n",
            "Accuracy rate for 64.140000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.67      0.92      0.77       980\n",
            "        1.0       0.71      0.97      0.82      1135\n",
            "        2.0       0.69      0.55      0.61      1032\n",
            "        3.0       0.66      0.34      0.45      1010\n",
            "        4.0       0.63      0.62      0.62       982\n",
            "        5.0       0.77      0.22      0.35       892\n",
            "        6.0       0.77      0.75      0.76       958\n",
            "        7.0       0.81      0.64      0.71      1028\n",
            "        8.0       0.43      0.77      0.55       974\n",
            "        9.0       0.55      0.57      0.56      1009\n",
            "\n",
            "avg / total       0.67      0.64      0.63     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 897    2   11    7    0   19    6    7   25    6]\n",
            " [   0 1105    1    4    0    0    4    0   21    0]\n",
            " [ 112  198  566   17   23    1   53   27   31    4]\n",
            " [  58   55   51  340    4    3   11   18  459   11]\n",
            " [   1   20   22    3  608    3   41   28   45  211]\n",
            " [ 133   16   25  107   23  199   37   12  329   11]\n",
            " [  96   15   83    2   13    3  717   10   14    5]\n",
            " [  22   66   27    5   30   14    4  657   16  187]\n",
            " [  12   64   19   20    8    6   61    7  754   23]\n",
            " [   9   15   12   10  256   10    2   46   78  571]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [10  7 16 16 24 35  9 16 18 24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.375 s \n",
            "\n",
            "Accuracy rate for 65.870000 \n",
            "Classification report for classifier LogisticRegression(C=0.2857142857142857, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.66      0.97      0.79       980\n",
            "        1.0       0.70      0.98      0.82      1135\n",
            "        2.0       0.76      0.48      0.59      1032\n",
            "        3.0       0.67      0.55      0.60      1010\n",
            "        4.0       0.57      0.59      0.58       982\n",
            "        5.0       0.87      0.22      0.35       892\n",
            "        6.0       0.75      0.70      0.73       958\n",
            "        7.0       0.79      0.62      0.70      1028\n",
            "        8.0       0.53      0.75      0.62       974\n",
            "        9.0       0.56      0.65      0.60      1009\n",
            "\n",
            "avg / total       0.69      0.66      0.64     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 954    2    2    3    1    2    4    2    9    1]\n",
            " [   0 1110    0    4    1    0    5    0   15    0]\n",
            " [ 125  188  496   33   54    1   61   34   31    9]\n",
            " [  65   75   25  551    8    2   11   21  242   10]\n",
            " [   5   20   13    2  583    2   41   29   31  256]\n",
            " [ 103   21    5  183   82  193   41    9  240   15]\n",
            " [ 134   12   71    1   31    0  673   16   10   10]\n",
            " [  20   58   23    2   65    5    5  640   12  198]\n",
            " [  23   71   12   29    9    6   54   12  735   23]\n",
            " [  15   19    9   14  182   11    2   45   60  652]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59825,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59825, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [11  7 20 18 27 41 12 19 18 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.413 s \n",
            "\n",
            "Accuracy rate for 66.990000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.62      0.94      0.75       980\n",
            "        1.0       0.72      0.97      0.83      1135\n",
            "        2.0       0.71      0.56      0.63      1032\n",
            "        3.0       0.63      0.53      0.58      1010\n",
            "        4.0       0.62      0.73      0.67       982\n",
            "        5.0       0.77      0.25      0.38       892\n",
            "        6.0       0.70      0.72      0.71       958\n",
            "        7.0       0.79      0.71      0.75      1028\n",
            "        8.0       0.54      0.72      0.62       974\n",
            "        9.0       0.75      0.49      0.59      1009\n",
            "\n",
            "avg / total       0.69      0.67      0.65     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 925    2   19    8    0    1   14    3    8    0]\n",
            " [   0 1100    0    4    4    1    3    0   23    0]\n",
            " [ 129  153  582   15   27    0   78   30   15    3]\n",
            " [  96   77   28  540   16   12   10   16  208    7]\n",
            " [   3   23   28    9  715   14   62   23   45   60]\n",
            " [ 145   12   35  208   47  227   26   13  175    4]\n",
            " [ 124   19   64    2   18    4  685   22   14    6]\n",
            " [  35   56   29    2   79    2    7  732   10   76]\n",
            " [  24   64   19   35   21   10   76   16  698   11]\n",
            " [  15   21   19   31  222   24   24   68   90  495]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 0. ... 5. 9. 7.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 5 9 7]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [12  7 20 22 29 44 13 23 21 34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.390 s \n",
            "\n",
            "Accuracy rate for 70.110000 \n",
            "Classification report for classifier LogisticRegression(C=0.2222222222222222, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.66      0.97      0.79       980\n",
            "        1.0       0.72      0.97      0.83      1135\n",
            "        2.0       0.72      0.60      0.66      1032\n",
            "        3.0       0.68      0.63      0.65      1010\n",
            "        4.0       0.70      0.70      0.70       982\n",
            "        5.0       0.83      0.24      0.38       892\n",
            "        6.0       0.70      0.80      0.75       958\n",
            "        7.0       0.85      0.72      0.78      1028\n",
            "        8.0       0.56      0.72      0.63       974\n",
            "        9.0       0.77      0.58      0.66      1009\n",
            "\n",
            "avg / total       0.72      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 950    2   13    0    1    0    7    3    4    0]\n",
            " [   0 1101    0    6    0    1    4    0   23    0]\n",
            " [  72  157  621   19   24    0   99   30   10    0]\n",
            " [  88   59   38  635    7    4    8    7  159    5]\n",
            " [   2   21   21    8  691   11   83   16   35   94]\n",
            " [ 143   14   38  187   40  217   33   10  202    8]\n",
            " [  99    9   62    2    3    3  767    9    4    0]\n",
            " [  43   71   27   12   55    7    9  744   10   50]\n",
            " [  15   74   26   45   13    4   75    7  697   18]\n",
            " [  19   20   16   24  159   15   15   52  101  588]]\n",
            "--------------------------------\n",
            "val predicted: (59775,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59775, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [13  8 22 24 33 48 14 27 23 38] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.403 s \n",
            "\n",
            "Accuracy rate for 70.440000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.97      0.82       980\n",
            "        1.0       0.70      0.98      0.81      1135\n",
            "        2.0       0.71      0.63      0.67      1032\n",
            "        3.0       0.67      0.64      0.65      1010\n",
            "        4.0       0.71      0.74      0.72       982\n",
            "        5.0       0.84      0.14      0.24       892\n",
            "        6.0       0.75      0.81      0.78       958\n",
            "        7.0       0.82      0.73      0.77      1028\n",
            "        8.0       0.54      0.67      0.60       974\n",
            "        9.0       0.76      0.65      0.70      1009\n",
            "\n",
            "avg / total       0.72      0.70      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    2    6    0    2    0   10    1    7    0]\n",
            " [   0 1113    5    4    0    1    3    0    9    0]\n",
            " [  81  160  652   10   28    0   54   35    7    5]\n",
            " [  57   79   31  643   10    4    8   12  151   15]\n",
            " [   7   15   25   13  730    5   76   12   33   66]\n",
            " [ 105   17   42  222   62  125   33   12  260   14]\n",
            " [  76   18   52    1   14    3  776    8   10    0]\n",
            " [  28   64   37    4   47    1    4  748    6   89]\n",
            " [  14  111   44   41   17    4   63   10  650   20]\n",
            " [  23   20   22   22  122    6   10   69   60  655]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 7. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 7 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [13  8 25 26 35 54 14 31 25 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.395 s \n",
            "\n",
            "Accuracy rate for 67.210000 \n",
            "Classification report for classifier LogisticRegression(C=0.18181818181818182, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.66      0.97      0.79       980\n",
            "        1.0       0.70      0.97      0.82      1135\n",
            "        2.0       0.72      0.65      0.68      1032\n",
            "        3.0       0.69      0.59      0.63      1010\n",
            "        4.0       0.77      0.68      0.72       982\n",
            "        5.0       0.77      0.28      0.41       892\n",
            "        6.0       0.74      0.79      0.76       958\n",
            "        7.0       0.90      0.33      0.49      1028\n",
            "        8.0       0.52      0.69      0.59       974\n",
            "        9.0       0.54      0.71      0.62      1009\n",
            "\n",
            "avg / total       0.70      0.67      0.65     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 955    2    4    1    0    0   12    0    6    0]\n",
            " [   0 1102    9    3    0    1    3    1   16    0]\n",
            " [  91  141  667   31   14    0   53   15   12    8]\n",
            " [  71   67   23  591    1   14   12    4  215   12]\n",
            " [  18   17   26    1  672   28   57    2   49  112]\n",
            " [ 110   19   49  182   20  252   30    6  216    8]\n",
            " [  78   26   62    2   16    6  753    0   13    2]\n",
            " [  78   55   47    0   51    3    3  344   11  436]\n",
            " [  16  110   21   40    7    4   84    2  668   22]\n",
            " [  31   30   21   11   95   18    5    9   72  717]]\n",
            "--------------------------------\n",
            "val predicted: (59725,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59725, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [13  8 28 29 36 60 17 32 27 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.394 s \n",
            "\n",
            "Accuracy rate for 71.170000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.77      0.96      0.85       980\n",
            "        1.0       0.72      0.97      0.83      1135\n",
            "        2.0       0.72      0.71      0.71      1032\n",
            "        3.0       0.75      0.61      0.67      1010\n",
            "        4.0       0.53      0.89      0.66       982\n",
            "        5.0       0.83      0.36      0.50       892\n",
            "        6.0       0.79      0.82      0.81       958\n",
            "        7.0       0.88      0.72      0.79      1028\n",
            "        8.0       0.59      0.67      0.62       974\n",
            "        9.0       0.81      0.36      0.50      1009\n",
            "\n",
            "avg / total       0.74      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 936    2    7    1    4    1   19    3    7    0]\n",
            " [   0 1101   11    3    0    1    3    1   15    0]\n",
            " [  46  130  728   21   46    2   39   13    6    1]\n",
            " [  49   79   58  614   13   18   14   11  150    4]\n",
            " [   5    7    9    1  871   13   31    7   18   20]\n",
            " [  68   23   29  118   68  323   40   10  200   13]\n",
            " [  43    9   68    2   28    5  789    0   14    0]\n",
            " [  33   52   43    2  120    0    0  739    4   35]\n",
            " [  14  107   35   42   35   12   62    1  651   15]\n",
            " [  17   19   19   14  458   16    3   52   46  365]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59700,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [13  8 30 36 36 65 17 33 31 56] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.416 s \n",
            "\n",
            "Accuracy rate for 70.330000 \n",
            "Classification report for classifier LogisticRegression(C=0.15384615384615385, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.66      0.97      0.79       980\n",
            "        1.0       0.63      0.99      0.77      1135\n",
            "        2.0       0.71      0.64      0.67      1032\n",
            "        3.0       0.65      0.71      0.68      1010\n",
            "        4.0       0.77      0.70      0.73       982\n",
            "        5.0       0.85      0.27      0.41       892\n",
            "        6.0       0.74      0.72      0.73       958\n",
            "        7.0       0.86      0.68      0.76      1028\n",
            "        8.0       0.65      0.60      0.62       974\n",
            "        9.0       0.74      0.67      0.70      1009\n",
            "\n",
            "avg / total       0.72      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 953    2    1    2    0    0   18    1    3    0]\n",
            " [   0 1119    3    4    0    1    2    0    6    0]\n",
            " [  88  182  658   24   12    0   34   15   16    3]\n",
            " [  66   96   35  720    4    6    9    5   58   11]\n",
            " [  14   19   20    3  692    8   84   17   32   93]\n",
            " [ 126   38   44  238   28  244   28    8  128   10]\n",
            " [ 109   35   90    0   19    0  692    5    7    1]\n",
            " [  39   65   41    8   38    5    0  697   17  118]\n",
            " [  20  193   22   77    7    4   62    5  580    4]\n",
            " [  20   40   15   24  104   19   11   53   45  678]]\n",
            "--------------------------------\n",
            "val predicted: (59675,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59675, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [13  9 36 37 41 69 18 36 31 60] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.466 s \n",
            "\n",
            "Accuracy rate for 70.120000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.69      0.97      0.81       980\n",
            "        1.0       0.65      0.99      0.78      1135\n",
            "        2.0       0.73      0.65      0.69      1032\n",
            "        3.0       0.68      0.64      0.66      1010\n",
            "        4.0       0.76      0.71      0.73       982\n",
            "        5.0       0.86      0.19      0.32       892\n",
            "        6.0       0.72      0.78      0.75       958\n",
            "        7.0       0.84      0.75      0.79      1028\n",
            "        8.0       0.53      0.67      0.59       974\n",
            "        9.0       0.82      0.59      0.68      1009\n",
            "\n",
            "avg / total       0.73      0.70      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 953    3    5    1    0    0   10    1    7    0]\n",
            " [   0 1122    3    1    0    1    2    1    5    0]\n",
            " [  58  146  668   11   12    0   59   27   46    5]\n",
            " [  70  109   79  644    6    4   11    7   72    8]\n",
            " [  10   31   11    5  693    6   98   18   53   57]\n",
            " [ 122   47   27  205   39  173   29   13  224   13]\n",
            " [  94   20   68    0   11    2  747    2   14    0]\n",
            " [  31   66   20    5   46    2    6  772   34   46]\n",
            " [  19  145   27   57   13    2   57    2  649    3]\n",
            " [  19   47    6   25   87   10   21   76  127  591]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [14  9 39 41 44 72 18 39 34 65] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.428 s \n",
            "\n",
            "Accuracy rate for 71.600000 \n",
            "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.94      0.83       980\n",
            "        1.0       0.63      0.99      0.77      1135\n",
            "        2.0       0.67      0.64      0.65      1032\n",
            "        3.0       0.75      0.58      0.65      1010\n",
            "        4.0       0.80      0.67      0.73       982\n",
            "        5.0       0.84      0.36      0.50       892\n",
            "        6.0       0.67      0.82      0.74       958\n",
            "        7.0       0.79      0.81      0.80      1028\n",
            "        8.0       0.63      0.63      0.63       974\n",
            "        9.0       0.81      0.66      0.73      1009\n",
            "\n",
            "avg / total       0.73      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 924    2    8    2    0    0   34    6    4    0]\n",
            " [   0 1122    1    3    0    1    2    1    5    0]\n",
            " [  60  155  656   13   12    0   77   34   23    2]\n",
            " [  58  141   84  585    4   14   14   13   91    6]\n",
            " [   6   30   21    2  654   17  111   37   14   90]\n",
            " [  93   49   37  134   27  321   44   17  159   11]\n",
            " [  45   16   86    2   10    4  786    3    6    0]\n",
            " [  17   67   22    1   30    2    7  833    9   40]\n",
            " [  15  150   57   36   11    7   72    6  618    2]\n",
            " [  22   47   14    4   66   15   24  107   49  661]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59625, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [14  9 42 44 48 77 19 40 37 70] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.453 s \n",
            "\n",
            "Accuracy rate for 70.300000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.72      0.97      0.82       980\n",
            "        1.0       0.60      0.99      0.74      1135\n",
            "        2.0       0.67      0.65      0.66      1032\n",
            "        3.0       0.62      0.55      0.58      1010\n",
            "        4.0       0.82      0.67      0.74       982\n",
            "        5.0       0.80      0.35      0.48       892\n",
            "        6.0       0.68      0.86      0.76       958\n",
            "        7.0       0.76      0.81      0.78      1028\n",
            "        8.0       0.73      0.53      0.61       974\n",
            "        9.0       0.85      0.60      0.70      1009\n",
            "\n",
            "avg / total       0.72      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 946    2   10    0    0    0   19    0    3    0]\n",
            " [   0 1125    1    1    0    0    4    1    3    0]\n",
            " [  59  162  668    2    9    1   79   39    9    4]\n",
            " [  69  167  111  556    1   23   16   14   49    4]\n",
            " [   6   31   20   19  658   20   94   48   22   64]\n",
            " [ 131   53   24  209   18  310   72   20   51    4]\n",
            " [  36   16   68    3    6    3  820    5    1    0]\n",
            " [  29   72   23    1   28    4    6  832    7   26]\n",
            " [  20  208   49   75    8   10   77    7  512    8]\n",
            " [  22   51   17   27   74   18   20  130   47  603]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [14  9 44 45 53 80 20 41 41 78] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.501 s \n",
            "\n",
            "Accuracy rate for 68.160000 \n",
            "Classification report for classifier LogisticRegression(C=0.11764705882352941, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.70      0.95      0.81       980\n",
            "        1.0       0.60      0.99      0.75      1135\n",
            "        2.0       0.69      0.66      0.68      1032\n",
            "        3.0       0.62      0.46      0.53      1010\n",
            "        4.0       0.77      0.73      0.75       982\n",
            "        5.0       0.73      0.29      0.41       892\n",
            "        6.0       0.70      0.85      0.77       958\n",
            "        7.0       0.75      0.82      0.78      1028\n",
            "        8.0       0.56      0.57      0.57       974\n",
            "        9.0       0.87      0.41      0.56      1009\n",
            "\n",
            "avg / total       0.70      0.68      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 935    2   14    0    0    0   23    3    3    0]\n",
            " [   0 1124    2    1    0    1    4    2    1    0]\n",
            " [  63  157  686    4   11    0   66   29   13    3]\n",
            " [  82  171  121  465    4   44   20   13   89    1]\n",
            " [   6   32   22   11  716   19   68   36   39   33]\n",
            " [ 131   55   19  187   25  259   81   17  115    3]\n",
            " [  47   20   52    3    8    5  815    3    5    0]\n",
            " [  23   66   28    1   35    1    2  841   10   21]\n",
            " [  25  198   36   53    8   10   75    8  557    4]\n",
            " [  23   46   20   28  122   18    9  165  160  418]]\n",
            "--------------------------------\n",
            "val predicted: (59575,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59575, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [14  9 44 48 56 87 21 43 43 85] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.499 s \n",
            "\n",
            "Accuracy rate for 69.510000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.74      0.96      0.83       980\n",
            "        1.0       0.63      0.99      0.77      1135\n",
            "        2.0       0.67      0.68      0.67      1032\n",
            "        3.0       0.61      0.48      0.54      1010\n",
            "        4.0       0.72      0.80      0.76       982\n",
            "        5.0       0.81      0.26      0.40       892\n",
            "        6.0       0.71      0.86      0.78       958\n",
            "        7.0       0.76      0.82      0.79      1028\n",
            "        8.0       0.61      0.59      0.60       974\n",
            "        9.0       0.89      0.44      0.59      1009\n",
            "\n",
            "avg / total       0.71      0.70      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    2   13    0    1    0   19    3    2    0]\n",
            " [   0 1120    3    1    0    1    6    2    2    0]\n",
            " [  53  148  700    2   11    0   62   35   19    2]\n",
            " [  65  156  113  486    8   20   32   18  110    2]\n",
            " [   7   28   31   10  788    9   43   25   14   27]\n",
            " [ 113   55   22  203   51  234   79   20  114    1]\n",
            " [  35   12   57    8    8    4  828    3    3    0]\n",
            " [  25   51   31    2   50    1    5  839    6   18]\n",
            " [  16  166   53   56   10   10   77   10  573    3]\n",
            " [  24   41   21   30  175   10   14  152   99  443]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [14  9 46 50 59 91 21 45 47 93] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.530 s \n",
            "\n",
            "Accuracy rate for 69.590000 \n",
            "Classification report for classifier LogisticRegression(C=0.10526315789473684, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.72      0.97      0.82       980\n",
            "        1.0       0.62      0.99      0.76      1135\n",
            "        2.0       0.71      0.66      0.68      1032\n",
            "        3.0       0.67      0.48      0.56      1010\n",
            "        4.0       0.74      0.77      0.75       982\n",
            "        5.0       0.78      0.33      0.47       892\n",
            "        6.0       0.71      0.87      0.78       958\n",
            "        7.0       0.72      0.82      0.77      1028\n",
            "        8.0       0.63      0.60      0.61       974\n",
            "        9.0       0.86      0.40      0.54      1009\n",
            "\n",
            "avg / total       0.71      0.70      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 948    2   11    0    1    0   15    2    1    0]\n",
            " [   0 1121    1    1    0    1    6    2    3    0]\n",
            " [  60  162  686    1    9    0   65   35   13    1]\n",
            " [  80  152  120  484    5   28   33   15   91    2]\n",
            " [   6   30   21    9  761   21   42   39   27   26]\n",
            " [ 118   61   16  148   47  298   97   20   86    1]\n",
            " [  42   18   39    3   10    8  830    3    5    0]\n",
            " [  23   51   25    0   33    1    3  848    9   35]\n",
            " [  26  178   36   54    7   11   69    8  582    3]\n",
            " [  19   43   16   25  161   13   16  213  102  401]]\n",
            "--------------------------------\n",
            "val predicted: (59525,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59525, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [14  9 48 55 61 96 22 45 51 99] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.543 s \n",
            "\n",
            "Accuracy rate for 70.850000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.74      0.96      0.84       980\n",
            "        1.0       0.62      0.99      0.76      1135\n",
            "        2.0       0.68      0.66      0.67      1032\n",
            "        3.0       0.69      0.55      0.62      1010\n",
            "        4.0       0.78      0.74      0.76       982\n",
            "        5.0       0.75      0.37      0.50       892\n",
            "        6.0       0.72      0.87      0.79       958\n",
            "        7.0       0.73      0.83      0.78      1028\n",
            "        8.0       0.68      0.56      0.62       974\n",
            "        9.0       0.83      0.47      0.60      1009\n",
            "\n",
            "avg / total       0.72      0.71      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    2   15    1    1    1   14    2    0    0]\n",
            " [   0 1119    2    2    0    1    6    2    3    0]\n",
            " [  53  152  683    3   14    1   72   37   14    3]\n",
            " [  61  142  110  559    1   32   25   15   57    8]\n",
            " [   3   31   33    6  730   31   50   32   22   44]\n",
            " [ 116   61   18  152   35  334   72   22   81    1]\n",
            " [  34   23   44    0    3   11  836    3    4    0]\n",
            " [  21   50   25    5   23    1    6  857    7   33]\n",
            " [  23  191   50   55    6   12   71   11  546    9]\n",
            " [  18   46   22   24  123   21   13  199   66  477]]\n",
            "--------------------------------\n",
            "final active learning accuracies [41.980000000000004, 52.12, 65.4, 64.84, 65.10000000000001, 64.14, 65.86999999999999, 66.99000000000001, 70.11, 70.44, 67.21000000000001, 71.17, 70.33, 70.12, 71.6, 70.3, 68.16, 69.51, 69.59, 70.85000000000001]\n",
            "saved Active-learning-experiment-39.pkl /content ['datalab', 'Active-learning-experiment-32.pkl', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-38.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-33.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-29.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 40, using model = LogModel, selection_function = MarginSamplingSelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [1 1 3 0 1 3 1] [0 1 2 4 5 6]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n",
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.230 s \n",
            "\n",
            "Accuracy rate for 33.270000 \n",
            "Classification report for classifier LogisticRegression(C=5.0, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.52      0.63      0.56       980\n",
            "        1.0       0.40      0.42      0.41      1135\n",
            "        2.0       0.61      0.65      0.63      1032\n",
            "        3.0       0.00      0.00      0.00      1010\n",
            "        4.0       0.36      0.51      0.43       982\n",
            "        5.0       0.16      0.82      0.26       892\n",
            "        6.0       0.63      0.35      0.45       958\n",
            "        7.0       0.00      0.00      0.00      1028\n",
            "        8.0       0.00      0.00      0.00       974\n",
            "        9.0       0.00      0.00      0.00      1009\n",
            "\n",
            "avg / total       0.27      0.33      0.28     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[613   0  85   0  21 178  83   0   0   0]\n",
            " [  2 474   2   0   0 656   1   0   0   0]\n",
            " [ 35  51 668   0  16 187  75   0   0   0]\n",
            " [ 19  79 137   0   6 767   2   0   0   0]\n",
            " [ 44  44  12   0 503 363  16   0   0   0]\n",
            " [ 67   8  34   0  46 732   5   0   0   0]\n",
            " [131   1  46   0   9 434 337   0   0   0]\n",
            " [156 359  42   0 231 231   9   0   0   0]\n",
            " [ 25  81  51   0  44 769   4   0   0   0]\n",
            " [ 98  77  10   0 508 316   0   0   0   0]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59990,) [0. 0. 5. ... 1. 1. 1.]\n",
            "probabilities: (59990, 6) \n",
            " [0 0 4 ... 1 1 1]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [2 1 3 1 2 3 2 3 1 2] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.323 s \n",
            "\n",
            "Accuracy rate for 56.630000 \n",
            "Classification report for classifier LogisticRegression(C=2.5, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.83      0.78       980\n",
            "        1.0       0.68      0.82      0.74      1135\n",
            "        2.0       0.47      0.57      0.51      1032\n",
            "        3.0       0.43      0.12      0.19      1010\n",
            "        4.0       0.52      0.62      0.57       982\n",
            "        5.0       0.40      0.55      0.46       892\n",
            "        6.0       0.81      0.68      0.74       958\n",
            "        7.0       0.74      0.77      0.75      1028\n",
            "        8.0       0.35      0.34      0.34       974\n",
            "        9.0       0.44      0.33      0.38      1009\n",
            "\n",
            "avg / total       0.56      0.57      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[816   1  50  13   3  44  17   2  30   4]\n",
            " [  0 927  14   0  39  72   4  40   5  34]\n",
            " [ 21  57 592  58  62  53  89  56  40   4]\n",
            " [ 34  15 439 120   7  38   4  30 164 159]\n",
            " [ 10  60   3   0 610 127  10  12  87  63]\n",
            " [ 44   6  63  25  25 492  15  22 129  71]\n",
            " [130  18  23   0  23  85 655   1   7  16]\n",
            " [ 17 116   2   9  37   9   1 789  21  27]\n",
            " [ 32  99  79  46  16 294   9  17 329  53]\n",
            " [ 12  57   6   9 352  11   0 100 129 333]]\n",
            "--------------------------------\n",
            "val predicted: (59980,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59980, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (20, 784) (20,)\n",
            "trainset after (30, 784) (30,)\n",
            "updated train set: (30, 784) (30,) unique(labels): [2 3 3 3 3 4 2 4 2 4] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59970, 784) (59970,)\n",
            "\n",
            "Train set: (30, 784) y: (30,)\n",
            "Val   set: (59970, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.330 s \n",
            "\n",
            "Accuracy rate for 57.710000 \n",
            "Classification report for classifier LogisticRegression(C=1.6666666666666667, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.68      0.74       980\n",
            "        1.0       0.58      0.93      0.72      1135\n",
            "        2.0       0.47      0.59      0.53      1032\n",
            "        3.0       0.37      0.39      0.38      1010\n",
            "        4.0       0.66      0.66      0.66       982\n",
            "        5.0       0.42      0.46      0.44       892\n",
            "        6.0       0.72      0.72      0.72       958\n",
            "        7.0       0.79      0.68      0.73      1028\n",
            "        8.0       0.12      0.00      0.01       974\n",
            "        9.0       0.50      0.59      0.54      1009\n",
            "\n",
            "avg / total       0.55      0.58      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 662    1  120   68    4   18   70   23    5    9]\n",
            " [   0 1059    3   35    0   35    2    0    0    1]\n",
            " [  16   90  612   63   21   32  132   31    2   33]\n",
            " [   5   81  344  394    7   79    4   30   11   55]\n",
            " [  12  108    6    0  653   89   16   11    3   84]\n",
            " [  19   64   72  141   34  412   20   38    3   89]\n",
            " [  84   57   31    1   12   79  687    2    0    5]\n",
            " [   2  114    3   46   14    5    4  696    1  143]\n",
            " [   2  160   92  289   18  216   15    7    4  171]\n",
            " [   6   85   13   31  231    5    2   40    4  592]]\n",
            "--------------------------------\n",
            "val predicted: (59970,) [0. 0. 3. ... 9. 9. 3.]\n",
            "probabilities: (59970, 10) \n",
            " [0 0 3 ... 9 9 3]\n",
            "trainset before (30, 784) (30,)\n",
            "trainset after (40, 784) (40,)\n",
            "updated train set: (40, 784) (40,) unique(labels): [2 3 5 3 5 8 2 6 2 4] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59960, 784) (59960,)\n",
            "\n",
            "Train set: (40, 784) y: (40,)\n",
            "Val   set: (59960, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.346 s \n",
            "\n",
            "Accuracy rate for 61.820000 \n",
            "Classification report for classifier LogisticRegression(C=1.25, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.82      0.82       980\n",
            "        1.0       0.64      0.96      0.77      1135\n",
            "        2.0       0.66      0.62      0.64      1032\n",
            "        3.0       0.35      0.29      0.32      1010\n",
            "        4.0       0.67      0.77      0.72       982\n",
            "        5.0       0.36      0.48      0.41       892\n",
            "        6.0       0.82      0.66      0.73       958\n",
            "        7.0       0.82      0.68      0.74      1028\n",
            "        8.0       0.35      0.26      0.30       974\n",
            "        9.0       0.66      0.59      0.62      1009\n",
            "\n",
            "avg / total       0.62      0.62      0.61     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 804    1   41   26    2   29   35    1   39    2]\n",
            " [   0 1086    2   41    0    5    1    0    0    0]\n",
            " [  16  123  643   65   48    5   66   19   23   24]\n",
            " [  14   25  183  297    0  287    3   22  164   15]\n",
            " [   6   84    1   10  755   19    9    4   26   68]\n",
            " [  26   96   33   87   19  426   14   34  145   12]\n",
            " [  81   43   15    0   46  140  630    1    1    1]\n",
            " [  18   80    4   44   32    1    4  698   16  131]\n",
            " [   8   88   43  249    8  255    9   12  250   52]\n",
            " [  11   60    3   21  209   12    1   58   41  593]]\n",
            "--------------------------------\n",
            "val predicted: (59960,) [0. 0. 5. ... 9. 9. 9.]\n",
            "probabilities: (59960, 10) \n",
            " [0 0 5 ... 9 9 9]\n",
            "trainset before (40, 784) (40,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [ 2  3  7  4  6 10  3  6  3  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.339 s \n",
            "\n",
            "Accuracy rate for 64.570000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.62      0.74       980\n",
            "        1.0       0.67      0.91      0.77      1135\n",
            "        2.0       0.68      0.68      0.68      1032\n",
            "        3.0       0.44      0.45      0.44      1010\n",
            "        4.0       0.64      0.82      0.72       982\n",
            "        5.0       0.43      0.35      0.38       892\n",
            "        6.0       0.77      0.82      0.79       958\n",
            "        7.0       0.79      0.78      0.78      1028\n",
            "        8.0       0.46      0.57      0.51       974\n",
            "        9.0       0.76      0.41      0.53      1009\n",
            "\n",
            "avg / total       0.66      0.65      0.64     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 604    1   48  151    4   21   52   12   85    2]\n",
            " [   0 1033   65   30    0    2    4    1    0    0]\n",
            " [   7   78  701   55   40    2   88   28   29    4]\n",
            " [   3   26   46  454    2  249   13   30  183    4]\n",
            " [   1   78    1    2  801    7   12    4   24   52]\n",
            " [   5   84   23  163   23  308   32   40  209    5]\n",
            " [  33   18   25    3   41   48  786    1    3    0]\n",
            " [   5   75   34   15   26    3    3  800   12   55]\n",
            " [   0   80   77  139    7   69   26    7  560    9]\n",
            " [   5   67    4   23  299    4    4   91  102  410]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 5. ... 7. 5. 3.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 5 ... 7 5 3]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (60, 784) (60,)\n",
            "updated train set: (60, 784) (60,) unique(labels): [ 4  3  9  6  6 11  4  7  3  7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59940, 784) (59940,)\n",
            "\n",
            "Train set: (60, 784) y: (60,)\n",
            "Val   set: (59940, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.348 s \n",
            "\n",
            "Accuracy rate for 67.430000 \n",
            "Classification report for classifier LogisticRegression(C=0.8333333333333334, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.85      0.79       980\n",
            "        1.0       0.71      0.87      0.78      1135\n",
            "        2.0       0.63      0.74      0.68      1032\n",
            "        3.0       0.55      0.61      0.58      1010\n",
            "        4.0       0.63      0.81      0.71       982\n",
            "        5.0       0.55      0.36      0.44       892\n",
            "        6.0       0.76      0.89      0.82       958\n",
            "        7.0       0.88      0.67      0.76      1028\n",
            "        8.0       0.61      0.41      0.49       974\n",
            "        9.0       0.66      0.48      0.56      1009\n",
            "\n",
            "avg / total       0.67      0.67      0.66     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[835   1  47  49   1   0  33   1  12   1]\n",
            " [  0 990 131   6   0   1   7   0   0   0]\n",
            " [ 41  49 761  28  43   1  76   9  20   4]\n",
            " [ 33  16  62 616   3 154  24  18  76   8]\n",
            " [ 10  52   8   1 797   9  10   0   7  88]\n",
            " [ 87  62  34 165  24 320  43  18 124  15]\n",
            " [ 33   7  30   1  21  17 848   1   0   0]\n",
            " [ 65  68  61  12  30   1   3 693   2  93]\n",
            " [ 17  90  76 214   5  68  63   3 400  38]\n",
            " [ 19  55   4  26 341   8   8  47  18 483]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59940,) [0. 0. 0. ... 0. 3. 3.]\n",
            "probabilities: (59940, 10) \n",
            " [0 0 0 ... 0 3 3]\n",
            "trainset before (60, 784) (60,)\n",
            "trainset after (70, 784) (70,)\n",
            "updated train set: (70, 784) (70,) unique(labels): [ 4  3 11  7  7 11  4  9  6  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59930, 784) (59930,)\n",
            "\n",
            "Train set: (70, 784) y: (70,)\n",
            "Val   set: (59930, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.345 s \n",
            "\n",
            "Accuracy rate for 69.240000 \n",
            "Classification report for classifier LogisticRegression(C=0.7142857142857143, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.83      0.81       980\n",
            "        1.0       0.72      0.94      0.82      1135\n",
            "        2.0       0.67      0.77      0.71      1032\n",
            "        3.0       0.61      0.65      0.63      1010\n",
            "        4.0       0.64      0.86      0.73       982\n",
            "        5.0       0.65      0.20      0.31       892\n",
            "        6.0       0.81      0.86      0.83       958\n",
            "        7.0       0.85      0.65      0.74      1028\n",
            "        8.0       0.52      0.60      0.56       974\n",
            "        9.0       0.72      0.50      0.59      1009\n",
            "\n",
            "avg / total       0.70      0.69      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 810    1   55   42    2    2   28    9   29    2]\n",
            " [   0 1067   56    2    0    0    6    1    3    0]\n",
            " [  21   50  791   27   27    1   53   28   24   10]\n",
            " [  20   12   86  652    0   23   21   23  166    7]\n",
            " [   5   60    8    0  840    3    9    1    9   47]\n",
            " [  70   68   24  212   27  180   36   11  247   17]\n",
            " [  28    9   34    1   34   18  825    1    8    0]\n",
            " [  52   65   47    3   70    0    4  672    9  106]\n",
            " [  10   84   82  114   11   39   35    5  585    9]\n",
            " [  11   65    3   17  299   13    3   44   52  502]]\n",
            "--------------------------------\n",
            "val predicted: (59930,) [0. 0. 0. ... 4. 5. 3.]\n",
            "probabilities: (59930, 10) \n",
            " [0 0 0 ... 4 5 3]\n",
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [ 4  3 12  8  9 15  4 10  7  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.344 s \n",
            "\n",
            "Accuracy rate for 69.760000 \n",
            "Classification report for classifier LogisticRegression(C=0.625, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.82      0.84       980\n",
            "        1.0       0.73      0.96      0.83      1135\n",
            "        2.0       0.74      0.66      0.70      1032\n",
            "        3.0       0.68      0.77      0.72      1010\n",
            "        4.0       0.52      0.82      0.64       982\n",
            "        5.0       0.77      0.34      0.47       892\n",
            "        6.0       0.78      0.90      0.84       958\n",
            "        7.0       0.78      0.53      0.63      1028\n",
            "        8.0       0.57      0.66      0.61       974\n",
            "        9.0       0.71      0.47      0.57      1009\n",
            "\n",
            "avg / total       0.71      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 802    1   32   27    2    3   52   11   45    5]\n",
            " [   0 1092   29    4    1    2    4    1    1    1]\n",
            " [  14   57  679   48   23    1   99   43   64    4]\n",
            " [  11   13   43  773    9   26    9   24   95    7]\n",
            " [   5   51   12    1  805    2   18   19   16   53]\n",
            " [  23   85   31  192   31  299   28   11  166   26]\n",
            " [  12   15   15    1   23   21  861    1    9    0]\n",
            " [  49   50   23    4  250    0    1  545   19   87]\n",
            " [   3   78   48   83   50   35   23    1  641   12]\n",
            " [   8   47    4    9  350    1    6   45   60  479]]\n",
            "--------------------------------\n",
            "val predicted: (59920,) [0. 0. 0. ... 4. 4. 4.]\n",
            "probabilities: (59920, 10) \n",
            " [0 0 0 ... 4 4 4]\n",
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [ 4  3 13  8 10 18  5 11  8 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.354 s \n",
            "\n",
            "Accuracy rate for 69.870000 \n",
            "Classification report for classifier LogisticRegression(C=0.5555555555555556, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.86      0.83       980\n",
            "        1.0       0.77      0.97      0.86      1135\n",
            "        2.0       0.69      0.68      0.68      1032\n",
            "        3.0       0.62      0.76      0.68      1010\n",
            "        4.0       0.65      0.68      0.66       982\n",
            "        5.0       0.83      0.30      0.44       892\n",
            "        6.0       0.75      0.89      0.81       958\n",
            "        7.0       0.77      0.47      0.58      1028\n",
            "        8.0       0.66      0.63      0.64       974\n",
            "        9.0       0.56      0.70      0.62      1009\n",
            "\n",
            "avg / total       0.71      0.70      0.69     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 838    1   50   46    0    3   16    8   16    2]\n",
            " [   0 1098   13    2   13    0    5    1    3    0]\n",
            " [  26   73  703   25   20    2   88   35   49   11]\n",
            " [  23   10   70  767    5   12   25   27   63    8]\n",
            " [   8   40    5    1  670    1   22   13    9  213]\n",
            " [  39   45   47  252   35  265   48   14  123   24]\n",
            " [  31   10   36    0   18    9  848    1    0    5]\n",
            " [  58   52   44    2  110    0    2  483   13  264]\n",
            " [   7   56   50  125   17   21   67    1  609   21]\n",
            " [  15   32    4   14  149    5    8   45   31  706]]\n",
            "--------------------------------\n",
            "val predicted: (59910,) [0. 0. 0. ... 9. 4. 4.]\n",
            "probabilities: (59910, 10) \n",
            " [0 0 0 ... 9 4 4]\n",
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 5  6 13  8 11 18  5 13  9 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.379 s \n",
            "\n",
            "Accuracy rate for 71.050000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.94      0.85       980\n",
            "        1.0       0.74      0.98      0.84      1135\n",
            "        2.0       0.72      0.59      0.65      1032\n",
            "        3.0       0.64      0.74      0.69      1010\n",
            "        4.0       0.65      0.82      0.72       982\n",
            "        5.0       0.83      0.32      0.46       892\n",
            "        6.0       0.76      0.85      0.81       958\n",
            "        7.0       0.78      0.55      0.65      1028\n",
            "        8.0       0.65      0.66      0.66       974\n",
            "        9.0       0.65      0.58      0.61      1009\n",
            "\n",
            "avg / total       0.72      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 922    2   13   19    1    0   11    6    3    3]\n",
            " [   0 1117    1    2    0    0    6    1    8    0]\n",
            " [  62  151  611    6   35    1   85   35   37    9]\n",
            " [  34   35   57  745    2   27   18   19   69    4]\n",
            " [   2   35    4    1  804    2   13   23   22   76]\n",
            " [  57   26   57  243   23  282   50   21  116   17]\n",
            " [  34   19   32    1   38    9  819    4    1    1]\n",
            " [  45   45   44    6  109    0    1  569   14  195]\n",
            " [  12   60   26  111   23   13   62    3  646   18]\n",
            " [  19   28    1   24  211    6    6   48   76  590]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 0. ... 4. 4. 4.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 0 ... 4 4 4]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [ 5  7 14  8 11 20  5 17  9 14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.375 s \n",
            "\n",
            "Accuracy rate for 73.270000 \n",
            "Classification report for classifier LogisticRegression(C=0.45454545454545453, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.92      0.85       980\n",
            "        1.0       0.70      0.99      0.82      1135\n",
            "        2.0       0.73      0.58      0.65      1032\n",
            "        3.0       0.64      0.76      0.69      1010\n",
            "        4.0       0.71      0.80      0.75       982\n",
            "        5.0       0.84      0.34      0.48       892\n",
            "        6.0       0.77      0.88      0.82       958\n",
            "        7.0       0.81      0.74      0.77      1028\n",
            "        8.0       0.70      0.63      0.66       974\n",
            "        9.0       0.73      0.63      0.67      1009\n",
            "\n",
            "avg / total       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 905    2   20   16    1    1   13   14    3    5]\n",
            " [   0 1118    0    2    0    3    6    2    4    0]\n",
            " [  65  171  598   10   25    0   81   37   41    4]\n",
            " [  39   35   49  763    3   17   18   21   58    7]\n",
            " [   1   47    7    1  787    5   19   22   16   77]\n",
            " [  58   34   71  242   16  304   42   24   80   21]\n",
            " [  26   17   28    2   23    8  846    4    1    3]\n",
            " [  21   49   20    6   58    0    2  765    8   99]\n",
            " [  11   78   25  126   17   17   64    6  610   20]\n",
            " [  11   37    2   24  178    7   11   52   56  631]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59890,) [0. 0. 0. ... 4. 4. 4.]\n",
            "probabilities: (59890, 10) \n",
            " [0 0 0 ... 4 4 4]\n",
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [ 5  7 15 11 11 21  6 18 11 15] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.367 s \n",
            "\n",
            "Accuracy rate for 71.350000 \n",
            "Classification report for classifier LogisticRegression(C=0.4166666666666667, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.77      0.94      0.85       980\n",
            "        1.0       0.71      0.97      0.82      1135\n",
            "        2.0       0.71      0.55      0.62      1032\n",
            "        3.0       0.60      0.73      0.66      1010\n",
            "        4.0       0.72      0.76      0.74       982\n",
            "        5.0       0.88      0.28      0.42       892\n",
            "        6.0       0.71      0.91      0.79       958\n",
            "        7.0       0.86      0.65      0.74      1028\n",
            "        8.0       0.63      0.65      0.64       974\n",
            "        9.0       0.71      0.64      0.67      1009\n",
            "\n",
            "avg / total       0.73      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 923    2   32    2    1    0   12    3    3    2]\n",
            " [   0 1097    0   29    0    0    3    3    3    0]\n",
            " [  59  176  570    4   18    0  123   35   42    5]\n",
            " [  43   35   46  737    3   17   14   12  101    2]\n",
            " [   2   41    5   15  748    1   48   10   25   87]\n",
            " [  67   22   83  255   10  246   50    9  106   44]\n",
            " [  20   19   25    1   19    4  867    2    1    0]\n",
            " [  58   51   23   19   83    0    3  669   16  106]\n",
            " [   8   75   15  102   16    6   99    1  633   19]\n",
            " [  14   27    1   55  142    4    9   32   80  645]]\n",
            "--------------------------------\n",
            "val predicted: (59880,) [0. 0. 0. ... 9. 4. 3.]\n",
            "probabilities: (59880, 10) \n",
            " [0 0 0 ... 9 4 3]\n",
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [ 5  7 15 12 11 24  6 21 12 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.350 s \n",
            "\n",
            "Accuracy rate for 70.750000 \n",
            "Classification report for classifier LogisticRegression(C=0.38461538461538464, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.95      0.85       980\n",
            "        1.0       0.68      0.95      0.79      1135\n",
            "        2.0       0.69      0.55      0.61      1032\n",
            "        3.0       0.57      0.77      0.66      1010\n",
            "        4.0       0.67      0.75      0.71       982\n",
            "        5.0       0.86      0.30      0.44       892\n",
            "        6.0       0.79      0.84      0.81       958\n",
            "        7.0       0.88      0.64      0.74      1028\n",
            "        8.0       0.68      0.62      0.65       974\n",
            "        9.0       0.67      0.64      0.66      1009\n",
            "\n",
            "avg / total       0.72      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 929    2   26    2    1    1    7    5    3    4]\n",
            " [   0 1082    0   47    0    0    1    2    3    0]\n",
            " [  66  190  564   11   37    0   80   37   39    8]\n",
            " [  42   39   43  781    8   17    8    8   62    2]\n",
            " [   0   57    4   20  739    1   30    6   23  102]\n",
            " [  66   27   98  268   12  267   23    6   73   52]\n",
            " [  34   23   37    8   37    9  805    0    0    5]\n",
            " [  39   54   19   23  105    1    1  659   16  111]\n",
            " [   8   83   20  139   14   11   63    1  600   35]\n",
            " [  14   32    2   62  153    4    3   25   65  649]]\n",
            "--------------------------------\n",
            "val predicted: (59870,) [0. 0. 0. ... 9. 4. 3.]\n",
            "probabilities: (59870, 10) \n",
            " [0 0 0 ... 9 4 3]\n",
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [ 5  7 15 14 11 28  6 23 13 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.375 s \n",
            "\n",
            "Accuracy rate for 72.610000 \n",
            "Classification report for classifier LogisticRegression(C=0.35714285714285715, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.85      0.91      0.88       980\n",
            "        1.0       0.68      0.98      0.80      1135\n",
            "        2.0       0.74      0.59      0.65      1032\n",
            "        3.0       0.60      0.72      0.66      1010\n",
            "        4.0       0.75      0.79      0.77       982\n",
            "        5.0       0.78      0.27      0.41       892\n",
            "        6.0       0.75      0.86      0.80       958\n",
            "        7.0       0.84      0.80      0.82      1028\n",
            "        8.0       0.61      0.64      0.62       974\n",
            "        9.0       0.77      0.63      0.69      1009\n",
            "\n",
            "avg / total       0.73      0.73      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 896    2   22    3    2    9   15   23    3    5]\n",
            " [   0 1107    0   19    0    1    3    0    4    1]\n",
            " [  32  174  608    6   21    1   90   45   51    4]\n",
            " [  35   58   48  730    7   22   12   11   84    3]\n",
            " [   0   56    6   12  771    5   40    9   22   61]\n",
            " [  39   29   57  284    3  245   32    9  152   42]\n",
            " [  23   19   40    3   36    8  824    2    1    2]\n",
            " [  13   61   11   14   38    3    4  818   20   46]\n",
            " [   9   82   33   93   18    9   71    1  627   31]\n",
            " [   8   40    1   50  133   12    5   55   70  635]]\n",
            "--------------------------------\n",
            "val predicted: (59860,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59860, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 5  8 17 14 11 29  7 24 14 21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.374 s \n",
            "\n",
            "Accuracy rate for 71.230000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.74      0.93      0.82       980\n",
            "        1.0       0.71      0.99      0.83      1135\n",
            "        2.0       0.71      0.61      0.65      1032\n",
            "        3.0       0.59      0.70      0.64      1010\n",
            "        4.0       0.75      0.81      0.78       982\n",
            "        5.0       0.84      0.26      0.40       892\n",
            "        6.0       0.75      0.86      0.80       958\n",
            "        7.0       0.83      0.81      0.82      1028\n",
            "        8.0       0.55      0.65      0.60       974\n",
            "        9.0       0.85      0.43      0.57      1009\n",
            "\n",
            "avg / total       0.73      0.71      0.70     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 913    2   33    3    3    5    9   10    2    0]\n",
            " [   0 1120    0    6    0    1    3    2    3    0]\n",
            " [  55  138  625    4   19    1   94   60   35    1]\n",
            " [  60   46   61  708    5   16   11   11   91    1]\n",
            " [   4   37   11   19  799    5   31    7   37   32]\n",
            " [  80   29   48  283    8  236   41    8  146   13]\n",
            " [  41   18   39    2   27    5  821    5    0    0]\n",
            " [  46   46   10   13   21    1    3  834   34   20]\n",
            " [  18   96   47   74   12    3   76    4  636    8]\n",
            " [  17   41    3   92  177    8    6   66  168  431]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [ 5  8 17 15 12 29  9 25 16 24] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.379 s \n",
            "\n",
            "Accuracy rate for 72.570000 \n",
            "Classification report for classifier LogisticRegression(C=0.3125, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.94      0.85       980\n",
            "        1.0       0.71      0.99      0.82      1135\n",
            "        2.0       0.72      0.59      0.65      1032\n",
            "        3.0       0.59      0.71      0.65      1010\n",
            "        4.0       0.82      0.72      0.77       982\n",
            "        5.0       0.82      0.31      0.45       892\n",
            "        6.0       0.73      0.90      0.81       958\n",
            "        7.0       0.84      0.79      0.82      1028\n",
            "        8.0       0.59      0.59      0.59       974\n",
            "        9.0       0.75      0.65      0.69      1009\n",
            "\n",
            "avg / total       0.74      0.73      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 924    2   24    2    2    3   12    9    2    0]\n",
            " [   0 1118    0   10    0    1    2    2    2    0]\n",
            " [  63  133  612    2    9    1  104   55   47    6]\n",
            " [  45   61   68  715    7   18   11    8   73    4]\n",
            " [   3   40   10   13  708    6   58   14   30  100]\n",
            " [  62   40   51  272    9  276   38    5  101   38]\n",
            " [  37   11   25    2    7    9  863    3    1    0]\n",
            " [  22   41   10   23   26    1    5  817   31   52]\n",
            " [  22  105   45  108   16   11   73    3  572   19]\n",
            " [  14   32    3   56   77   11    9   51  104  652]]\n",
            "--------------------------------\n",
            "val predicted: (59840,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59840, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [ 5  9 18 15 12 32  9 25 18 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.396 s \n",
            "\n",
            "Accuracy rate for 72.380000 \n",
            "Classification report for classifier LogisticRegression(C=0.29411764705882354, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.68      0.95      0.80       980\n",
            "        1.0       0.71      0.98      0.82      1135\n",
            "        2.0       0.77      0.62      0.69      1032\n",
            "        3.0       0.59      0.72      0.65      1010\n",
            "        4.0       0.78      0.75      0.76       982\n",
            "        5.0       0.78      0.32      0.46       892\n",
            "        6.0       0.76      0.86      0.81       958\n",
            "        7.0       0.87      0.77      0.82      1028\n",
            "        8.0       0.64      0.56      0.60       974\n",
            "        9.0       0.76      0.65      0.70      1009\n",
            "\n",
            "avg / total       0.73      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 929    2    9    2    2    7   13   16    0    0]\n",
            " [   0 1108    0   15    0    0    2    1    9    0]\n",
            " [  88  119  642    4   13    2   78   36   40   10]\n",
            " [  91   40   43  726    4   27   11    6   50   12]\n",
            " [   1   37    8   10  734    9   40    4   29  110]\n",
            " [ 123   32   39  269    9  289   36    6   66   23]\n",
            " [  54   15   31    4   13   11  822    0    8    0]\n",
            " [  23   64   12   24   37    1    4  792   33   38]\n",
            " [  31  106   53  117   24   17   64    3  542   17]\n",
            " [  17   44    2   62  103    6    9   47   65  654]]\n",
            "--------------------------------\n",
            "val predicted: (59830,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59830, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [ 5 10 18 16 13 34  9 26 19 30] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.394 s \n",
            "\n",
            "Accuracy rate for 73.170000 \n",
            "Classification report for classifier LogisticRegression(C=0.2777777777777778, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.91      0.82       980\n",
            "        1.0       0.74      0.98      0.84      1135\n",
            "        2.0       0.77      0.65      0.70      1032\n",
            "        3.0       0.61      0.72      0.66      1010\n",
            "        4.0       0.75      0.76      0.75       982\n",
            "        5.0       0.68      0.39      0.49       892\n",
            "        6.0       0.74      0.88      0.80       958\n",
            "        7.0       0.84      0.81      0.83      1028\n",
            "        8.0       0.69      0.58      0.63       974\n",
            "        9.0       0.75      0.59      0.66      1009\n",
            "\n",
            "avg / total       0.73      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 893    2   17    1    1   10   29   23    3    1]\n",
            " [   0 1110    3   11    0    4    3    2    2    0]\n",
            " [  64  100  668    4   22    2   94   37   31   10]\n",
            " [  75   40   44  727    6   42   13    8   45   10]\n",
            " [   1   32    7   15  744   24   37    8   29   85]\n",
            " [  80   37   24  246   14  347   38   14   62   30]\n",
            " [  33   13   25    2   12   29  842    1    1    0]\n",
            " [  18   49   15   17   23    3    5  830   23   45]\n",
            " [  13   89   68   95   24   30   71    3  562   19]\n",
            " [  14   31    1   73  150   22    8   58   58  594]]\n",
            "--------------------------------\n",
            "val predicted: (59820,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59820, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [ 6 10 19 16 15 37  9 26 20 32] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.405 s \n",
            "\n",
            "Accuracy rate for 73.940000 \n",
            "Classification report for classifier LogisticRegression(C=0.2631578947368421, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.94      0.88       980\n",
            "        1.0       0.74      0.98      0.84      1135\n",
            "        2.0       0.75      0.71      0.73      1032\n",
            "        3.0       0.60      0.73      0.66      1010\n",
            "        4.0       0.73      0.80      0.77       982\n",
            "        5.0       0.67      0.36      0.47       892\n",
            "        6.0       0.74      0.88      0.81       958\n",
            "        7.0       0.85      0.84      0.84      1028\n",
            "        8.0       0.66      0.59      0.62       974\n",
            "        9.0       0.84      0.49      0.62      1009\n",
            "\n",
            "avg / total       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 919    2   13    3    2    9   20   10    2    0]\n",
            " [   0 1114    4    6    0    3    4    0    3    1]\n",
            " [  34   77  736    5   25    2   82   37   30    4]\n",
            " [  37   43   65  737    4   35   10    8   65    6]\n",
            " [   2   33    7   15  790   29   42    6   31   27]\n",
            " [  60   44   30  285   23  318   37   12   72   11]\n",
            " [  32   14   31    4    7   24  843    1    2    0]\n",
            " [   9   50   13   24   10    3    7  860   24   28]\n",
            " [  14   91   75   71   17   27   79    3  578   19]\n",
            " [  11   34    3   87  198   24    8   74   71  499]]\n",
            "--------------------------------\n",
            "val predicted: (59810,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59810, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [ 6 10 20 16 18 38 10 26 21 35] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.393 s \n",
            "\n",
            "Accuracy rate for 73.440000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.83      0.96      0.89       980\n",
            "        1.0       0.75      0.98      0.85      1135\n",
            "        2.0       0.81      0.71      0.75      1032\n",
            "        3.0       0.56      0.80      0.66      1010\n",
            "        4.0       0.73      0.78      0.76       982\n",
            "        5.0       0.69      0.26      0.38       892\n",
            "        6.0       0.76      0.87      0.81       958\n",
            "        7.0       0.84      0.83      0.84      1028\n",
            "        8.0       0.61      0.61      0.61       974\n",
            "        9.0       0.82      0.48      0.61      1009\n",
            "\n",
            "avg / total       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 936    2   12    5    2    2   13    7    1    0]\n",
            " [   0 1115    0   17    0    1    1    0    1    0]\n",
            " [  18   88  729   12   21    1   85   45   28    5]\n",
            " [  28   30   37  807    2   24    9    8   61    4]\n",
            " [   2   30    6   28  765   16   44   15   34   42]\n",
            " [  68   45   27  317   32  232   28    9  132    2]\n",
            " [  30   13   26    8   27   20  830    3    1    0]\n",
            " [  22   46   13   23    7    3    3  854   20   37]\n",
            " [   8   79   49  124    8   21   75    4  593   13]\n",
            " [  11   29    1  111  177   14   11   72  100  483]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59800,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [ 6 10 21 18 19 40 10 26 21 39] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.413 s \n",
            "\n",
            "Accuracy rate for 72.260000 \n",
            "Classification report for classifier LogisticRegression(C=0.23809523809523808, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.70      0.97      0.81       980\n",
            "        1.0       0.74      0.99      0.84      1135\n",
            "        2.0       0.77      0.73      0.75      1032\n",
            "        3.0       0.61      0.68      0.65      1010\n",
            "        4.0       0.70      0.75      0.73       982\n",
            "        5.0       0.70      0.27      0.38       892\n",
            "        6.0       0.73      0.87      0.79       958\n",
            "        7.0       0.82      0.82      0.82      1028\n",
            "        8.0       0.67      0.57      0.62       974\n",
            "        9.0       0.81      0.50      0.62      1009\n",
            "\n",
            "avg / total       0.73      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 950    2   11    1    4    2    5    5    0    0]\n",
            " [   0 1119    5    7    0    1    2    0    1    0]\n",
            " [  32   55  756    5   18    1   92   50   15    8]\n",
            " [  70   36   84  687    6   36    8    8   62   13]\n",
            " [   4   41    5   13  741   15   86   17   29   31]\n",
            " [ 173   65   23  218   18  237   25   11  117    5]\n",
            " [  59   16   19    4   11   12  833    4    0    0]\n",
            " [  28   55   12   19    5    2    8  848    6   45]\n",
            " [  30   97   68   92   12   22   74    8  554   17]\n",
            " [  18   34    3   72  237   13   11   77   43  501]]\n",
            "--------------------------------\n",
            "val predicted: (59790,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59790, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [ 6 10 23 19 21 41 11 26 22 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.449 s \n",
            "\n",
            "Accuracy rate for 72.780000 \n",
            "Classification report for classifier LogisticRegression(C=0.22727272727272727, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.95      0.83       980\n",
            "        1.0       0.74      0.98      0.84      1135\n",
            "        2.0       0.78      0.75      0.76      1032\n",
            "        3.0       0.55      0.72      0.62      1010\n",
            "        4.0       0.80      0.73      0.76       982\n",
            "        5.0       0.70      0.31      0.43       892\n",
            "        6.0       0.71      0.87      0.78       958\n",
            "        7.0       0.79      0.82      0.81      1028\n",
            "        8.0       0.68      0.52      0.59       974\n",
            "        9.0       0.83      0.57      0.67      1009\n",
            "\n",
            "avg / total       0.73      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 928    3   23    1    2    2    9   12    0    0]\n",
            " [   0 1114    5    5    0    2    5    0    3    1]\n",
            " [  30   77  770    7    9    3   76   42   10    8]\n",
            " [  58   41   67  725    3   38    5    8   51   14]\n",
            " [   3   30    6   23  717   14   85   39   25   40]\n",
            " [ 121   43   23  250   32  274   44    8   94    3]\n",
            " [  46   19   25   10    7   14  830    6    1    0]\n",
            " [  25   50   20   20    6    3   11  844    8   41]\n",
            " [  19  103   48  158   12   28   83    8  503   12]\n",
            " [  13   29    2  111  111   15   16   97   42  573]]\n",
            "--------------------------------\n",
            "val predicted: (59780,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59780, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [ 6 11 24 20 24 42 11 27 24 41] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.417 s \n",
            "\n",
            "Accuracy rate for 73.680000 \n",
            "Classification report for classifier LogisticRegression(C=0.21739130434782608, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.87      0.88       980\n",
            "        1.0       0.71      0.98      0.82      1135\n",
            "        2.0       0.75      0.68      0.71      1032\n",
            "        3.0       0.58      0.77      0.66      1010\n",
            "        4.0       0.79      0.75      0.77       982\n",
            "        5.0       0.74      0.41      0.53       892\n",
            "        6.0       0.72      0.92      0.81       958\n",
            "        7.0       0.72      0.82      0.77      1028\n",
            "        8.0       0.75      0.54      0.62       974\n",
            "        9.0       0.82      0.59      0.68      1009\n",
            "\n",
            "avg / total       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 848    1   21    3    5    6   31   64    1    0]\n",
            " [   0 1114   11    6    0    1    2    0    1    0]\n",
            " [  16  138  699    4    9    2   77   68   14    5]\n",
            " [  18   57   51  773    0   32   12   15   38   14]\n",
            " [   1   24   14   17  733   18   82   37   25   31]\n",
            " [  23   37   41  264   42  362   45   22   49    7]\n",
            " [  11   18   19    6    7    8  881    7    1    0]\n",
            " [  10   61   17   18    3    3    4  845   18   49]\n",
            " [   5  105   51  136   18   37   70    7  522   23]\n",
            " [   5   24    4  101  115   18   18  102   31  591]]\n",
            "--------------------------------\n",
            "val predicted: (59770,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59770, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [ 6 11 26 21 25 45 11 27 25 43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.444 s \n",
            "\n",
            "Accuracy rate for 72.750000 \n",
            "Classification report for classifier LogisticRegression(C=0.20833333333333334, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.97      0.85       980\n",
            "        1.0       0.71      0.98      0.82      1135\n",
            "        2.0       0.76      0.72      0.74      1032\n",
            "        3.0       0.59      0.74      0.65      1010\n",
            "        4.0       0.79      0.64      0.71       982\n",
            "        5.0       0.77      0.35      0.48       892\n",
            "        6.0       0.71      0.89      0.79       958\n",
            "        7.0       0.78      0.83      0.80      1028\n",
            "        8.0       0.71      0.45      0.55       974\n",
            "        9.0       0.80      0.63      0.70      1009\n",
            "\n",
            "avg / total       0.74      0.73      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 949    3    4    2    2    2    8    9    1    0]\n",
            " [   0 1110   16    5    0    2    2    0    0    0]\n",
            " [  47   93  746    6   10    2   63   47    7   11]\n",
            " [  44   73   63  749    2   21    6    8   24   20]\n",
            " [   2   23    6   13  627   18  125   72   31   65]\n",
            " [ 114   44   16  241   42  314   41   16   60    4]\n",
            " [  43   17   30    3    2    4  849   10    0    0]\n",
            " [  18   61   22   16    3    1    4  853   12   38]\n",
            " [  17  111   77  169   20   27   84    5  442   22]\n",
            " [  13   32    5   76   85   19   21   78   44  636]]\n",
            "--------------------------------\n",
            "val predicted: (59760,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59760, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [ 7 11 27 21 27 49 11 27 26 44] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.409 s \n",
            "\n",
            "Accuracy rate for 73.790000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.81      0.95      0.88       980\n",
            "        1.0       0.71      0.98      0.82      1135\n",
            "        2.0       0.79      0.71      0.75      1032\n",
            "        3.0       0.61      0.75      0.67      1010\n",
            "        4.0       0.82      0.68      0.74       982\n",
            "        5.0       0.81      0.33      0.47       892\n",
            "        6.0       0.67      0.91      0.78       958\n",
            "        7.0       0.75      0.84      0.79      1028\n",
            "        8.0       0.78      0.47      0.59       974\n",
            "        9.0       0.77      0.67      0.72      1009\n",
            "\n",
            "avg / total       0.75      0.74      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 930    3    1    2    0    1   24   19    0    0]\n",
            " [   0 1116   11    0    0    2    4    1    0    1]\n",
            " [  41   91  730    7    2    3   85   62    4    7]\n",
            " [  30   66   40  760    3   25   18   19   24   25]\n",
            " [   3   21   16   13  669   14  102   51   15   78]\n",
            " [  71   41   20  268   35  292   53   23   65   24]\n",
            " [  29   15   22    1    5    5  875    6    0    0]\n",
            " [  12   53   21    8    6    1    6  865   12   44]\n",
            " [  14  143   56  111   21   14  115    9  462   29]\n",
            " [  12   28    4   73   79    5   18   98   12  680]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [ 8 11 27 23 28 54 11 27 26 45] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.393 s \n",
            "\n",
            "Accuracy rate for 73.910000 \n",
            "Classification report for classifier LogisticRegression(C=0.19230769230769232, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.74      0.98      0.84       980\n",
            "        1.0       0.68      0.99      0.81      1135\n",
            "        2.0       0.82      0.72      0.77      1032\n",
            "        3.0       0.61      0.76      0.68      1010\n",
            "        4.0       0.77      0.74      0.75       982\n",
            "        5.0       0.84      0.28      0.42       892\n",
            "        6.0       0.74      0.88      0.81       958\n",
            "        7.0       0.80      0.82      0.81      1028\n",
            "        8.0       0.74      0.51      0.60       974\n",
            "        9.0       0.82      0.63      0.71      1009\n",
            "\n",
            "avg / total       0.75      0.74      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 961    3    3    2    0    1    3    6    1    0]\n",
            " [   0 1123    5    0    0    1    3    1    1    1]\n",
            " [  50  105  742    8    7    1   60   47    7    5]\n",
            " [  53   78   38  770    2   10    9    8   29   13]\n",
            " [  12   28    8    5  728    9   93   37   25   37]\n",
            " [  94   53   18  292   38  253   48   16   70   10]\n",
            " [  60   20   18    0    5    7  843    3    2    0]\n",
            " [  22   59   20    8    8    1    9  838   14   49]\n",
            " [  25  151   49  123   31   10   56    7  495   27]\n",
            " [  23   32    5   50  131    8   12   83   27  638]]\n",
            "--------------------------------\n",
            "val predicted: (59740,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59740, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [ 8 11 28 24 29 55 14 29 26 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.426 s \n",
            "\n",
            "Accuracy rate for 72.390000 \n",
            "Classification report for classifier LogisticRegression(C=0.18518518518518517, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.69      0.98      0.81       980\n",
            "        1.0       0.67      0.99      0.80      1135\n",
            "        2.0       0.75      0.75      0.75      1032\n",
            "        3.0       0.60      0.69      0.64      1010\n",
            "        4.0       0.77      0.77      0.77       982\n",
            "        5.0       0.75      0.28      0.41       892\n",
            "        6.0       0.75      0.80      0.77       958\n",
            "        7.0       0.82      0.83      0.82      1028\n",
            "        8.0       0.73      0.49      0.58       974\n",
            "        9.0       0.86      0.57      0.69      1009\n",
            "\n",
            "avg / total       0.74      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 962    3    4    1    0    1    7    2    0    0]\n",
            " [   0 1121   10    0    0    2    1    1    0    0]\n",
            " [  53  105  770    5    8    3   47   28    8    5]\n",
            " [  62  105   48  701    2    7   40   10   24   11]\n",
            " [  20   26   18    3  757   22   55   31   23   27]\n",
            " [ 137   52   22  291   32  250   41   12   50    5]\n",
            " [  84   12   51    1   17   20  769    1    2    1]\n",
            " [  31   58   25    3    7    0    5  856   18   25]\n",
            " [  26  164   64  112   24   17   62    9  475   21]\n",
            " [  28   36   10   59  131   11    4   98   54  578]]\n",
            "--------------------------------\n",
            "val predicted: (59730,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59730, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [ 9 11 30 26 29 56 14 31 28 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.449 s \n",
            "\n",
            "Accuracy rate for 71.720000 \n",
            "Classification report for classifier LogisticRegression(C=0.17857142857142858, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.96      0.82       980\n",
            "        1.0       0.64      0.98      0.78      1135\n",
            "        2.0       0.72      0.72      0.72      1032\n",
            "        3.0       0.73      0.47      0.57      1010\n",
            "        4.0       0.75      0.77      0.76       982\n",
            "        5.0       0.67      0.42      0.52       892\n",
            "        6.0       0.71      0.83      0.77       958\n",
            "        7.0       0.78      0.81      0.80      1028\n",
            "        8.0       0.69      0.54      0.61       974\n",
            "        9.0       0.81      0.60      0.69      1009\n",
            "\n",
            "avg / total       0.72      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 938    4    6    1    0    2   17   12    0    0]\n",
            " [   0 1116   13    0    0    3    1    2    0    0]\n",
            " [  51  114  741    0    7    8   47   45   11    8]\n",
            " [  79  133   90  473    2   68   72   19   52   22]\n",
            " [  16   29    8    1  761   30   54   30   19   34]\n",
            " [ 122   56   18  105   47  379   60   17   81    7]\n",
            " [  38   14   60    0   17   27  797    1    3    1]\n",
            " [  26   65   20    2   10    2    5  836   16   46]\n",
            " [  25  162   65   40   29   29   67    9  527   21]\n",
            " [  19   39    3   27  141   20    3  103   50  604]]\n",
            "--------------------------------\n",
            "val predicted: (59720,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59720, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [ 9 11 31 27 29 58 18 32 29 46] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.451 s \n",
            "\n",
            "Accuracy rate for 74.390000 \n",
            "Classification report for classifier LogisticRegression(C=0.1724137931034483, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.96      0.86       980\n",
            "        1.0       0.68      0.97      0.80      1135\n",
            "        2.0       0.75      0.74      0.75      1032\n",
            "        3.0       0.68      0.64      0.66      1010\n",
            "        4.0       0.76      0.80      0.78       982\n",
            "        5.0       0.69      0.42      0.52       892\n",
            "        6.0       0.75      0.87      0.80       958\n",
            "        7.0       0.80      0.82      0.81      1028\n",
            "        8.0       0.73      0.58      0.65       974\n",
            "        9.0       0.84      0.58      0.69      1009\n",
            "\n",
            "avg / total       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    3    4    1    1    1   15   15    0    0]\n",
            " [   0 1104   23    0    0    2    4    2    0    0]\n",
            " [  34   95  764    3    7    6   55   50   12    6]\n",
            " [  55   89   67  644    2   53   33   17   40   10]\n",
            " [  10   24    8    4  781   35   50   13   21   36]\n",
            " [  76   46   24  179   41  372   53   19   75    7]\n",
            " [  32   14   32    1   14   30  835    0    0    0]\n",
            " [  25   66   21    2   17    2    3  846   13   33]\n",
            " [  17  136   63   56   26   22   60   10  563   21]\n",
            " [  12   38    6   57  141   20   11   89   45  590]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59710,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59710, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [ 9 11 32 27 30 60 19 33 30 49] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.439 s \n",
            "\n",
            "Accuracy rate for 73.090000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.69      0.97      0.81       980\n",
            "        1.0       0.67      0.97      0.79      1135\n",
            "        2.0       0.78      0.73      0.75      1032\n",
            "        3.0       0.71      0.54      0.61      1010\n",
            "        4.0       0.75      0.78      0.76       982\n",
            "        5.0       0.68      0.42      0.52       892\n",
            "        6.0       0.76      0.88      0.82       958\n",
            "        7.0       0.80      0.82      0.81      1028\n",
            "        8.0       0.69      0.58      0.63       974\n",
            "        9.0       0.81      0.57      0.67      1009\n",
            "\n",
            "avg / total       0.73      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 954    3    3    1    0    1   12    6    0    0]\n",
            " [   0 1100   30    0    0    1    2    1    1    0]\n",
            " [  62  101  751    3   11    4   50   34    8    8]\n",
            " [  90  106   63  542    3   68   27   26   73   12]\n",
            " [  13   22    6    3  764   34   59   18   22   41]\n",
            " [ 138   45   16  124   48  374   46   18   78    5]\n",
            " [  44   14   23    1   10   22  843    0    1    0]\n",
            " [  24   58   29    2    9    1    2  839   12   52]\n",
            " [  32  146   39   49   33   21   61    6  568   19]\n",
            " [  21   38    4   35  146   22    8  105   56  574]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [ 9 11 33 29 30 61 20 33 32 52] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.428 s \n",
            "\n",
            "Accuracy rate for 73.390000 \n",
            "Classification report for classifier LogisticRegression(C=0.16129032258064516, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.66      0.98      0.79       980\n",
            "        1.0       0.68      0.97      0.80      1135\n",
            "        2.0       0.79      0.71      0.74      1032\n",
            "        3.0       0.71      0.60      0.65      1010\n",
            "        4.0       0.76      0.81      0.79       982\n",
            "        5.0       0.70      0.31      0.43       892\n",
            "        6.0       0.77      0.89      0.83       958\n",
            "        7.0       0.84      0.81      0.82      1028\n",
            "        8.0       0.69      0.62      0.65       974\n",
            "        9.0       0.83      0.57      0.68      1009\n",
            "\n",
            "avg / total       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 962    2    2    1    0    0    9    4    0    0]\n",
            " [   0 1101   27    1    0    2    3    1    0    0]\n",
            " [  73  109  728    0    8    3   54   38   12    7]\n",
            " [ 102   91   63  609    3   38   33   10   49   12]\n",
            " [  12   20    7    6  798   27   43   15   23   31]\n",
            " [ 171   51   20  154   44  279   54    6  108    5]\n",
            " [  48   13   10    0   12   16  855    0    4    0]\n",
            " [  35   72   24    2    8    1    2  828   13   43]\n",
            " [  36  131   38   42   25   15   55    6  603   23]\n",
            " [  23   37    8   48  148   16    6   82   65  576]]\n",
            "--------------------------------\n",
            "val predicted: (59690,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59690, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [ 9 11 34 29 30 64 21 34 35 53] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.484 s \n",
            "\n",
            "Accuracy rate for 73.250000 \n",
            "Classification report for classifier LogisticRegression(C=0.15625, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.67      0.96      0.79       980\n",
            "        1.0       0.65      0.98      0.78      1135\n",
            "        2.0       0.78      0.69      0.73      1032\n",
            "        3.0       0.74      0.56      0.64      1010\n",
            "        4.0       0.82      0.72      0.77       982\n",
            "        5.0       0.68      0.46      0.55       892\n",
            "        6.0       0.76      0.88      0.82       958\n",
            "        7.0       0.78      0.83      0.80      1028\n",
            "        8.0       0.73      0.57      0.64       974\n",
            "        9.0       0.80      0.61      0.69      1009\n",
            "\n",
            "avg / total       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 944    3    5    1    0    1    9   17    0    0]\n",
            " [   0 1113   16    1    0    2    2    1    0    0]\n",
            " [  77  113  715    1    6    9   56   39   10    6]\n",
            " [  86  101   79  570    2   70   29   19   41   13]\n",
            " [  18   25    2    6  707   38   64   29   18   75]\n",
            " [ 140   58   14   94   30  411   44   12   82    7]\n",
            " [  49   18   22    0    3   18  845    0    3    0]\n",
            " [  29   67   21    2    8    2    4  849   13   33]\n",
            " [  34  166   40   46   16   32   49   10  558   23]\n",
            " [  22   40    5   50   92   19   11  117   40  613]]\n",
            "--------------------------------\n",
            "val predicted: (59680,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59680, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [ 9 11 35 30 32 64 22 35 36 56] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.435 s \n",
            "\n",
            "Accuracy rate for 72.800000 \n",
            "Classification report for classifier LogisticRegression(C=0.15151515151515152, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.59      0.99      0.74       980\n",
            "        1.0       0.65      0.98      0.79      1135\n",
            "        2.0       0.82      0.63      0.71      1032\n",
            "        3.0       0.71      0.63      0.67      1010\n",
            "        4.0       0.81      0.73      0.77       982\n",
            "        5.0       0.68      0.43      0.53       892\n",
            "        6.0       0.77      0.86      0.82       958\n",
            "        7.0       0.83      0.81      0.82      1028\n",
            "        8.0       0.79      0.53      0.63       974\n",
            "        9.0       0.81      0.62      0.70      1009\n",
            "\n",
            "avg / total       0.75      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 971    2    1    1    0    0    3    2    0    0]\n",
            " [   2 1115   14    2    0    1    1    0    0    0]\n",
            " [ 118  126  651    3   10    4   59   37   19    5]\n",
            " [ 113   94   43  635    1   55   24   16   23    6]\n",
            " [  35   23    2    9  719   34   60   14   11   75]\n",
            " [ 218   49    4  119   15  387   35    3   53    9]\n",
            " [  74   14   18    0    2   21  827    0    1    1]\n",
            " [  45   70   20    2   14    2    6  833   10   26]\n",
            " [  42  171   40   62   21   38   52   10  513   25]\n",
            " [  36   39    5   65  108   26    2   83   16  629]]\n",
            "--------------------------------\n",
            "val predicted: (59670,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59670, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [ 9 11 35 31 32 67 22 35 38 60] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.442 s \n",
            "\n",
            "Accuracy rate for 74.510000 \n",
            "Classification report for classifier LogisticRegression(C=0.14705882352941177, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.96      0.85       980\n",
            "        1.0       0.69      0.98      0.81      1135\n",
            "        2.0       0.78      0.69      0.73      1032\n",
            "        3.0       0.69      0.68      0.68      1010\n",
            "        4.0       0.78      0.74      0.76       982\n",
            "        5.0       0.75      0.39      0.52       892\n",
            "        6.0       0.75      0.91      0.82       958\n",
            "        7.0       0.79      0.84      0.81      1028\n",
            "        8.0       0.70      0.58      0.64       974\n",
            "        9.0       0.81      0.61      0.70      1009\n",
            "\n",
            "avg / total       0.75      0.75      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 942    3    5    1    0    2   14   12    1    0]\n",
            " [   0 1110   18    2    0    2    3    0    0    0]\n",
            " [  54  110  713    1    9    3   73   48   18    3]\n",
            " [  44   76   64  682    3   23   23   15   64   16]\n",
            " [  12   20   10    5  728   31   59   23   22   72]\n",
            " [  92   47   25  195   30  352   46   16   84    5]\n",
            " [  36   13   15    0    5   18  869    0    2    0]\n",
            " [  19   61   18    8   12    0    1  867   10   32]\n",
            " [  23  145   40   58   21   25   62   10  568   22]\n",
            " [  15   33    8   38  123   14   10  111   37  620]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59660, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [ 9 11 35 32 33 69 23 35 40 63] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.515 s \n",
            "\n",
            "Accuracy rate for 72.150000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.95      0.84       980\n",
            "        1.0       0.66      0.98      0.79      1135\n",
            "        2.0       0.75      0.69      0.72      1032\n",
            "        3.0       0.71      0.57      0.63      1010\n",
            "        4.0       0.75      0.72      0.74       982\n",
            "        5.0       0.70      0.49      0.57       892\n",
            "        6.0       0.71      0.86      0.78       958\n",
            "        7.0       0.81      0.80      0.80      1028\n",
            "        8.0       0.62      0.55      0.58       974\n",
            "        9.0       0.75      0.55      0.64      1009\n",
            "\n",
            "avg / total       0.72      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 934    4    6    3    0    2   11   20    0    0]\n",
            " [   0 1115   15    0    0    2    2    1    0    0]\n",
            " [  51  129  707    0    8    7   86   30    9    5]\n",
            " [  43   97   72  576    4   46   28   14  114   16]\n",
            " [  12   19    7    7  710   41   62    8   21   95]\n",
            " [  77   43   22  112   42  434   54   15   90    3]\n",
            " [  40   17   26    1    9   40  824    0    0    1]\n",
            " [  33   65   24   19   10    1    4  824    8   40]\n",
            " [  25  158   50   57   21   24   75    6  535   23]\n",
            " [  18   35   11   35  137   22    9  104   82  556]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [ 9 11 35 33 34 70 24 35 41 68] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.503 s \n",
            "\n",
            "Accuracy rate for 72.080000 \n",
            "Classification report for classifier LogisticRegression(C=0.1388888888888889, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.70      0.98      0.81       980\n",
            "        1.0       0.66      0.99      0.79      1135\n",
            "        2.0       0.78      0.66      0.72      1032\n",
            "        3.0       0.71      0.57      0.64      1010\n",
            "        4.0       0.80      0.70      0.75       982\n",
            "        5.0       0.69      0.46      0.56       892\n",
            "        6.0       0.74      0.88      0.81       958\n",
            "        7.0       0.80      0.82      0.81      1028\n",
            "        8.0       0.62      0.54      0.58       974\n",
            "        9.0       0.74      0.56      0.63      1009\n",
            "\n",
            "avg / total       0.72      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 959    3    1    1    0    1    8    7    0    0]\n",
            " [   0 1118   11    0    0    2    4    0    0    0]\n",
            " [  85  123  682    2    8   10   73   30   15    4]\n",
            " [  70   93   63  580    2   51   27   12  100   12]\n",
            " [  15   24    4    5  689   38   44   22   12  129]\n",
            " [ 117   47   16  106   31  414   59    8   91    3]\n",
            " [  43   19   10    1    9   32  841    0    1    2]\n",
            " [  30   72   23   12    6    1    1  838   11   34]\n",
            " [  33  157   53   72   24   22   66    6  525   16]\n",
            " [  24   39    7   34   91   28    8  119   97  562]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59640, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [ 9 11 35 35 36 70 24 36 43 71] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.555 s \n",
            "\n",
            "Accuracy rate for 71.780000 \n",
            "Classification report for classifier LogisticRegression(C=0.13513513513513514, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.98      0.84       980\n",
            "        1.0       0.64      0.98      0.78      1135\n",
            "        2.0       0.81      0.66      0.73      1032\n",
            "        3.0       0.68      0.58      0.62      1010\n",
            "        4.0       0.83      0.68      0.75       982\n",
            "        5.0       0.68      0.49      0.57       892\n",
            "        6.0       0.73      0.87      0.79       958\n",
            "        7.0       0.79      0.81      0.80      1028\n",
            "        8.0       0.59      0.52      0.55       974\n",
            "        9.0       0.75      0.55      0.63      1009\n",
            "\n",
            "avg / total       0.72      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 960    3    1    1    0    2    8    5    0    0]\n",
            " [   0 1116   12    2    0    2    3    0    0    0]\n",
            " [  72  133  685    0    5    9   84   29   12    3]\n",
            " [  45  106   54  587    2   55   28   14  108   11]\n",
            " [  14   21    6    9  665   48   43   33   22  121]\n",
            " [  94   55    7  124   22  435   62    6   83    4]\n",
            " [  47   18    9    0    9   35  838    1    1    0]\n",
            " [  33   64   23   25    4    3    2  836   11   27]\n",
            " [  30  174   45   75   16   28   75   10  504   17]\n",
            " [  22   41    7   46   75   27   10  118  111  552]]\n",
            "--------------------------------\n",
            "val predicted: (59630,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59630, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [ 9 11 36 35 39 70 24 38 44 74] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.495 s \n",
            "\n",
            "Accuracy rate for 73.690000 \n",
            "Classification report for classifier LogisticRegression(C=0.13157894736842105, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.70      0.98      0.82       980\n",
            "        1.0       0.65      0.99      0.78      1135\n",
            "        2.0       0.80      0.69      0.74      1032\n",
            "        3.0       0.71      0.61      0.65      1010\n",
            "        4.0       0.83      0.72      0.77       982\n",
            "        5.0       0.69      0.51      0.59       892\n",
            "        6.0       0.79      0.84      0.82       958\n",
            "        7.0       0.80      0.79      0.80      1028\n",
            "        8.0       0.70      0.55      0.62       974\n",
            "        9.0       0.76      0.65      0.70      1009\n",
            "\n",
            "avg / total       0.74      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 960    2    3    1    0    1    5    8    0    0]\n",
            " [   1 1118   11    1    0    1    3    0    0    0]\n",
            " [  72  128  713    0   11    6   51   33   15    3]\n",
            " [  62   94   61  612    4   51   22   14   84    6]\n",
            " [  20   25    6    4  703   42   23   26   17  116]\n",
            " [ 106   49   19  108   28  454   47    3   62   16]\n",
            " [  55   21   17    1   10   44  806    1    2    1]\n",
            " [  44   76   23   20    8    4    2  811   11   29]\n",
            " [  30  163   37   73   18   28   50    9  535   31]\n",
            " [  24   42    5   39   63   28    7  105   39  657]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59620,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59620, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [ 9 11 37 37 40 71 25 39 45 76] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.519 s \n",
            "\n",
            "Accuracy rate for 73.190000 \n",
            "Classification report for classifier LogisticRegression(C=0.1282051282051282, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.95      0.84       980\n",
            "        1.0       0.64      0.98      0.78      1135\n",
            "        2.0       0.79      0.65      0.71      1032\n",
            "        3.0       0.66      0.67      0.66      1010\n",
            "        4.0       0.85      0.71      0.77       982\n",
            "        5.0       0.68      0.52      0.59       892\n",
            "        6.0       0.72      0.87      0.79       958\n",
            "        7.0       0.81      0.78      0.80      1028\n",
            "        8.0       0.69      0.50      0.58       974\n",
            "        9.0       0.79      0.63      0.70      1009\n",
            "\n",
            "avg / total       0.74      0.73      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 928    4    2    2    0    2   25   16    1    0]\n",
            " [   0 1110   20    0    0    2    3    0    0    0]\n",
            " [  69  147  675    0    7    7   75   32   17    3]\n",
            " [  37   91   47  678    3   47   37    8   54    8]\n",
            " [  12   26   10    8  694   48   36   20   21  107]\n",
            " [  70   46   18  158   16  465   70    4   43    2]\n",
            " [  28   16   11    3   15   46  835    2    2    0]\n",
            " [  38   80   26   16    8    6    4  805   10   35]\n",
            " [  20  162   40  114   29   30   60   10  490   19]\n",
            " [  16   41    9   55   43   29    8   99   70  639]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59610, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [ 9 11 37 37 42 72 26 39 48 79] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.551 s \n",
            "\n",
            "Accuracy rate for 73.010000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.77      0.94      0.85       980\n",
            "        1.0       0.64      0.98      0.78      1135\n",
            "        2.0       0.81      0.63      0.71      1032\n",
            "        3.0       0.67      0.66      0.66      1010\n",
            "        4.0       0.83      0.68      0.75       982\n",
            "        5.0       0.70      0.52      0.60       892\n",
            "        6.0       0.75      0.87      0.81       958\n",
            "        7.0       0.79      0.80      0.80      1028\n",
            "        8.0       0.64      0.54      0.59       974\n",
            "        9.0       0.76      0.62      0.68      1009\n",
            "\n",
            "avg / total       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 923    3    4    3    0    2   22   23    0    0]\n",
            " [   0 1117   14    0    0    2    2    0    0    0]\n",
            " [  59  163  650    4   13    7   70   35   28    3]\n",
            " [  32   91   34  664    2   45   33   13   91    5]\n",
            " [  13   27    7    5  671   43   34   31   24  127]\n",
            " [  67   48   20  154   19  465   61    4   52    2]\n",
            " [  31   18   10    0   16   42  837    1    2    1]\n",
            " [  34   75   23   19    4    4    1  820   11   37]\n",
            " [  23  165   37   89   29   22   46   11  528   24]\n",
            " [  14   38    8   49   50   30    9   96   89  626]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [ 9 11 37 40 43 75 26 39 48 82] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.550 s \n",
            "\n",
            "Accuracy rate for 72.680000 \n",
            "Classification report for classifier LogisticRegression(C=0.12195121951219512, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.91      0.85       980\n",
            "        1.0       0.65      0.97      0.78      1135\n",
            "        2.0       0.80      0.63      0.71      1032\n",
            "        3.0       0.68      0.67      0.68      1010\n",
            "        4.0       0.86      0.62      0.72       982\n",
            "        5.0       0.66      0.55      0.60       892\n",
            "        6.0       0.70      0.87      0.78       958\n",
            "        7.0       0.77      0.82      0.80      1028\n",
            "        8.0       0.69      0.52      0.59       974\n",
            "        9.0       0.73      0.64      0.69      1009\n",
            "\n",
            "avg / total       0.73      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 896    3    4    6    0    3   39   28    1    0]\n",
            " [   0 1106   22    2    0    2    3    0    0    0]\n",
            " [  56  145  655    4    8    7   88   43   24    2]\n",
            " [  33   90   36  675    1   46   42   13   69    5]\n",
            " [  11   22    8    6  609   55   41   40   23  167]\n",
            " [  48   49   13  161   12  490   76    8   32    3]\n",
            " [  21   20    9    0   15   53  834    2    3    1]\n",
            " [  24   66   25   14    8    6    2  845    9   29]\n",
            " [  18  176   40   78   21   41   53   11  508   28]\n",
            " [  10   36    8   44   35   39   10  106   71  650]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59590, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [ 9 11 38 45 43 76 26 39 50 83] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.585 s \n",
            "\n",
            "Accuracy rate for 71.670000 \n",
            "Classification report for classifier LogisticRegression(C=0.11904761904761904, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.91      0.84       980\n",
            "        1.0       0.63      0.98      0.77      1135\n",
            "        2.0       0.80      0.59      0.68      1032\n",
            "        3.0       0.70      0.64      0.67      1010\n",
            "        4.0       0.83      0.62      0.71       982\n",
            "        5.0       0.64      0.55      0.59       892\n",
            "        6.0       0.70      0.87      0.78       958\n",
            "        7.0       0.76      0.82      0.79      1028\n",
            "        8.0       0.66      0.51      0.58       974\n",
            "        9.0       0.73      0.63      0.68      1009\n",
            "\n",
            "avg / total       0.72      0.72      0.71     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 895    4    3    2    0    3   38   34    1    0]\n",
            " [   0 1110   21    0    0    2    2    0    0    0]\n",
            " [  76  167  612    6   13   10   91   31   24    2]\n",
            " [  56   95   18  643    0   63   33   12   82    8]\n",
            " [   4   22    4   11  605   51   52   50   21  162]\n",
            " [  66   47    2  136   19  492   64   17   46    3]\n",
            " [  22   20    5    1   20   56  830    2    1    1]\n",
            " [  13   75   30   12    8    4    2  846    6   32]\n",
            " [  14  174   66   58   28   44   58   10  499   23]\n",
            " [   7   41    8   46   37   39   11  108   77  635]]\n",
            "--------------------------------\n",
            "val predicted: (59580,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59580, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [10 11 40 45 47 78 26 39 50 84] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.538 s \n",
            "\n",
            "Accuracy rate for 72.710000 \n",
            "Classification report for classifier LogisticRegression(C=0.11627906976744186, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.98      0.85       980\n",
            "        1.0       0.62      0.97      0.76      1135\n",
            "        2.0       0.78      0.56      0.65      1032\n",
            "        3.0       0.72      0.62      0.66      1010\n",
            "        4.0       0.83      0.71      0.77       982\n",
            "        5.0       0.63      0.59      0.61       892\n",
            "        6.0       0.73      0.86      0.79       958\n",
            "        7.0       0.80      0.79      0.79      1028\n",
            "        8.0       0.70      0.48      0.57       974\n",
            "        9.0       0.79      0.66      0.72      1009\n",
            "\n",
            "avg / total       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 960    3    1    1    1    2    8    4    0    0]\n",
            " [   0 1105   24    1    0    2    3    0    0    0]\n",
            " [  75  189  577    3   23    9   95   32   23    6]\n",
            " [  36  105   24  625    2   99   34   15   63    7]\n",
            " [  10   20    5    5  701   51   41   27   20  102]\n",
            " [  50   43    3  143   28  529   53   10   28    5]\n",
            " [  39   20    4    1   17   50  824    1    1    1]\n",
            " [  52   67   31    9   14    5    2  812    7   29]\n",
            " [  26  191   59   50   25   55   58   11  472   27]\n",
            " [  23   38    8   34   34   36    6  108   56  666]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59570,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59570, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [10 11 41 47 49 78 27 40 52 85] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.543 s \n",
            "\n",
            "Accuracy rate for 74.110000 \n",
            "Classification report for classifier LogisticRegression(C=0.11363636363636363, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.97      0.88       980\n",
            "        1.0       0.63      0.97      0.77      1135\n",
            "        2.0       0.78      0.61      0.68      1032\n",
            "        3.0       0.71      0.69      0.70      1010\n",
            "        4.0       0.89      0.68      0.77       982\n",
            "        5.0       0.67      0.59      0.63       892\n",
            "        6.0       0.72      0.88      0.79       958\n",
            "        7.0       0.78      0.81      0.80      1028\n",
            "        8.0       0.77      0.49      0.60       974\n",
            "        9.0       0.78      0.69      0.73      1009\n",
            "\n",
            "avg / total       0.75      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 951    3    1    1    1    4   14    5    0    0]\n",
            " [   0 1097   34    0    0    2    2    0    0    0]\n",
            " [  63  155  625   13   15    8   97   39   14    3]\n",
            " [  27   94   31  692    1   59   30   14   55    7]\n",
            " [   7   18    4    6  665   57   61   37   11  116]\n",
            " [  39   50    5  163   11  530   54   10   25    5]\n",
            " [  32   18   10    1    4   42  847    1    2    1]\n",
            " [  35   68   34    5    8    4    4  832    3   35]\n",
            " [  15  192   56   63   16   49   61   13  474   35]\n",
            " [  18   37    5   32   27   35   12  111   34  698]]\n",
            "--------------------------------\n",
            "val predicted: (59560,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59560, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [10 11 43 48 50 79 27 40 54 88] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.603 s \n",
            "\n",
            "Accuracy rate for 73.060000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.98      0.85       980\n",
            "        1.0       0.64      0.97      0.77      1135\n",
            "        2.0       0.76      0.59      0.66      1032\n",
            "        3.0       0.75      0.66      0.70      1010\n",
            "        4.0       0.85      0.70      0.76       982\n",
            "        5.0       0.65      0.59      0.62       892\n",
            "        6.0       0.73      0.87      0.79       958\n",
            "        7.0       0.78      0.79      0.79      1028\n",
            "        8.0       0.67      0.52      0.59       974\n",
            "        9.0       0.81      0.60      0.69      1009\n",
            "\n",
            "avg / total       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 961    4    0    1    0    3    8    3    0    0]\n",
            " [   0 1103   28    0    0    2    2    0    0    0]\n",
            " [  78  159  607    7   15   10   95   29   29    3]\n",
            " [  38   87   29  663    1   63   30   15   78    6]\n",
            " [  10   21    7    4  683   63   61   39   22   72]\n",
            " [  63   50    5  131   20  523   52   12   31    5]\n",
            " [  43   19    8    0    6   41  836    1    3    1]\n",
            " [  48   76   37    4    9    4    4  815    3   28]\n",
            " [  26  169   67   52   15   51   51   11  508   24]\n",
            " [  22   41    6   26   55   39   12  118   83  607]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [10 11 45 51 50 79 28 41 55 90] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.497 s \n",
            "\n",
            "Accuracy rate for 74.340000 \n",
            "Classification report for classifier LogisticRegression(C=0.10869565217391304, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.97      0.87       980\n",
            "        1.0       0.64      0.98      0.78      1135\n",
            "        2.0       0.80      0.60      0.68      1032\n",
            "        3.0       0.75      0.64      0.69      1010\n",
            "        4.0       0.86      0.73      0.79       982\n",
            "        5.0       0.64      0.59      0.62       892\n",
            "        6.0       0.72      0.87      0.79       958\n",
            "        7.0       0.79      0.82      0.81      1028\n",
            "        8.0       0.71      0.53      0.60       974\n",
            "        9.0       0.83      0.67      0.74      1009\n",
            "\n",
            "avg / total       0.75      0.74      0.74     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 946    3    2    1    0    3   14   10    0    1]\n",
            " [   0 1108   21    1    0    2    2    1    0    0]\n",
            " [  58  155  617    5    8    8   93   46   36    6]\n",
            " [  34   96   46  644    2   66   27   15   72    8]\n",
            " [  10   20    4    1  714   63   61   34   19   56]\n",
            " [  43   51   11  134   25  528   52   12   24   12]\n",
            " [  35   15   14    0    8   43  837    3    2    1]\n",
            " [  41   71   23    1    6    1    2  844   11   28]\n",
            " [  17  163   31   57   15   66   69    9  515   32]\n",
            " [  21   36    3   19   52   44   11   91   51  681]]\n",
            "--------------------------------\n",
            "val predicted: (59540,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59540, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [11 11 45 51 54 80 28 41 56 93] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.561 s \n",
            "\n",
            "Accuracy rate for 72.560000 \n",
            "Classification report for classifier LogisticRegression(C=0.10638297872340426, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.74      0.96      0.83       980\n",
            "        1.0       0.63      0.98      0.77      1135\n",
            "        2.0       0.78      0.58      0.67      1032\n",
            "        3.0       0.74      0.64      0.69      1010\n",
            "        4.0       0.89      0.65      0.75       982\n",
            "        5.0       0.65      0.59      0.62       892\n",
            "        6.0       0.69      0.86      0.77       958\n",
            "        7.0       0.78      0.80      0.79      1028\n",
            "        8.0       0.67      0.49      0.57       974\n",
            "        9.0       0.79      0.66      0.72      1009\n",
            "\n",
            "avg / total       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    4    0    2    0    4   27    5    1    0]\n",
            " [   1 1117   14    0    0    1    2    0    0    0]\n",
            " [  72  184  598    4    7    8   91   36   28    4]\n",
            " [  28   89   47  649    1   69   34   11   76    6]\n",
            " [  24   23    5    4  640   55   53   56   24   98]\n",
            " [  78   43   15  129    8  526   52   11   25    5]\n",
            " [  37   21    8    1    5   51  827    4    3    1]\n",
            " [  47   85   27    5    8    3    2  819    7   25]\n",
            " [  24  175   44   50   18   49   93    7  480   34]\n",
            " [  25   41    4   28   33   39   11   96   69  663]]\n",
            "--------------------------------\n",
            "val predicted: (59530,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59530, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [11 11 45 54 55 81 28 42 59 94] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.558 s \n",
            "\n",
            "Accuracy rate for 72.640000 \n",
            "Classification report for classifier LogisticRegression(C=0.10416666666666667, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.69      0.98      0.81       980\n",
            "        1.0       0.63      0.98      0.77      1135\n",
            "        2.0       0.80      0.56      0.66      1032\n",
            "        3.0       0.74      0.64      0.69      1010\n",
            "        4.0       0.84      0.71      0.77       982\n",
            "        5.0       0.66      0.57      0.61       892\n",
            "        6.0       0.72      0.86      0.78       958\n",
            "        7.0       0.80      0.78      0.79      1028\n",
            "        8.0       0.71      0.51      0.59       974\n",
            "        9.0       0.81      0.63      0.71      1009\n",
            "\n",
            "avg / total       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 963    3    0    2    0    2    9    1    0    0]\n",
            " [   1 1115   15    0    0    1    2    0    1    0]\n",
            " [  88  168  582    7   11    8  105   30   30    3]\n",
            " [  50   89   40  647    2   79   26   15   56    6]\n",
            " [  31   21    4    1  697   53   56   25   20   74]\n",
            " [ 104   47   18  125   11  505   43   12   22    5]\n",
            " [  53   21    8    0    5   42  827    1    1    0]\n",
            " [  57   82   26    2   20    3    3  797    8   30]\n",
            " [  25  178   31   60   25   48   74    7  492   34]\n",
            " [  27   45    4   25   54   29   11  113   62  639]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59520, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [11 11 49 55 56 81 28 42 62 95] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.665 s \n",
            "\n",
            "Accuracy rate for 72.350000 \n",
            "Classification report for classifier LogisticRegression(C=0.10204081632653061, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.98      0.83       980\n",
            "        1.0       0.63      0.99      0.77      1135\n",
            "        2.0       0.81      0.56      0.66      1032\n",
            "        3.0       0.74      0.64      0.69      1010\n",
            "        4.0       0.83      0.71      0.76       982\n",
            "        5.0       0.65      0.56      0.60       892\n",
            "        6.0       0.70      0.85      0.77       958\n",
            "        7.0       0.78      0.78      0.78      1028\n",
            "        8.0       0.71      0.50      0.59       974\n",
            "        9.0       0.79      0.62      0.70      1009\n",
            "\n",
            "avg / total       0.74      0.72      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 960    3    0    1    0    4   11    1    0    0]\n",
            " [   0 1121    4    0    0    2    2    0    6    0]\n",
            " [  72  181  580    0   11    8   92   34   50    4]\n",
            " [  42   94   64  646    2   71   26   17   43    5]\n",
            " [  21   18    3    3  695   62   63   29   14   74]\n",
            " [  87   45   20  128   20  500   53   12   22    5]\n",
            " [  54   21   10    0    6   51  812    2    1    1]\n",
            " [  53   79   19    2   19    5    2  806   11   32]\n",
            " [  26  185   17   61   15   39   86   11  487   47]\n",
            " [  29   42    3   30   70   33    8  115   51  628]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59510, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [11 11 49 56 56 83 28 44 65 97] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.606 s \n",
            "\n",
            "Accuracy rate for 72.860000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.77      0.97      0.86       980\n",
            "        1.0       0.62      0.98      0.76      1135\n",
            "        2.0       0.78      0.58      0.66      1032\n",
            "        3.0       0.70      0.67      0.69      1010\n",
            "        4.0       0.84      0.71      0.77       982\n",
            "        5.0       0.67      0.57      0.61       892\n",
            "        6.0       0.70      0.87      0.78       958\n",
            "        7.0       0.76      0.80      0.78      1028\n",
            "        8.0       0.77      0.49      0.60       974\n",
            "        9.0       0.79      0.62      0.69      1009\n",
            "\n",
            "avg / total       0.74      0.73      0.72     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 953    3    0    1    1    5   10    5    2    0]\n",
            " [   0 1117   11    1    0    2    2    0    2    0]\n",
            " [  64  177  598    1   10    6   97   39   35    5]\n",
            " [  24   95   76  674    1   65   26   13   27    9]\n",
            " [  13   21    1    6  695   52   70   35   12   77]\n",
            " [  60   52   24  159   13  504   44   15   19    2]\n",
            " [  40   22    9    0    6   46  829    4    2    0]\n",
            " [  48   76   20    6   17    3    2  821    8   27]\n",
            " [  21  189   24   71   20   40   84   11  473   41]\n",
            " [  17   45    4   38   65   34   14  136   34  622]]\n",
            "--------------------------------\n",
            "final active learning accuracies [33.269999999999996, 56.63, 57.709999999999994, 61.82, 64.57000000000001, 67.43, 69.24, 69.76, 69.87, 71.05, 73.27, 71.35000000000001, 70.75, 72.61, 71.23, 72.57000000000001, 72.38, 73.17, 73.94, 73.44000000000001, 72.26, 72.78, 73.68, 72.75, 73.79, 73.91, 72.39, 71.72, 74.39, 73.09, 73.39, 73.25, 72.8, 74.51, 72.15, 72.08, 71.78, 73.69, 73.19, 73.00999999999999, 72.68, 71.67, 72.71, 74.11, 73.06, 74.33999999999999, 72.56, 72.64, 72.35000000000001, 72.86]\n",
            "saved Active-learning-experiment-40.pkl /content ['datalab', 'Active-learning-experiment-32.pkl', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-38.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-33.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-29.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "{\n",
            "  \"LogModel\": {\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          33.269999999999996,\n",
            "          56.63,\n",
            "          57.709999999999994,\n",
            "          61.82,\n",
            "          64.57000000000001,\n",
            "          67.43,\n",
            "          69.24,\n",
            "          69.76,\n",
            "          69.87,\n",
            "          71.05,\n",
            "          73.27,\n",
            "          71.35000000000001,\n",
            "          70.75,\n",
            "          72.61,\n",
            "          71.23,\n",
            "          72.57000000000001,\n",
            "          72.38,\n",
            "          73.17,\n",
            "          73.94,\n",
            "          73.44000000000001,\n",
            "          72.26,\n",
            "          72.78,\n",
            "          73.68,\n",
            "          72.75,\n",
            "          73.79,\n",
            "          73.91,\n",
            "          72.39,\n",
            "          71.72,\n",
            "          74.39,\n",
            "          73.09,\n",
            "          73.39,\n",
            "          73.25,\n",
            "          72.8,\n",
            "          74.51,\n",
            "          72.15,\n",
            "          72.08,\n",
            "          71.78,\n",
            "          73.69,\n",
            "          73.19,\n",
            "          73.00999999999999,\n",
            "          72.68,\n",
            "          71.67,\n",
            "          72.71,\n",
            "          74.11,\n",
            "          73.06,\n",
            "          74.33999999999999,\n",
            "          72.56,\n",
            "          72.64,\n",
            "          72.35000000000001,\n",
            "          72.86\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          41.980000000000004,\n",
            "          52.12,\n",
            "          65.4,\n",
            "          64.84,\n",
            "          65.10000000000001,\n",
            "          64.14,\n",
            "          65.86999999999999,\n",
            "          66.99000000000001,\n",
            "          70.11,\n",
            "          70.44,\n",
            "          67.21000000000001,\n",
            "          71.17,\n",
            "          70.33,\n",
            "          70.12,\n",
            "          71.6,\n",
            "          70.3,\n",
            "          68.16,\n",
            "          69.51,\n",
            "          69.59,\n",
            "          70.85000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          62.8,\n",
            "          70.19,\n",
            "          68.39,\n",
            "          71.65,\n",
            "          69.44,\n",
            "          70.94,\n",
            "          70.7,\n",
            "          70.14,\n",
            "          71.17,\n",
            "          70.21\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.11,\n",
            "          72.42,\n",
            "          72.0,\n",
            "          72.81\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          73.76,\n",
            "          73.76\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.61,\n",
            "          50.36000000000001,\n",
            "          53.1,\n",
            "          59.74,\n",
            "          62.7,\n",
            "          64.03999999999999,\n",
            "          64.25,\n",
            "          61.629999999999995,\n",
            "          66.47,\n",
            "          68.0,\n",
            "          65.75999999999999,\n",
            "          65.0,\n",
            "          65.27,\n",
            "          66.46,\n",
            "          66.99000000000001,\n",
            "          66.86,\n",
            "          67.28,\n",
            "          66.72,\n",
            "          67.10000000000001,\n",
            "          68.33,\n",
            "          69.25,\n",
            "          69.69999999999999,\n",
            "          69.32000000000001,\n",
            "          67.72,\n",
            "          69.87,\n",
            "          68.69,\n",
            "          68.83,\n",
            "          70.00999999999999,\n",
            "          69.65,\n",
            "          70.19,\n",
            "          71.41,\n",
            "          70.53,\n",
            "          70.15,\n",
            "          68.74,\n",
            "          70.0,\n",
            "          68.24,\n",
            "          68.92,\n",
            "          67.91,\n",
            "          69.17999999999999,\n",
            "          68.87,\n",
            "          69.02000000000001,\n",
            "          70.00999999999999,\n",
            "          70.47,\n",
            "          71.83,\n",
            "          70.78,\n",
            "          70.61,\n",
            "          71.33,\n",
            "          70.91,\n",
            "          71.0,\n",
            "          71.78999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          46.63,\n",
            "          57.86,\n",
            "          62.019999999999996,\n",
            "          70.61,\n",
            "          72.74000000000001,\n",
            "          69.82000000000001,\n",
            "          69.6,\n",
            "          70.81,\n",
            "          70.82000000000001,\n",
            "          69.49,\n",
            "          71.46000000000001,\n",
            "          71.48,\n",
            "          72.04,\n",
            "          72.11,\n",
            "          72.65,\n",
            "          73.09,\n",
            "          73.72,\n",
            "          73.86,\n",
            "          74.69,\n",
            "          73.72999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          68.38,\n",
            "          66.14999999999999,\n",
            "          70.45,\n",
            "          72.68,\n",
            "          72.31,\n",
            "          72.33000000000001,\n",
            "          73.44000000000001,\n",
            "          71.78999999999999,\n",
            "          73.11999999999999,\n",
            "          70.84\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          68.95,\n",
            "          68.53,\n",
            "          71.67,\n",
            "          73.09\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          73.11,\n",
            "          74.56\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"RfModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          37.519999999999996,\n",
            "          42.53,\n",
            "          51.42,\n",
            "          49.03,\n",
            "          49.25,\n",
            "          52.01,\n",
            "          51.41,\n",
            "          51.89,\n",
            "          53.04,\n",
            "          55.48,\n",
            "          56.989999999999995,\n",
            "          56.720000000000006,\n",
            "          56.93,\n",
            "          55.169999999999995,\n",
            "          56.26,\n",
            "          55.64,\n",
            "          54.769999999999996,\n",
            "          54.98,\n",
            "          54.06999999999999,\n",
            "          53.71,\n",
            "          53.21,\n",
            "          52.800000000000004,\n",
            "          53.54,\n",
            "          52.72,\n",
            "          52.65,\n",
            "          51.849999999999994,\n",
            "          51.67,\n",
            "          51.89,\n",
            "          52.54,\n",
            "          53.03,\n",
            "          56.06,\n",
            "          56.26,\n",
            "          55.669999999999995,\n",
            "          60.17,\n",
            "          60.480000000000004,\n",
            "          59.9,\n",
            "          58.97,\n",
            "          60.019999999999996,\n",
            "          59.81999999999999,\n",
            "          59.86,\n",
            "          59.95,\n",
            "          62.970000000000006,\n",
            "          63.7,\n",
            "          62.94,\n",
            "          62.19,\n",
            "          62.019999999999996,\n",
            "          63.89,\n",
            "          62.150000000000006,\n",
            "          60.17,\n",
            "          62.39\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          44.21,\n",
            "          39.2,\n",
            "          37.57,\n",
            "          35.82,\n",
            "          36.120000000000005,\n",
            "          33.64,\n",
            "          32.09,\n",
            "          32.1,\n",
            "          32.28,\n",
            "          30.759999999999998,\n",
            "          31.230000000000004,\n",
            "          29.34,\n",
            "          26.419999999999998,\n",
            "          27.05,\n",
            "          26.58,\n",
            "          23.23,\n",
            "          24.0,\n",
            "          23.7,\n",
            "          21.58,\n",
            "          23.84\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          63.85999999999999,\n",
            "          60.309999999999995,\n",
            "          59.760000000000005,\n",
            "          59.89,\n",
            "          59.160000000000004,\n",
            "          59.519999999999996,\n",
            "          57.9,\n",
            "          59.74,\n",
            "          57.06,\n",
            "          59.91\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          75.02,\n",
            "          74.36,\n",
            "          72.39999999999999,\n",
            "          72.08\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.39999999999999,\n",
            "          81.82000000000001\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          25.72,\n",
            "          38.83,\n",
            "          53.99,\n",
            "          57.53,\n",
            "          62.39,\n",
            "          66.58,\n",
            "          64.23,\n",
            "          67.5,\n",
            "          72.75,\n",
            "          76.35,\n",
            "          77.31,\n",
            "          77.96,\n",
            "          78.17,\n",
            "          80.67,\n",
            "          81.76,\n",
            "          83.63000000000001,\n",
            "          85.26,\n",
            "          85.37,\n",
            "          85.82,\n",
            "          85.76,\n",
            "          86.00999999999999,\n",
            "          87.01,\n",
            "          87.45,\n",
            "          87.83,\n",
            "          88.64999999999999,\n",
            "          88.1,\n",
            "          87.92999999999999,\n",
            "          89.21,\n",
            "          89.57000000000001,\n",
            "          90.34,\n",
            "          91.12,\n",
            "          90.86,\n",
            "          91.17,\n",
            "          91.53999999999999,\n",
            "          91.84,\n",
            "          91.75999999999999,\n",
            "          91.07,\n",
            "          91.36,\n",
            "          91.22,\n",
            "          91.88,\n",
            "          92.0,\n",
            "          91.97,\n",
            "          91.7,\n",
            "          92.12,\n",
            "          92.28,\n",
            "          92.57,\n",
            "          92.63,\n",
            "          92.55,\n",
            "          92.80000000000001,\n",
            "          92.75999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          39.050000000000004,\n",
            "          51.85999999999999,\n",
            "          67.30000000000001,\n",
            "          74.29,\n",
            "          74.42999999999999,\n",
            "          80.15,\n",
            "          83.55,\n",
            "          83.58,\n",
            "          86.24000000000001,\n",
            "          87.22999999999999,\n",
            "          87.89,\n",
            "          88.42999999999999,\n",
            "          88.94,\n",
            "          90.06,\n",
            "          89.57000000000001,\n",
            "          90.03999999999999,\n",
            "          90.03999999999999,\n",
            "          91.14,\n",
            "          91.86,\n",
            "          91.79\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          62.99,\n",
            "          75.07000000000001,\n",
            "          75.38,\n",
            "          83.96000000000001,\n",
            "          87.89,\n",
            "          89.62,\n",
            "          89.7,\n",
            "          91.47999999999999,\n",
            "          91.84,\n",
            "          92.49000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          76.4,\n",
            "          85.66,\n",
            "          90.22,\n",
            "          92.13\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          81.26,\n",
            "          87.98\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          36.01,\n",
            "          43.34,\n",
            "          53.94,\n",
            "          58.02,\n",
            "          60.97,\n",
            "          66.44,\n",
            "          68.63,\n",
            "          70.8,\n",
            "          72.08,\n",
            "          73.58,\n",
            "          73.63,\n",
            "          74.0,\n",
            "          74.2,\n",
            "          75.52,\n",
            "          75.41,\n",
            "          75.81,\n",
            "          75.98,\n",
            "          77.97,\n",
            "          77.5,\n",
            "          80.15,\n",
            "          79.81,\n",
            "          81.13,\n",
            "          80.87,\n",
            "          80.58999999999999,\n",
            "          80.86,\n",
            "          81.26,\n",
            "          82.26,\n",
            "          82.44,\n",
            "          82.75,\n",
            "          82.92,\n",
            "          83.76,\n",
            "          83.50999999999999,\n",
            "          85.05,\n",
            "          85.50999999999999,\n",
            "          85.13,\n",
            "          86.02,\n",
            "          86.02,\n",
            "          86.5,\n",
            "          86.09,\n",
            "          85.83,\n",
            "          86.9,\n",
            "          86.46000000000001,\n",
            "          86.38,\n",
            "          86.88,\n",
            "          87.09,\n",
            "          87.87,\n",
            "          87.47,\n",
            "          87.59,\n",
            "          87.74,\n",
            "          87.78\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.64,\n",
            "          60.72,\n",
            "          65.45,\n",
            "          70.28999999999999,\n",
            "          72.94,\n",
            "          76.08,\n",
            "          77.51,\n",
            "          77.78,\n",
            "          79.35,\n",
            "          80.39,\n",
            "          81.6,\n",
            "          81.17,\n",
            "          82.73,\n",
            "          84.28,\n",
            "          84.15,\n",
            "          85.2,\n",
            "          86.13,\n",
            "          86.78,\n",
            "          86.95,\n",
            "          87.59\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          56.86,\n",
            "          69.43,\n",
            "          71.87,\n",
            "          75.68,\n",
            "          80.01,\n",
            "          82.06,\n",
            "          84.5,\n",
            "          85.92,\n",
            "          86.76,\n",
            "          87.32\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.5,\n",
            "          82.39,\n",
            "          85.76,\n",
            "          87.56\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.19,\n",
            "          88.14999999999999\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"SvmModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          35.93,\n",
            "          35.97,\n",
            "          40.33,\n",
            "          39.39,\n",
            "          41.349999999999994,\n",
            "          42.99,\n",
            "          46.23,\n",
            "          46.18,\n",
            "          47.260000000000005,\n",
            "          52.5,\n",
            "          52.400000000000006,\n",
            "          51.25999999999999,\n",
            "          51.690000000000005,\n",
            "          51.800000000000004,\n",
            "          53.18000000000001,\n",
            "          53.82,\n",
            "          55.88999999999999,\n",
            "          56.120000000000005,\n",
            "          57.269999999999996,\n",
            "          59.41,\n",
            "          59.95,\n",
            "          62.629999999999995,\n",
            "          61.339999999999996,\n",
            "          63.88,\n",
            "          65.34,\n",
            "          65.77,\n",
            "          66.9,\n",
            "          67.96,\n",
            "          68.27,\n",
            "          67.44,\n",
            "          68.45,\n",
            "          68.63,\n",
            "          68.0,\n",
            "          68.47,\n",
            "          68.77,\n",
            "          68.8,\n",
            "          69.17,\n",
            "          68.97,\n",
            "          69.33,\n",
            "          69.67999999999999,\n",
            "          69.95,\n",
            "          70.34,\n",
            "          70.47,\n",
            "          71.19,\n",
            "          71.97,\n",
            "          72.26,\n",
            "          72.06,\n",
            "          71.98,\n",
            "          72.55,\n",
            "          72.78999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          50.33,\n",
            "          51.59,\n",
            "          56.599999999999994,\n",
            "          60.24,\n",
            "          61.57,\n",
            "          63.5,\n",
            "          66.74,\n",
            "          68.19,\n",
            "          68.02,\n",
            "          69.8,\n",
            "          75.88000000000001,\n",
            "          77.24,\n",
            "          78.09,\n",
            "          79.38,\n",
            "          80.4,\n",
            "          80.99,\n",
            "          80.28999999999999,\n",
            "          80.12,\n",
            "          79.75999999999999,\n",
            "          80.36999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          64.55,\n",
            "          68.75,\n",
            "          71.34,\n",
            "          74.11999999999999,\n",
            "          75.96000000000001,\n",
            "          77.03999999999999,\n",
            "          76.85,\n",
            "          79.19,\n",
            "          80.51,\n",
            "          80.99\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          78.4,\n",
            "          78.21000000000001,\n",
            "          80.08,\n",
            "          81.0\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.11,\n",
            "          84.53\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.86,\n",
            "          37.6,\n",
            "          46.23,\n",
            "          58.41,\n",
            "          60.34,\n",
            "          65.98,\n",
            "          65.01,\n",
            "          69.86,\n",
            "          72.28999999999999,\n",
            "          74.65,\n",
            "          76.24,\n",
            "          77.37,\n",
            "          77.59,\n",
            "          78.7,\n",
            "          79.06,\n",
            "          80.06,\n",
            "          81.21000000000001,\n",
            "          82.32000000000001,\n",
            "          83.17,\n",
            "          83.78,\n",
            "          84.6,\n",
            "          84.58,\n",
            "          84.47,\n",
            "          85.07000000000001,\n",
            "          85.64,\n",
            "          85.75,\n",
            "          85.7,\n",
            "          86.18,\n",
            "          86.58,\n",
            "          86.50999999999999,\n",
            "          86.71,\n",
            "          87.09,\n",
            "          86.91,\n",
            "          87.13,\n",
            "          87.42999999999999,\n",
            "          87.75,\n",
            "          87.97,\n",
            "          88.23,\n",
            "          88.23,\n",
            "          88.22,\n",
            "          88.16000000000001,\n",
            "          88.03,\n",
            "          88.38000000000001,\n",
            "          88.39,\n",
            "          88.64,\n",
            "          88.98,\n",
            "          89.05999999999999,\n",
            "          89.34,\n",
            "          89.3,\n",
            "          89.52\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          50.160000000000004,\n",
            "          63.73,\n",
            "          70.14,\n",
            "          74.4,\n",
            "          78.99000000000001,\n",
            "          80.36999999999999,\n",
            "          82.76,\n",
            "          84.35000000000001,\n",
            "          85.78,\n",
            "          86.61999999999999,\n",
            "          87.46000000000001,\n",
            "          87.64,\n",
            "          88.08,\n",
            "          88.75,\n",
            "          88.68,\n",
            "          89.02,\n",
            "          89.39,\n",
            "          89.57000000000001,\n",
            "          89.66,\n",
            "          89.8\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          59.099999999999994,\n",
            "          69.91000000000001,\n",
            "          75.66000000000001,\n",
            "          81.41000000000001,\n",
            "          82.69,\n",
            "          85.07000000000001,\n",
            "          85.92,\n",
            "          86.89,\n",
            "          87.8,\n",
            "          87.6\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.45,\n",
            "          84.1,\n",
            "          86.36,\n",
            "          88.16000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.58,\n",
            "          87.38\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.009999999999998,\n",
            "          33.54,\n",
            "          48.67,\n",
            "          57.34,\n",
            "          61.68,\n",
            "          64.75999999999999,\n",
            "          69.28,\n",
            "          71.97,\n",
            "          73.2,\n",
            "          74.03,\n",
            "          75.08,\n",
            "          76.01,\n",
            "          76.55,\n",
            "          77.42999999999999,\n",
            "          77.75,\n",
            "          79.72,\n",
            "          80.78,\n",
            "          81.62,\n",
            "          81.8,\n",
            "          82.03,\n",
            "          81.82000000000001,\n",
            "          82.72,\n",
            "          82.94,\n",
            "          83.03,\n",
            "          83.72,\n",
            "          83.81,\n",
            "          83.72,\n",
            "          83.95,\n",
            "          84.38,\n",
            "          85.02,\n",
            "          85.36,\n",
            "          85.65,\n",
            "          85.26,\n",
            "          85.37,\n",
            "          85.37,\n",
            "          85.19,\n",
            "          85.18,\n",
            "          85.61999999999999,\n",
            "          85.47,\n",
            "          85.61999999999999,\n",
            "          85.78,\n",
            "          86.00999999999999,\n",
            "          86.05000000000001,\n",
            "          85.96000000000001,\n",
            "          85.96000000000001,\n",
            "          86.0,\n",
            "          86.24000000000001,\n",
            "          86.6,\n",
            "          86.66,\n",
            "          86.81\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.449999999999996,\n",
            "          67.88,\n",
            "          72.25,\n",
            "          77.82,\n",
            "          79.19,\n",
            "          80.32000000000001,\n",
            "          81.19,\n",
            "          81.91000000000001,\n",
            "          82.67999999999999,\n",
            "          82.89,\n",
            "          82.89,\n",
            "          83.05,\n",
            "          83.91999999999999,\n",
            "          84.69,\n",
            "          84.77,\n",
            "          84.66,\n",
            "          85.0,\n",
            "          85.3,\n",
            "          85.79,\n",
            "          86.08\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          56.38999999999999,\n",
            "          72.92999999999999,\n",
            "          78.44,\n",
            "          81.0,\n",
            "          82.73,\n",
            "          83.52000000000001,\n",
            "          84.35000000000001,\n",
            "          85.17,\n",
            "          86.17,\n",
            "          86.66\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          73.76,\n",
            "          83.52000000000001,\n",
            "          85.6,\n",
            "          86.44\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.02000000000001,\n",
            "          85.64\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 41, using model = LogModel, selection_function = EntropySelection, k = 250, iteration = 0.\n",
            "\n",
            "initial random chosen samples (250,)\n",
            "initial train set: (250, 784) (250,) unique(labels): [24 20 16 22 26 31 28 38 23 22] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,) (250,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.417 s \n",
            "\n",
            "Accuracy rate for 73.770000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.92      0.87       980\n",
            "        1.0       0.74      0.99      0.85      1135\n",
            "        2.0       0.77      0.56      0.65      1032\n",
            "        3.0       0.71      0.78      0.74      1010\n",
            "        4.0       0.73      0.72      0.72       982\n",
            "        5.0       0.59      0.43      0.50       892\n",
            "        6.0       0.76      0.86      0.80       958\n",
            "        7.0       0.80      0.76      0.78      1028\n",
            "        8.0       0.71      0.64      0.68       974\n",
            "        9.0       0.70      0.67      0.68      1009\n",
            "\n",
            "avg / total       0.73      0.74      0.73     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 898    2    4   10    5   12   22   17    9    1]\n",
            " [   0 1121    3    1    0    0    5    3    2    0]\n",
            " [  46  135  575  103   46    0   57   22   34   14]\n",
            " [  13   21   31  783    1   44   13   37   53   14]\n",
            " [  10   23   11    0  706   46   41    6   14  125]\n",
            " [  39   17   28  148   59  384   59   52   88   18]\n",
            " [  39   12   20    1   31   17  821    0   15    2]\n",
            " [  15   66   21    4   20    6    7  783    8   98]\n",
            " [  13   93   40   46   25   59   39    9  628   22]\n",
            " [  17   23   14   10   76   88   18   51   34  678]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59750,) [0. 0. 8. ... 9. 4. 5.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 8 ... 9 4 5]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [ 28  32  31  50  41 136  45  69  34  34] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.533 s \n",
            "\n",
            "Accuracy rate for 63.230000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.66      0.92      0.77       980\n",
            "        1.0       0.58      0.97      0.73      1135\n",
            "        2.0       0.77      0.41      0.53      1032\n",
            "        3.0       0.62      0.43      0.51      1010\n",
            "        4.0       0.73      0.76      0.75       982\n",
            "        5.0       0.37      0.12      0.18       892\n",
            "        6.0       0.70      0.83      0.76       958\n",
            "        7.0       0.86      0.60      0.70      1028\n",
            "        8.0       0.44      0.55      0.49       974\n",
            "        9.0       0.60      0.67      0.63      1009\n",
            "\n",
            "avg / total       0.64      0.63      0.61     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 906    1   27    1    1    4   32    0    5    3]\n",
            " [   0 1105    0    3    0    3    8    1   15    0]\n",
            " [  63  263  419    7   44    4  127   51   35   19]\n",
            " [ 114   78   14  434    3   86   32    6  229   14]\n",
            " [   8   15   14   14  745   17   10    5   45  109]\n",
            " [ 160   80    6  151   41  106   73    1  207   67]\n",
            " [  35   22   19    4   52   18  791    1   16    0]\n",
            " [  49   61   13   15   27   20    3  612   20  208]\n",
            " [  26  251   24   28    9   19   42    9  533   33]\n",
            " [  17   32    5   46   95   13    4   24  101  672]]\n",
            "--------------------------------\n",
            "final active learning accuracies [73.77, 63.23]\n",
            "saved Active-learning-experiment-41.pkl /content ['datalab', 'Active-learning-experiment-32.pkl', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-38.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-41.pkl', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-33.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-29.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 42, using model = LogModel, selection_function = EntropySelection, k = 125, iteration = 0.\n",
            "\n",
            "initial random chosen samples (125,)\n",
            "initial train set: (125, 784) (125,) unique(labels): [11 10  5 13  9 10 21 17 11 18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,) (125,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.372 s \n",
            "\n",
            "Accuracy rate for 69.070000 \n",
            "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.81      0.86      0.84       980\n",
            "        1.0       0.76      0.83      0.79      1135\n",
            "        2.0       0.67      0.27      0.39      1032\n",
            "        3.0       0.70      0.74      0.72      1010\n",
            "        4.0       0.73      0.67      0.70       982\n",
            "        5.0       0.74      0.51      0.60       892\n",
            "        6.0       0.62      0.89      0.73       958\n",
            "        7.0       0.78      0.78      0.78      1028\n",
            "        8.0       0.49      0.68      0.57       974\n",
            "        9.0       0.68      0.66      0.67      1009\n",
            "\n",
            "avg / total       0.70      0.69      0.68     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[846   1  18   0   2  10  70  18  15   0]\n",
            " [  0 943   0   2   0   1   6   1 182   0]\n",
            " [ 80  63 283   0  57   3 219  32 293   2]\n",
            " [ 34  38  22 744  14  36  35  21  62   4]\n",
            " [  0  30  43  12 659  18  32   8  13 167]\n",
            " [ 39  35  10 147  38 456  78  49  30  10]\n",
            " [ 11   5  22   1  23  12 854   3  26   1]\n",
            " [  7  45   2   9  13   3   8 799  41 101]\n",
            " [ 21  66   8  67  24  44  51  10 658  25]\n",
            " [  8  17  15  79  68  37  18  83  19 665]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) [0. 0. 8. ... 9. 3. 3.]\n",
            "probabilities: (59875, 10) \n",
            " [0 0 8 ... 9 3 3]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [14 10 24 33 14 52 23 35 18 27] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.431 s \n",
            "\n",
            "Accuracy rate for 62.660000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.67      0.88      0.76       980\n",
            "        1.0       0.70      0.93      0.80      1135\n",
            "        2.0       0.60      0.38      0.46      1032\n",
            "        3.0       0.71      0.36      0.48      1010\n",
            "        4.0       0.52      0.79      0.63       982\n",
            "        5.0       0.74      0.26      0.39       892\n",
            "        6.0       0.61      0.91      0.73       958\n",
            "        7.0       0.86      0.50      0.63      1028\n",
            "        8.0       0.52      0.72      0.60       974\n",
            "        9.0       0.57      0.49      0.53      1009\n",
            "\n",
            "avg / total       0.65      0.63      0.61     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 859    1    6    2    2   14   83    7    6    0]\n",
            " [   0 1059    2    2    0    0    5    1   66    0]\n",
            " [  54  114  388    1   89    5  225   21  115   20]\n",
            " [ 130   79  179  365   23   48   49    4  122   11]\n",
            " [   1   38    1    2  775    4   28   15   68   50]\n",
            " [ 151   27   13  109   94  234  104    3  119   38]\n",
            " [   8   13    8    1   24    2  872    5   23    2]\n",
            " [  42   62   13    5  105    0    6  515   35  245]\n",
            " [  24   84   24   16   49    9   55    1  700   12]\n",
            " [  17   30    8    8  318    0   13   26   90  499]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 9. 9. 7.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 9 9 7]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [ 15  12  37  41  27 110  24  42  30  37] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.502 s \n",
            "\n",
            "Accuracy rate for 58.930000 \n",
            "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.62      0.89      0.73       980\n",
            "        1.0       0.63      0.97      0.76      1135\n",
            "        2.0       0.77      0.16      0.26      1032\n",
            "        3.0       0.56      0.30      0.39      1010\n",
            "        4.0       0.70      0.70      0.70       982\n",
            "        5.0       0.77      0.05      0.09       892\n",
            "        6.0       0.49      0.93      0.64       958\n",
            "        7.0       0.79      0.64      0.71      1028\n",
            "        8.0       0.41      0.65      0.50       974\n",
            "        9.0       0.62      0.55      0.58      1009\n",
            "\n",
            "avg / total       0.64      0.59      0.54     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 868    2    1    4    0    0   95    6    4    0]\n",
            " [   0 1097    1    1    0    1    5    2   26    2]\n",
            " [  65  140  165    2   53    1  465   44   76   21]\n",
            " [ 199  149   26  304    4    1   54   11  238   24]\n",
            " [   4   36    1    8  688    5   59   29   66   86]\n",
            " [ 151   52    3  160   41   44  116    7  316    2]\n",
            " [  14   13    3    2   23    0  891    4    8    0]\n",
            " [  40   56    7   18   10    1   11  654   37  194]\n",
            " [  35  167    5   21   10    0   90    2  630   14]\n",
            " [  13   37    3   26  149    4   28   68  129  552]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) [0. 0. 0. ... 5. 7. 7.]\n",
            "probabilities: (59625, 10) \n",
            " [0 0 0 ... 5 7 7]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [ 18  14  53  54  33 179  26  43  37  43] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.574 s \n",
            "\n",
            "Accuracy rate for 60.500000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.70      0.91      0.79       980\n",
            "        1.0       0.62      0.98      0.76      1135\n",
            "        2.0       0.91      0.07      0.13      1032\n",
            "        3.0       0.53      0.56      0.54      1010\n",
            "        4.0       0.76      0.65      0.70       982\n",
            "        5.0       0.82      0.07      0.12       892\n",
            "        6.0       0.50      0.94      0.65       958\n",
            "        7.0       0.75      0.68      0.71      1028\n",
            "        8.0       0.42      0.53      0.47       974\n",
            "        9.0       0.68      0.60      0.63      1009\n",
            "\n",
            "avg / total       0.67      0.60      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 896    2    0    1    0    0   76    3    2    0]\n",
            " [   0 1111    0    3    0    1    6    0   14    0]\n",
            " [  80  188   71   14   78    1  456   58   64   22]\n",
            " [  89  110    3  564    9    1   55   17  151   11]\n",
            " [  15   24    0   29  635    5   45   61   81   87]\n",
            " [ 104   36    0  239   29   59  140   17  254   14]\n",
            " [  15   15    0    2   12    0  898    6   10    0]\n",
            " [  49   76    2   18   12    0   10  699   22  140]\n",
            " [  16  208    1  103   11    2   96    6  516   15]\n",
            " [  24   27    1   90   54    3   22   71  116  601]]\n",
            "--------------------------------\n",
            "final active learning accuracies [69.07, 62.660000000000004, 58.93000000000001, 60.5]\n",
            "saved Active-learning-experiment-42.pkl /content ['datalab', 'Active-learning-experiment-32.pkl', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-38.pkl', 'Active-learning-experiment-42.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-41.pkl', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-33.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-29.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 43, using model = LogModel, selection_function = EntropySelection, k = 50, iteration = 0.\n",
            "\n",
            "initial random chosen samples (50,)\n",
            "initial train set: (50, 784) (50,) unique(labels): [4 2 8 6 7 2 6 4 4 7] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,) (50,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.323 s \n",
            "\n",
            "Accuracy rate for 61.820000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.72      0.92      0.81       980\n",
            "        1.0       0.84      0.80      0.82      1135\n",
            "        2.0       0.72      0.74      0.73      1032\n",
            "        3.0       0.47      0.62      0.54      1010\n",
            "        4.0       0.75      0.50      0.60       982\n",
            "        5.0       0.31      0.15      0.21       892\n",
            "        6.0       0.80      0.77      0.78       958\n",
            "        7.0       0.62      0.53      0.57      1028\n",
            "        8.0       0.47      0.50      0.48       974\n",
            "        9.0       0.44      0.58      0.50      1009\n",
            "\n",
            "avg / total       0.62      0.62      0.61     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[906   0  10   5   0   9  30   3   2  15]\n",
            " [  0 905  37  14   0   0   3   1 173   2]\n",
            " [ 46  53 765  20  14   3  40  25  41  25]\n",
            " [ 23   6  87 627   0 184   2  18  44  19]\n",
            " [ 40  16   2  71 488   8  54  32  48 223]\n",
            " [ 66  15  41 235   3 137  24 144 175  52]\n",
            " [ 96   8  56  19   7  24 734   2   9   3]\n",
            " [ 15  30  24   8  15   7   0 548  42 339]\n",
            " [ 24  34  35 208   7  59  23  16 486  82]\n",
            " [ 39   6   3 124 115   6   8 100  22 586]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 6. ... 9. 9. 9.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 6 ... 9 9 9]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 4 24  9  7  7 13 10  6 12  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.347 s \n",
            "\n",
            "Accuracy rate for 60.320000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.83      0.84       980\n",
            "        1.0       0.82      0.56      0.67      1135\n",
            "        2.0       0.68      0.66      0.67      1032\n",
            "        3.0       0.47      0.72      0.57      1010\n",
            "        4.0       0.78      0.68      0.73       982\n",
            "        5.0       0.41      0.13      0.20       892\n",
            "        6.0       0.61      0.83      0.70       958\n",
            "        7.0       0.74      0.39      0.51      1028\n",
            "        8.0       0.53      0.51      0.52       974\n",
            "        9.0       0.39      0.69      0.50      1009\n",
            "\n",
            "avg / total       0.63      0.60      0.59     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[818   0  14   6   0  21  38  15  50  18]\n",
            " [  0 635 114  49   0   2 208  10 101  16]\n",
            " [ 28   8 684  50  12   2 114  13  66  55]\n",
            " [ 13   6  79 726   0  60  14  11  55  46]\n",
            " [ 23   3   1  36 666  32  27   5   4 185]\n",
            " [ 12  45  21 328   0 117  52  50 127 140]\n",
            " [ 50   5  42  28  12  12 794   2   7   6]\n",
            " [ 10   9  16  11  53   8  10 400   7 504]\n",
            " [  2  54  34 209   4  20  41   3 493 114]\n",
            " [ 15   8   2 103 106  11  14  31  20 699]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 5. ... 9. 9. 9.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 5 ... 9 9 9]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 4 26 16  8 14 22 13 16 21 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.386 s \n",
            "\n",
            "Accuracy rate for 54.030000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.87      0.83       980\n",
            "        1.0       0.79      0.55      0.65      1135\n",
            "        2.0       0.79      0.34      0.48      1032\n",
            "        3.0       0.45      0.80      0.58      1010\n",
            "        4.0       0.79      0.48      0.60       982\n",
            "        5.0       0.49      0.23      0.31       892\n",
            "        6.0       0.62      0.79      0.70       958\n",
            "        7.0       0.95      0.17      0.29      1028\n",
            "        8.0       0.36      0.45      0.40       974\n",
            "        9.0       0.32      0.72      0.44      1009\n",
            "\n",
            "avg / total       0.64      0.54      0.53     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[851   0  16  14   0  44  38   0   1  16]\n",
            " [  0 625   0   8   0   1  11   1 466  23]\n",
            " [ 51  20 356  50  18   3 286   3 111 134]\n",
            " [ 17  24  24 807   0  30  17   2  29  60]\n",
            " [ 25   2   5  64 471  48   9   0  50 308]\n",
            " [ 16  51  14 367   8 201  49   3  40 143]\n",
            " [ 64  12  16  34  14  33 760   0   8  17]\n",
            " [ 24   8   2  42  17  12  11 175  53 684]\n",
            " [  1  48  17 245   3  24  34   0 435 167]\n",
            " [ 17   6   0 143  69  15   4   1  32 722]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 3. ... 9. 9. 9.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 3 ... 9 9 9]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [12 26 19  8 14 33 14 39 22 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.415 s \n",
            "\n",
            "Accuracy rate for 57.220000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.92      0.85       980\n",
            "        1.0       0.77      0.53      0.63      1135\n",
            "        2.0       0.79      0.21      0.34      1032\n",
            "        3.0       0.47      0.76      0.58      1010\n",
            "        4.0       0.73      0.64      0.68       982\n",
            "        5.0       0.64      0.18      0.28       892\n",
            "        6.0       0.59      0.83      0.69       958\n",
            "        7.0       0.83      0.40      0.54      1028\n",
            "        8.0       0.35      0.60      0.44       974\n",
            "        9.0       0.43      0.64      0.51      1009\n",
            "\n",
            "avg / total       0.64      0.57      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[900   0   6   5   0  15  35  13   0   6]\n",
            " [  0 603   0   4   1   0  12   0 506   9]\n",
            " [ 38  19 221  47  30   3 378   8 195  93]\n",
            " [ 49  28   4 764   3  21  14   6  71  50]\n",
            " [  1   4  31  69 633  20  20  20  85  99]\n",
            " [ 85  49   4 329   9 157  43  15  66 135]\n",
            " [ 17  12   9  30  33   7 798   5  36  11]\n",
            " [ 30  10   2  26  78   6   6 411  80 379]\n",
            " [ 12  49   1 179   5  11  37   1 587  92]\n",
            " [ 14   8   1 161  80   5   7  15  70 648]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [12 39 31 19 14 37 18 42 24 14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.420 s \n",
            "\n",
            "Accuracy rate for 58.670000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.92      0.81       980\n",
            "        1.0       0.80      0.67      0.73      1135\n",
            "        2.0       0.78      0.14      0.24      1032\n",
            "        3.0       0.53      0.71      0.61      1010\n",
            "        4.0       0.70      0.68      0.69       982\n",
            "        5.0       0.70      0.13      0.21       892\n",
            "        6.0       0.59      0.83      0.69       958\n",
            "        7.0       0.84      0.44      0.58      1028\n",
            "        8.0       0.36      0.59      0.44       974\n",
            "        9.0       0.44      0.73      0.55      1009\n",
            "\n",
            "avg / total       0.65      0.59      0.56     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[906   0   2  13   1  11  36   9   0   2]\n",
            " [  0 762   7   8   2   0  13   0 341   2]\n",
            " [ 38  47 149  78  57   1 333  10 204 115]\n",
            " [ 83  12   4 718   2   9  11   7  94  70]\n",
            " [  2   6   2   7 670  10  31  28 103 123]\n",
            " [136  38   1 308   5 112  52  11  85 144]\n",
            " [ 26  19   8  13  60   6 791   4  29   2]\n",
            " [ 24  12   9   4  62   2   5 457  79 374]\n",
            " [ 15  45   6 164   3   5  64   1 570 101]\n",
            " [ 18   7   4  32  92   5   3  16 100 732]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 3. ... 9. 9. 9.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 3 ... 9 9 9]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [12 41 43 28 18 43 20 45 25 25] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.439 s \n",
            "\n",
            "Accuracy rate for 57.110000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.66      0.93      0.77       980\n",
            "        1.0       0.72      0.73      0.73      1135\n",
            "        2.0       0.75      0.25      0.37      1032\n",
            "        3.0       0.61      0.51      0.56      1010\n",
            "        4.0       0.67      0.55      0.60       982\n",
            "        5.0       0.67      0.09      0.15       892\n",
            "        6.0       0.59      0.79      0.68       958\n",
            "        7.0       0.88      0.46      0.61      1028\n",
            "        8.0       0.33      0.74      0.46       974\n",
            "        9.0       0.45      0.61      0.52      1009\n",
            "\n",
            "avg / total       0.64      0.57      0.55     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[913   1   9   2   2   6  36   9   0   2]\n",
            " [  0 834   3   6   0   0  13   0 279   0]\n",
            " [ 39  63 255  11  34   2 291   8 282  47]\n",
            " [153  46  20 519   0   9  29  11 186  37]\n",
            " [  3   9   2   9 541   7  13   1 180 217]\n",
            " [176  85  11 202  17  77  80  17 177  50]\n",
            " [ 16   9   7   7  85   2 758   4  58  12]\n",
            " [ 37  36  18   2   6   0   4 477  98 350]\n",
            " [ 28  61  10  60   7   7  47   2 721  31]\n",
            " [ 22  19   5  36 115   5   4  12 175 616]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 6. ... 9. 9. 9.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 6 ... 9 9 9]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [12 42 49 31 18 49 22 63 28 36] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.454 s \n",
            "\n",
            "Accuracy rate for 53.180000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.63      0.96      0.76       980\n",
            "        1.0       0.72      0.78      0.75      1135\n",
            "        2.0       0.73      0.07      0.13      1032\n",
            "        3.0       0.56      0.52      0.54      1010\n",
            "        4.0       0.61      0.61      0.61       982\n",
            "        5.0       0.63      0.01      0.03       892\n",
            "        6.0       0.65      0.70      0.67       958\n",
            "        7.0       0.78      0.35      0.48      1028\n",
            "        8.0       0.32      0.68      0.43       974\n",
            "        9.0       0.35      0.59      0.44      1009\n",
            "\n",
            "avg / total       0.60      0.53      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[939   1   0   2   4   2  22   5   0   5]\n",
            " [  0 886   2   6   0   0   6   2 230   3]\n",
            " [ 49  62  73  28  56   0 221  39 346 158]\n",
            " [134  44   2 530   0   2  11  17 153 117]\n",
            " [  6   9   2   8 599   0  12   7 174 165]\n",
            " [190 103   4 260  22  12  53  13 177  58]\n",
            " [ 32  15   1   9 130   1 672   8  80  10]\n",
            " [ 74  28  10   3  18   0   1 355  60 479]\n",
            " [ 28  73   3  76   7   0  36   0 659  92]\n",
            " [ 30  14   3  24 151   2   2   7 183 593]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [18 42 53 37 19 65 23 65 31 47] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.459 s \n",
            "\n",
            "Accuracy rate for 57.760000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.69      0.92      0.79       980\n",
            "        1.0       0.71      0.87      0.78      1135\n",
            "        2.0       0.68      0.07      0.13      1032\n",
            "        3.0       0.58      0.56      0.57      1010\n",
            "        4.0       0.68      0.71      0.70       982\n",
            "        5.0       0.54      0.07      0.13       892\n",
            "        6.0       0.54      0.84      0.66       958\n",
            "        7.0       0.87      0.46      0.61      1028\n",
            "        8.0       0.36      0.68      0.47       974\n",
            "        9.0       0.46      0.53      0.49      1009\n",
            "\n",
            "avg / total       0.61      0.58      0.54     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[902   1   0   3   2   2  59   3   0   8]\n",
            " [  0 985   1   3   0   1   7   1 135   2]\n",
            " [ 53  86  73  20  63   2 391  27 229  88]\n",
            " [133  43   1 567   0  12  45   7 147  55]\n",
            " [  0  14   1  18 702  20  10   4 159  54]\n",
            " [119  82   4 249  16  66 111  11 197  37]\n",
            " [ 12  14   1   7  70   2 805   8  38   1]\n",
            " [ 63  40  20   4  13   5   3 478  63 339]\n",
            " [ 17 106   1  68   7   3  50   3 663  56]\n",
            " [  8  19   5  44 161   9   6  10 212 535]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 0 ... 9 9 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "trainset before (400, 784) (400,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [18 42 59 40 20 94 25 68 34 50] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.501 s \n",
            "\n",
            "Accuracy rate for 55.080000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.65      0.91      0.76       980\n",
            "        1.0       0.69      0.85      0.76      1135\n",
            "        2.0       0.60      0.03      0.06      1032\n",
            "        3.0       0.53      0.49      0.51      1010\n",
            "        4.0       0.72      0.71      0.72       982\n",
            "        5.0       0.50      0.00      0.00       892\n",
            "        6.0       0.52      0.83      0.64       958\n",
            "        7.0       0.89      0.51      0.65      1028\n",
            "        8.0       0.31      0.70      0.43       974\n",
            "        9.0       0.44      0.42      0.43      1009\n",
            "\n",
            "avg / total       0.59      0.55      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[895   2   0   4   0   0  70   3   0   6]\n",
            " [  0 965   1   4   0   0   8   1 154   2]\n",
            " [ 63  88  32  15  63   0 383  20 309  59]\n",
            " [160  48   0 493   1   1  55  10 190  52]\n",
            " [  0  15   4  22 695   0  11   3 188  44]\n",
            " [116  90   3 222  13   2 135  10 222  79]\n",
            " [  9  23   0   9  60   0 791   6  57   3]\n",
            " [ 93  46   6  10  11   0  10 523  64 265]\n",
            " [ 21  92   4  81   8   0  40   3 684  41]\n",
            " [ 12  20   3  72 108   1   8  11 346 428]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 9. 9. 9.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 9 9 9]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [ 18  42  64  50  21 124  26  68  36  51] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.506 s \n",
            "\n",
            "Accuracy rate for 53.420000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.60      0.93      0.73       980\n",
            "        1.0       0.68      0.91      0.78      1135\n",
            "        2.0       0.71      0.04      0.08      1032\n",
            "        3.0       0.56      0.29      0.38      1010\n",
            "        4.0       0.59      0.67      0.63       982\n",
            "        5.0       0.50      0.01      0.02       892\n",
            "        6.0       0.53      0.76      0.63       958\n",
            "        7.0       0.80      0.52      0.63      1028\n",
            "        8.0       0.33      0.68      0.44       974\n",
            "        9.0       0.39      0.45      0.42      1009\n",
            "\n",
            "avg / total       0.57      0.53      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 912    1    0    0    2    0   49    5    0   11]\n",
            " [   0 1033    1    4    0    1    8    1   85    2]\n",
            " [  66  121   42    8   60    0  327   37  281   90]\n",
            " [ 246   52    0  295    0    0   63   20  233  101]\n",
            " [   0   14    4   11  658    4   12   20  210   49]\n",
            " [ 168   89    3  141   20   11  123   15  216  106]\n",
            " [  11   26    2    7   74    3  730   10   87    8]\n",
            " [  65   40    4    5   27    0    3  538   54  292]\n",
            " [  32  128    2   37    6    0   46    3  667   53]\n",
            " [   9   20    1   15  275    3    7   23  200  456]]\n",
            "--------------------------------\n",
            "final active learning accuracies [61.82, 60.31999999999999, 54.03, 57.220000000000006, 58.67, 57.11000000000001, 53.18000000000001, 57.76, 55.08, 53.42]\n",
            "saved Active-learning-experiment-43.pkl /content ['datalab', 'Active-learning-experiment-32.pkl', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-38.pkl', 'Active-learning-experiment-42.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-41.pkl', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-33.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-43.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-29.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 44, using model = LogModel, selection_function = EntropySelection, k = 25, iteration = 0.\n",
            "\n",
            "initial random chosen samples (25,)\n",
            "initial train set: (25, 784) (25,) unique(labels): [3 2 2 4 3 1 1 2 4 3] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59975, 784) (59975,) (25,)\n",
            "\n",
            "Train set: (25, 784) y: (25,)\n",
            "Val   set: (59975, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.329 s \n",
            "\n",
            "Accuracy rate for 59.050000 \n",
            "Classification report for classifier LogisticRegression(C=2.0, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.74      0.53      0.61       980\n",
            "        1.0       0.74      0.99      0.85      1135\n",
            "        2.0       0.70      0.49      0.58      1032\n",
            "        3.0       0.47      0.73      0.57      1010\n",
            "        4.0       0.79      0.53      0.63       982\n",
            "        5.0       0.50      0.09      0.15       892\n",
            "        6.0       0.90      0.57      0.70       958\n",
            "        7.0       0.60      0.64      0.62      1028\n",
            "        8.0       0.41      0.71      0.52       974\n",
            "        9.0       0.42      0.53      0.47      1009\n",
            "\n",
            "avg / total       0.63      0.59      0.58     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 517    1   36  234    1    0   30    4  110   47]\n",
            " [   0 1118    1    2    1    0    3    7    3    0]\n",
            " [   1  114  510   85   43    2    4  128  130   15]\n",
            " [  39   15    7  736    7   66   11   22   93   14]\n",
            " [   1   26   33    8  517    2    2   15  104  274]\n",
            " [  51   65   18  304   10   77    5   47  274   41]\n",
            " [  62   10  110   86   34    1  548    2   64   41]\n",
            " [   9   42    3    7   16    0    0  662   15  274]\n",
            " [  13   99    3   86    6    4    5   33  688   37]\n",
            " [   9   13   12   26   20    1    0  191  205  532]]\n",
            "--------------------------------\n",
            "val predicted: (59975,) [3. 0. 3. ... 7. 7. 7.]\n",
            "probabilities: (59975, 10) \n",
            " [3 0 3 ... 7 7 7]\n",
            "trainset before (25, 784) (25,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [ 3  7  8 10  3  4  1  3  6  5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.342 s \n",
            "\n",
            "Accuracy rate for 52.850000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.59      0.65       980\n",
            "        1.0       0.61      0.69      0.65      1135\n",
            "        2.0       0.73      0.63      0.67      1032\n",
            "        3.0       0.58      0.40      0.47      1010\n",
            "        4.0       0.62      0.61      0.62       982\n",
            "        5.0       0.28      0.08      0.13       892\n",
            "        6.0       0.92      0.27      0.42       958\n",
            "        7.0       0.69      0.75      0.72      1028\n",
            "        8.0       0.26      0.60      0.37       974\n",
            "        9.0       0.39      0.59      0.47      1009\n",
            "\n",
            "avg / total       0.59      0.53      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[578   1  18   7   9  64   7   0 150 146]\n",
            " [  0 782   3   1  93   0   1  11 244   0]\n",
            " [  7  27 649  10  95   8   4  61 147  24]\n",
            " [ 33  53  67 402   9  70   6  53 311   6]\n",
            " [  3  16   2  10 601   2   0   3  98 247]\n",
            " [ 82 118  22 116  21  72   3  54 374  30]\n",
            " [ 59  46 100  80  41   2 260   1 102 267]\n",
            " [ 12  12   7   2  25   2   0 766  29 173]\n",
            " [  7 205  22  41  13  36   1  40 584  25]\n",
            " [ 10  25   3  22  56   1   0 114 187 591]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 8. ... 9. 9. 7.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 8 ... 9 9 7]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (75, 784) (75,)\n",
            "updated train set: (75, 784) (75,) unique(labels): [ 7  7  8 13  3 10 12  4  6  5] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59925, 784) (59925,)\n",
            "\n",
            "Train set: (75, 784) y: (75,)\n",
            "Val   set: (59925, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.356 s \n",
            "\n",
            "Accuracy rate for 54.710000 \n",
            "Classification report for classifier LogisticRegression(C=0.6666666666666666, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.61      0.67       980\n",
            "        1.0       0.64      0.97      0.77      1135\n",
            "        2.0       0.83      0.59      0.69      1032\n",
            "        3.0       0.52      0.60      0.56      1010\n",
            "        4.0       0.76      0.50      0.60       982\n",
            "        5.0       0.19      0.03      0.06       892\n",
            "        6.0       0.76      0.46      0.58       958\n",
            "        7.0       0.80      0.45      0.58      1028\n",
            "        8.0       0.28      0.57      0.37       974\n",
            "        9.0       0.36      0.56      0.44      1009\n",
            "\n",
            "avg / total       0.59      0.55      0.54     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 599    0   19    5    4   59   14    2  256   22]\n",
            " [   0 1102    1    2   11    1    4    1   13    0]\n",
            " [  21   49  611   11   52    4   83   15  129   57]\n",
            " [   3   78   50  608    4    2    8   13  235    9]\n",
            " [  29   29    0   29  490    8    0    2   75  320]\n",
            " [  35  113   14  234   12   30   21   16  403   14]\n",
            " [ 104   32   17   90    9   37  445    2   62  160]\n",
            " [   9   47    6   22   14    2    3  463   55  407]\n",
            " [   1  244   21   90    4    9    2   23  558   22]\n",
            " [  14   37    1   78   44    3    2   44  221  565]]\n",
            "--------------------------------\n",
            "val predicted: (59925,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59925, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (75, 784) (75,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 7  7 16 13  7 16 16  4  8  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.353 s \n",
            "\n",
            "Accuracy rate for 55.160000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.63      0.72       980\n",
            "        1.0       0.62      0.97      0.76      1135\n",
            "        2.0       0.79      0.32      0.46      1032\n",
            "        3.0       0.50      0.66      0.57      1010\n",
            "        4.0       0.72      0.66      0.69       982\n",
            "        5.0       0.90      0.07      0.13       892\n",
            "        6.0       0.67      0.65      0.66       958\n",
            "        7.0       0.84      0.33      0.47      1028\n",
            "        8.0       0.30      0.58      0.39       974\n",
            "        9.0       0.36      0.54      0.44      1009\n",
            "\n",
            "avg / total       0.65      0.55      0.54     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 622    0   40   31    2    3   59    2  184   37]\n",
            " [   0 1106    0    9    0    0    4    1   15    0]\n",
            " [  17   86  334   38   61    0  193    4  235   64]\n",
            " [   5   79    7  663    3    0   18    6  217   12]\n",
            " [   7   30    4   19  649    1    1    0   56  215]\n",
            " [  22  111    7  291   12   64   23   14  327   21]\n",
            " [  55   28   19   72   31    0  624    0   39   90]\n",
            " [   6   57    5   15   24    0    3  339   69  510]\n",
            " [   1  251    8  110    8    2    4    8  566   16]\n",
            " [   9   36    0   67  113    1    0   29  205  549]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (125, 784) (125,)\n",
            "updated train set: (125, 784) (125,) unique(labels): [ 7  7 19 14  8 34 16  6  8  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59875, 784) (59875,)\n",
            "\n",
            "Train set: (125, 784) y: (125,)\n",
            "Val   set: (59875, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.372 s \n",
            "\n",
            "Accuracy rate for 52.350000 \n",
            "Classification report for classifier LogisticRegression(C=0.4, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.66      0.72       980\n",
            "        1.0       0.66      0.97      0.79      1135\n",
            "        2.0       0.77      0.10      0.18      1032\n",
            "        3.0       0.50      0.73      0.59      1010\n",
            "        4.0       0.63      0.61      0.62       982\n",
            "        5.0       0.42      0.13      0.20       892\n",
            "        6.0       0.62      0.71      0.66       958\n",
            "        7.0       0.79      0.26      0.39      1028\n",
            "        8.0       0.31      0.56      0.40       974\n",
            "        9.0       0.29      0.44      0.35      1009\n",
            "\n",
            "avg / total       0.58      0.52      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 648    1    1   33    0   88   73    1  106   29]\n",
            " [   0 1101    0    3    1    1    2    1   26    0]\n",
            " [  29   65  102   42   49    5  273   14  347  106]\n",
            " [   5   66    1  738    2    5   14    4  153   22]\n",
            " [  22   32    7   19  598   28    7    0   49  220]\n",
            " [  19   90    4  334   13  120   28    9  231   44]\n",
            " [  55   22   10   73   11   18  677    0   37   55]\n",
            " [  15   32    3   40   45    5    3  265   64  556]\n",
            " [   3  226    5  137    8    6   15    2  544   28]\n",
            " [  12   34    0   63  225    9    0   41  183  442]]\n",
            "--------------------------------\n",
            "val predicted: (59875,) [0. 0. 8. ... 9. 9. 3.]\n",
            "probabilities: (59875, 10) \n",
            " [0 0 8 ... 9 9 3]\n",
            "trainset before (125, 784) (125,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 7  9 25 15 14 37 19  7  9  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.376 s \n",
            "\n",
            "Accuracy rate for 53.940000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.78      0.70      0.74       980\n",
            "        1.0       0.66      0.99      0.79      1135\n",
            "        2.0       0.93      0.19      0.31      1032\n",
            "        3.0       0.53      0.68      0.60      1010\n",
            "        4.0       0.78      0.49      0.60       982\n",
            "        5.0       0.28      0.06      0.09       892\n",
            "        6.0       0.55      0.77      0.64       958\n",
            "        7.0       0.80      0.39      0.52      1028\n",
            "        8.0       0.30      0.64      0.41       974\n",
            "        9.0       0.35      0.43      0.39      1009\n",
            "\n",
            "avg / total       0.60      0.54      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 684    1    1   14    8   32   94    0  141    5]\n",
            " [   0 1118    0    0    0    1    6    2    8    0]\n",
            " [  17  127  192   24    7    6  377   45  185   52]\n",
            " [  13   62    3  684    0    0   20    5  215    8]\n",
            " [  23   20    5   15  480   58   29    2  181  169]\n",
            " [  33   95    1  321   13   51   42    7  313   16]\n",
            " [  67   16    3   43   26    5  734    0   36   28]\n",
            " [  21   37    2   14    9   10    5  400   44  486]\n",
            " [   4  200    0   96    5    2   22    4  622   19]\n",
            " [  13   25    0   68   71   17    2   33  351  429]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 8. ... 9. 9. 7.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 8 ... 9 9 7]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (175, 784) (175,)\n",
            "updated train set: (175, 784) (175,) unique(labels): [ 8  9 30 15 15 46 21 12 10  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59825, 784) (59825,)\n",
            "\n",
            "Train set: (175, 784) y: (175,)\n",
            "Val   set: (59825, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.385 s \n",
            "\n",
            "Accuracy rate for 53.430000 \n",
            "Classification report for classifier LogisticRegression(C=0.2857142857142857, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.88      0.69      0.77       980\n",
            "        1.0       0.58      0.96      0.72      1135\n",
            "        2.0       0.94      0.07      0.13      1032\n",
            "        3.0       0.50      0.77      0.61      1010\n",
            "        4.0       0.50      0.67      0.57       982\n",
            "        5.0       0.31      0.05      0.08       892\n",
            "        6.0       0.52      0.74      0.61       958\n",
            "        7.0       0.87      0.71      0.79      1028\n",
            "        8.0       0.27      0.45      0.34       974\n",
            "        9.0       0.35      0.13      0.20      1009\n",
            "\n",
            "avg / total       0.58      0.53      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 680    2    3   14   48   27  122   14   56   14]\n",
            " [   0 1092    0    0    0    0    8    3   32    0]\n",
            " [  14  128   72   29   26    2  354   18  342   47]\n",
            " [   4  106    1  781    7    6   18   15   69    3]\n",
            " [   7   24    1   25  656   25   35    1  159   49]\n",
            " [  12  123    0  393   63   43   58   23  166   11]\n",
            " [  41   19    0   37   64    4  709    0   62   22]\n",
            " [   6   45    0   21   46   10   23  733   58   86]\n",
            " [   1  313    0  148   13    1   33    8  441   16]\n",
            " [  10   46    0  114  390   20    7   23  263  136]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59825,) [0. 0. 8. ... 7. 7. 3.]\n",
            "probabilities: (59825, 10) \n",
            " [0 0 8 ... 7 7 3]\n",
            "trainset before (175, 784) (175,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [13  9 39 15 15 54 22 13 10 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.420 s \n",
            "\n",
            "Accuracy rate for 51.480000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.81      0.85       980\n",
            "        1.0       0.59      0.87      0.70      1135\n",
            "        2.0       0.84      0.11      0.19      1032\n",
            "        3.0       0.50      0.75      0.60      1010\n",
            "        4.0       0.53      0.60      0.56       982\n",
            "        5.0       0.29      0.09      0.13       892\n",
            "        6.0       0.52      0.76      0.62       958\n",
            "        7.0       0.92      0.36      0.51      1028\n",
            "        8.0       0.27      0.48      0.34       974\n",
            "        9.0       0.31      0.27      0.29      1009\n",
            "\n",
            "avg / total       0.57      0.51      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[791   1   0  19  20  39  88   2  17   3]\n",
            " [  0 987   0   0   0   1  31   2 114   0]\n",
            " [ 10  63 113  26  17   3 377   3 379  41]\n",
            " [ 17 103   2 762   3   4  22   8  78  11]\n",
            " [  1  21   5  27 587  61  24   0 187  69]\n",
            " [ 31 139   3 378  55  76  49  13 134  14]\n",
            " [ 17  16   4  46  41  13 731   0  79  11]\n",
            " [  1  28   8  16  57  17  41 366  69 425]\n",
            " [  4 280   0 162   8   2  31   1 465  21]\n",
            " [  5  39   0  95 327  43   6   5 219 270]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 8. ... 9. 5. 3.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 8 ... 9 5 3]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (225, 784) (225,)\n",
            "updated train set: (225, 784) (225,) unique(labels): [13 12 46 16 18 58 24 17 11 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59775, 784) (59775,)\n",
            "\n",
            "Train set: (225, 784) y: (225,)\n",
            "Val   set: (59775, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.419 s \n",
            "\n",
            "Accuracy rate for 45.940000 \n",
            "Classification report for classifier LogisticRegression(C=0.2222222222222222, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.87      0.87      0.87       980\n",
            "        1.0       0.35      0.49      0.40      1135\n",
            "        2.0       0.73      0.09      0.15      1032\n",
            "        3.0       0.56      0.75      0.64      1010\n",
            "        4.0       0.66      0.53      0.58       982\n",
            "        5.0       0.45      0.11      0.18       892\n",
            "        6.0       0.51      0.73      0.60       958\n",
            "        7.0       0.94      0.03      0.06      1028\n",
            "        8.0       0.26      0.59      0.36       974\n",
            "        9.0       0.33      0.41      0.36      1009\n",
            "\n",
            "avg / total       0.56      0.46      0.42     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[850   1  14   8   3  38  49   0   9   8]\n",
            " [  0 551   0   1   0   0 159   0 424   0]\n",
            " [ 12 154  89  28  17   2 305   0 381  44]\n",
            " [ 20  79   4 759   6  11  16   0 105  10]\n",
            " [  4  56   4  11 516  28  29   0 219 115]\n",
            " [ 41 161   3 321  42 101  64   0 119  40]\n",
            " [ 26  24   3  34  34  14 703   0  98  22]\n",
            " [  7 271   5  15  21   9  32  33  61 574]\n",
            " [  5 169   0 137   4   3  33   1 577  45]\n",
            " [  7 129   0  52 144  18   2   1 241 415]]\n",
            "--------------------------------\n",
            "val predicted: (59775,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59775, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (225, 784) (225,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [14 25 51 17 18 63 24 17 11 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.439 s \n",
            "\n",
            "Accuracy rate for 48.920000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.92      0.83      0.87       980\n",
            "        1.0       0.59      0.82      0.68      1135\n",
            "        2.0       0.52      0.08      0.14      1032\n",
            "        3.0       0.54      0.75      0.63      1010\n",
            "        4.0       0.69      0.45      0.54       982\n",
            "        5.0       0.53      0.07      0.12       892\n",
            "        6.0       0.52      0.69      0.59       958\n",
            "        7.0       0.85      0.06      0.11      1028\n",
            "        8.0       0.27      0.70      0.39       974\n",
            "        9.0       0.30      0.40      0.34      1009\n",
            "\n",
            "avg / total       0.57      0.49      0.45     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[809   1  26  29   4   8  73   0  15  15]\n",
            " [  0 929   1   2   0   0  16   0 187   0]\n",
            " [ 12 101  83  26  13   2 335   2 404  54]\n",
            " [  6  58   2 756   2   2  16   3 151  14]\n",
            " [  3  47  16  16 439  10  26   0 303 122]\n",
            " [ 13  79   8 349  30  60  73   5 227  48]\n",
            " [ 20  21   7  34  34   5 662   0 158  17]\n",
            " [  5 148  14  19  18  11  43  62  48 660]\n",
            " [  3 122   0  95   3   0  33   0 685  33]\n",
            " [  8  74   2  66  91  15   5   1 340 407]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 8. ... 9. 9. 3.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 8 ... 9 9 3]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (275, 784) (275,)\n",
            "updated train set: (275, 784) (275,) unique(labels): [14 26 62 18 18 68 29 18 11 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59725, 784) (59725,)\n",
            "\n",
            "Train set: (275, 784) y: (275,)\n",
            "Val   set: (59725, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.420 s \n",
            "\n",
            "Accuracy rate for 48.550000 \n",
            "Classification report for classifier LogisticRegression(C=0.18181818181818182, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.90      0.85      0.87       980\n",
            "        1.0       0.58      0.85      0.68      1135\n",
            "        2.0       0.66      0.21      0.31      1032\n",
            "        3.0       0.53      0.75      0.62      1010\n",
            "        4.0       0.64      0.49      0.56       982\n",
            "        5.0       0.48      0.04      0.08       892\n",
            "        6.0       0.60      0.52      0.56       958\n",
            "        7.0       0.84      0.06      0.12      1028\n",
            "        8.0       0.25      0.69      0.37       974\n",
            "        9.0       0.27      0.33      0.30      1009\n",
            "\n",
            "avg / total       0.58      0.49      0.45     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[829   2  21  16   2   8  79   0  10  13]\n",
            " [  0 960   1   4   0   0   2   0 168   0]\n",
            " [ 16 138 212  40   6   1 110   4 485  20]\n",
            " [  9  61   4 757   3   3  16   2 146   9]\n",
            " [  4  32  13  20 484  12  27   1 319  70]\n",
            " [ 20  92  33 331  45  40  62   1 183  85]\n",
            " [ 25  24  12  42  59   2 499   0 264  31]\n",
            " [  6 151  25  24  32  12  13  64  60 641]\n",
            " [  2 148   1 101   4   0  16   0 672  30]\n",
            " [  8  61   1  88 124   6   2   4 377 338]]\n",
            "--------------------------------\n",
            "val predicted: (59725,) [0. 0. 8. ... 9. 9. 3.]\n",
            "probabilities: (59725, 10) \n",
            " [0 0 8 ... 9 9 3]\n",
            "trainset before (275, 784) (275,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [16 27 64 21 18 81 31 18 11 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.423 s \n",
            "\n",
            "Accuracy rate for 44.510000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.73      0.82       980\n",
            "        1.0       0.51      0.73      0.60      1135\n",
            "        2.0       0.45      0.14      0.22      1032\n",
            "        3.0       0.52      0.76      0.62      1010\n",
            "        4.0       0.52      0.52      0.52       982\n",
            "        5.0       0.58      0.03      0.06       892\n",
            "        6.0       0.57      0.61      0.59       958\n",
            "        7.0       0.91      0.03      0.06      1028\n",
            "        8.0       0.25      0.75      0.37       974\n",
            "        9.0       0.12      0.09      0.11      1009\n",
            "\n",
            "avg / total       0.54      0.45      0.40     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[719   1  10  39   8   6 122   0  19  56]\n",
            " [  0 833   1   2   0   0   4   0 295   0]\n",
            " [ 14 122 148  28  14   1 178   0 492  35]\n",
            " [  2  45   7 767   0   0  26   2 152   9]\n",
            " [  2  46  14  21 510   3  25   0 327  34]\n",
            " [  8  98  24 397  48  28  66   0 203  20]\n",
            " [ 10  24   5  19  61   0 589   0 227  23]\n",
            " [  6 253 111  19  43   8  12  32  69 475]\n",
            " [  0 115   2  90   6   0  13   0 730  18]\n",
            " [  3  82   7  96 282   2   3   1 438  95]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59700,) [0. 0. 8. ... 9. 9. 3.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 8 ... 9 9 3]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (325, 784) (325,)\n",
            "updated train set: (325, 784) (325,) unique(labels): [16 27 70 22 20 90 31 20 12 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59675, 784) (59675,)\n",
            "\n",
            "Train set: (325, 784) y: (325,)\n",
            "Val   set: (59675, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.453 s \n",
            "\n",
            "Accuracy rate for 50.720000 \n",
            "Classification report for classifier LogisticRegression(C=0.15384615384615385, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.78      0.84       980\n",
            "        1.0       0.54      0.92      0.68      1135\n",
            "        2.0       0.82      0.21      0.33      1032\n",
            "        3.0       0.50      0.77      0.61      1010\n",
            "        4.0       0.59      0.45      0.51       982\n",
            "        5.0       0.60      0.04      0.07       892\n",
            "        6.0       0.62      0.65      0.63       958\n",
            "        7.0       0.88      0.19      0.32      1028\n",
            "        8.0       0.28      0.58      0.38       974\n",
            "        9.0       0.31      0.41      0.35      1009\n",
            "\n",
            "avg / total       0.60      0.51      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 763    1   10   32    2    9  114    2   14   33]\n",
            " [   0 1047    1    6    0    0    3    0   78    0]\n",
            " [  18  220  215   40   16    1  131    3  314   74]\n",
            " [   6   55    3  780    1    3   22    6   96   38]\n",
            " [   2   56    5   32  441    0   20    1  295  130]\n",
            " [  15   92   10  392   37   33   70    6  200   37]\n",
            " [  17   31    3   43   66    3  620    0  162   13]\n",
            " [  11  159   13   19   27    4    8  198   41  548]\n",
            " [   1  205    1  140    3    0   14    1  566   43]\n",
            " [   6   76    0   76  157    2    1    9  273  409]]\n",
            "--------------------------------\n",
            "val predicted: (59675,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59675, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (325, 784) (325,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [ 17  27  74  25  20 103  32  22  12  18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.469 s \n",
            "\n",
            "Accuracy rate for 48.290000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.91      0.83      0.87       980\n",
            "        1.0       0.56      0.93      0.70      1135\n",
            "        2.0       0.72      0.24      0.36      1032\n",
            "        3.0       0.53      0.62      0.57      1010\n",
            "        4.0       0.57      0.44      0.49       982\n",
            "        5.0       0.51      0.04      0.07       892\n",
            "        6.0       0.60      0.67      0.63       958\n",
            "        7.0       0.68      0.01      0.03      1028\n",
            "        8.0       0.27      0.68      0.38       974\n",
            "        9.0       0.23      0.30      0.26      1009\n",
            "\n",
            "avg / total       0.56      0.48      0.44     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 813    1   15   58    4    7   58    0   15    9]\n",
            " [   0 1054    0    1    0    0    4    0   76    0]\n",
            " [  18  198  246    7   11    1  182    5  340   24]\n",
            " [  14   83   34  630    1    0   23    1  165   59]\n",
            " [   2   42    6   20  430    6   24    0  372   80]\n",
            " [  19   65   16  335   32   33   86    0  217   89]\n",
            " [  14   21    5   31   49    2  641    0  189    6]\n",
            " [   4  157   16   20   45   10   23   15   55  683]\n",
            " [   5  184    1   57    8    1   22    0  666   30]\n",
            " [   5   73    1   29  178    5    8    1  408  301]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 8. ... 9. 5. 6.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 8 ... 9 5 6]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (375, 784) (375,)\n",
            "updated train set: (375, 784) (375,) unique(labels): [ 17  27  79  29  21 109  33  27  13  20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59625, 784) (59625,)\n",
            "\n",
            "Train set: (375, 784) y: (375,)\n",
            "Val   set: (59625, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.496 s \n",
            "\n",
            "Accuracy rate for 49.690000 \n",
            "Classification report for classifier LogisticRegression(C=0.13333333333333333, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.94      0.79      0.86       980\n",
            "        1.0       0.53      0.94      0.68      1135\n",
            "        2.0       0.65      0.19      0.29      1032\n",
            "        3.0       0.67      0.61      0.64      1010\n",
            "        4.0       0.58      0.47      0.52       982\n",
            "        5.0       0.61      0.06      0.11       892\n",
            "        6.0       0.57      0.58      0.57       958\n",
            "        7.0       0.81      0.17      0.28      1028\n",
            "        8.0       0.26      0.67      0.38       974\n",
            "        9.0       0.30      0.41      0.35      1009\n",
            "\n",
            "avg / total       0.59      0.50      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 779    1   26    5    9    5  102    5   30   18]\n",
            " [   0 1063    0    3    0    0    4    0   65    0]\n",
            " [  11  252  191    3   12    4  163   12  328   56]\n",
            " [   6   76   26  615    3    5   36    5  159   79]\n",
            " [   0   46    2    7  465    3   16    4  332  107]\n",
            " [  15   92   35  208   40   54   79    6  295   68]\n",
            " [   6   32    9    5   57    6  555    0  270   18]\n",
            " [   5  160    3   24   41    5    3  174   31  582]\n",
            " [   4  217    0   35    7    2   19    2  657   31]\n",
            " [   4   67    0   19  169    4    1    6  323  416]]\n",
            "--------------------------------\n",
            "val predicted: (59625,) [0. 0. 8. ... 9. 9. 9.]\n",
            "probabilities: (59625, 10) \n",
            " [0 0 8 ... 9 9 9]\n",
            "trainset before (375, 784) (375,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [ 17  27  82  30  22 120  37  27  15  23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.503 s \n",
            "\n",
            "Accuracy rate for 53.610000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.85      0.88      0.86       980\n",
            "        1.0       0.50      0.97      0.66      1135\n",
            "        2.0       0.79      0.18      0.30      1032\n",
            "        3.0       0.63      0.66      0.64      1010\n",
            "        4.0       0.55      0.63      0.59       982\n",
            "        5.0       0.53      0.06      0.10       892\n",
            "        6.0       0.62      0.73      0.67       958\n",
            "        7.0       0.88      0.31      0.46      1028\n",
            "        8.0       0.30      0.62      0.40       974\n",
            "        9.0       0.33      0.25      0.28      1009\n",
            "\n",
            "avg / total       0.60      0.54      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 859    1    9    6    1    8   58    1   33    4]\n",
            " [   0 1103    0    6    0    0    7    0   19    0]\n",
            " [  25  265  190   12   18    3  165   11  324   19]\n",
            " [  28   86    9  669    1   12   34    3  141   27]\n",
            " [   2   72    4   18  623   11   32    3  189   28]\n",
            " [  47  118   12  194   34   51   90    8  315   23]\n",
            " [  23   35    4    7   39    2  699    0  148    1]\n",
            " [   9  168   10   39   52    1   12  317   29  391]\n",
            " [  10  261    0   57   10    2   21    2  600   11]\n",
            " [   9   90    1   60  350    7    6   15  221  250]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 8. ... 9. 7. 7.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 8 ... 9 7 7]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (425, 784) (425,)\n",
            "updated train set: (425, 784) (425,) unique(labels): [ 17  29  82  32  22 137  38  28  17  23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59575, 784) (59575,)\n",
            "\n",
            "Train set: (425, 784) y: (425,)\n",
            "Val   set: (59575, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.534 s \n",
            "\n",
            "Accuracy rate for 49.910000 \n",
            "Classification report for classifier LogisticRegression(C=0.11764705882352941, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.84      0.89      0.86       980\n",
            "        1.0       0.51      0.91      0.65      1135\n",
            "        2.0       0.75      0.13      0.22      1032\n",
            "        3.0       0.57      0.66      0.61      1010\n",
            "        4.0       0.52      0.62      0.57       982\n",
            "        5.0       0.42      0.01      0.01       892\n",
            "        6.0       0.56      0.62      0.59       958\n",
            "        7.0       0.82      0.33      0.47      1028\n",
            "        8.0       0.26      0.67      0.38       974\n",
            "        9.0       0.19      0.09      0.12      1009\n",
            "\n",
            "avg / total       0.55      0.50      0.45     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 871    1   10    3    4    2   47   12   29    1]\n",
            " [   0 1032    0    3    0    0    5    0   95    0]\n",
            " [  15  217  135    8   16    1  211   14  407    8]\n",
            " [  33   57   12  669    0    0   40    7  184    8]\n",
            " [   2   56    2   18  604    0   24    6  256   14]\n",
            " [  50  130    6  317   41    5   80    3  245   15]\n",
            " [  31   35    2    9   44    1  597    0  238    1]\n",
            " [  14  194   11   16   53    3   22  335   37  343]\n",
            " [   8  210    0   48    7    0   31    6  649   15]\n",
            " [  11   88    1   75  385    0    5   28  322   94]]\n",
            "--------------------------------\n",
            "val predicted: (59575,) [0. 0. 8. ... 7. 7. 7.]\n",
            "probabilities: (59575, 10) \n",
            " [0 0 8 ... 7 7 7]\n",
            "trainset before (425, 784) (425,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [ 18  29  86  32  22 156  39  28  17  23] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.495 s \n",
            "\n",
            "Accuracy rate for 50.120000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.85      0.88      0.86       980\n",
            "        1.0       0.53      0.92      0.67      1135\n",
            "        2.0       0.70      0.14      0.24      1032\n",
            "        3.0       0.62      0.66      0.64      1010\n",
            "        4.0       0.51      0.61      0.55       982\n",
            "        5.0       0.30      0.02      0.04       892\n",
            "        6.0       0.55      0.48      0.51       958\n",
            "        7.0       0.80      0.35      0.49      1028\n",
            "        8.0       0.27      0.69      0.39       974\n",
            "        9.0       0.26      0.19      0.22      1009\n",
            "\n",
            "avg / total       0.54      0.50      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 859    1   11    0    7    9   43   12   25   13]\n",
            " [   0 1048    0    3    0    0    4    0   80    0]\n",
            " [  25  222  149   12   10    3  189   18  381   23]\n",
            " [  29   54   18  664    1    1   24   12  180   27]\n",
            " [   1   47    2   16  597   11   15   10  242   41]\n",
            " [  39  101   21  271   50   18   62    4  287   39]\n",
            " [  28   36    6    5   81    6  457    0  331    8]\n",
            " [  13  176    6   15   41    6   10  362   32  367]\n",
            " [   9  205    0   38    7    0   21    5  669   20]\n",
            " [   9   87    1   39  388    6    2   30  258  189]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 8. ... 7. 7. 7.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 8 ... 7 7 7]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (475, 784) (475,)\n",
            "updated train set: (475, 784) (475,) unique(labels): [ 18  29  91  34  22 168  41  28  19  25] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59525, 784) (59525,)\n",
            "\n",
            "Train set: (475, 784) y: (475,)\n",
            "Val   set: (59525, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.528 s \n",
            "\n",
            "Accuracy rate for 50.590000 \n",
            "Classification report for classifier LogisticRegression(C=0.10526315789473684, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.67      0.96      0.79       980\n",
            "        1.0       0.54      0.93      0.68      1135\n",
            "        2.0       0.81      0.16      0.26      1032\n",
            "        3.0       0.63      0.48      0.55      1010\n",
            "        4.0       0.51      0.63      0.57       982\n",
            "        5.0       0.15      0.00      0.01       892\n",
            "        6.0       0.63      0.64      0.63       958\n",
            "        7.0       0.76      0.29      0.42      1028\n",
            "        8.0       0.30      0.74      0.43       974\n",
            "        9.0       0.22      0.15      0.18      1009\n",
            "\n",
            "avg / total       0.53      0.51      0.46     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 940    1    2    0    2    0   19    1   14    1]\n",
            " [   1 1059    1    6    0    0    6    0   62    0]\n",
            " [  69  219  163    7   20    2  201   19  317   15]\n",
            " [ 146   65    5  488    0    0   28   10  256   12]\n",
            " [   3   45    6   14  618    9   21   14  207   45]\n",
            " [ 161  139    5  183   43    4   57    6  276   18]\n",
            " [  44   37    7    6   61    2  612    0  186    3]\n",
            " [  20  149   12    9   61    4    7  301   47  418]\n",
            " [  15  171    0   21    8    1   17    7  724   10]\n",
            " [  12   78    1   37  390    5    3   38  295  150]]\n",
            "--------------------------------\n",
            "val predicted: (59525,) [0. 0. 8. ... 7. 7. 7.]\n",
            "probabilities: (59525, 10) \n",
            " [0 0 8 ... 7 7 7]\n",
            "trainset before (475, 784) (475,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [ 18  31  97  34  22 181  42  28  21  26] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.587 s \n",
            "\n",
            "Accuracy rate for 52.660000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.83      0.88      0.85       980\n",
            "        1.0       0.52      0.99      0.68      1135\n",
            "        2.0       0.82      0.24      0.37      1032\n",
            "        3.0       0.59      0.69      0.64      1010\n",
            "        4.0       0.49      0.63      0.55       982\n",
            "        5.0       0.27      0.01      0.03       892\n",
            "        6.0       0.65      0.55      0.60       958\n",
            "        7.0       0.73      0.37      0.49      1028\n",
            "        8.0       0.30      0.63      0.41       974\n",
            "        9.0       0.27      0.18      0.22      1009\n",
            "\n",
            "avg / total       0.55      0.53      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 867    1    7   17    5    3   40    7   28    5]\n",
            " [   0 1120    1    2    0    0    6    0    6    0]\n",
            " [  30  314  250   10   29    3  151   31  204   10]\n",
            " [  31   76   10  695    1    1   21   11  157    7]\n",
            " [   1   36    6   10  619   11    8   14  210   67]\n",
            " [  55  133    2  306   33   12   41   10  283   17]\n",
            " [  33   36   12   18  104    5  527    0  220    3]\n",
            " [  14  124   16    7   66    3    4  381   39  374]\n",
            " [   8  242    0   71   10    0   12   13  613    5]\n",
            " [  11   68    0   33  398    7    2   53  255  182]]\n",
            "--------------------------------\n",
            "final active learning accuracies [59.050000000000004, 52.849999999999994, 54.71, 55.16, 52.349999999999994, 53.94, 53.43, 51.480000000000004, 45.94, 48.92, 48.55, 44.51, 50.72, 48.29, 49.69, 53.61, 49.91, 50.12, 50.59, 52.66]\n",
            "saved Active-learning-experiment-44.pkl /content ['datalab', 'Active-learning-experiment-32.pkl', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-38.pkl', 'Active-learning-experiment-42.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-44.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-41.pkl', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-33.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-43.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-29.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "Count = 45, using model = LogModel, selection_function = EntropySelection, k = 10, iteration = 0.\n",
            "\n",
            "initial random chosen samples (10,)\n",
            "initial train set: (10, 784) (10,) unique(labels): [3 0 1 2 1 0 1 1 1] [0 2 3 4 6 7 8]\n",
            "val set: (59990, 784) (59990,) (10,)\n",
            "\n",
            "Train set: (10, 784) y: (10,)\n",
            "Val   set: (59990, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 1\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.243 s \n",
            "\n",
            "Accuracy rate for 36.620000 \n",
            "Classification report for classifier LogisticRegression(C=5.0, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.55      0.83      0.66       980\n",
            "        1.0       0.00      0.00      0.00      1135\n",
            "        2.0       0.28      0.43      0.34      1032\n",
            "        3.0       0.24      0.55      0.33      1010\n",
            "        4.0       0.38      0.40      0.39       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.64      0.44      0.52       958\n",
            "        7.0       0.41      0.71      0.52      1028\n",
            "        8.0       0.27      0.31      0.29       974\n",
            "        9.0       0.00      0.00      0.00      1009\n",
            "\n",
            "avg / total       0.27      0.37      0.30     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[815   0  36  35   0   0  11  59  24   0]\n",
            " [  0   0 355 499 147   0  34   0 100   0]\n",
            " [ 39   0 441 434   7   0  35  48  28   0]\n",
            " [ 19   0  96 555   1   0   3  52 284   0]\n",
            " [ 58   0  68  90 392   0  82 287   5   0]\n",
            " [202   0 117 121  35   0  54 105 258   0]\n",
            " [270   0  77 155  12   0 425  19   0   0]\n",
            " [  3   0  39  87  80   0   1 735  83   0]\n",
            " [ 45   0 279 165  92   0  12  82 299   0]\n",
            " [ 37   0  53 218 257   0  12 389  43   0]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59990,) [0. 0. 7. ... 7. 4. 8.]\n",
            "probabilities: (59990, 7) \n",
            " [0 0 5 ... 5 3 6]\n",
            "trainset before (10, 784) (10,)\n",
            "trainset after (20, 784) (20,)\n",
            "updated train set: (20, 784) (20,) unique(labels): [3 5 1 2 1 4 1 1 1 1] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59980, 784) (59980,)\n",
            "\n",
            "Train set: (20, 784) y: (20,)\n",
            "Val   set: (59980, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 2\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.321 s \n",
            "\n",
            "Accuracy rate for 46.790000 \n",
            "Classification report for classifier LogisticRegression(C=2.5, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.54      0.81      0.64       980\n",
            "        1.0       0.87      0.76      0.81      1135\n",
            "        2.0       0.42      0.37      0.39      1032\n",
            "        3.0       0.29      0.56      0.38      1010\n",
            "        4.0       0.36      0.28      0.31       982\n",
            "        5.0       0.75      0.20      0.32       892\n",
            "        6.0       0.85      0.35      0.50       958\n",
            "        7.0       0.58      0.47      0.52      1028\n",
            "        8.0       0.25      0.32      0.28       974\n",
            "        9.0       0.40      0.50      0.44      1009\n",
            "\n",
            "avg / total       0.53      0.47      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[793   0  41  44   0   1  15  25  52   9]\n",
            " [  0 864  39  32  75   1   0   0 123   1]\n",
            " [ 42   8 378 481   6   1  20  21  32  43]\n",
            " [ 26   5  89 565   0   4   0  19 274  28]\n",
            " [ 43  18  32  87 273   8  10 137   7 367]\n",
            " [155  21  38 133  16 178  14  14 294  29]\n",
            " [325  11  48 168  18  24 338  10   5  11]\n",
            " [  4  23  46  97 136   0   0 480  96 146]\n",
            " [ 53  29 178 183  69  15   1  24 309 113]\n",
            " [ 41   9  14 145 162   4   1  99  33 501]]\n",
            "--------------------------------\n",
            "val predicted: (59980,) [0. 0. 2. ... 7. 8. 8.]\n",
            "probabilities: (59980, 10) \n",
            " [0 0 2 ... 7 8 8]\n",
            "trainset before (20, 784) (20,)\n",
            "trainset after (30, 784) (30,)\n",
            "updated train set: (30, 784) (30,) unique(labels): [ 3  5  2  3  1 10  1  1  3  1] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59970, 784) (59970,)\n",
            "\n",
            "Train set: (30, 784) y: (30,)\n",
            "Val   set: (59970, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 3\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.327 s \n",
            "\n",
            "Accuracy rate for 47.490000 \n",
            "Classification report for classifier LogisticRegression(C=1.6666666666666667, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.64      0.83      0.72       980\n",
            "        1.0       0.84      0.82      0.83      1135\n",
            "        2.0       0.33      0.43      0.37      1032\n",
            "        3.0       0.34      0.62      0.44      1010\n",
            "        4.0       0.36      0.24      0.29       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.88      0.17      0.28       958\n",
            "        7.0       0.51      0.64      0.57      1028\n",
            "        8.0       0.34      0.55      0.42       974\n",
            "        9.0       0.49      0.34      0.40      1009\n",
            "\n",
            "avg / total       0.48      0.47      0.44     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[815   0  41  11   5   0  11  75  18   4]\n",
            " [  0 928 130  12  11   0   0   0  54   0]\n",
            " [ 26  16 446 412   6   0   3  37  80   6]\n",
            " [ 18  13  43 626   1   0   0  43 259   7]\n",
            " [ 34  29  81  96 233   0   1 177  82 249]\n",
            " [ 94  37 122 188  41   0   6  47 350   7]\n",
            " [266  19 190 194  14   0 160  36  77   2]\n",
            " [  1  25 118  53  86   0   0 660  13  72]\n",
            " [ 13  27 164 111  63   0   0  47 539  10]\n",
            " [ 13  13  37 131 190   0   0 178 105 342]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59970,) [0. 0. 8. ... 7. 2. 2.]\n",
            "probabilities: (59970, 10) \n",
            " [0 0 8 ... 7 2 2]\n",
            "trainset before (30, 784) (30,)\n",
            "trainset after (40, 784) (40,)\n",
            "updated train set: (40, 784) (40,) unique(labels): [ 3  5  2  5  2 16  2  1  3  1] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59960, 784) (59960,)\n",
            "\n",
            "Train set: (40, 784) y: (40,)\n",
            "Val   set: (59960, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 4\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.328 s \n",
            "\n",
            "Accuracy rate for 49.960000 \n",
            "Classification report for classifier LogisticRegression(C=1.25, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.65      0.85      0.74       980\n",
            "        1.0       0.85      0.85      0.85      1135\n",
            "        2.0       0.54      0.32      0.41      1032\n",
            "        3.0       0.50      0.58      0.54      1010\n",
            "        4.0       0.28      0.27      0.28       982\n",
            "        5.0       0.00      0.00      0.00       892\n",
            "        6.0       0.63      0.27      0.38       958\n",
            "        7.0       0.60      0.48      0.53      1028\n",
            "        8.0       0.33      0.62      0.43       974\n",
            "        9.0       0.37      0.64      0.47      1009\n",
            "\n",
            "avg / total       0.49      0.50      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[835   0   9  26  18   0   0  48  30  14]\n",
            " [  0 969  43  27   2   0   1   0  90   3]\n",
            " [ 36  28 334 160  15   0 140  25 190 104]\n",
            " [ 16   4   8 584   8   0   1  18 318  53]\n",
            " [ 15  19  23   9 265   0   7 103  53 488]\n",
            " [ 69  26  33 197 152   0   3  19 342  51]\n",
            " [272  11  25  40 141   1 263  25 131  49]\n",
            " [  1  37  83  74  69   0   1 492  27 244]\n",
            " [ 17  33  47  21 115   0   0  21 604 116]\n",
            " [ 15  12  12  34 154   0   0  68  64 650]]\n",
            "--------------------------------\n",
            "val predicted: (59960,) [0. 0. 8. ... 7. 4. 8.]\n",
            "probabilities: (59960, 10) \n",
            " [0 0 8 ... 7 4 8]\n",
            "trainset before (40, 784) (40,)\n",
            "trainset after (50, 784) (50,)\n",
            "updated train set: (50, 784) (50,) unique(labels): [ 3  5  3  5  3 22  2  1  4  2] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59950, 784) (59950,)\n",
            "\n",
            "Train set: (50, 784) y: (50,)\n",
            "Val   set: (59950, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 5\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.347 s \n",
            "\n",
            "Accuracy rate for 51.590000 \n",
            "Classification report for classifier LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.68      0.76      0.72       980\n",
            "        1.0       0.78      0.88      0.83      1135\n",
            "        2.0       0.55      0.55      0.55      1032\n",
            "        3.0       0.40      0.68      0.51      1010\n",
            "        4.0       0.35      0.43      0.39       982\n",
            "        5.0       0.60      0.00      0.01       892\n",
            "        6.0       0.81      0.40      0.54       958\n",
            "        7.0       0.50      0.63      0.56      1028\n",
            "        8.0       0.34      0.31      0.32       974\n",
            "        9.0       0.40      0.40      0.40      1009\n",
            "\n",
            "avg / total       0.54      0.52      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 745    0   33   39   19    0    3   88   50    3]\n",
            " [   0 1000   57   52    2    0    2    2   18    2]\n",
            " [  17   39  567  207   18    0   68   40   24   52]\n",
            " [  18   53   47  689   15    1    1   55  126    5]\n",
            " [  15   25    5   31  425    0    6  154    4  317]\n",
            " [  57   34   65  281  168    3    3   64  207   10]\n",
            " [ 202    9   21   48  166    0  383   45   29   55]\n",
            " [   8   36   61   81   25    1    2  649   40  125]\n",
            " [  16   73  158  155  171    0    2   63  299   37]\n",
            " [  18   20   15  120  203    0    2  148   84  399]]\n",
            "--------------------------------\n",
            "val predicted: (59950,) [0. 0. 8. ... 7. 8. 8.]\n",
            "probabilities: (59950, 10) \n",
            " [0 0 8 ... 7 8 8]\n",
            "trainset before (50, 784) (50,)\n",
            "trainset after (60, 784) (60,)\n",
            "updated train set: (60, 784) (60,) unique(labels): [ 3  5  3  7  3 27  2  2  4  4] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59940, 784) (59940,)\n",
            "\n",
            "Train set: (60, 784) y: (60,)\n",
            "Val   set: (59940, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 6\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.349 s \n",
            "\n",
            "Accuracy rate for 54.250000 \n",
            "Classification report for classifier LogisticRegression(C=0.8333333333333334, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.76      0.87      0.81       980\n",
            "        1.0       0.70      0.96      0.81      1135\n",
            "        2.0       0.55      0.56      0.55      1032\n",
            "        3.0       0.49      0.65      0.56      1010\n",
            "        4.0       0.45      0.43      0.44       982\n",
            "        5.0       0.71      0.01      0.01       892\n",
            "        6.0       0.75      0.48      0.59       958\n",
            "        7.0       0.76      0.42      0.54      1028\n",
            "        8.0       0.28      0.46      0.35       974\n",
            "        9.0       0.41      0.49      0.44      1009\n",
            "\n",
            "avg / total       0.59      0.54      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 850    0   17   27    9    0    5    3   57   12]\n",
            " [   0 1085   41    3    1    0    2    0    3    0]\n",
            " [  15  115  573   82   27    0  117   21   61   21]\n",
            " [  13   67   75  654    4    2    4   36  134   21]\n",
            " [  12   29    4   28  427    0   10    9   58  405]\n",
            " [  35   48   58  309   97    5    8   24  264   44]\n",
            " [ 159   19   17   36  145    0  464    7   58   53]\n",
            " [   9   60  140   37   28    0    4  427  197  126]\n",
            " [   9  113  104  128  131    0    2    4  450   33]\n",
            " [  13   23   16   37   88    0    6   32  304  490]]\n",
            "--------------------------------\n",
            "val predicted: (59940,) [0. 0. 8. ... 8. 8. 2.]\n",
            "probabilities: (59940, 10) \n",
            " [0 0 8 ... 8 8 2]\n",
            "trainset before (60, 784) (60,)\n",
            "trainset after (70, 784) (70,)\n",
            "updated train set: (70, 784) (70,) unique(labels): [ 3  5  3  8  3 31  3  4  4  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59930, 784) (59930,)\n",
            "\n",
            "Train set: (70, 784) y: (70,)\n",
            "Val   set: (59930, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 7\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.346 s \n",
            "\n",
            "Accuracy rate for 49.430000 \n",
            "Classification report for classifier LogisticRegression(C=0.7142857142857143, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.77      0.79       980\n",
            "        1.0       0.71      0.96      0.82      1135\n",
            "        2.0       0.48      0.55      0.51      1032\n",
            "        3.0       0.55      0.58      0.56      1010\n",
            "        4.0       0.33      0.39      0.36       982\n",
            "        5.0       0.46      0.02      0.04       892\n",
            "        6.0       0.64      0.28      0.39       958\n",
            "        7.0       0.61      0.34      0.44      1028\n",
            "        8.0       0.27      0.58      0.36       974\n",
            "        9.0       0.37      0.37      0.37      1009\n",
            "\n",
            "avg / total       0.53      0.49      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 753    1   78   52   25    2   16   14   14   25]\n",
            " [   0 1087   28    3    1    0    2    0   14    0]\n",
            " [  14  116  563   53   49    0   99   10  101   27]\n",
            " [  11   46   86  582    6   10   11    8  243    7]\n",
            " [   3   30    7    9  385    1    6   77  121  343]\n",
            " [  23   44   82  246  121   17    8   23  290   38]\n",
            " [ 100   22   75   33  272    2  272   16   81   85]\n",
            " [   3   67  120   24   47    3    8  351  305  100]\n",
            " [   8   95  106   47  128    1    3   13  563   10]\n",
            " [   7   23   18   16  132    1    1   60  381  370]]\n",
            "--------------------------------\n",
            "val predicted: (59930,) [0. 0. 8. ... 8. 2. 2.]\n",
            "probabilities: (59930, 10) \n",
            " [0 0 8 ... 8 2 2]\n",
            "trainset before (70, 784) (70,)\n",
            "trainset after (80, 784) (80,)\n",
            "updated train set: (80, 784) (80,) unique(labels): [ 3  5  4  8  3 36  4  5  6  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59920, 784) (59920,)\n",
            "\n",
            "Train set: (80, 784) y: (80,)\n",
            "Val   set: (59920, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 8\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.352 s \n",
            "\n",
            "Accuracy rate for 55.510000 \n",
            "Classification report for classifier LogisticRegression(C=0.625, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.89      0.70      0.78       980\n",
            "        1.0       0.68      0.93      0.79      1135\n",
            "        2.0       0.47      0.55      0.51      1032\n",
            "        3.0       0.52      0.64      0.57      1010\n",
            "        4.0       0.38      0.50      0.43       982\n",
            "        5.0       0.58      0.02      0.05       892\n",
            "        6.0       0.56      0.68      0.61       958\n",
            "        7.0       0.82      0.53      0.65      1028\n",
            "        8.0       0.45      0.37      0.40       974\n",
            "        9.0       0.42      0.51      0.46      1009\n",
            "\n",
            "avg / total       0.58      0.56      0.53     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 689    1   41   27    9    3  157    8   28   17]\n",
            " [   0 1060   66    2    1    0    4    0    2    0]\n",
            " [  15   93  565   31   32    0  220    5   50   21]\n",
            " [   6   83   34  649   13    9   42   18  143   13]\n",
            " [   5   25   18   37  492    0   19    6    3  377]\n",
            " [  10   33   82  315  163   22   36   28  155   48]\n",
            " [  41   11   75   23  101    0  652    2   24   29]\n",
            " [   4   52  156   17   64    3    9  546    1  176]\n",
            " [   2  177  130   84  149    0   25    6  360   41]\n",
            " [   6   29   27   74  264    1    6   45   41  516]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59920,) [0. 0. 6. ... 8. 3. 2.]\n",
            "probabilities: (59920, 10) \n",
            " [0 0 6 ... 8 3 2]\n",
            "trainset before (80, 784) (80,)\n",
            "trainset after (90, 784) (90,)\n",
            "updated train set: (90, 784) (90,) unique(labels): [ 4  5  7  9  3 38  5  6  7  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59910, 784) (59910,)\n",
            "\n",
            "Train set: (90, 784) y: (90,)\n",
            "Val   set: (59910, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 9\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.351 s \n",
            "\n",
            "Accuracy rate for 52.880000 \n",
            "Classification report for classifier LogisticRegression(C=0.5555555555555556, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.75      0.86      0.80       980\n",
            "        1.0       0.68      0.94      0.79      1135\n",
            "        2.0       0.60      0.34      0.44      1032\n",
            "        3.0       0.52      0.45      0.48      1010\n",
            "        4.0       0.36      0.42      0.39       982\n",
            "        5.0       0.36      0.01      0.01       892\n",
            "        6.0       0.52      0.52      0.52       958\n",
            "        7.0       0.85      0.43      0.58      1028\n",
            "        8.0       0.37      0.62      0.46       974\n",
            "        9.0       0.38      0.60      0.46      1009\n",
            "\n",
            "avg / total       0.55      0.53      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 844    0   12   45   11    0   35    4   23    6]\n",
            " [   0 1065   60    2    1    0    4    0    3    0]\n",
            " [  44  103  356   57   39    0  257    2  121   53]\n",
            " [   9   82   13  453    4    3   45   10  376   15]\n",
            " [   8   33    7    0  414    1   28    8   18  465]\n",
            " [  58   41   25  236  132    5   37   19  287   52]\n",
            " [ 121   12   10   26  165    0  496    0   80   48]\n",
            " [  13   66   76   10   56    5   30  447    8  317]\n",
            " [  15  126   25   24  125    0   12    3  605   39]\n",
            " [  10   29    8   11  195    0    5   32  116  603]]\n",
            "--------------------------------\n",
            "val predicted: (59910,) [0. 0. 8. ... 4. 3. 3.]\n",
            "probabilities: (59910, 10) \n",
            " [0 0 8 ... 4 3 3]\n",
            "trainset before (90, 784) (90,)\n",
            "trainset after (100, 784) (100,)\n",
            "updated train set: (100, 784) (100,) unique(labels): [ 4  5  8  9  3 40  5  9 11  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59900, 784) (59900,)\n",
            "\n",
            "Train set: (100, 784) y: (100,)\n",
            "Val   set: (59900, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 10\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.362 s \n",
            "\n",
            "Accuracy rate for 50.890000 \n",
            "Classification report for classifier LogisticRegression(C=0.5, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.81      0.82       980\n",
            "        1.0       0.71      0.92      0.81      1135\n",
            "        2.0       0.42      0.34      0.38      1032\n",
            "        3.0       0.49      0.67      0.57      1010\n",
            "        4.0       0.31      0.46      0.37       982\n",
            "        5.0       0.71      0.02      0.05       892\n",
            "        6.0       0.48      0.60      0.54       958\n",
            "        7.0       0.90      0.21      0.34      1028\n",
            "        8.0       0.52      0.39      0.44       974\n",
            "        9.0       0.34      0.57      0.42      1009\n",
            "\n",
            "avg / total       0.57      0.51      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 798    2    4   69   27    0   68    4    1    7]\n",
            " [   0 1047   62    5    1    0    4    1   15    0]\n",
            " [  32   75  352   86   50    0  357    1   20   59]\n",
            " [   1   98   11  672   25    3   68    7   93   32]\n",
            " [  10   16    9    2  450    0   20    2   22  451]\n",
            " [  29   34   26  372  190   22   47    2  102   68]\n",
            " [  73   13   29   37  141    0  577    0   26   62]\n",
            " [  14   35  207   38   72    4   36  219    6  397]\n",
            " [   6  123  124   63  214    2   12    1  376   53]\n",
            " [   6   22   20   20  288    0    7    5   65  576]]\n",
            "--------------------------------\n",
            "val predicted: (59900,) [0. 0. 3. ... 4. 8. 2.]\n",
            "probabilities: (59900, 10) \n",
            " [0 0 3 ... 4 8 2]\n",
            "trainset before (100, 784) (100,)\n",
            "trainset after (110, 784) (110,)\n",
            "updated train set: (110, 784) (110,) unique(labels): [ 5  5  9  9  4 43  6 12 11  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59890, 784) (59890,)\n",
            "\n",
            "Train set: (110, 784) y: (110,)\n",
            "Val   set: (59890, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 11\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.361 s \n",
            "\n",
            "Accuracy rate for 53.040000 \n",
            "Classification report for classifier LogisticRegression(C=0.45454545454545453, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.80      0.87      0.84       980\n",
            "        1.0       0.62      0.91      0.74      1135\n",
            "        2.0       0.61      0.46      0.52      1032\n",
            "        3.0       0.51      0.48      0.50      1010\n",
            "        4.0       0.32      0.41      0.36       982\n",
            "        5.0       0.50      0.02      0.03       892\n",
            "        6.0       0.52      0.64      0.58       958\n",
            "        7.0       0.83      0.35      0.49      1028\n",
            "        8.0       0.49      0.43      0.46       974\n",
            "        9.0       0.36      0.63      0.46      1009\n",
            "\n",
            "avg / total       0.56      0.53      0.51     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 855    1    8   38    2    0   68    5    2    1]\n",
            " [   0 1038   71    4    5    1    3    0   13    0]\n",
            " [  24   88  473   63   66    1  262    4   10   41]\n",
            " [  10  217   34  489   23    4   88   14  103   28]\n",
            " [   9   18    2    0  406    0   11    3   31  502]\n",
            " [  78   58   36  252  167   16   69   14  131   71]\n",
            " [  40   14   30   22  143    0  613    5   27   64]\n",
            " [  18   57   54   38   82    8   14  362   16  379]\n",
            " [  20  147   65   30  198    1   37   11  414   51]\n",
            " [   9   34    5   22  183    1    5   17   95  638]]\n",
            "--------------------------------\n",
            "val predicted: (59890,) [0. 0. 3. ... 3. 3. 3.]\n",
            "probabilities: (59890, 10) \n",
            " [0 0 3 ... 3 3 3]\n",
            "trainset before (110, 784) (110,)\n",
            "trainset after (120, 784) (120,)\n",
            "updated train set: (120, 784) (120,) unique(labels): [ 5  5 10  9  4 48  7 14 12  6] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59880, 784) (59880,)\n",
            "\n",
            "Train set: (120, 784) y: (120,)\n",
            "Val   set: (59880, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 12\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.372 s \n",
            "\n",
            "Accuracy rate for 52.420000 \n",
            "Classification report for classifier LogisticRegression(C=0.4166666666666667, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.92      0.80       980\n",
            "        1.0       0.64      0.93      0.76      1135\n",
            "        2.0       0.46      0.32      0.38      1032\n",
            "        3.0       0.57      0.60      0.58      1010\n",
            "        4.0       0.33      0.49      0.40       982\n",
            "        5.0       0.59      0.05      0.09       892\n",
            "        6.0       0.52      0.55      0.54       958\n",
            "        7.0       0.77      0.38      0.51      1028\n",
            "        8.0       0.49      0.33      0.40       974\n",
            "        9.0       0.37      0.57      0.45      1009\n",
            "\n",
            "avg / total       0.55      0.52      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 903    1    5   33    2    0   32    3    1    0]\n",
            " [   0 1055   60    4    1    1    3    1   10    0]\n",
            " [  69  113  335   32   98    1  312   14   16   42]\n",
            " [  19  169    9  605   32   10   45   28   70   23]\n",
            " [  14   17    2    1  486    1    5    6   22  428]\n",
            " [ 110   49   19  292  159   43   50    8   96   66]\n",
            " [  77   18   13   25  198    0  526    1   45   55]\n",
            " [  30   45  118   22   65   10    5  388    5  340]\n",
            " [  29  158  159   27  190    1   25   26  325   34]\n",
            " [  25   29    7   24  240    6    4   27   71  576]]\n",
            "--------------------------------\n",
            "val predicted: (59880,) [0. 0. 3. ... 3. 7. 7.]\n",
            "probabilities: (59880, 10) \n",
            " [0 0 3 ... 3 7 7]\n",
            "trainset before (120, 784) (120,)\n",
            "trainset after (130, 784) (130,)\n",
            "updated train set: (130, 784) (130,) unique(labels): [ 6  5 11  9  5 49  7 18 12  8] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59870, 784) (59870,)\n",
            "\n",
            "Train set: (130, 784) y: (130,)\n",
            "Val   set: (59870, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 13\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.364 s \n",
            "\n",
            "Accuracy rate for 52.410000 \n",
            "Classification report for classifier LogisticRegression(C=0.38461538461538464, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.69      0.92      0.79       980\n",
            "        1.0       0.74      0.84      0.79      1135\n",
            "        2.0       0.50      0.32      0.39      1032\n",
            "        3.0       0.64      0.64      0.64      1010\n",
            "        4.0       0.28      0.66      0.39       982\n",
            "        5.0       0.61      0.04      0.07       892\n",
            "        6.0       0.47      0.55      0.50       958\n",
            "        7.0       0.75      0.31      0.44      1028\n",
            "        8.0       0.66      0.33      0.44       974\n",
            "        9.0       0.42      0.55      0.48      1009\n",
            "\n",
            "avg / total       0.58      0.52      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[899   0   5  17   3   2  40   1  11   2]\n",
            " [  0 957 140   4   1   0   4  19  10   0]\n",
            " [ 87  56 331  13 128   1 349  34   5  28]\n",
            " [ 17  97  28 649  35   7  61  27  38  51]\n",
            " [ 17   7   1   5 648   2   7   2   7 286]\n",
            " [123  33  12 258 212  34  80   4  35 101]\n",
            " [107   9  12  18 225   0 524   1  56   6]\n",
            " [ 18  29  32  10 341   5  10 319   3 261]\n",
            " [ 27  91  96  27 327   3  41  14 324  24]\n",
            " [ 13  19   2  13 389   2   5   7   3 556]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59870,) [0. 0. 3. ... 4. 4. 4.]\n",
            "probabilities: (59870, 10) \n",
            " [0 0 3 ... 4 4 4]\n",
            "trainset before (130, 784) (130,)\n",
            "trainset after (140, 784) (140,)\n",
            "updated train set: (140, 784) (140,) unique(labels): [ 6  5 13 11  5 53  7 19 12  9] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59860, 784) (59860,)\n",
            "\n",
            "Train set: (140, 784) y: (140,)\n",
            "Val   set: (59860, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 14\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.355 s \n",
            "\n",
            "Accuracy rate for 50.950000 \n",
            "Classification report for classifier LogisticRegression(C=0.35714285714285715, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.72      0.87      0.79       980\n",
            "        1.0       0.62      0.95      0.75      1135\n",
            "        2.0       0.50      0.30      0.38      1032\n",
            "        3.0       0.65      0.49      0.56      1010\n",
            "        4.0       0.29      0.60      0.39       982\n",
            "        5.0       0.58      0.18      0.27       892\n",
            "        6.0       0.43      0.62      0.51       958\n",
            "        7.0       0.92      0.23      0.37      1028\n",
            "        8.0       0.77      0.27      0.40       974\n",
            "        9.0       0.37      0.51      0.43      1009\n",
            "\n",
            "avg / total       0.59      0.51      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 856    2   15    5    5    3   88    1    5    0]\n",
            " [   0 1077   42    2    1    0    4    1    6    2]\n",
            " [  66  136  312    9   93    1  367    9    9   30]\n",
            " [  13  196   22  491   11   54  125    4   29   65]\n",
            " [  12   18    7    5  590    2   11    1    4  332]\n",
            " [ 116   50   23  165  193  158  126    3   10   48]\n",
            " [  47   28   25    8  225    2  595    1   15   12]\n",
            " [  31   43   53   27  267   12   15  237    0  343]\n",
            " [  23  164  119   20  270   24   47    1  261   45]\n",
            " [  19   15    6   23  400   18    8    0    2  518]]\n",
            "--------------------------------\n",
            "val predicted: (59860,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59860, 10) \n",
            " [0 0 6 ... 4 4 4]\n",
            "trainset before (140, 784) (140,)\n",
            "trainset after (150, 784) (150,)\n",
            "updated train set: (150, 784) (150,) unique(labels): [ 6  5 13 12  6 55  7 22 14 10] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59850, 784) (59850,)\n",
            "\n",
            "Train set: (150, 784) y: (150,)\n",
            "Val   set: (59850, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 15\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.376 s \n",
            "\n",
            "Accuracy rate for 48.700000 \n",
            "Classification report for classifier LogisticRegression(C=0.3333333333333333, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.72      0.87      0.78       980\n",
            "        1.0       0.60      0.88      0.72      1135\n",
            "        2.0       0.47      0.19      0.27      1032\n",
            "        3.0       0.68      0.29      0.40      1010\n",
            "        4.0       0.29      0.69      0.41       982\n",
            "        5.0       0.57      0.08      0.13       892\n",
            "        6.0       0.38      0.63      0.47       958\n",
            "        7.0       0.87      0.41      0.55      1028\n",
            "        8.0       0.46      0.40      0.42       974\n",
            "        9.0       0.40      0.37      0.39      1009\n",
            "\n",
            "avg / total       0.55      0.49      0.46     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 848    3    8    2    6    0   87    3   18    5]\n",
            " [   0 1004   89    2   16    0    4    8   12    0]\n",
            " [  94   81  201    6   50    0  531   21   40    8]\n",
            " [  15  303    7  289   34   24  119   15  197    7]\n",
            " [  17   17    5    3  681    1   35    1   19  203]\n",
            " [  89   59   10  104  314   67  124    4   83   38]\n",
            " [  57   29   30    3  202    0  606    1   26    4]\n",
            " [  28   40   34    5  174   12   17  418   21  279]\n",
            " [  18  105   43    3  359    6   49    4  385    2]\n",
            " [  15   24    3    6  507    7   27    8   41  371]]\n",
            "--------------------------------\n",
            "val predicted: (59850,) [0. 0. 6. ... 4. 4. 4.]\n",
            "probabilities: (59850, 10) \n",
            " [0 0 6 ... 4 4 4]\n",
            "trainset before (150, 784) (150,)\n",
            "trainset after (160, 784) (160,)\n",
            "updated train set: (160, 784) (160,) unique(labels): [ 6  5 14 12  8 59  7 23 15 11] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59840, 784) (59840,)\n",
            "\n",
            "Train set: (160, 784) y: (160,)\n",
            "Val   set: (59840, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 16\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.380 s \n",
            "\n",
            "Accuracy rate for 48.890000 \n",
            "Classification report for classifier LogisticRegression(C=0.3125, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.83      0.77       980\n",
            "        1.0       0.67      0.83      0.74      1135\n",
            "        2.0       0.66      0.07      0.12      1032\n",
            "        3.0       0.71      0.27      0.39      1010\n",
            "        4.0       0.30      0.76      0.43       982\n",
            "        5.0       0.65      0.04      0.08       892\n",
            "        6.0       0.38      0.65      0.48       958\n",
            "        7.0       0.69      0.51      0.58      1028\n",
            "        8.0       0.48      0.58      0.53       974\n",
            "        9.0       0.35      0.30      0.32      1009\n",
            "\n",
            "avg / total       0.56      0.49      0.45     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[810   2   0   2  21   0  97   8  18  22]\n",
            " [  0 944  15   2   1   0   4 101  68   0]\n",
            " [ 81  62  68   7  68   0 560  65 102  19]\n",
            " [  6 206   2 272 149  12 118  28 199  18]\n",
            " [ 26   4   2   1 743   1  36   4  20 145]\n",
            " [ 73  41   0  84 361  37 114   6  85  91]\n",
            " [ 68  14   1   1 182   1 622   1  60   8]\n",
            " [ 21  34   9   6 147   3  12 520  23 253]\n",
            " [ 16  76   4   5 233   2  39  10 569  20]\n",
            " [ 16  18   2   2 594   1  21  15  36 304]]\n",
            "--------------------------------\n",
            "val predicted: (59840,) [0. 0. 8. ... 4. 4. 4.]\n",
            "probabilities: (59840, 10) \n",
            " [0 0 8 ... 4 4 4]\n",
            "trainset before (160, 784) (160,)\n",
            "trainset after (170, 784) (170,)\n",
            "updated train set: (170, 784) (170,) unique(labels): [ 7  5 14 14  8 64  7 23 16 12] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59830, 784) (59830,)\n",
            "\n",
            "Train set: (170, 784) y: (170,)\n",
            "Val   set: (59830, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 17\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.382 s \n",
            "\n",
            "Accuracy rate for 51.160000 \n",
            "Classification report for classifier LogisticRegression(C=0.29411764705882354, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.74      0.83      0.78       980\n",
            "        1.0       0.70      0.92      0.79      1135\n",
            "        2.0       0.41      0.06      0.11      1032\n",
            "        3.0       0.78      0.32      0.45      1010\n",
            "        4.0       0.32      0.76      0.45       982\n",
            "        5.0       0.73      0.04      0.08       892\n",
            "        6.0       0.39      0.81      0.53       958\n",
            "        7.0       0.80      0.46      0.59      1028\n",
            "        8.0       0.47      0.48      0.48       974\n",
            "        9.0       0.43      0.36      0.39      1009\n",
            "\n",
            "avg / total       0.58      0.51      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 816    3    5    1    4    0  121    2   17   11]\n",
            " [   0 1043   31    2    1    0    5   48    5    0]\n",
            " [  64   82   63   10   69    0  647   30   63    4]\n",
            " [  16  157    2  324  167   10  129   16  181    8]\n",
            " [  11    4    3    0  751    0   23    3    8  179]\n",
            " [ 103   42    1   59  277   37  160    6  133   74]\n",
            " [  31   19    5    1  109    1  777    0    7    8]\n",
            " [  23   33   14    6  203    1   19  476   65  188]\n",
            " [  36   95   28    9  243    2   82    3  464   12]\n",
            " [  10   18    2    3  548    0   20    9   34  365]]\n",
            "--------------------------------\n",
            "val predicted: (59830,) [0. 0. 0. ... 4. 4. 5.]\n",
            "probabilities: (59830, 10) \n",
            " [0 0 0 ... 4 4 5]\n",
            "trainset before (170, 784) (170,)\n",
            "trainset after (180, 784) (180,)\n",
            "updated train set: (180, 784) (180,) unique(labels): [ 7  5 14 15  8 68  8 26 16 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59820, 784) (59820,)\n",
            "\n",
            "Train set: (180, 784) y: (180,)\n",
            "Val   set: (59820, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 18\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.396 s \n",
            "\n",
            "Accuracy rate for 47.680000 \n",
            "Classification report for classifier LogisticRegression(C=0.2777777777777778, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.70      0.88      0.78       980\n",
            "        1.0       0.62      0.91      0.74      1135\n",
            "        2.0       0.39      0.08      0.13      1032\n",
            "        3.0       0.59      0.24      0.34      1010\n",
            "        4.0       0.27      0.79      0.41       982\n",
            "        5.0       0.58      0.02      0.03       892\n",
            "        6.0       0.39      0.66      0.49       958\n",
            "        7.0       0.84      0.46      0.60      1028\n",
            "        8.0       0.41      0.34      0.37       974\n",
            "        9.0       0.48      0.32      0.38      1009\n",
            "\n",
            "avg / total       0.53      0.48      0.43     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 863    2    4    4   21    0   57    2   14   13]\n",
            " [   0 1031   30   49    1    0    4   17    3    0]\n",
            " [  96   99   83   18   79    0  562   33   56    6]\n",
            " [  24  252    7  245  205    2  108   18  141    8]\n",
            " [  11   10   14    1  773    1   30    2    9  131]\n",
            " [  73   52    3   45  431   14  116    6  113   39]\n",
            " [  83   19   11    0  195    0  637    2    6    5]\n",
            " [  30   38   27   32  172    3   12  475  100  139]\n",
            " [  33  130   30   13  340    2   89    4  329    4]\n",
            " [  15   17    6    8  601    2    9    7   26  318]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59820,) [0. 0. 0. ... 4. 4. 3.]\n",
            "probabilities: (59820, 10) \n",
            " [0 0 0 ... 4 4 3]\n",
            "trainset before (180, 784) (180,)\n",
            "trainset after (190, 784) (190,)\n",
            "updated train set: (190, 784) (190,) unique(labels): [ 7  6 15 16  8 73  9 26 17 13] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59810, 784) (59810,)\n",
            "\n",
            "Train set: (190, 784) y: (190,)\n",
            "Val   set: (59810, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 19\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.406 s \n",
            "\n",
            "Accuracy rate for 46.100000 \n",
            "Classification report for classifier LogisticRegression(C=0.2631578947368421, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.63      0.89      0.74       980\n",
            "        1.0       0.77      0.82      0.79      1135\n",
            "        2.0       0.62      0.06      0.11      1032\n",
            "        3.0       0.46      0.37      0.41      1010\n",
            "        4.0       0.27      0.88      0.41       982\n",
            "        5.0       0.61      0.06      0.11       892\n",
            "        6.0       0.31      0.47      0.37       958\n",
            "        7.0       0.92      0.32      0.48      1028\n",
            "        8.0       0.51      0.39      0.44       974\n",
            "        9.0       0.43      0.29      0.35      1009\n",
            "\n",
            "avg / total       0.56      0.46      0.43     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[869   0   2   4  11   0  66   2  10  16]\n",
            " [  0 933   6 180   3   0   5   3   5   0]\n",
            " [126  84  64  41 109   2 528  13  44  21]\n",
            " [ 40  41   1 374 228  19 114   2 180  11]\n",
            " [ 13   4   1   4 860   0   4   0   3  93]\n",
            " [ 94  38   3  45 418  54 109   5  84  42]\n",
            " [162   9   3   3 296   1 452   1  18  13]\n",
            " [ 30  26   8  88 282   4  65 329   9 187]\n",
            " [ 30  69  14  44 321   5 107   0 381   3]\n",
            " [ 15   9   1  24 644   4   6   1  11 294]]\n",
            "--------------------------------\n",
            "val predicted: (59810,) [0. 0. 0. ... 4. 4. 6.]\n",
            "probabilities: (59810, 10) \n",
            " [0 0 0 ... 4 4 6]\n",
            "trainset before (190, 784) (190,)\n",
            "trainset after (200, 784) (200,)\n",
            "updated train set: (200, 784) (200,) unique(labels): [ 7  6 15 17  8 77  9 29 18 14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59800, 784) (59800,)\n",
            "\n",
            "Train set: (200, 784) y: (200,)\n",
            "Val   set: (59800, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 20\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.416 s \n",
            "\n",
            "Accuracy rate for 48.910000 \n",
            "Classification report for classifier LogisticRegression(C=0.25, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.66      0.87      0.75       980\n",
            "        1.0       0.72      0.90      0.80      1135\n",
            "        2.0       0.54      0.12      0.20      1032\n",
            "        3.0       0.57      0.38      0.46      1010\n",
            "        4.0       0.25      0.81      0.39       982\n",
            "        5.0       0.59      0.10      0.18       892\n",
            "        6.0       0.34      0.52      0.41       958\n",
            "        7.0       0.87      0.55      0.67      1028\n",
            "        8.0       0.59      0.30      0.40       974\n",
            "        9.0       0.51      0.25      0.34      1009\n",
            "\n",
            "avg / total       0.57      0.49      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 849    1    3    3   29    1   73   10    6    5]\n",
            " [   0 1027    5   82    1    0    5    8    7    0]\n",
            " [ 111  117  124   30   95    1  506   23   20    5]\n",
            " [  22   55    8  388  261   25  131   18  101    1]\n",
            " [  18    6   10    2  798    2   19    1    5  121]\n",
            " [  78   46    7   41  449   93  108    2   41   27]\n",
            " [ 131   13   18    2  277    0  502    0    9    6]\n",
            " [  22   33    7   88  204   11   26  563    4   70]\n",
            " [  27  108   43   24  356   18   93    7  296    2]\n",
            " [  21   13    4   16  667    7    8   12   10  251]]\n",
            "--------------------------------\n",
            "val predicted: (59800,) [0. 0. 0. ... 4. 4. 6.]\n",
            "probabilities: (59800, 10) \n",
            " [0 0 0 ... 4 4 6]\n",
            "trainset before (200, 784) (200,)\n",
            "trainset after (210, 784) (210,)\n",
            "updated train set: (210, 784) (210,) unique(labels): [ 7  6 16 17 13 78  9 31 19 14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59790, 784) (59790,)\n",
            "\n",
            "Train set: (210, 784) y: (210,)\n",
            "Val   set: (59790, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 21\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.413 s \n",
            "\n",
            "Accuracy rate for 50.740000 \n",
            "Classification report for classifier LogisticRegression(C=0.23809523809523808, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.62      0.90      0.74       980\n",
            "        1.0       0.66      0.85      0.75      1135\n",
            "        2.0       0.52      0.04      0.08      1032\n",
            "        3.0       0.44      0.53      0.48      1010\n",
            "        4.0       0.37      0.45      0.40       982\n",
            "        5.0       0.43      0.18      0.25       892\n",
            "        6.0       0.37      0.65      0.47       958\n",
            "        7.0       0.79      0.57      0.66      1028\n",
            "        8.0       0.46      0.28      0.35       974\n",
            "        9.0       0.45      0.56      0.50      1009\n",
            "\n",
            "avg / total       0.52      0.51      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[878   2   2   7  12   4  54  10   4   7]\n",
            " [  0 968   0 145   0   1   4  17   0   0]\n",
            " [ 92  88  44  70 220   2 469  16  25   6]\n",
            " [ 27  70  15 539  15  48 178  27  74  17]\n",
            " [  8  32   3  42 437  36   2   4  15 403]\n",
            " [165  76   6  85  43 157 144  14  96 106]\n",
            " [161  31   5   9  94   8 621   0   2  27]\n",
            " [ 15  34   1 112 101  24  11 589  34 107]\n",
            " [ 51 132   8 113 117  30 189  44 271  19]\n",
            " [ 11  24   0  97 146  59  13  24  65 570]]\n",
            "--------------------------------\n",
            "val predicted: (59790,) [0. 0. 0. ... 4. 8. 5.]\n",
            "probabilities: (59790, 10) \n",
            " [0 0 0 ... 4 8 5]\n",
            "trainset before (210, 784) (210,)\n",
            "trainset after (220, 784) (220,)\n",
            "updated train set: (220, 784) (220,) unique(labels): [ 7  6 16 17 14 81  9 31 25 14] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59780, 784) (59780,)\n",
            "\n",
            "Train set: (220, 784) y: (220,)\n",
            "Val   set: (59780, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 22\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.406 s \n",
            "\n",
            "Accuracy rate for 53.080000 \n",
            "Classification report for classifier LogisticRegression(C=0.22727272727272727, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.64      0.89      0.74       980\n",
            "        1.0       0.73      0.85      0.79      1135\n",
            "        2.0       0.68      0.01      0.03      1032\n",
            "        3.0       0.59      0.42      0.49      1010\n",
            "        4.0       0.45      0.49      0.47       982\n",
            "        5.0       0.57      0.11      0.18       892\n",
            "        6.0       0.39      0.68      0.49       958\n",
            "        7.0       0.86      0.59      0.70      1028\n",
            "        8.0       0.37      0.69      0.49       974\n",
            "        9.0       0.46      0.53      0.49      1009\n",
            "\n",
            "avg / total       0.58      0.53      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[871   0   1   3   7   0  68  10  10  10]\n",
            " [  0 965   0  33   0   1   5  17 114   0]\n",
            " [ 91  76  15   7 138   2 530  23 145   5]\n",
            " [ 25  57   1 423  10  29 154  15 284  12]\n",
            " [ 19  20   0  18 480   4   7   3  87 344]\n",
            " [124  66   2  80  81  96 123  14 216  90]\n",
            " [158  12   1   2  64   1 648   0  64   8]\n",
            " [ 26  28   2  78  71  13  35 605  24 146]\n",
            " [ 32  76   0   9  71   7  89   5 672  13]\n",
            " [ 20  16   0  68 149  14  16  14 179 533]]\n",
            "--------------------------------\n",
            "val predicted: (59780,) [0. 0. 0. ... 8. 6. 6.]\n",
            "probabilities: (59780, 10) \n",
            " [0 0 0 ... 8 6 6]\n",
            "trainset before (220, 784) (220,)\n",
            "trainset after (230, 784) (230,)\n",
            "updated train set: (230, 784) (230,) unique(labels): [11  6 16 18 14 84  9 31 25 16] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59770, 784) (59770,)\n",
            "\n",
            "Train set: (230, 784) y: (230,)\n",
            "Val   set: (59770, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 23\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.425 s \n",
            "\n",
            "Accuracy rate for 54.790000 \n",
            "Classification report for classifier LogisticRegression(C=0.21739130434782608, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.86      0.78       980\n",
            "        1.0       0.75      0.86      0.80      1135\n",
            "        2.0       0.50      0.00      0.01      1032\n",
            "        3.0       0.59      0.61      0.60      1010\n",
            "        4.0       0.41      0.69      0.52       982\n",
            "        5.0       0.49      0.14      0.21       892\n",
            "        6.0       0.48      0.78      0.59       958\n",
            "        7.0       0.84      0.68      0.75      1028\n",
            "        8.0       0.33      0.68      0.44       974\n",
            "        9.0       0.75      0.14      0.23      1009\n",
            "\n",
            "avg / total       0.59      0.55      0.50     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[846   1   1   4   5  16  91   2  14   0]\n",
            " [  0 979   0  25   8   1   6   7 109   0]\n",
            " [ 46  77   5  23 257   3 423  30 168   0]\n",
            " [  6  59   0 612  16  29  91  16 180   1]\n",
            " [ 11  20   1  24 679  11   4   7 202  23]\n",
            " [119  54   0 133  95 121 109  17 239   5]\n",
            " [ 34  10   0   7  98   2 744   1  59   3]\n",
            " [ 63  30   2  65 107  28   7 695  18  13]\n",
            " [ 12  69   0  23 119  10  67  13 661   0]\n",
            " [ 53  15   1 113 267  24   5  37 357 137]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59770,) [0. 0. 8. ... 4. 3. 5.]\n",
            "probabilities: (59770, 10) \n",
            " [0 0 8 ... 4 3 5]\n",
            "trainset before (230, 784) (230,)\n",
            "trainset after (240, 784) (240,)\n",
            "updated train set: (240, 784) (240,) unique(labels): [11  6 16 18 14 93  9 31 25 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59760, 784) (59760,)\n",
            "\n",
            "Train set: (240, 784) y: (240,)\n",
            "Val   set: (59760, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 24\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.443 s \n",
            "\n",
            "Accuracy rate for 50.880000 \n",
            "Classification report for classifier LogisticRegression(C=0.20833333333333334, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.68      0.84      0.75       980\n",
            "        1.0       0.70      0.90      0.79      1135\n",
            "        2.0       0.40      0.00      0.00      1032\n",
            "        3.0       0.61      0.56      0.58      1010\n",
            "        4.0       0.41      0.57      0.48       982\n",
            "        5.0       0.56      0.09      0.15       892\n",
            "        6.0       0.39      0.76      0.52       958\n",
            "        7.0       0.88      0.51      0.64      1028\n",
            "        8.0       0.30      0.60      0.40       974\n",
            "        9.0       0.40      0.22      0.28      1009\n",
            "\n",
            "avg / total       0.54      0.51      0.47     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 822    0    0    2    3    2  122    1   27    1]\n",
            " [   0 1016    0   13    7    0    4    7   87    1]\n",
            " [  42   92    2   12  210    2  493   21  149    9]\n",
            " [  15   74    0  567   13   27  115    9  170   20]\n",
            " [  22   27    2   41  558    4   34    3  259   32]\n",
            " [ 136   78    0  126   55   76  126   16  230   49]\n",
            " [  32   21    0    8   67    1  726    0   99    4]\n",
            " [  64   34    1   29   87    9   65  521   20  198]\n",
            " [  13   90    0   26  132    6  114    3  581    9]\n",
            " [  55   16    0  105  225    8   43    9  329  219]]\n",
            "--------------------------------\n",
            "val predicted: (59760,) [0. 0. 8. ... 4. 6. 6.]\n",
            "probabilities: (59760, 10) \n",
            " [0 0 8 ... 4 6 6]\n",
            "trainset before (240, 784) (240,)\n",
            "trainset after (250, 784) (250,)\n",
            "updated train set: (250, 784) (250,) unique(labels): [12  6 16 19 15 96 12 31 26 17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59750, 784) (59750,)\n",
            "\n",
            "Train set: (250, 784) y: (250,)\n",
            "Val   set: (59750, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 25\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.411 s \n",
            "\n",
            "Accuracy rate for 53.790000 \n",
            "Classification report for classifier LogisticRegression(C=0.2, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.72      0.93      0.81       980\n",
            "        1.0       0.71      0.89      0.79      1135\n",
            "        2.0       0.62      0.01      0.02      1032\n",
            "        3.0       0.57      0.55      0.56      1010\n",
            "        4.0       0.40      0.66      0.50       982\n",
            "        5.0       0.58      0.07      0.12       892\n",
            "        6.0       0.49      0.82      0.62       958\n",
            "        7.0       0.88      0.66      0.76      1028\n",
            "        8.0       0.32      0.63      0.42       974\n",
            "        9.0       0.38      0.10      0.16      1009\n",
            "\n",
            "avg / total       0.57      0.54      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 908    2    0    3    1    1   52    1   12    0]\n",
            " [   0 1011    0   75   12    0    5    6   26    0]\n",
            " [  73   82    8   36  247    1  469   25   87    4]\n",
            " [  12   88    0  558   20   24   81   15  207    5]\n",
            " [  14   25    2   11  650    2    2    2  260   14]\n",
            " [ 134   48    0  125   57   60  144   19  272   33]\n",
            " [  31   18    0    4   60    1  786    3   54    1]\n",
            " [  45   36    2   47   85    7    4  683   10  109]\n",
            " [  17   91    0   42  145    4   50    9  610    6]\n",
            " [  30   22    1   82  366    4    3    9  387  105]]\n",
            "--------------------------------\n",
            "val predicted: (59750,) [0. 0. 0. ... 8. 3. 3.]\n",
            "probabilities: (59750, 10) \n",
            " [0 0 0 ... 8 3 3]\n",
            "trainset before (250, 784) (250,)\n",
            "trainset after (260, 784) (260,)\n",
            "updated train set: (260, 784) (260,) unique(labels): [ 12   7  16  20  15 100  12  31  30  17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59740, 784) (59740,)\n",
            "\n",
            "Train set: (260, 784) y: (260,)\n",
            "Val   set: (59740, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 26\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.413 s \n",
            "\n",
            "Accuracy rate for 56.050000 \n",
            "Classification report for classifier LogisticRegression(C=0.19230769230769232, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.93      0.82       980\n",
            "        1.0       0.76      0.90      0.82      1135\n",
            "        2.0       0.67      0.00      0.01      1032\n",
            "        3.0       0.53      0.56      0.55      1010\n",
            "        4.0       0.48      0.69      0.56       982\n",
            "        5.0       0.44      0.05      0.09       892\n",
            "        6.0       0.55      0.72      0.63       958\n",
            "        7.0       0.87      0.62      0.73      1028\n",
            "        8.0       0.33      0.76      0.46       974\n",
            "        9.0       0.54      0.31      0.39      1009\n",
            "\n",
            "avg / total       0.60      0.56      0.51     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 909    2    1    4    0    4   49    2    4    5]\n",
            " [   0 1025    0   45    0    0    3    3   59    0]\n",
            " [  57   97    4   41  208    0  366   38  213    8]\n",
            " [   6   47    0  567    7   19   33   14  308    9]\n",
            " [  12   17    0   20  680    5    1    3  201   43]\n",
            " [ 103   37    0  143   59   42   79   19  353   57]\n",
            " [  38   26    0   13   97    3  688    3   83    7]\n",
            " [  70   23    0   89   42    7    0  642   36  119]\n",
            " [  16   67    0   61   43    7   23    6  740   11]\n",
            " [  34   11    1   85  292    8    0   12  258  308]]\n",
            "--------------------------------\n",
            "val predicted: (59740,) [0. 0. 0. ... 0. 9. 5.]\n",
            "probabilities: (59740, 10) \n",
            " [0 0 0 ... 0 9 5]\n",
            "trainset before (260, 784) (260,)\n",
            "trainset after (270, 784) (270,)\n",
            "updated train set: (270, 784) (270,) unique(labels): [ 13   7  16  21  15 107  12  31  31  17] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59730, 784) (59730,)\n",
            "\n",
            "Train set: (270, 784) y: (270,)\n",
            "Val   set: (59730, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 27\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.439 s \n",
            "\n",
            "Accuracy rate for 54.070000 \n",
            "Classification report for classifier LogisticRegression(C=0.18518518518518517, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.58      0.92      0.71       980\n",
            "        1.0       0.75      0.93      0.83      1135\n",
            "        2.0       0.88      0.01      0.03      1032\n",
            "        3.0       0.59      0.49      0.54      1010\n",
            "        4.0       0.45      0.72      0.56       982\n",
            "        5.0       0.52      0.05      0.09       892\n",
            "        6.0       0.47      0.71      0.56       958\n",
            "        7.0       0.86      0.56      0.68      1028\n",
            "        8.0       0.35      0.72      0.47       974\n",
            "        9.0       0.57      0.23      0.32      1009\n",
            "\n",
            "avg / total       0.61      0.54      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 900    2    0    2    0    0   70    4    2    0]\n",
            " [   0 1057    0   30    0    0    4    3   41    0]\n",
            " [  52  115   14   16  198    0  444   34  155    4]\n",
            " [  70   34    0  499   13   18   85   13  269    9]\n",
            " [   5   13    0   30  707    4   18    2  175   28]\n",
            " [ 212   48    0   69   84   44   99   16  280   40]\n",
            " [  37   26    0    9  122    0  678    4   77    5]\n",
            " [ 201   27    2   63   58    4    1  576   26   70]\n",
            " [  15   83    0   26   72    4   52    5  704   13]\n",
            " [  63    8    0  103  309   10    1   10  277  228]]\n",
            "--------------------------------\n",
            "val predicted: (59730,) [0. 0. 0. ... 0. 3. 0.]\n",
            "probabilities: (59730, 10) \n",
            " [0 0 0 ... 0 3 0]\n",
            "trainset before (270, 784) (270,)\n",
            "trainset after (280, 784) (280,)\n",
            "updated train set: (280, 784) (280,) unique(labels): [ 13   7  17  24  15 112  12  31  31  18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59720, 784) (59720,)\n",
            "\n",
            "Train set: (280, 784) y: (280,)\n",
            "Val   set: (59720, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 28\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.406 s \n",
            "\n",
            "Accuracy rate for 57.850000 \n",
            "Classification report for classifier LogisticRegression(C=0.17857142857142858, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.69      0.93      0.79       980\n",
            "        1.0       0.73      0.95      0.83      1135\n",
            "        2.0       0.81      0.01      0.02      1032\n",
            "        3.0       0.64      0.52      0.57      1010\n",
            "        4.0       0.50      0.69      0.58       982\n",
            "        5.0       0.60      0.04      0.08       892\n",
            "        6.0       0.53      0.83      0.65       958\n",
            "        7.0       0.85      0.66      0.75      1028\n",
            "        8.0       0.35      0.76      0.48       974\n",
            "        9.0       0.59      0.32      0.42      1009\n",
            "\n",
            "avg / total       0.63      0.58      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 909    2    1    2    0    3   41   13    9    0]\n",
            " [   0 1078    0   19    0    0    7    3   28    0]\n",
            " [  52  138   13    5  212    0  410   32  167    3]\n",
            " [  35   34    0  522   10    2   94   24  282    7]\n",
            " [   6   11    0   25  682    2    4    5  213   34]\n",
            " [ 163   58    0  127   81   37  106   14  261   45]\n",
            " [  21   34    0    4   60    2  794    6   35    2]\n",
            " [  64   24    2   16   61    9    8  681   39  124]\n",
            " [  13   83    0   23   59    4   34    5  744    9]\n",
            " [  46    9    0   77  192    3    2   17  338  325]]\n",
            "--------------------------------\n",
            "val predicted: (59720,) [0. 0. 0. ... 8. 3. 5.]\n",
            "probabilities: (59720, 10) \n",
            " [0 0 0 ... 8 3 5]\n",
            "trainset before (280, 784) (280,)\n",
            "trainset after (290, 784) (290,)\n",
            "updated train set: (290, 784) (290,) unique(labels): [ 14   7  18  24  15 114  12  32  36  18] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59710, 784) (59710,)\n",
            "\n",
            "Train set: (290, 784) y: (290,)\n",
            "Val   set: (59710, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 29\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.427 s \n",
            "\n",
            "Accuracy rate for 54.280000 \n",
            "Classification report for classifier LogisticRegression(C=0.1724137931034483, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.66      0.92      0.76       980\n",
            "        1.0       0.72      0.98      0.83      1135\n",
            "        2.0       0.61      0.04      0.08      1032\n",
            "        3.0       0.71      0.24      0.36      1010\n",
            "        4.0       0.49      0.64      0.56       982\n",
            "        5.0       0.44      0.05      0.09       892\n",
            "        6.0       0.48      0.84      0.61       958\n",
            "        7.0       0.84      0.64      0.73      1028\n",
            "        8.0       0.29      0.71      0.41       974\n",
            "        9.0       0.64      0.32      0.42      1009\n",
            "\n",
            "avg / total       0.59      0.54      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 898    2    4    0    5    2   58    1   10    0]\n",
            " [   0 1107    0    3    3    0    6    7    9    0]\n",
            " [  27  131   46    4  208    0  500   38   75    3]\n",
            " [  43   37    4  240    7   12  105   23  531    8]\n",
            " [   7   20    3    5  626    8    8    7  246   52]\n",
            " [ 159   48    6   38   67   44  123   16  374   17]\n",
            " [  18   30    3    0   48    3  803    4   46    3]\n",
            " [ 141   35    4   10   61   12    8  657   12   88]\n",
            " [  10  123    4    5   71    4   54    8  689    6]\n",
            " [  65   13    1   33  176   16    5   17  365  318]]\n",
            "--------------------------------\n",
            "val predicted: (59710,) [0. 0. 8. ... 8. 6. 5.]\n",
            "probabilities: (59710, 10) \n",
            " [0 0 8 ... 8 6 5]\n",
            "trainset before (290, 784) (290,)\n",
            "trainset after (300, 784) (300,)\n",
            "updated train set: (300, 784) (300,) unique(labels): [ 14   7  18  26  16 118  12  33  37  19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59700, 784) (59700,)\n",
            "\n",
            "Train set: (300, 784) y: (300,)\n",
            "Val   set: (59700, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 30\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.414 s \n",
            "\n",
            "Accuracy rate for 55.860000 \n",
            "Classification report for classifier LogisticRegression(C=0.16666666666666666, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.93      0.86       980\n",
            "        1.0       0.72      0.99      0.83      1135\n",
            "        2.0       0.28      0.36      0.32      1032\n",
            "        3.0       0.74      0.22      0.34      1010\n",
            "        4.0       0.53      0.81      0.64       982\n",
            "        5.0       0.51      0.06      0.10       892\n",
            "        6.0       0.57      0.81      0.67       958\n",
            "        7.0       0.92      0.52      0.67      1028\n",
            "        8.0       0.30      0.55      0.39       974\n",
            "        9.0       0.77      0.27      0.40      1009\n",
            "\n",
            "avg / total       0.62      0.56      0.53     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 915    2   12    0    1    2   39    2    7    0]\n",
            " [   0 1119    7    1    0    1    6    0    1    0]\n",
            " [  15  138  370    0  132    0  352    4   21    0]\n",
            " [  11   51  147  223   14    9   73    6  471    5]\n",
            " [   6   16   24    3  791    6    4    8  103   21]\n",
            " [  77   43  186   42   93   50   75   11  301   14]\n",
            " [  10   26   18    3   87    2  773    3   34    2]\n",
            " [  80   35  231    8   69   15   11  537    6   36]\n",
            " [   5  109  223    3   62    4   29    1  537    1]\n",
            " [  36   11   96   18  256   10    1   12  298  271]]\n",
            "--------------------------------\n",
            "val predicted: (59700,) [0. 0. 0. ... 8. 3. 3.]\n",
            "probabilities: (59700, 10) \n",
            " [0 0 0 ... 8 3 3]\n",
            "trainset before (300, 784) (300,)\n",
            "trainset after (310, 784) (310,)\n",
            "updated train set: (310, 784) (310,) unique(labels): [ 14   7  18  26  16 126  12  35  37  19] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59690, 784) (59690,)\n",
            "\n",
            "Train set: (310, 784) y: (310,)\n",
            "Val   set: (59690, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 31\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.395 s \n",
            "\n",
            "Accuracy rate for 57.430000 \n",
            "Classification report for classifier LogisticRegression(C=0.16129032258064516, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.82      0.93      0.87       980\n",
            "        1.0       0.49      0.99      0.65      1135\n",
            "        2.0       0.86      0.02      0.05      1032\n",
            "        3.0       0.76      0.27      0.40      1010\n",
            "        4.0       0.51      0.74      0.61       982\n",
            "        5.0       0.57      0.11      0.19       892\n",
            "        6.0       0.52      0.78      0.63       958\n",
            "        7.0       0.81      0.71      0.75      1028\n",
            "        8.0       0.39      0.55      0.46       974\n",
            "        9.0       0.63      0.57      0.60      1009\n",
            "\n",
            "avg / total       0.64      0.57      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 907    2    0    0    3    3   43   10   10    2]\n",
            " [   0 1124    0    1    0    1    3    6    0    0]\n",
            " [  31  265   24    2  233    0  378   54   36    9]\n",
            " [   8  346    0  274   11   23   83   36  221    8]\n",
            " [   3   42    0    6  728   10    1    6   58  128]\n",
            " [  66   84    0   47  106  102  143   22  272   50]\n",
            " [  13   61    1    2   88    1  749   12   27    4]\n",
            " [  37   55    2    3   69   14    2  727    8  111]\n",
            " [   9  302    1    5   56    4   33    7  536   21]\n",
            " [  26   30    0   22  122   21    2   22  192  572]]\n",
            "--------------------------------\n",
            "val predicted: (59690,) [0. 0. 0. ... 9. 9. 5.]\n",
            "probabilities: (59690, 10) \n",
            " [0 0 0 ... 9 9 5]\n",
            "trainset before (310, 784) (310,)\n",
            "trainset after (320, 784) (320,)\n",
            "updated train set: (320, 784) (320,) unique(labels): [ 14   7  19  30  16 128  12  35  39  20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59680, 784) (59680,)\n",
            "\n",
            "Train set: (320, 784) y: (320,)\n",
            "Val   set: (59680, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 32\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.402 s \n",
            "\n",
            "Accuracy rate for 47.570000 \n",
            "Classification report for classifier LogisticRegression(C=0.15625, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.96      0.82       980\n",
            "        1.0       0.28      0.99      0.44      1135\n",
            "        2.0       0.80      0.07      0.13      1032\n",
            "        3.0       0.53      0.23      0.32      1010\n",
            "        4.0       0.58      0.55      0.56       982\n",
            "        5.0       0.44      0.06      0.10       892\n",
            "        6.0       0.58      0.54      0.56       958\n",
            "        7.0       0.84      0.64      0.73      1028\n",
            "        8.0       0.21      0.13      0.16       974\n",
            "        9.0       0.59      0.49      0.53      1009\n",
            "\n",
            "avg / total       0.56      0.48      0.44     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 943    8    0    1    2    2   15    7    0    2]\n",
            " [   0 1129    0    4    0    0    0    2    0    0]\n",
            " [  75  399   71   16  103    2  300   39   16   11]\n",
            " [   9  697    1  228    1    1    9   13   47    4]\n",
            " [  13  140    3   10  538   15    2    9   97  155]\n",
            " [ 154  358    0   75   35   53   36   15  146   20]\n",
            " [  36  250    5    8  109    4  515   19    9    3]\n",
            " [  43   94    3   42   37    8    0  659    3  139]\n",
            " [  23  734    6    9   39    9    8    3  129   14]\n",
            " [  37  171    0   34   60   27    1   18  169  492]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59680,) [0. 0. 0. ... 8. 7. 5.]\n",
            "probabilities: (59680, 10) \n",
            " [0 0 0 ... 8 7 5]\n",
            "trainset before (320, 784) (320,)\n",
            "trainset after (330, 784) (330,)\n",
            "updated train set: (330, 784) (330,) unique(labels): [ 14   7  27  30  16 130  12  35  39  20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59670, 784) (59670,)\n",
            "\n",
            "Train set: (330, 784) y: (330,)\n",
            "Val   set: (59670, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 33\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.490 s \n",
            "\n",
            "Accuracy rate for 53.480000 \n",
            "Classification report for classifier LogisticRegression(C=0.15151515151515152, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.68      0.86      0.76       980\n",
            "        1.0       0.71      0.98      0.82      1135\n",
            "        2.0       0.62      0.07      0.13      1032\n",
            "        3.0       0.51      0.31      0.38      1010\n",
            "        4.0       0.52      0.67      0.59       982\n",
            "        5.0       0.30      0.02      0.04       892\n",
            "        6.0       0.43      0.82      0.57       958\n",
            "        7.0       0.87      0.52      0.65      1028\n",
            "        8.0       0.30      0.67      0.42       974\n",
            "        9.0       0.65      0.36      0.46      1009\n",
            "\n",
            "avg / total       0.57      0.53      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 840    2    2    3   14    2  107    2    8    0]\n",
            " [   0 1111    0   11    0    0    8    1    4    0]\n",
            " [  22  130   77   11  155    1  568   25   40    3]\n",
            " [  10   42   14  309    5    5   98    7  515    5]\n",
            " [   7   26    1   14  659    4   16    4  179   72]\n",
            " [ 104   39    7  102   72   18  145   14  370   21]\n",
            " [  10   25    0    1   72    1  787    5   55    2]\n",
            " [ 187   39    7   82   70    8   12  537   10   76]\n",
            " [   6  144   11   21   37   10   74    5  650   16]\n",
            " [  47   13    6   48  175   12    8   14  326  360]]\n",
            "--------------------------------\n",
            "val predicted: (59670,) [0. 0. 8. ... 8. 8. 5.]\n",
            "probabilities: (59670, 10) \n",
            " [0 0 8 ... 8 8 5]\n",
            "trainset before (330, 784) (330,)\n",
            "trainset after (340, 784) (340,)\n",
            "updated train set: (340, 784) (340,) unique(labels): [ 15   7  30  33  16 131  12  35  41  20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59660, 784) (59660,)\n",
            "\n",
            "Train set: (340, 784) y: (340,)\n",
            "Val   set: (59660, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 34\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.422 s \n",
            "\n",
            "Accuracy rate for 55.210000 \n",
            "Classification report for classifier LogisticRegression(C=0.14705882352941177, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.73      0.87      0.79       980\n",
            "        1.0       0.86      0.72      0.78      1135\n",
            "        2.0       0.53      0.16      0.25      1032\n",
            "        3.0       0.51      0.52      0.52      1010\n",
            "        4.0       0.56      0.63      0.59       982\n",
            "        5.0       0.37      0.06      0.10       892\n",
            "        6.0       0.45      0.75      0.56       958\n",
            "        7.0       0.82      0.59      0.68      1028\n",
            "        8.0       0.33      0.73      0.46       974\n",
            "        9.0       0.57      0.46      0.51      1009\n",
            "\n",
            "avg / total       0.58      0.55      0.53     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[852   0   0   0   1  15  70  17  20   5]\n",
            " [  0 817  24 147   7   0  56   4  80   0]\n",
            " [ 56  43 169   8 116   3 546  29  56   6]\n",
            " [  9   4   9 528   5   4  67  11 370   3]\n",
            " [ 29   2   3  12 618   9  11   6 210  82]\n",
            " [ 80  28   4 173  54  50  85  24 354  40]\n",
            " [ 53  14   3   3 101   3 714  15  50   2]\n",
            " [ 24   9  39  53  54  19   4 604  20 202]\n",
            " [ 16  30  60  55  25  10  49  10 708  11]\n",
            " [ 51   2   8  57 121  23   1  20 265 461]]\n",
            "--------------------------------\n",
            "val predicted: (59660,) [0. 0. 8. ... 8. 7. 5.]\n",
            "probabilities: (59660, 10) \n",
            " [0 0 8 ... 8 7 5]\n",
            "trainset before (340, 784) (340,)\n",
            "trainset after (350, 784) (350,)\n",
            "updated train set: (350, 784) (350,) unique(labels): [ 16  10  31  33  17 131  14  36  42  20] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59650, 784) (59650,)\n",
            "\n",
            "Train set: (350, 784) y: (350,)\n",
            "Val   set: (59650, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 35\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.406 s \n",
            "\n",
            "Accuracy rate for 53.320000 \n",
            "Classification report for classifier LogisticRegression(C=0.14285714285714285, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.71      0.93      0.81       980\n",
            "        1.0       0.61      0.98      0.75      1135\n",
            "        2.0       0.69      0.19      0.30      1032\n",
            "        3.0       0.46      0.59      0.52      1010\n",
            "        4.0       0.37      0.79      0.50       982\n",
            "        5.0       0.48      0.14      0.21       892\n",
            "        6.0       0.62      0.71      0.67       958\n",
            "        7.0       0.92      0.23      0.37      1028\n",
            "        8.0       0.43      0.43      0.43       974\n",
            "        9.0       0.44      0.28      0.34      1009\n",
            "\n",
            "avg / total       0.58      0.53      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 913    3    1    4    3   12   37    1    1    5]\n",
            " [   0 1107    8    9    2    0    3    0    6    0]\n",
            " [  58  163  199   29  302    5  265    3    5    3]\n",
            " [  30  160    5  596   34   12   22    5  143    3]\n",
            " [   9   29    0   36  772   10    2    0   58   66]\n",
            " [ 116   68    0  193   97  121   53    7  206   31]\n",
            " [  14   37    4   14  161   17  684    1   19    7]\n",
            " [  94   39   20  204  149   35    2  239    3  243]\n",
            " [  24  202   46   52  171   26   26    2  421    4]\n",
            " [  19   21    7  155  388   15    2    1  121  280]]\n",
            "--------------------------------\n",
            "val predicted: (59650,) [0. 0. 0. ... 4. 3. 5.]\n",
            "probabilities: (59650, 10) \n",
            " [0 0 0 ... 4 3 5]\n",
            "trainset before (350, 784) (350,)\n",
            "trainset after (360, 784) (360,)\n",
            "updated train set: (360, 784) (360,) unique(labels): [ 16  10  33  33  20 133  14  38  42  21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59640, 784) (59640,)\n",
            "\n",
            "Train set: (360, 784) y: (360,)\n",
            "Val   set: (59640, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 36\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.425 s \n",
            "\n",
            "Accuracy rate for 54.980000 \n",
            "Classification report for classifier LogisticRegression(C=0.1388888888888889, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.66      0.89      0.76       980\n",
            "        1.0       0.55      0.98      0.71      1135\n",
            "        2.0       0.36      0.09      0.14      1032\n",
            "        3.0       0.60      0.56      0.58      1010\n",
            "        4.0       0.47      0.61      0.53       982\n",
            "        5.0       0.35      0.15      0.21       892\n",
            "        6.0       0.48      0.87      0.62       958\n",
            "        7.0       0.94      0.54      0.69      1028\n",
            "        8.0       0.60      0.28      0.38       974\n",
            "        9.0       0.46      0.44      0.45      1009\n",
            "\n",
            "avg / total       0.55      0.55      0.51     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 873    3    0    1   24    4   63    1    4    7]\n",
            " [   0 1111   13    3    0    0    5    1    2    0]\n",
            " [  67  154   91    4  210    4  487   12    1    2]\n",
            " [  46  224   15  569   15   19   55   10   51    6]\n",
            " [   5   39    2   23  599   42   18    1   11  242]\n",
            " [ 178   91    6  138   32  136  118    7   65  121]\n",
            " [  17   31    3    7   26   17  836    0    8   13]\n",
            " [  58   44   63   46   59   35   65  560    9   89]\n",
            " [  60  280   57   86   11   64   92    1  276   47]\n",
            " [  20   33    6   78  299   71   15    5   35  447]]\n",
            "--------------------------------\n",
            "val predicted: (59640,) [0. 0. 0. ... 9. 9. 5.]\n",
            "probabilities: (59640, 10) \n",
            " [0 0 0 ... 9 9 5]\n",
            "trainset before (360, 784) (360,)\n",
            "trainset after (370, 784) (370,)\n",
            "updated train set: (370, 784) (370,) unique(labels): [ 16  10  36  34  20 139  14  38  42  21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59630, 784) (59630,)\n",
            "\n",
            "Train set: (370, 784) y: (370,)\n",
            "Val   set: (59630, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 37\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.451 s \n",
            "\n",
            "Accuracy rate for 52.510000 \n",
            "Classification report for classifier LogisticRegression(C=0.13513513513513514, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.63      0.94      0.75       980\n",
            "        1.0       0.58      0.98      0.73      1135\n",
            "        2.0       0.57      0.17      0.27      1032\n",
            "        3.0       0.45      0.28      0.35      1010\n",
            "        4.0       0.52      0.64      0.57       982\n",
            "        5.0       0.29      0.08      0.12       892\n",
            "        6.0       0.59      0.85      0.69       958\n",
            "        7.0       0.95      0.37      0.53      1028\n",
            "        8.0       0.32      0.63      0.42       974\n",
            "        9.0       0.52      0.25      0.33      1009\n",
            "\n",
            "avg / total       0.55      0.53      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 926    3    0    1    4    3   31    0   11    1]\n",
            " [   0 1108    9    9    0    0    3    0    6    0]\n",
            " [ 125  161  180    5  165    3  346    6   40    1]\n",
            " [  97  198    9  284    4   10   31    5  369    3]\n",
            " [  13   45    0   20  626   24   14    1  158   81]\n",
            " [ 168   78    3   83   31   69   61    4  376   19]\n",
            " [  30   34    2    1   21   11  812    0   45    2]\n",
            " [  55   44   83  155   74   64   38  380   18  117]\n",
            " [  40  207   28   19    6   13   36    2  618    5]\n",
            " [  25   41    3   58  272   40    9    1  312  248]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59630,) [0. 0. 8. ... 8. 3. 5.]\n",
            "probabilities: (59630, 10) \n",
            " [0 0 8 ... 8 3 5]\n",
            "trainset before (370, 784) (370,)\n",
            "trainset after (380, 784) (380,)\n",
            "updated train set: (380, 784) (380,) unique(labels): [ 16  10  38  34  20 144  14  38  45  21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59620, 784) (59620,)\n",
            "\n",
            "Train set: (380, 784) y: (380,)\n",
            "Val   set: (59620, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 38\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.427 s \n",
            "\n",
            "Accuracy rate for 54.390000 \n",
            "Classification report for classifier LogisticRegression(C=0.13157894736842105, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.59      0.95      0.73       980\n",
            "        1.0       0.58      0.96      0.73      1135\n",
            "        2.0       0.39      0.34      0.36      1032\n",
            "        3.0       0.61      0.42      0.50      1010\n",
            "        4.0       0.55      0.61      0.58       982\n",
            "        5.0       0.34      0.13      0.19       892\n",
            "        6.0       0.58      0.84      0.68       958\n",
            "        7.0       0.93      0.43      0.59      1028\n",
            "        8.0       0.32      0.37      0.34       974\n",
            "        9.0       0.59      0.32      0.41      1009\n",
            "\n",
            "avg / total       0.55      0.54      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 928    3    0    0    3    5   37    0    4    0]\n",
            " [   0 1090   33    2    0    1    3    1    5    0]\n",
            " [  77  129  348    5  137    4  318   10    4    0]\n",
            " [  99  209   35  424    4   17   50    6  165    1]\n",
            " [   9   41   44   18  603   53   15    0   58  141]\n",
            " [ 205   76   17   94   33  120   91    9  235   12]\n",
            " [  23   32   33    5   28   19  807    1    9    1]\n",
            " [ 159   41   87   49   33   45   23  441   86   64]\n",
            " [  46  206  252   39    8   20   41    1  356    5]\n",
            " [  29   38   41   64  252   65   14    5  179  322]]\n",
            "--------------------------------\n",
            "val predicted: (59620,) [0. 0. 0. ... 8. 6. 5.]\n",
            "probabilities: (59620, 10) \n",
            " [0 0 0 ... 8 6 5]\n",
            "trainset before (380, 784) (380,)\n",
            "trainset after (390, 784) (390,)\n",
            "updated train set: (390, 784) (390,) unique(labels): [ 16  10  38  36  20 148  15  38  48  21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59610, 784) (59610,)\n",
            "\n",
            "Train set: (390, 784) y: (390,)\n",
            "Val   set: (59610, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 39\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.439 s \n",
            "\n",
            "Accuracy rate for 55.890000 \n",
            "Classification report for classifier LogisticRegression(C=0.1282051282051282, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.69      0.92      0.78       980\n",
            "        1.0       0.63      0.96      0.76      1135\n",
            "        2.0       0.61      0.20      0.30      1032\n",
            "        3.0       0.46      0.40      0.43      1010\n",
            "        4.0       0.49      0.59      0.54       982\n",
            "        5.0       0.23      0.05      0.08       892\n",
            "        6.0       0.57      0.86      0.68       958\n",
            "        7.0       0.92      0.63      0.75      1028\n",
            "        8.0       0.36      0.65      0.46       974\n",
            "        9.0       0.57      0.25      0.35      1009\n",
            "\n",
            "avg / total       0.56      0.56      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 897    3    0    0   13    3   53    1    8    2]\n",
            " [   0 1094   16    9    0    0    8    3    5    0]\n",
            " [  69  123  208    8  191    1  383   15   32    2]\n",
            " [  86  153    9  402    5    6   40   12  295    2]\n",
            " [  11   35    9   43  584   31   11    0  182   76]\n",
            " [ 128   66    6  170   36   43   78   12  339   14]\n",
            " [  19   26    3   10   40    4  821    1   31    3]\n",
            " [  50   39   41   47   39   51   11  651   14   85]\n",
            " [  29  160   33   49    9   10   36    3  637    8]\n",
            " [  18   27   16  142  276   38    7    6  227  252]]\n",
            "--------------------------------\n",
            "val predicted: (59610,) [0. 0. 0. ... 8. 3. 3.]\n",
            "probabilities: (59610, 10) \n",
            " [0 0 0 ... 8 3 3]\n",
            "trainset before (390, 784) (390,)\n",
            "trainset after (400, 784) (400,)\n",
            "updated train set: (400, 784) (400,) unique(labels): [ 16  10  39  36  20 154  16  38  50  21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59600, 784) (59600,)\n",
            "\n",
            "Train set: (400, 784) y: (400,)\n",
            "Val   set: (59600, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 40\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.469 s \n",
            "\n",
            "Accuracy rate for 54.610000 \n",
            "Classification report for classifier LogisticRegression(C=0.125, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.64      0.93      0.76       980\n",
            "        1.0       0.56      0.97      0.71      1135\n",
            "        2.0       0.62      0.34      0.44      1032\n",
            "        3.0       0.51      0.38      0.43      1010\n",
            "        4.0       0.43      0.67      0.52       982\n",
            "        5.0       0.28      0.11      0.15       892\n",
            "        6.0       0.75      0.61      0.67       958\n",
            "        7.0       0.90      0.64      0.75      1028\n",
            "        8.0       0.35      0.60      0.44       974\n",
            "        9.0       0.53      0.14      0.22      1009\n",
            "\n",
            "avg / total       0.56      0.55      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 916    3    1    0   30    7   12    2    8    1]\n",
            " [   0 1103   21    4    0    1    1    0    5    0]\n",
            " [ 108  182  347    8  200    6  119   27   34    1]\n",
            " [  79  211    8  381    5   26   14   11  274    1]\n",
            " [  12   40    8   33  655   43    2    0  118   71]\n",
            " [ 139   80   19  139   43   95   22   15  332    8]\n",
            " [  44   56   26    9  155   31  581    4   38   14]\n",
            " [  75   43   58   41   47   57    2  663   18   24]\n",
            " [  22  218   63   26   17   20   24    1  582    1]\n",
            " [  27   40   12  104  371   50    0   11  256  138]]\n",
            "--------------------------------\n",
            "val predicted: (59600,) [0. 0. 0. ... 8. 3. 3.]\n",
            "probabilities: (59600, 10) \n",
            " [0 0 0 ... 8 3 3]\n",
            "trainset before (400, 784) (400,)\n",
            "trainset after (410, 784) (410,)\n",
            "updated train set: (410, 784) (410,) unique(labels): [ 16  10  40  37  22 158  17  38  51  21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59590, 784) (59590,)\n",
            "\n",
            "Train set: (410, 784) y: (410,)\n",
            "Val   set: (59590, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 41\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.439 s \n",
            "\n",
            "Accuracy rate for 55.690000 \n",
            "Classification report for classifier LogisticRegression(C=0.12195121951219512, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.59      0.97      0.74       980\n",
            "        1.0       0.54      0.97      0.69      1135\n",
            "        2.0       0.56      0.37      0.44      1032\n",
            "        3.0       0.58      0.35      0.43      1010\n",
            "        4.0       0.52      0.46      0.49       982\n",
            "        5.0       0.29      0.15      0.20       892\n",
            "        6.0       0.82      0.63      0.71       958\n",
            "        7.0       0.93      0.61      0.74      1028\n",
            "        8.0       0.36      0.49      0.41       974\n",
            "        9.0       0.50      0.49      0.50      1009\n",
            "\n",
            "avg / total       0.57      0.56      0.54     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 952    3    0    1    3    8   10    0    3    0]\n",
            " [   0 1103   23    2    0    1    1    1    4    0]\n",
            " [ 123  181  382   10  169    6   87   17   53    4]\n",
            " [ 125  266    6  349    9   16    3    9  223    4]\n",
            " [   9   46   18   18  453   83    3    1   82  269]\n",
            " [ 203   92   21  110   18  134   14    8  251   41]\n",
            " [  53   49   56   21   51   56  601    1   34   36]\n",
            " [  57   42   44   27   22   54    8  627   31  116]\n",
            " [  47  233  129   25   10   27    8    4  476   15]\n",
            " [  34   38    9   43  138   83    1    3  168  492]]\n",
            "--------------------------------\n",
            "val predicted: (59590,) [0. 0. 0. ... 8. 5. 5.]\n",
            "probabilities: (59590, 10) \n",
            " [0 0 0 ... 8 5 5]\n",
            "trainset before (410, 784) (410,)\n",
            "trainset after (420, 784) (420,)\n",
            "updated train set: (420, 784) (420,) unique(labels): [ 16  10  44  39  22 162  17  38  51  21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59580, 784) (59580,)\n",
            "\n",
            "Train set: (420, 784) y: (420,)\n",
            "Val   set: (59580, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 42\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.437 s \n",
            "\n",
            "Accuracy rate for 54.510000 \n",
            "Classification report for classifier LogisticRegression(C=0.11904761904761904, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.51      0.98      0.67       980\n",
            "        1.0       0.54      0.96      0.70      1135\n",
            "        2.0       0.67      0.28      0.39      1032\n",
            "        3.0       0.41      0.48      0.44      1010\n",
            "        4.0       0.47      0.58      0.52       982\n",
            "        5.0       0.29      0.13      0.18       892\n",
            "        6.0       0.85      0.59      0.70       958\n",
            "        7.0       0.87      0.61      0.72      1028\n",
            "        8.0       0.47      0.49      0.48       974\n",
            "        9.0       0.54      0.26      0.35      1009\n",
            "\n",
            "avg / total       0.57      0.55      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 961    3    0    1    2    3    9    0    0    1]\n",
            " [   0 1094    8   28    0    1    0    0    4    0]\n",
            " [ 192  181  287   54  193    5   49   35   34    2]\n",
            " [ 122  236    5  485   14   17    4    9  116    2]\n",
            " [  14   38    7   69  572   67    2    9   63  141]\n",
            " [ 290   91    4  148   32  119   14    8  152   34]\n",
            " [  84   43   19   30  127   52  570    5   18   10]\n",
            " [ 134   39   33   69   27   48    5  629   24   20]\n",
            " [  50  250   51   83   12   22   17    5  474   10]\n",
            " [  32   34   16  206  246   76    1   25  113  260]]\n",
            "--------------------------------\n",
            "val predicted: (59580,) [0. 0. 0. ... 8. 3. 3.]\n",
            "probabilities: (59580, 10) \n",
            " [0 0 0 ... 8 3 3]\n",
            "trainset before (420, 784) (420,)\n",
            "trainset after (430, 784) (430,)\n",
            "updated train set: (430, 784) (430,) unique(labels): [ 16  10  46  42  22 167  17  38  51  21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59570, 784) (59570,)\n",
            "\n",
            "Train set: (430, 784) y: (430,)\n",
            "Val   set: (59570, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 43\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.496 s \n",
            "\n",
            "Accuracy rate for 52.560000 \n",
            "Classification report for classifier LogisticRegression(C=0.11627906976744186, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.55      0.93      0.69       980\n",
            "        1.0       0.47      0.98      0.63      1135\n",
            "        2.0       0.65      0.21      0.32      1032\n",
            "        3.0       0.45      0.20      0.27      1010\n",
            "        4.0       0.44      0.58      0.50       982\n",
            "        5.0       0.25      0.09      0.13       892\n",
            "        6.0       0.75      0.68      0.71       958\n",
            "        7.0       0.85      0.68      0.76      1028\n",
            "        8.0       0.38      0.49      0.43       974\n",
            "        9.0       0.55      0.32      0.41      1009\n",
            "\n",
            "avg / total       0.54      0.53      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 916    4    4    2   25    4   16    3    5    1]\n",
            " [   0 1117    7    1    0    1    1    6    2    0]\n",
            " [ 120  219  221    6  249    4  124   36   48    5]\n",
            " [ 189  387    5  197   14    6    7   16  185    4]\n",
            " [  10   50    3   27  569   57    7    9   72  178]\n",
            " [ 227  133    4   90   45   77   25   17  241   33]\n",
            " [  59   72   12   10  103   17  649    2   25    9]\n",
            " [  83   53   32    8   34   42   10  704   33   29]\n",
            " [  43  309   37   24   19   23   26    4  482    7]\n",
            " [  22   58   14   75  223   76    3   33  181  324]]\n",
            "--------------------------------\n",
            "val predicted: (59570,) [0. 0. 0. ... 8. 3. 5.]\n",
            "probabilities: (59570, 10) \n",
            " [0 0 0 ... 8 3 5]\n",
            "trainset before (430, 784) (430,)\n",
            "trainset after (440, 784) (440,)\n",
            "updated train set: (440, 784) (440,) unique(labels): [ 16  10  50  44  22 169  18  39  51  21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59560, 784) (59560,)\n",
            "\n",
            "Train set: (440, 784) y: (440,)\n",
            "Val   set: (59560, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 44\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.442 s \n",
            "\n",
            "Accuracy rate for 53.660000 \n",
            "Classification report for classifier LogisticRegression(C=0.11363636363636363, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.51      0.94      0.66       980\n",
            "        1.0       0.54      0.96      0.69      1135\n",
            "        2.0       0.73      0.35      0.48      1032\n",
            "        3.0       0.51      0.27      0.35      1010\n",
            "        4.0       0.41      0.52      0.45       982\n",
            "        5.0       0.33      0.14      0.19       892\n",
            "        6.0       0.82      0.53      0.65       958\n",
            "        7.0       0.93      0.52      0.67      1028\n",
            "        8.0       0.43      0.57      0.49       974\n",
            "        9.0       0.47      0.47      0.47      1009\n",
            "\n",
            "avg / total       0.57      0.54      0.52     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 924    3    3    1   18    9   12    1    4    5]\n",
            " [   0 1091   22   16    0    1    0    0    5    0]\n",
            " [ 132  162  366   15  243    7   51   16   34    6]\n",
            " [ 174  271    8  274   17   22   12    6  222    4]\n",
            " [  21   41    1   19  507   37    0    1   62  293]\n",
            " [ 253   95    8   62   36  121   22   10  229   56]\n",
            " [  85   47   10    7  199   37  510    2   27   34]\n",
            " [ 127   41   44   44   30   56    2  539   34  111]\n",
            " [  62  219   39   20   20   23   12    1  560   18]\n",
            " [  49   41    2   76  179   58    2    6  122  474]]\n",
            "--------------------------------\n",
            "val predicted: (59560,) [0. 0. 0. ... 9. 3. 3.]\n",
            "probabilities: (59560, 10) \n",
            " [0 0 0 ... 9 3 3]\n",
            "trainset before (440, 784) (440,)\n",
            "trainset after (450, 784) (450,)\n",
            "updated train set: (450, 784) (450,) unique(labels): [ 16  10  53  45  22 172  19  39  53  21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59550, 784) (59550,)\n",
            "\n",
            "Train set: (450, 784) y: (450,)\n",
            "Val   set: (59550, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 45\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.450 s \n",
            "\n",
            "Accuracy rate for 56.090000 \n",
            "Classification report for classifier LogisticRegression(C=0.1111111111111111, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.53      0.97      0.69       980\n",
            "        1.0       0.57      0.97      0.72      1135\n",
            "        2.0       0.66      0.21      0.32      1032\n",
            "        3.0       0.54      0.39      0.45      1010\n",
            "        4.0       0.43      0.51      0.47       982\n",
            "        5.0       0.36      0.07      0.12       892\n",
            "        6.0       0.67      0.75      0.70       958\n",
            "        7.0       0.84      0.70      0.76      1028\n",
            "        8.0       0.50      0.43      0.46       974\n",
            "        9.0       0.47      0.53      0.50      1009\n",
            "\n",
            "avg / total       0.56      0.56      0.53     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 950    3    0    1   11    2   10    0    3    0]\n",
            " [   0 1097   15    8    0    1    2    8    4    0]\n",
            " [ 124  153  215    8  255    3  188   66   12    8]\n",
            " [ 154  221    8  398   19    8   27   21  148    6]\n",
            " [  21   36    0   29  499   32    4    4   20  337]\n",
            " [ 270   81   11  129   37   66   54   17  137   90]\n",
            " [  44   38    3   15   78    9  714    1    6   50]\n",
            " [ 113   40   18    8   30   13    3  721   12   70]\n",
            " [  62  218   55   67   32   18   65    5  419   33]\n",
            " [  40   31    2   80  197   31    1   17   80  530]]\n",
            "--------------------------------\n",
            "val predicted: (59550,) [0. 0. 0. ... 9. 3. 5.]\n",
            "probabilities: (59550, 10) \n",
            " [0 0 0 ... 9 3 5]\n",
            "trainset before (450, 784) (450,)\n",
            "trainset after (460, 784) (460,)\n",
            "updated train set: (460, 784) (460,) unique(labels): [ 16  10  55  46  22 177  19  40  54  21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59540, 784) (59540,)\n",
            "\n",
            "Train set: (460, 784) y: (460,)\n",
            "Val   set: (59540, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 46\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.446 s \n",
            "\n",
            "Accuracy rate for 54.230000 \n",
            "Classification report for classifier LogisticRegression(C=0.10869565217391304, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.54      0.95      0.69       980\n",
            "        1.0       0.56      0.97      0.71      1135\n",
            "        2.0       0.69      0.18      0.28      1032\n",
            "        3.0       0.65      0.25      0.36      1010\n",
            "        4.0       0.42      0.41      0.42       982\n",
            "        5.0       0.35      0.22      0.27       892\n",
            "        6.0       0.64      0.75      0.69       958\n",
            "        7.0       0.89      0.58      0.70      1028\n",
            "        8.0       0.42      0.55      0.48       974\n",
            "        9.0       0.47      0.50      0.48      1009\n",
            "\n",
            "avg / total       0.57      0.54      0.51     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 931    3    0    1   31    2   10    0    2    0]\n",
            " [   0 1100   17    7    0    1    2    5    3    0]\n",
            " [ 120  154  185    2  252    3  255   36   17    8]\n",
            " [ 160  256    6  254   13   24   33   11  245    8]\n",
            " [  12   41    1   11  402   92    4    1   45  373]\n",
            " [ 216   90    3   46   27  197   50    6  235   22]\n",
            " [  69   29    3    6   55   40  714    1   15   26]\n",
            " [ 147   42   20   11   18   44    2  599   16  129]\n",
            " [  40  211   35   15   24   46   48    6  534   15]\n",
            " [  33   28    0   38  125  110    1    8  159  507]]\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "val predicted: (59540,) [0. 0. 0. ... 9. 3. 5.]\n",
            "probabilities: (59540, 10) \n",
            " [0 0 0 ... 9 3 5]\n",
            "trainset before (460, 784) (460,)\n",
            "trainset after (470, 784) (470,)\n",
            "updated train set: (470, 784) (470,) unique(labels): [ 16  10  55  47  22 183  19  41  56  21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59530, 784) (59530,)\n",
            "\n",
            "Train set: (470, 784) y: (470,)\n",
            "Val   set: (59530, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 47\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.512 s \n",
            "\n",
            "Accuracy rate for 51.770000 \n",
            "Classification report for classifier LogisticRegression(C=0.10638297872340426, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.50      0.95      0.65       980\n",
            "        1.0       0.48      0.97      0.64      1135\n",
            "        2.0       0.60      0.26      0.36      1032\n",
            "        3.0       0.43      0.14      0.21      1010\n",
            "        4.0       0.46      0.54      0.50       982\n",
            "        5.0       0.33      0.05      0.09       892\n",
            "        6.0       0.72      0.72      0.72       958\n",
            "        7.0       0.91      0.53      0.67      1028\n",
            "        8.0       0.37      0.50      0.42       974\n",
            "        9.0       0.49      0.44      0.46      1009\n",
            "\n",
            "avg / total       0.53      0.52      0.48     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 931    3    9    1   18    0   10    0    4    4]\n",
            " [   0 1099   22    9    0    0    0    4    1    0]\n",
            " [ 136  180  268    6  228    3  158   31   17    5]\n",
            " [ 237  376   12  142   13    2   10    8  203    7]\n",
            " [  11   50    2   22  531   19   11    0   93  243]\n",
            " [ 275  115   13   54   44   44   43    7  270   27]\n",
            " [  58   68    5   11   83    5  690    1   20   17]\n",
            " [ 142   49   38   20   34   25    5  543   28  144]\n",
            " [  47  281   68   18   15   11   26    1  489   18]\n",
            " [  30   53    9   45  187   25    4    3  213  440]]\n",
            "--------------------------------\n",
            "val predicted: (59530,) [0. 0. 0. ... 8. 3. 3.]\n",
            "probabilities: (59530, 10) \n",
            " [0 0 0 ... 8 3 3]\n",
            "trainset before (470, 784) (470,)\n",
            "trainset after (480, 784) (480,)\n",
            "updated train set: (480, 784) (480,) unique(labels): [ 16  10  60  47  22 186  19  43  56  21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59520, 784) (59520,)\n",
            "\n",
            "Train set: (480, 784) y: (480,)\n",
            "Val   set: (59520, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 48\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.516 s \n",
            "\n",
            "Accuracy rate for 52.630000 \n",
            "Classification report for classifier LogisticRegression(C=0.10416666666666667, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.70      0.92      0.80       980\n",
            "        1.0       0.53      0.97      0.68      1135\n",
            "        2.0       0.65      0.21      0.32      1032\n",
            "        3.0       0.59      0.17      0.27      1010\n",
            "        4.0       0.39      0.51      0.44       982\n",
            "        5.0       0.39      0.09      0.14       892\n",
            "        6.0       0.65      0.67      0.66       958\n",
            "        7.0       0.76      0.74      0.75      1028\n",
            "        8.0       0.32      0.59      0.41       974\n",
            "        9.0       0.45      0.30      0.36      1009\n",
            "\n",
            "avg / total       0.54      0.53      0.49     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 898    3    0    1   36    0   32    4    4    2]\n",
            " [   0 1105   13    7    0    0    3    5    2    0]\n",
            " [  77  177  221    6  271    3  161   69   43    4]\n",
            " [  50  314   31  173   14    6   17   59  342    4]\n",
            " [   8   39    1    9  505   21    8   21  132  238]\n",
            " [ 122  103   24   47   40   78   58   33  357   30]\n",
            " [  25   43    4    5  132   31  639    7   26   46]\n",
            " [  66   45   13    9   26   16   15  762   31   45]\n",
            " [  20  229   32   14   28   11   52    2  578    8]\n",
            " [   9   38    1   21  238   34    5   43  316  304]]\n",
            "--------------------------------\n",
            "val predicted: (59520,) [0. 0. 0. ... 8. 3. 5.]\n",
            "probabilities: (59520, 10) \n",
            " [0 0 0 ... 8 3 5]\n",
            "trainset before (480, 784) (480,)\n",
            "trainset after (490, 784) (490,)\n",
            "updated train set: (490, 784) (490,) unique(labels): [ 16  10  63  48  22 187  22  43  58  21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59510, 784) (59510,)\n",
            "\n",
            "Train set: (490, 784) y: (490,)\n",
            "Val   set: (59510, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n",
            "--------------------------------\n",
            "Iteration: 49\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.459 s \n",
            "\n",
            "Accuracy rate for 55.000000 \n",
            "Classification report for classifier LogisticRegression(C=0.10204081632653061, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.67      0.92      0.77       980\n",
            "        1.0       0.62      0.97      0.76      1135\n",
            "        2.0       0.66      0.28      0.40      1032\n",
            "        3.0       0.63      0.10      0.17      1010\n",
            "        4.0       0.41      0.47      0.44       982\n",
            "        5.0       0.33      0.11      0.17       892\n",
            "        6.0       0.67      0.62      0.64       958\n",
            "        7.0       0.85      0.75      0.79      1028\n",
            "        8.0       0.34      0.69      0.45       974\n",
            "        9.0       0.47      0.51      0.49      1009\n",
            "\n",
            "avg / total       0.57      0.55      0.51     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 906    3    4    0   30    1   16    3    9    8]\n",
            " [   0 1104   13    3    0    1    1    7    6    0]\n",
            " [  65  150  291    2  252    5  153   54   49   11]\n",
            " [ 156  178   14   99   11   10   25   23  484   10]\n",
            " [   3   31    8    3  462   52    5    4   79  335]\n",
            " [ 143   72   30   29   28   99   38   21  390   42]\n",
            " [  31   29   23    0  152   35  591    3   44   50]\n",
            " [  19   40   22    3   25   26    7  766   23   97]\n",
            " [  25  148   32    8   11   13   41    3  668   25]\n",
            " [  14   30    2   11  147   61    2   16  212  514]]\n",
            "--------------------------------\n",
            "val predicted: (59510,) [0. 0. 0. ... 8. 5. 5.]\n",
            "probabilities: (59510, 10) \n",
            " [0 0 0 ... 8 5 5]\n",
            "trainset before (490, 784) (490,)\n",
            "trainset after (500, 784) (500,)\n",
            "updated train set: (500, 784) (500,) unique(labels): [ 16  11  65  52  22 189  22  43  59  21] [0 1 2 3 4 5 6 7 8 9]\n",
            "val set: (59500, 784) (59500,)\n",
            "\n",
            "Train set: (500, 784) y: (500,)\n",
            "Val   set: (59500, 784)\n",
            "Test  set: (10000, 784)\n",
            "training multinomial logistic regression\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Iteration: 50\n",
            "--------------------------------\n",
            "y-test set: (10000,)\n",
            "Example run in 0.560 s \n",
            "\n",
            "Accuracy rate for 48.970000 \n",
            "Classification report for classifier LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
            "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
            "          multi_class='multinomial', n_jobs=1, penalty='l1',\n",
            "          random_state=None, solver='saga', tol=0.1, verbose=0,\n",
            "          warm_start=False):\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.51      0.96      0.66       980\n",
            "        1.0       0.43      1.00      0.60      1135\n",
            "        2.0       0.61      0.18      0.28      1032\n",
            "        3.0       0.54      0.10      0.17      1010\n",
            "        4.0       0.45      0.49      0.47       982\n",
            "        5.0       0.24      0.07      0.11       892\n",
            "        6.0       0.71      0.64      0.68       958\n",
            "        7.0       0.91      0.59      0.72      1028\n",
            "        8.0       0.31      0.49      0.38       974\n",
            "        9.0       0.47      0.30      0.37      1009\n",
            "\n",
            "avg / total       0.52      0.49      0.45     10000\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[ 937    4    0    0   20    1   12    0    5    1]\n",
            " [   0 1130    0    1    0    1    2    0    1    0]\n",
            " [ 165  281  185    4  205    4  118   29   36    5]\n",
            " [ 191  443    6  101    7    7   18    6  227    4]\n",
            " [  14   76   12   10  483   43   10    5  132  197]\n",
            " [ 231  114   44   23   26   64   43    8  321   18]\n",
            " [ 103   62   13    2   90   23  613    0   24   28]\n",
            " [ 124   75   15   11   30   57   10  608   22   76]\n",
            " [  51  344   26   11    9   16   30    1  474   12]\n",
            " [  30   95    3   23  204   54    2   11  285  302]]\n",
            "--------------------------------\n",
            "final active learning accuracies [36.620000000000005, 46.79, 47.49, 49.96, 51.59, 54.25, 49.43, 55.510000000000005, 52.88, 50.89, 53.04, 52.42, 52.410000000000004, 50.949999999999996, 48.699999999999996, 48.89, 51.160000000000004, 47.68, 46.1, 48.91, 50.739999999999995, 53.080000000000005, 54.790000000000006, 50.88, 53.790000000000006, 56.05, 54.06999999999999, 57.85, 54.279999999999994, 55.86, 57.43000000000001, 47.57, 53.480000000000004, 55.21, 53.32, 54.98, 52.51, 54.39000000000001, 55.88999999999999, 54.61, 55.69, 54.510000000000005, 52.559999999999995, 53.66, 56.089999999999996, 54.230000000000004, 51.77, 52.629999999999995, 55.00000000000001, 48.97]\n",
            "saved Active-learning-experiment-45.pkl /content ['datalab', 'Active-learning-experiment-32.pkl', '.forever', 'Active-learning-experiment-22.pkl', 'Active-learning-experiment-4.pkl', 'Active-learning-experiment-2.pkl', 'Active-learning-experiment-45.pkl', 'Active-learning-experiment-11.pkl', 'Active-learning-experiment-24.pkl', 'Active-learning-experiment-18.pkl', 'Active-learning-experiment-38.pkl', 'Active-learning-experiment-42.pkl', 'Active-learning-experiment-37.pkl', 'Active-learning-experiment-44.pkl', 'Active-learning-experiment-5.pkl', 'Active-learning-experiment-20.pkl', 'Active-learning-experiment-12.pkl', 'Active-learning-experiment-1.pkl', 'Active-learning-experiment-30.pkl', 'Active-learning-experiment-34.pkl', 'Active-learning-experiment-6.pkl', 'Active-learning-experiment-39.pkl', 'Active-learning-experiment-16.pkl', '.ipython', 'Active-learning-experiment-35.pkl', 'Active-learning-experiment-8.pkl', '.cache', 'Active-learning-experiment-41.pkl', 'Active-learning-experiment-27.pkl', '.config', 'scikit_learn_data', 'Active-learning-experiment-25.pkl', 'Active-learning-experiment-14.pkl', 'Active-learning-experiment-33.pkl', '.rnd', 'Active-learning-experiment-9.pkl', 'Active-learning-experiment-43.pkl', 'Active-learning-experiment-31.pkl', 'Active-learning-experiment-3.pkl', 'Active-learning-experiment-29.pkl', '.local', 'Active-learning-experiment-21.pkl', 'Active-learning-experiment-36.pkl', 'Active-learning-experiment-19.pkl', '.nv', 'Active-learning-experiment-15.pkl', 'Active-learning-experiment-26.pkl', 'Active-learning-experiment-40.pkl', 'Active-learning-experiment-17.pkl', 'Active-learning-experiment-10.pkl', 'Active-learning-experiment-28.pkl', 'Active-learning-experiment-23.pkl', '.keras', 'Active-learning-experiment-13.pkl', 'Active-learning-experiment-7.pkl']\n",
            "{\n",
            "  \"LogModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          36.620000000000005,\n",
            "          46.79,\n",
            "          47.49,\n",
            "          49.96,\n",
            "          51.59,\n",
            "          54.25,\n",
            "          49.43,\n",
            "          55.510000000000005,\n",
            "          52.88,\n",
            "          50.89,\n",
            "          53.04,\n",
            "          52.42,\n",
            "          52.410000000000004,\n",
            "          50.949999999999996,\n",
            "          48.699999999999996,\n",
            "          48.89,\n",
            "          51.160000000000004,\n",
            "          47.68,\n",
            "          46.1,\n",
            "          48.91,\n",
            "          50.739999999999995,\n",
            "          53.080000000000005,\n",
            "          54.790000000000006,\n",
            "          50.88,\n",
            "          53.790000000000006,\n",
            "          56.05,\n",
            "          54.06999999999999,\n",
            "          57.85,\n",
            "          54.279999999999994,\n",
            "          55.86,\n",
            "          57.43000000000001,\n",
            "          47.57,\n",
            "          53.480000000000004,\n",
            "          55.21,\n",
            "          53.32,\n",
            "          54.98,\n",
            "          52.51,\n",
            "          54.39000000000001,\n",
            "          55.88999999999999,\n",
            "          54.61,\n",
            "          55.69,\n",
            "          54.510000000000005,\n",
            "          52.559999999999995,\n",
            "          53.66,\n",
            "          56.089999999999996,\n",
            "          54.230000000000004,\n",
            "          51.77,\n",
            "          52.629999999999995,\n",
            "          55.00000000000001,\n",
            "          48.97\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          59.050000000000004,\n",
            "          52.849999999999994,\n",
            "          54.71,\n",
            "          55.16,\n",
            "          52.349999999999994,\n",
            "          53.94,\n",
            "          53.43,\n",
            "          51.480000000000004,\n",
            "          45.94,\n",
            "          48.92,\n",
            "          48.55,\n",
            "          44.51,\n",
            "          50.72,\n",
            "          48.29,\n",
            "          49.69,\n",
            "          53.61,\n",
            "          49.91,\n",
            "          50.12,\n",
            "          50.59,\n",
            "          52.66\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          61.82,\n",
            "          60.31999999999999,\n",
            "          54.03,\n",
            "          57.220000000000006,\n",
            "          58.67,\n",
            "          57.11000000000001,\n",
            "          53.18000000000001,\n",
            "          57.76,\n",
            "          55.08,\n",
            "          53.42\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          69.07,\n",
            "          62.660000000000004,\n",
            "          58.93000000000001,\n",
            "          60.5\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          73.77,\n",
            "          63.23\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          33.269999999999996,\n",
            "          56.63,\n",
            "          57.709999999999994,\n",
            "          61.82,\n",
            "          64.57000000000001,\n",
            "          67.43,\n",
            "          69.24,\n",
            "          69.76,\n",
            "          69.87,\n",
            "          71.05,\n",
            "          73.27,\n",
            "          71.35000000000001,\n",
            "          70.75,\n",
            "          72.61,\n",
            "          71.23,\n",
            "          72.57000000000001,\n",
            "          72.38,\n",
            "          73.17,\n",
            "          73.94,\n",
            "          73.44000000000001,\n",
            "          72.26,\n",
            "          72.78,\n",
            "          73.68,\n",
            "          72.75,\n",
            "          73.79,\n",
            "          73.91,\n",
            "          72.39,\n",
            "          71.72,\n",
            "          74.39,\n",
            "          73.09,\n",
            "          73.39,\n",
            "          73.25,\n",
            "          72.8,\n",
            "          74.51,\n",
            "          72.15,\n",
            "          72.08,\n",
            "          71.78,\n",
            "          73.69,\n",
            "          73.19,\n",
            "          73.00999999999999,\n",
            "          72.68,\n",
            "          71.67,\n",
            "          72.71,\n",
            "          74.11,\n",
            "          73.06,\n",
            "          74.33999999999999,\n",
            "          72.56,\n",
            "          72.64,\n",
            "          72.35000000000001,\n",
            "          72.86\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          41.980000000000004,\n",
            "          52.12,\n",
            "          65.4,\n",
            "          64.84,\n",
            "          65.10000000000001,\n",
            "          64.14,\n",
            "          65.86999999999999,\n",
            "          66.99000000000001,\n",
            "          70.11,\n",
            "          70.44,\n",
            "          67.21000000000001,\n",
            "          71.17,\n",
            "          70.33,\n",
            "          70.12,\n",
            "          71.6,\n",
            "          70.3,\n",
            "          68.16,\n",
            "          69.51,\n",
            "          69.59,\n",
            "          70.85000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          62.8,\n",
            "          70.19,\n",
            "          68.39,\n",
            "          71.65,\n",
            "          69.44,\n",
            "          70.94,\n",
            "          70.7,\n",
            "          70.14,\n",
            "          71.17,\n",
            "          70.21\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.11,\n",
            "          72.42,\n",
            "          72.0,\n",
            "          72.81\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          73.76,\n",
            "          73.76\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.61,\n",
            "          50.36000000000001,\n",
            "          53.1,\n",
            "          59.74,\n",
            "          62.7,\n",
            "          64.03999999999999,\n",
            "          64.25,\n",
            "          61.629999999999995,\n",
            "          66.47,\n",
            "          68.0,\n",
            "          65.75999999999999,\n",
            "          65.0,\n",
            "          65.27,\n",
            "          66.46,\n",
            "          66.99000000000001,\n",
            "          66.86,\n",
            "          67.28,\n",
            "          66.72,\n",
            "          67.10000000000001,\n",
            "          68.33,\n",
            "          69.25,\n",
            "          69.69999999999999,\n",
            "          69.32000000000001,\n",
            "          67.72,\n",
            "          69.87,\n",
            "          68.69,\n",
            "          68.83,\n",
            "          70.00999999999999,\n",
            "          69.65,\n",
            "          70.19,\n",
            "          71.41,\n",
            "          70.53,\n",
            "          70.15,\n",
            "          68.74,\n",
            "          70.0,\n",
            "          68.24,\n",
            "          68.92,\n",
            "          67.91,\n",
            "          69.17999999999999,\n",
            "          68.87,\n",
            "          69.02000000000001,\n",
            "          70.00999999999999,\n",
            "          70.47,\n",
            "          71.83,\n",
            "          70.78,\n",
            "          70.61,\n",
            "          71.33,\n",
            "          70.91,\n",
            "          71.0,\n",
            "          71.78999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          46.63,\n",
            "          57.86,\n",
            "          62.019999999999996,\n",
            "          70.61,\n",
            "          72.74000000000001,\n",
            "          69.82000000000001,\n",
            "          69.6,\n",
            "          70.81,\n",
            "          70.82000000000001,\n",
            "          69.49,\n",
            "          71.46000000000001,\n",
            "          71.48,\n",
            "          72.04,\n",
            "          72.11,\n",
            "          72.65,\n",
            "          73.09,\n",
            "          73.72,\n",
            "          73.86,\n",
            "          74.69,\n",
            "          73.72999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          68.38,\n",
            "          66.14999999999999,\n",
            "          70.45,\n",
            "          72.68,\n",
            "          72.31,\n",
            "          72.33000000000001,\n",
            "          73.44000000000001,\n",
            "          71.78999999999999,\n",
            "          73.11999999999999,\n",
            "          70.84\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          68.95,\n",
            "          68.53,\n",
            "          71.67,\n",
            "          73.09\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          73.11,\n",
            "          74.56\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"RfModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          37.519999999999996,\n",
            "          42.53,\n",
            "          51.42,\n",
            "          49.03,\n",
            "          49.25,\n",
            "          52.01,\n",
            "          51.41,\n",
            "          51.89,\n",
            "          53.04,\n",
            "          55.48,\n",
            "          56.989999999999995,\n",
            "          56.720000000000006,\n",
            "          56.93,\n",
            "          55.169999999999995,\n",
            "          56.26,\n",
            "          55.64,\n",
            "          54.769999999999996,\n",
            "          54.98,\n",
            "          54.06999999999999,\n",
            "          53.71,\n",
            "          53.21,\n",
            "          52.800000000000004,\n",
            "          53.54,\n",
            "          52.72,\n",
            "          52.65,\n",
            "          51.849999999999994,\n",
            "          51.67,\n",
            "          51.89,\n",
            "          52.54,\n",
            "          53.03,\n",
            "          56.06,\n",
            "          56.26,\n",
            "          55.669999999999995,\n",
            "          60.17,\n",
            "          60.480000000000004,\n",
            "          59.9,\n",
            "          58.97,\n",
            "          60.019999999999996,\n",
            "          59.81999999999999,\n",
            "          59.86,\n",
            "          59.95,\n",
            "          62.970000000000006,\n",
            "          63.7,\n",
            "          62.94,\n",
            "          62.19,\n",
            "          62.019999999999996,\n",
            "          63.89,\n",
            "          62.150000000000006,\n",
            "          60.17,\n",
            "          62.39\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          44.21,\n",
            "          39.2,\n",
            "          37.57,\n",
            "          35.82,\n",
            "          36.120000000000005,\n",
            "          33.64,\n",
            "          32.09,\n",
            "          32.1,\n",
            "          32.28,\n",
            "          30.759999999999998,\n",
            "          31.230000000000004,\n",
            "          29.34,\n",
            "          26.419999999999998,\n",
            "          27.05,\n",
            "          26.58,\n",
            "          23.23,\n",
            "          24.0,\n",
            "          23.7,\n",
            "          21.58,\n",
            "          23.84\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          63.85999999999999,\n",
            "          60.309999999999995,\n",
            "          59.760000000000005,\n",
            "          59.89,\n",
            "          59.160000000000004,\n",
            "          59.519999999999996,\n",
            "          57.9,\n",
            "          59.74,\n",
            "          57.06,\n",
            "          59.91\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          75.02,\n",
            "          74.36,\n",
            "          72.39999999999999,\n",
            "          72.08\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.39999999999999,\n",
            "          81.82000000000001\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          25.72,\n",
            "          38.83,\n",
            "          53.99,\n",
            "          57.53,\n",
            "          62.39,\n",
            "          66.58,\n",
            "          64.23,\n",
            "          67.5,\n",
            "          72.75,\n",
            "          76.35,\n",
            "          77.31,\n",
            "          77.96,\n",
            "          78.17,\n",
            "          80.67,\n",
            "          81.76,\n",
            "          83.63000000000001,\n",
            "          85.26,\n",
            "          85.37,\n",
            "          85.82,\n",
            "          85.76,\n",
            "          86.00999999999999,\n",
            "          87.01,\n",
            "          87.45,\n",
            "          87.83,\n",
            "          88.64999999999999,\n",
            "          88.1,\n",
            "          87.92999999999999,\n",
            "          89.21,\n",
            "          89.57000000000001,\n",
            "          90.34,\n",
            "          91.12,\n",
            "          90.86,\n",
            "          91.17,\n",
            "          91.53999999999999,\n",
            "          91.84,\n",
            "          91.75999999999999,\n",
            "          91.07,\n",
            "          91.36,\n",
            "          91.22,\n",
            "          91.88,\n",
            "          92.0,\n",
            "          91.97,\n",
            "          91.7,\n",
            "          92.12,\n",
            "          92.28,\n",
            "          92.57,\n",
            "          92.63,\n",
            "          92.55,\n",
            "          92.80000000000001,\n",
            "          92.75999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          39.050000000000004,\n",
            "          51.85999999999999,\n",
            "          67.30000000000001,\n",
            "          74.29,\n",
            "          74.42999999999999,\n",
            "          80.15,\n",
            "          83.55,\n",
            "          83.58,\n",
            "          86.24000000000001,\n",
            "          87.22999999999999,\n",
            "          87.89,\n",
            "          88.42999999999999,\n",
            "          88.94,\n",
            "          90.06,\n",
            "          89.57000000000001,\n",
            "          90.03999999999999,\n",
            "          90.03999999999999,\n",
            "          91.14,\n",
            "          91.86,\n",
            "          91.79\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          62.99,\n",
            "          75.07000000000001,\n",
            "          75.38,\n",
            "          83.96000000000001,\n",
            "          87.89,\n",
            "          89.62,\n",
            "          89.7,\n",
            "          91.47999999999999,\n",
            "          91.84,\n",
            "          92.49000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          76.4,\n",
            "          85.66,\n",
            "          90.22,\n",
            "          92.13\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          81.26,\n",
            "          87.98\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          36.01,\n",
            "          43.34,\n",
            "          53.94,\n",
            "          58.02,\n",
            "          60.97,\n",
            "          66.44,\n",
            "          68.63,\n",
            "          70.8,\n",
            "          72.08,\n",
            "          73.58,\n",
            "          73.63,\n",
            "          74.0,\n",
            "          74.2,\n",
            "          75.52,\n",
            "          75.41,\n",
            "          75.81,\n",
            "          75.98,\n",
            "          77.97,\n",
            "          77.5,\n",
            "          80.15,\n",
            "          79.81,\n",
            "          81.13,\n",
            "          80.87,\n",
            "          80.58999999999999,\n",
            "          80.86,\n",
            "          81.26,\n",
            "          82.26,\n",
            "          82.44,\n",
            "          82.75,\n",
            "          82.92,\n",
            "          83.76,\n",
            "          83.50999999999999,\n",
            "          85.05,\n",
            "          85.50999999999999,\n",
            "          85.13,\n",
            "          86.02,\n",
            "          86.02,\n",
            "          86.5,\n",
            "          86.09,\n",
            "          85.83,\n",
            "          86.9,\n",
            "          86.46000000000001,\n",
            "          86.38,\n",
            "          86.88,\n",
            "          87.09,\n",
            "          87.87,\n",
            "          87.47,\n",
            "          87.59,\n",
            "          87.74,\n",
            "          87.78\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.64,\n",
            "          60.72,\n",
            "          65.45,\n",
            "          70.28999999999999,\n",
            "          72.94,\n",
            "          76.08,\n",
            "          77.51,\n",
            "          77.78,\n",
            "          79.35,\n",
            "          80.39,\n",
            "          81.6,\n",
            "          81.17,\n",
            "          82.73,\n",
            "          84.28,\n",
            "          84.15,\n",
            "          85.2,\n",
            "          86.13,\n",
            "          86.78,\n",
            "          86.95,\n",
            "          87.59\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          56.86,\n",
            "          69.43,\n",
            "          71.87,\n",
            "          75.68,\n",
            "          80.01,\n",
            "          82.06,\n",
            "          84.5,\n",
            "          85.92,\n",
            "          86.76,\n",
            "          87.32\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.5,\n",
            "          82.39,\n",
            "          85.76,\n",
            "          87.56\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.19,\n",
            "          88.14999999999999\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"SvmModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          35.93,\n",
            "          35.97,\n",
            "          40.33,\n",
            "          39.39,\n",
            "          41.349999999999994,\n",
            "          42.99,\n",
            "          46.23,\n",
            "          46.18,\n",
            "          47.260000000000005,\n",
            "          52.5,\n",
            "          52.400000000000006,\n",
            "          51.25999999999999,\n",
            "          51.690000000000005,\n",
            "          51.800000000000004,\n",
            "          53.18000000000001,\n",
            "          53.82,\n",
            "          55.88999999999999,\n",
            "          56.120000000000005,\n",
            "          57.269999999999996,\n",
            "          59.41,\n",
            "          59.95,\n",
            "          62.629999999999995,\n",
            "          61.339999999999996,\n",
            "          63.88,\n",
            "          65.34,\n",
            "          65.77,\n",
            "          66.9,\n",
            "          67.96,\n",
            "          68.27,\n",
            "          67.44,\n",
            "          68.45,\n",
            "          68.63,\n",
            "          68.0,\n",
            "          68.47,\n",
            "          68.77,\n",
            "          68.8,\n",
            "          69.17,\n",
            "          68.97,\n",
            "          69.33,\n",
            "          69.67999999999999,\n",
            "          69.95,\n",
            "          70.34,\n",
            "          70.47,\n",
            "          71.19,\n",
            "          71.97,\n",
            "          72.26,\n",
            "          72.06,\n",
            "          71.98,\n",
            "          72.55,\n",
            "          72.78999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          50.33,\n",
            "          51.59,\n",
            "          56.599999999999994,\n",
            "          60.24,\n",
            "          61.57,\n",
            "          63.5,\n",
            "          66.74,\n",
            "          68.19,\n",
            "          68.02,\n",
            "          69.8,\n",
            "          75.88000000000001,\n",
            "          77.24,\n",
            "          78.09,\n",
            "          79.38,\n",
            "          80.4,\n",
            "          80.99,\n",
            "          80.28999999999999,\n",
            "          80.12,\n",
            "          79.75999999999999,\n",
            "          80.36999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          64.55,\n",
            "          68.75,\n",
            "          71.34,\n",
            "          74.11999999999999,\n",
            "          75.96000000000001,\n",
            "          77.03999999999999,\n",
            "          76.85,\n",
            "          79.19,\n",
            "          80.51,\n",
            "          80.99\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          78.4,\n",
            "          78.21000000000001,\n",
            "          80.08,\n",
            "          81.0\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.11,\n",
            "          84.53\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.86,\n",
            "          37.6,\n",
            "          46.23,\n",
            "          58.41,\n",
            "          60.34,\n",
            "          65.98,\n",
            "          65.01,\n",
            "          69.86,\n",
            "          72.28999999999999,\n",
            "          74.65,\n",
            "          76.24,\n",
            "          77.37,\n",
            "          77.59,\n",
            "          78.7,\n",
            "          79.06,\n",
            "          80.06,\n",
            "          81.21000000000001,\n",
            "          82.32000000000001,\n",
            "          83.17,\n",
            "          83.78,\n",
            "          84.6,\n",
            "          84.58,\n",
            "          84.47,\n",
            "          85.07000000000001,\n",
            "          85.64,\n",
            "          85.75,\n",
            "          85.7,\n",
            "          86.18,\n",
            "          86.58,\n",
            "          86.50999999999999,\n",
            "          86.71,\n",
            "          87.09,\n",
            "          86.91,\n",
            "          87.13,\n",
            "          87.42999999999999,\n",
            "          87.75,\n",
            "          87.97,\n",
            "          88.23,\n",
            "          88.23,\n",
            "          88.22,\n",
            "          88.16000000000001,\n",
            "          88.03,\n",
            "          88.38000000000001,\n",
            "          88.39,\n",
            "          88.64,\n",
            "          88.98,\n",
            "          89.05999999999999,\n",
            "          89.34,\n",
            "          89.3,\n",
            "          89.52\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          50.160000000000004,\n",
            "          63.73,\n",
            "          70.14,\n",
            "          74.4,\n",
            "          78.99000000000001,\n",
            "          80.36999999999999,\n",
            "          82.76,\n",
            "          84.35000000000001,\n",
            "          85.78,\n",
            "          86.61999999999999,\n",
            "          87.46000000000001,\n",
            "          87.64,\n",
            "          88.08,\n",
            "          88.75,\n",
            "          88.68,\n",
            "          89.02,\n",
            "          89.39,\n",
            "          89.57000000000001,\n",
            "          89.66,\n",
            "          89.8\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          59.099999999999994,\n",
            "          69.91000000000001,\n",
            "          75.66000000000001,\n",
            "          81.41000000000001,\n",
            "          82.69,\n",
            "          85.07000000000001,\n",
            "          85.92,\n",
            "          86.89,\n",
            "          87.8,\n",
            "          87.6\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.45,\n",
            "          84.1,\n",
            "          86.36,\n",
            "          88.16000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.58,\n",
            "          87.38\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.009999999999998,\n",
            "          33.54,\n",
            "          48.67,\n",
            "          57.34,\n",
            "          61.68,\n",
            "          64.75999999999999,\n",
            "          69.28,\n",
            "          71.97,\n",
            "          73.2,\n",
            "          74.03,\n",
            "          75.08,\n",
            "          76.01,\n",
            "          76.55,\n",
            "          77.42999999999999,\n",
            "          77.75,\n",
            "          79.72,\n",
            "          80.78,\n",
            "          81.62,\n",
            "          81.8,\n",
            "          82.03,\n",
            "          81.82000000000001,\n",
            "          82.72,\n",
            "          82.94,\n",
            "          83.03,\n",
            "          83.72,\n",
            "          83.81,\n",
            "          83.72,\n",
            "          83.95,\n",
            "          84.38,\n",
            "          85.02,\n",
            "          85.36,\n",
            "          85.65,\n",
            "          85.26,\n",
            "          85.37,\n",
            "          85.37,\n",
            "          85.19,\n",
            "          85.18,\n",
            "          85.61999999999999,\n",
            "          85.47,\n",
            "          85.61999999999999,\n",
            "          85.78,\n",
            "          86.00999999999999,\n",
            "          86.05000000000001,\n",
            "          85.96000000000001,\n",
            "          85.96000000000001,\n",
            "          86.0,\n",
            "          86.24000000000001,\n",
            "          86.6,\n",
            "          86.66,\n",
            "          86.81\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.449999999999996,\n",
            "          67.88,\n",
            "          72.25,\n",
            "          77.82,\n",
            "          79.19,\n",
            "          80.32000000000001,\n",
            "          81.19,\n",
            "          81.91000000000001,\n",
            "          82.67999999999999,\n",
            "          82.89,\n",
            "          82.89,\n",
            "          83.05,\n",
            "          83.91999999999999,\n",
            "          84.69,\n",
            "          84.77,\n",
            "          84.66,\n",
            "          85.0,\n",
            "          85.3,\n",
            "          85.79,\n",
            "          86.08\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          56.38999999999999,\n",
            "          72.92999999999999,\n",
            "          78.44,\n",
            "          81.0,\n",
            "          82.73,\n",
            "          83.52000000000001,\n",
            "          84.35000000000001,\n",
            "          85.17,\n",
            "          86.17,\n",
            "          86.66\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          73.76,\n",
            "          83.52000000000001,\n",
            "          85.6,\n",
            "          86.44\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.02000000000001,\n",
            "          85.64\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "---------------------------- FINISHED ---------------------------\n",
            "\n",
            "{\n",
            "  \"LogModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          36.620000000000005,\n",
            "          46.79,\n",
            "          47.49,\n",
            "          49.96,\n",
            "          51.59,\n",
            "          54.25,\n",
            "          49.43,\n",
            "          55.510000000000005,\n",
            "          52.88,\n",
            "          50.89,\n",
            "          53.04,\n",
            "          52.42,\n",
            "          52.410000000000004,\n",
            "          50.949999999999996,\n",
            "          48.699999999999996,\n",
            "          48.89,\n",
            "          51.160000000000004,\n",
            "          47.68,\n",
            "          46.1,\n",
            "          48.91,\n",
            "          50.739999999999995,\n",
            "          53.080000000000005,\n",
            "          54.790000000000006,\n",
            "          50.88,\n",
            "          53.790000000000006,\n",
            "          56.05,\n",
            "          54.06999999999999,\n",
            "          57.85,\n",
            "          54.279999999999994,\n",
            "          55.86,\n",
            "          57.43000000000001,\n",
            "          47.57,\n",
            "          53.480000000000004,\n",
            "          55.21,\n",
            "          53.32,\n",
            "          54.98,\n",
            "          52.51,\n",
            "          54.39000000000001,\n",
            "          55.88999999999999,\n",
            "          54.61,\n",
            "          55.69,\n",
            "          54.510000000000005,\n",
            "          52.559999999999995,\n",
            "          53.66,\n",
            "          56.089999999999996,\n",
            "          54.230000000000004,\n",
            "          51.77,\n",
            "          52.629999999999995,\n",
            "          55.00000000000001,\n",
            "          48.97\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          59.050000000000004,\n",
            "          52.849999999999994,\n",
            "          54.71,\n",
            "          55.16,\n",
            "          52.349999999999994,\n",
            "          53.94,\n",
            "          53.43,\n",
            "          51.480000000000004,\n",
            "          45.94,\n",
            "          48.92,\n",
            "          48.55,\n",
            "          44.51,\n",
            "          50.72,\n",
            "          48.29,\n",
            "          49.69,\n",
            "          53.61,\n",
            "          49.91,\n",
            "          50.12,\n",
            "          50.59,\n",
            "          52.66\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          61.82,\n",
            "          60.31999999999999,\n",
            "          54.03,\n",
            "          57.220000000000006,\n",
            "          58.67,\n",
            "          57.11000000000001,\n",
            "          53.18000000000001,\n",
            "          57.76,\n",
            "          55.08,\n",
            "          53.42\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          69.07,\n",
            "          62.660000000000004,\n",
            "          58.93000000000001,\n",
            "          60.5\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          73.77,\n",
            "          63.23\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          33.269999999999996,\n",
            "          56.63,\n",
            "          57.709999999999994,\n",
            "          61.82,\n",
            "          64.57000000000001,\n",
            "          67.43,\n",
            "          69.24,\n",
            "          69.76,\n",
            "          69.87,\n",
            "          71.05,\n",
            "          73.27,\n",
            "          71.35000000000001,\n",
            "          70.75,\n",
            "          72.61,\n",
            "          71.23,\n",
            "          72.57000000000001,\n",
            "          72.38,\n",
            "          73.17,\n",
            "          73.94,\n",
            "          73.44000000000001,\n",
            "          72.26,\n",
            "          72.78,\n",
            "          73.68,\n",
            "          72.75,\n",
            "          73.79,\n",
            "          73.91,\n",
            "          72.39,\n",
            "          71.72,\n",
            "          74.39,\n",
            "          73.09,\n",
            "          73.39,\n",
            "          73.25,\n",
            "          72.8,\n",
            "          74.51,\n",
            "          72.15,\n",
            "          72.08,\n",
            "          71.78,\n",
            "          73.69,\n",
            "          73.19,\n",
            "          73.00999999999999,\n",
            "          72.68,\n",
            "          71.67,\n",
            "          72.71,\n",
            "          74.11,\n",
            "          73.06,\n",
            "          74.33999999999999,\n",
            "          72.56,\n",
            "          72.64,\n",
            "          72.35000000000001,\n",
            "          72.86\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          41.980000000000004,\n",
            "          52.12,\n",
            "          65.4,\n",
            "          64.84,\n",
            "          65.10000000000001,\n",
            "          64.14,\n",
            "          65.86999999999999,\n",
            "          66.99000000000001,\n",
            "          70.11,\n",
            "          70.44,\n",
            "          67.21000000000001,\n",
            "          71.17,\n",
            "          70.33,\n",
            "          70.12,\n",
            "          71.6,\n",
            "          70.3,\n",
            "          68.16,\n",
            "          69.51,\n",
            "          69.59,\n",
            "          70.85000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          62.8,\n",
            "          70.19,\n",
            "          68.39,\n",
            "          71.65,\n",
            "          69.44,\n",
            "          70.94,\n",
            "          70.7,\n",
            "          70.14,\n",
            "          71.17,\n",
            "          70.21\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.11,\n",
            "          72.42,\n",
            "          72.0,\n",
            "          72.81\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          73.76,\n",
            "          73.76\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.61,\n",
            "          50.36000000000001,\n",
            "          53.1,\n",
            "          59.74,\n",
            "          62.7,\n",
            "          64.03999999999999,\n",
            "          64.25,\n",
            "          61.629999999999995,\n",
            "          66.47,\n",
            "          68.0,\n",
            "          65.75999999999999,\n",
            "          65.0,\n",
            "          65.27,\n",
            "          66.46,\n",
            "          66.99000000000001,\n",
            "          66.86,\n",
            "          67.28,\n",
            "          66.72,\n",
            "          67.10000000000001,\n",
            "          68.33,\n",
            "          69.25,\n",
            "          69.69999999999999,\n",
            "          69.32000000000001,\n",
            "          67.72,\n",
            "          69.87,\n",
            "          68.69,\n",
            "          68.83,\n",
            "          70.00999999999999,\n",
            "          69.65,\n",
            "          70.19,\n",
            "          71.41,\n",
            "          70.53,\n",
            "          70.15,\n",
            "          68.74,\n",
            "          70.0,\n",
            "          68.24,\n",
            "          68.92,\n",
            "          67.91,\n",
            "          69.17999999999999,\n",
            "          68.87,\n",
            "          69.02000000000001,\n",
            "          70.00999999999999,\n",
            "          70.47,\n",
            "          71.83,\n",
            "          70.78,\n",
            "          70.61,\n",
            "          71.33,\n",
            "          70.91,\n",
            "          71.0,\n",
            "          71.78999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          46.63,\n",
            "          57.86,\n",
            "          62.019999999999996,\n",
            "          70.61,\n",
            "          72.74000000000001,\n",
            "          69.82000000000001,\n",
            "          69.6,\n",
            "          70.81,\n",
            "          70.82000000000001,\n",
            "          69.49,\n",
            "          71.46000000000001,\n",
            "          71.48,\n",
            "          72.04,\n",
            "          72.11,\n",
            "          72.65,\n",
            "          73.09,\n",
            "          73.72,\n",
            "          73.86,\n",
            "          74.69,\n",
            "          73.72999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          68.38,\n",
            "          66.14999999999999,\n",
            "          70.45,\n",
            "          72.68,\n",
            "          72.31,\n",
            "          72.33000000000001,\n",
            "          73.44000000000001,\n",
            "          71.78999999999999,\n",
            "          73.11999999999999,\n",
            "          70.84\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          68.95,\n",
            "          68.53,\n",
            "          71.67,\n",
            "          73.09\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          73.11,\n",
            "          74.56\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"RfModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          37.519999999999996,\n",
            "          42.53,\n",
            "          51.42,\n",
            "          49.03,\n",
            "          49.25,\n",
            "          52.01,\n",
            "          51.41,\n",
            "          51.89,\n",
            "          53.04,\n",
            "          55.48,\n",
            "          56.989999999999995,\n",
            "          56.720000000000006,\n",
            "          56.93,\n",
            "          55.169999999999995,\n",
            "          56.26,\n",
            "          55.64,\n",
            "          54.769999999999996,\n",
            "          54.98,\n",
            "          54.06999999999999,\n",
            "          53.71,\n",
            "          53.21,\n",
            "          52.800000000000004,\n",
            "          53.54,\n",
            "          52.72,\n",
            "          52.65,\n",
            "          51.849999999999994,\n",
            "          51.67,\n",
            "          51.89,\n",
            "          52.54,\n",
            "          53.03,\n",
            "          56.06,\n",
            "          56.26,\n",
            "          55.669999999999995,\n",
            "          60.17,\n",
            "          60.480000000000004,\n",
            "          59.9,\n",
            "          58.97,\n",
            "          60.019999999999996,\n",
            "          59.81999999999999,\n",
            "          59.86,\n",
            "          59.95,\n",
            "          62.970000000000006,\n",
            "          63.7,\n",
            "          62.94,\n",
            "          62.19,\n",
            "          62.019999999999996,\n",
            "          63.89,\n",
            "          62.150000000000006,\n",
            "          60.17,\n",
            "          62.39\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          44.21,\n",
            "          39.2,\n",
            "          37.57,\n",
            "          35.82,\n",
            "          36.120000000000005,\n",
            "          33.64,\n",
            "          32.09,\n",
            "          32.1,\n",
            "          32.28,\n",
            "          30.759999999999998,\n",
            "          31.230000000000004,\n",
            "          29.34,\n",
            "          26.419999999999998,\n",
            "          27.05,\n",
            "          26.58,\n",
            "          23.23,\n",
            "          24.0,\n",
            "          23.7,\n",
            "          21.58,\n",
            "          23.84\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          63.85999999999999,\n",
            "          60.309999999999995,\n",
            "          59.760000000000005,\n",
            "          59.89,\n",
            "          59.160000000000004,\n",
            "          59.519999999999996,\n",
            "          57.9,\n",
            "          59.74,\n",
            "          57.06,\n",
            "          59.91\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          75.02,\n",
            "          74.36,\n",
            "          72.39999999999999,\n",
            "          72.08\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.39999999999999,\n",
            "          81.82000000000001\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          25.72,\n",
            "          38.83,\n",
            "          53.99,\n",
            "          57.53,\n",
            "          62.39,\n",
            "          66.58,\n",
            "          64.23,\n",
            "          67.5,\n",
            "          72.75,\n",
            "          76.35,\n",
            "          77.31,\n",
            "          77.96,\n",
            "          78.17,\n",
            "          80.67,\n",
            "          81.76,\n",
            "          83.63000000000001,\n",
            "          85.26,\n",
            "          85.37,\n",
            "          85.82,\n",
            "          85.76,\n",
            "          86.00999999999999,\n",
            "          87.01,\n",
            "          87.45,\n",
            "          87.83,\n",
            "          88.64999999999999,\n",
            "          88.1,\n",
            "          87.92999999999999,\n",
            "          89.21,\n",
            "          89.57000000000001,\n",
            "          90.34,\n",
            "          91.12,\n",
            "          90.86,\n",
            "          91.17,\n",
            "          91.53999999999999,\n",
            "          91.84,\n",
            "          91.75999999999999,\n",
            "          91.07,\n",
            "          91.36,\n",
            "          91.22,\n",
            "          91.88,\n",
            "          92.0,\n",
            "          91.97,\n",
            "          91.7,\n",
            "          92.12,\n",
            "          92.28,\n",
            "          92.57,\n",
            "          92.63,\n",
            "          92.55,\n",
            "          92.80000000000001,\n",
            "          92.75999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          39.050000000000004,\n",
            "          51.85999999999999,\n",
            "          67.30000000000001,\n",
            "          74.29,\n",
            "          74.42999999999999,\n",
            "          80.15,\n",
            "          83.55,\n",
            "          83.58,\n",
            "          86.24000000000001,\n",
            "          87.22999999999999,\n",
            "          87.89,\n",
            "          88.42999999999999,\n",
            "          88.94,\n",
            "          90.06,\n",
            "          89.57000000000001,\n",
            "          90.03999999999999,\n",
            "          90.03999999999999,\n",
            "          91.14,\n",
            "          91.86,\n",
            "          91.79\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          62.99,\n",
            "          75.07000000000001,\n",
            "          75.38,\n",
            "          83.96000000000001,\n",
            "          87.89,\n",
            "          89.62,\n",
            "          89.7,\n",
            "          91.47999999999999,\n",
            "          91.84,\n",
            "          92.49000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          76.4,\n",
            "          85.66,\n",
            "          90.22,\n",
            "          92.13\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          81.26,\n",
            "          87.98\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          36.01,\n",
            "          43.34,\n",
            "          53.94,\n",
            "          58.02,\n",
            "          60.97,\n",
            "          66.44,\n",
            "          68.63,\n",
            "          70.8,\n",
            "          72.08,\n",
            "          73.58,\n",
            "          73.63,\n",
            "          74.0,\n",
            "          74.2,\n",
            "          75.52,\n",
            "          75.41,\n",
            "          75.81,\n",
            "          75.98,\n",
            "          77.97,\n",
            "          77.5,\n",
            "          80.15,\n",
            "          79.81,\n",
            "          81.13,\n",
            "          80.87,\n",
            "          80.58999999999999,\n",
            "          80.86,\n",
            "          81.26,\n",
            "          82.26,\n",
            "          82.44,\n",
            "          82.75,\n",
            "          82.92,\n",
            "          83.76,\n",
            "          83.50999999999999,\n",
            "          85.05,\n",
            "          85.50999999999999,\n",
            "          85.13,\n",
            "          86.02,\n",
            "          86.02,\n",
            "          86.5,\n",
            "          86.09,\n",
            "          85.83,\n",
            "          86.9,\n",
            "          86.46000000000001,\n",
            "          86.38,\n",
            "          86.88,\n",
            "          87.09,\n",
            "          87.87,\n",
            "          87.47,\n",
            "          87.59,\n",
            "          87.74,\n",
            "          87.78\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.64,\n",
            "          60.72,\n",
            "          65.45,\n",
            "          70.28999999999999,\n",
            "          72.94,\n",
            "          76.08,\n",
            "          77.51,\n",
            "          77.78,\n",
            "          79.35,\n",
            "          80.39,\n",
            "          81.6,\n",
            "          81.17,\n",
            "          82.73,\n",
            "          84.28,\n",
            "          84.15,\n",
            "          85.2,\n",
            "          86.13,\n",
            "          86.78,\n",
            "          86.95,\n",
            "          87.59\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          56.86,\n",
            "          69.43,\n",
            "          71.87,\n",
            "          75.68,\n",
            "          80.01,\n",
            "          82.06,\n",
            "          84.5,\n",
            "          85.92,\n",
            "          86.76,\n",
            "          87.32\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          71.5,\n",
            "          82.39,\n",
            "          85.76,\n",
            "          87.56\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.19,\n",
            "          88.14999999999999\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"SvmModel\": {\n",
            "    \"EntropySelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          35.93,\n",
            "          35.97,\n",
            "          40.33,\n",
            "          39.39,\n",
            "          41.349999999999994,\n",
            "          42.99,\n",
            "          46.23,\n",
            "          46.18,\n",
            "          47.260000000000005,\n",
            "          52.5,\n",
            "          52.400000000000006,\n",
            "          51.25999999999999,\n",
            "          51.690000000000005,\n",
            "          51.800000000000004,\n",
            "          53.18000000000001,\n",
            "          53.82,\n",
            "          55.88999999999999,\n",
            "          56.120000000000005,\n",
            "          57.269999999999996,\n",
            "          59.41,\n",
            "          59.95,\n",
            "          62.629999999999995,\n",
            "          61.339999999999996,\n",
            "          63.88,\n",
            "          65.34,\n",
            "          65.77,\n",
            "          66.9,\n",
            "          67.96,\n",
            "          68.27,\n",
            "          67.44,\n",
            "          68.45,\n",
            "          68.63,\n",
            "          68.0,\n",
            "          68.47,\n",
            "          68.77,\n",
            "          68.8,\n",
            "          69.17,\n",
            "          68.97,\n",
            "          69.33,\n",
            "          69.67999999999999,\n",
            "          69.95,\n",
            "          70.34,\n",
            "          70.47,\n",
            "          71.19,\n",
            "          71.97,\n",
            "          72.26,\n",
            "          72.06,\n",
            "          71.98,\n",
            "          72.55,\n",
            "          72.78999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          50.33,\n",
            "          51.59,\n",
            "          56.599999999999994,\n",
            "          60.24,\n",
            "          61.57,\n",
            "          63.5,\n",
            "          66.74,\n",
            "          68.19,\n",
            "          68.02,\n",
            "          69.8,\n",
            "          75.88000000000001,\n",
            "          77.24,\n",
            "          78.09,\n",
            "          79.38,\n",
            "          80.4,\n",
            "          80.99,\n",
            "          80.28999999999999,\n",
            "          80.12,\n",
            "          79.75999999999999,\n",
            "          80.36999999999999\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          64.55,\n",
            "          68.75,\n",
            "          71.34,\n",
            "          74.11999999999999,\n",
            "          75.96000000000001,\n",
            "          77.03999999999999,\n",
            "          76.85,\n",
            "          79.19,\n",
            "          80.51,\n",
            "          80.99\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          78.4,\n",
            "          78.21000000000001,\n",
            "          80.08,\n",
            "          81.0\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.11,\n",
            "          84.53\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"MarginSamplingSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.86,\n",
            "          37.6,\n",
            "          46.23,\n",
            "          58.41,\n",
            "          60.34,\n",
            "          65.98,\n",
            "          65.01,\n",
            "          69.86,\n",
            "          72.28999999999999,\n",
            "          74.65,\n",
            "          76.24,\n",
            "          77.37,\n",
            "          77.59,\n",
            "          78.7,\n",
            "          79.06,\n",
            "          80.06,\n",
            "          81.21000000000001,\n",
            "          82.32000000000001,\n",
            "          83.17,\n",
            "          83.78,\n",
            "          84.6,\n",
            "          84.58,\n",
            "          84.47,\n",
            "          85.07000000000001,\n",
            "          85.64,\n",
            "          85.75,\n",
            "          85.7,\n",
            "          86.18,\n",
            "          86.58,\n",
            "          86.50999999999999,\n",
            "          86.71,\n",
            "          87.09,\n",
            "          86.91,\n",
            "          87.13,\n",
            "          87.42999999999999,\n",
            "          87.75,\n",
            "          87.97,\n",
            "          88.23,\n",
            "          88.23,\n",
            "          88.22,\n",
            "          88.16000000000001,\n",
            "          88.03,\n",
            "          88.38000000000001,\n",
            "          88.39,\n",
            "          88.64,\n",
            "          88.98,\n",
            "          89.05999999999999,\n",
            "          89.34,\n",
            "          89.3,\n",
            "          89.52\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          50.160000000000004,\n",
            "          63.73,\n",
            "          70.14,\n",
            "          74.4,\n",
            "          78.99000000000001,\n",
            "          80.36999999999999,\n",
            "          82.76,\n",
            "          84.35000000000001,\n",
            "          85.78,\n",
            "          86.61999999999999,\n",
            "          87.46000000000001,\n",
            "          87.64,\n",
            "          88.08,\n",
            "          88.75,\n",
            "          88.68,\n",
            "          89.02,\n",
            "          89.39,\n",
            "          89.57000000000001,\n",
            "          89.66,\n",
            "          89.8\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          59.099999999999994,\n",
            "          69.91000000000001,\n",
            "          75.66000000000001,\n",
            "          81.41000000000001,\n",
            "          82.69,\n",
            "          85.07000000000001,\n",
            "          85.92,\n",
            "          86.89,\n",
            "          87.8,\n",
            "          87.6\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          79.45,\n",
            "          84.1,\n",
            "          86.36,\n",
            "          88.16000000000001\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          84.58,\n",
            "          87.38\n",
            "        ]\n",
            "      ]\n",
            "    },\n",
            "    \"RandomSelection\": {\n",
            "      \"10\": [\n",
            "        [\n",
            "          31.009999999999998,\n",
            "          33.54,\n",
            "          48.67,\n",
            "          57.34,\n",
            "          61.68,\n",
            "          64.75999999999999,\n",
            "          69.28,\n",
            "          71.97,\n",
            "          73.2,\n",
            "          74.03,\n",
            "          75.08,\n",
            "          76.01,\n",
            "          76.55,\n",
            "          77.42999999999999,\n",
            "          77.75,\n",
            "          79.72,\n",
            "          80.78,\n",
            "          81.62,\n",
            "          81.8,\n",
            "          82.03,\n",
            "          81.82000000000001,\n",
            "          82.72,\n",
            "          82.94,\n",
            "          83.03,\n",
            "          83.72,\n",
            "          83.81,\n",
            "          83.72,\n",
            "          83.95,\n",
            "          84.38,\n",
            "          85.02,\n",
            "          85.36,\n",
            "          85.65,\n",
            "          85.26,\n",
            "          85.37,\n",
            "          85.37,\n",
            "          85.19,\n",
            "          85.18,\n",
            "          85.61999999999999,\n",
            "          85.47,\n",
            "          85.61999999999999,\n",
            "          85.78,\n",
            "          86.00999999999999,\n",
            "          86.05000000000001,\n",
            "          85.96000000000001,\n",
            "          85.96000000000001,\n",
            "          86.0,\n",
            "          86.24000000000001,\n",
            "          86.6,\n",
            "          86.66,\n",
            "          86.81\n",
            "        ]\n",
            "      ],\n",
            "      \"25\": [\n",
            "        [\n",
            "          51.449999999999996,\n",
            "          67.88,\n",
            "          72.25,\n",
            "          77.82,\n",
            "          79.19,\n",
            "          80.32000000000001,\n",
            "          81.19,\n",
            "          81.91000000000001,\n",
            "          82.67999999999999,\n",
            "          82.89,\n",
            "          82.89,\n",
            "          83.05,\n",
            "          83.91999999999999,\n",
            "          84.69,\n",
            "          84.77,\n",
            "          84.66,\n",
            "          85.0,\n",
            "          85.3,\n",
            "          85.79,\n",
            "          86.08\n",
            "        ]\n",
            "      ],\n",
            "      \"50\": [\n",
            "        [\n",
            "          56.38999999999999,\n",
            "          72.92999999999999,\n",
            "          78.44,\n",
            "          81.0,\n",
            "          82.73,\n",
            "          83.52000000000001,\n",
            "          84.35000000000001,\n",
            "          85.17,\n",
            "          86.17,\n",
            "          86.66\n",
            "        ]\n",
            "      ],\n",
            "      \"125\": [\n",
            "        [\n",
            "          73.76,\n",
            "          83.52000000000001,\n",
            "          85.6,\n",
            "          86.44\n",
            "        ]\n",
            "      ],\n",
            "      \"250\": [\n",
            "        [\n",
            "          83.02000000000001,\n",
            "          85.64\n",
            "        ]\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jea0AHlpe18z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Manual assignment of the dictionary json dump to a variable, these are the results from the previous cell.\n",
        "\n",
        "d = {\n",
        "  \"LogModel\": {\n",
        "    \"EntropySelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          36.620000000000005,\n",
        "          46.79,\n",
        "          47.49,\n",
        "          49.96,\n",
        "          51.59,\n",
        "          54.25,\n",
        "          49.43,\n",
        "          55.510000000000005,\n",
        "          52.88,\n",
        "          50.89,\n",
        "          53.04,\n",
        "          52.42,\n",
        "          52.410000000000004,\n",
        "          50.949999999999996,\n",
        "          48.699999999999996,\n",
        "          48.89,\n",
        "          51.160000000000004,\n",
        "          47.68,\n",
        "          46.1,\n",
        "          48.91,\n",
        "          50.739999999999995,\n",
        "          53.080000000000005,\n",
        "          54.790000000000006,\n",
        "          50.88,\n",
        "          53.790000000000006,\n",
        "          56.05,\n",
        "          54.06999999999999,\n",
        "          57.85,\n",
        "          54.279999999999994,\n",
        "          55.86,\n",
        "          57.43000000000001,\n",
        "          47.57,\n",
        "          53.480000000000004,\n",
        "          55.21,\n",
        "          53.32,\n",
        "          54.98,\n",
        "          52.51,\n",
        "          54.39000000000001,\n",
        "          55.88999999999999,\n",
        "          54.61,\n",
        "          55.69,\n",
        "          54.510000000000005,\n",
        "          52.559999999999995,\n",
        "          53.66,\n",
        "          56.089999999999996,\n",
        "          54.230000000000004,\n",
        "          51.77,\n",
        "          52.629999999999995,\n",
        "          55.00000000000001,\n",
        "          48.97\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          59.050000000000004,\n",
        "          52.849999999999994,\n",
        "          54.71,\n",
        "          55.16,\n",
        "          52.349999999999994,\n",
        "          53.94,\n",
        "          53.43,\n",
        "          51.480000000000004,\n",
        "          45.94,\n",
        "          48.92,\n",
        "          48.55,\n",
        "          44.51,\n",
        "          50.72,\n",
        "          48.29,\n",
        "          49.69,\n",
        "          53.61,\n",
        "          49.91,\n",
        "          50.12,\n",
        "          50.59,\n",
        "          52.66\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          61.82,\n",
        "          60.31999999999999,\n",
        "          54.03,\n",
        "          57.220000000000006,\n",
        "          58.67,\n",
        "          57.11000000000001,\n",
        "          53.18000000000001,\n",
        "          57.76,\n",
        "          55.08,\n",
        "          53.42\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          69.07,\n",
        "          62.660000000000004,\n",
        "          58.93000000000001,\n",
        "          60.5\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          73.77,\n",
        "          63.23\n",
        "        ]\n",
        "      ]\n",
        "    },\n",
        "    \"MarginSamplingSelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          33.269999999999996,\n",
        "          56.63,\n",
        "          57.709999999999994,\n",
        "          61.82,\n",
        "          64.57000000000001,\n",
        "          67.43,\n",
        "          69.24,\n",
        "          69.76,\n",
        "          69.87,\n",
        "          71.05,\n",
        "          73.27,\n",
        "          71.35000000000001,\n",
        "          70.75,\n",
        "          72.61,\n",
        "          71.23,\n",
        "          72.57000000000001,\n",
        "          72.38,\n",
        "          73.17,\n",
        "          73.94,\n",
        "          73.44000000000001,\n",
        "          72.26,\n",
        "          72.78,\n",
        "          73.68,\n",
        "          72.75,\n",
        "          73.79,\n",
        "          73.91,\n",
        "          72.39,\n",
        "          71.72,\n",
        "          74.39,\n",
        "          73.09,\n",
        "          73.39,\n",
        "          73.25,\n",
        "          72.8,\n",
        "          74.51,\n",
        "          72.15,\n",
        "          72.08,\n",
        "          71.78,\n",
        "          73.69,\n",
        "          73.19,\n",
        "          73.00999999999999,\n",
        "          72.68,\n",
        "          71.67,\n",
        "          72.71,\n",
        "          74.11,\n",
        "          73.06,\n",
        "          74.33999999999999,\n",
        "          72.56,\n",
        "          72.64,\n",
        "          72.35000000000001,\n",
        "          72.86\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          41.980000000000004,\n",
        "          52.12,\n",
        "          65.4,\n",
        "          64.84,\n",
        "          65.10000000000001,\n",
        "          64.14,\n",
        "          65.86999999999999,\n",
        "          66.99000000000001,\n",
        "          70.11,\n",
        "          70.44,\n",
        "          67.21000000000001,\n",
        "          71.17,\n",
        "          70.33,\n",
        "          70.12,\n",
        "          71.6,\n",
        "          70.3,\n",
        "          68.16,\n",
        "          69.51,\n",
        "          69.59,\n",
        "          70.85000000000001\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          62.8,\n",
        "          70.19,\n",
        "          68.39,\n",
        "          71.65,\n",
        "          69.44,\n",
        "          70.94,\n",
        "          70.7,\n",
        "          70.14,\n",
        "          71.17,\n",
        "          70.21\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          71.11,\n",
        "          72.42,\n",
        "          72.0,\n",
        "          72.81\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          73.76,\n",
        "          73.76\n",
        "        ]\n",
        "      ]\n",
        "    },\n",
        "    \"RandomSelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          31.61,\n",
        "          50.36000000000001,\n",
        "          53.1,\n",
        "          59.74,\n",
        "          62.7,\n",
        "          64.03999999999999,\n",
        "          64.25,\n",
        "          61.629999999999995,\n",
        "          66.47,\n",
        "          68.0,\n",
        "          65.75999999999999,\n",
        "          65.0,\n",
        "          65.27,\n",
        "          66.46,\n",
        "          66.99000000000001,\n",
        "          66.86,\n",
        "          67.28,\n",
        "          66.72,\n",
        "          67.10000000000001,\n",
        "          68.33,\n",
        "          69.25,\n",
        "          69.69999999999999,\n",
        "          69.32000000000001,\n",
        "          67.72,\n",
        "          69.87,\n",
        "          68.69,\n",
        "          68.83,\n",
        "          70.00999999999999,\n",
        "          69.65,\n",
        "          70.19,\n",
        "          71.41,\n",
        "          70.53,\n",
        "          70.15,\n",
        "          68.74,\n",
        "          70.0,\n",
        "          68.24,\n",
        "          68.92,\n",
        "          67.91,\n",
        "          69.17999999999999,\n",
        "          68.87,\n",
        "          69.02000000000001,\n",
        "          70.00999999999999,\n",
        "          70.47,\n",
        "          71.83,\n",
        "          70.78,\n",
        "          70.61,\n",
        "          71.33,\n",
        "          70.91,\n",
        "          71.0,\n",
        "          71.78999999999999\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          46.63,\n",
        "          57.86,\n",
        "          62.019999999999996,\n",
        "          70.61,\n",
        "          72.74000000000001,\n",
        "          69.82000000000001,\n",
        "          69.6,\n",
        "          70.81,\n",
        "          70.82000000000001,\n",
        "          69.49,\n",
        "          71.46000000000001,\n",
        "          71.48,\n",
        "          72.04,\n",
        "          72.11,\n",
        "          72.65,\n",
        "          73.09,\n",
        "          73.72,\n",
        "          73.86,\n",
        "          74.69,\n",
        "          73.72999999999999\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          68.38,\n",
        "          66.14999999999999,\n",
        "          70.45,\n",
        "          72.68,\n",
        "          72.31,\n",
        "          72.33000000000001,\n",
        "          73.44000000000001,\n",
        "          71.78999999999999,\n",
        "          73.11999999999999,\n",
        "          70.84\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          68.95,\n",
        "          68.53,\n",
        "          71.67,\n",
        "          73.09\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          73.11,\n",
        "          74.56\n",
        "        ]\n",
        "      ]\n",
        "    }\n",
        "  },\n",
        "  \"RfModel\": {\n",
        "    \"EntropySelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          37.519999999999996,\n",
        "          42.53,\n",
        "          51.42,\n",
        "          49.03,\n",
        "          49.25,\n",
        "          52.01,\n",
        "          51.41,\n",
        "          51.89,\n",
        "          53.04,\n",
        "          55.48,\n",
        "          56.989999999999995,\n",
        "          56.720000000000006,\n",
        "          56.93,\n",
        "          55.169999999999995,\n",
        "          56.26,\n",
        "          55.64,\n",
        "          54.769999999999996,\n",
        "          54.98,\n",
        "          54.06999999999999,\n",
        "          53.71,\n",
        "          53.21,\n",
        "          52.800000000000004,\n",
        "          53.54,\n",
        "          52.72,\n",
        "          52.65,\n",
        "          51.849999999999994,\n",
        "          51.67,\n",
        "          51.89,\n",
        "          52.54,\n",
        "          53.03,\n",
        "          56.06,\n",
        "          56.26,\n",
        "          55.669999999999995,\n",
        "          60.17,\n",
        "          60.480000000000004,\n",
        "          59.9,\n",
        "          58.97,\n",
        "          60.019999999999996,\n",
        "          59.81999999999999,\n",
        "          59.86,\n",
        "          59.95,\n",
        "          62.970000000000006,\n",
        "          63.7,\n",
        "          62.94,\n",
        "          62.19,\n",
        "          62.019999999999996,\n",
        "          63.89,\n",
        "          62.150000000000006,\n",
        "          60.17,\n",
        "          62.39\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          44.21,\n",
        "          39.2,\n",
        "          37.57,\n",
        "          35.82,\n",
        "          36.120000000000005,\n",
        "          33.64,\n",
        "          32.09,\n",
        "          32.1,\n",
        "          32.28,\n",
        "          30.759999999999998,\n",
        "          31.230000000000004,\n",
        "          29.34,\n",
        "          26.419999999999998,\n",
        "          27.05,\n",
        "          26.58,\n",
        "          23.23,\n",
        "          24.0,\n",
        "          23.7,\n",
        "          21.58,\n",
        "          23.84\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          63.85999999999999,\n",
        "          60.309999999999995,\n",
        "          59.760000000000005,\n",
        "          59.89,\n",
        "          59.160000000000004,\n",
        "          59.519999999999996,\n",
        "          57.9,\n",
        "          59.74,\n",
        "          57.06,\n",
        "          59.91\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          75.02,\n",
        "          74.36,\n",
        "          72.39999999999999,\n",
        "          72.08\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          84.39999999999999,\n",
        "          81.82000000000001\n",
        "        ]\n",
        "      ]\n",
        "    },\n",
        "    \"MarginSamplingSelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          25.72,\n",
        "          38.83,\n",
        "          53.99,\n",
        "          57.53,\n",
        "          62.39,\n",
        "          66.58,\n",
        "          64.23,\n",
        "          67.5,\n",
        "          72.75,\n",
        "          76.35,\n",
        "          77.31,\n",
        "          77.96,\n",
        "          78.17,\n",
        "          80.67,\n",
        "          81.76,\n",
        "          83.63000000000001,\n",
        "          85.26,\n",
        "          85.37,\n",
        "          85.82,\n",
        "          85.76,\n",
        "          86.00999999999999,\n",
        "          87.01,\n",
        "          87.45,\n",
        "          87.83,\n",
        "          88.64999999999999,\n",
        "          88.1,\n",
        "          87.92999999999999,\n",
        "          89.21,\n",
        "          89.57000000000001,\n",
        "          90.34,\n",
        "          91.12,\n",
        "          90.86,\n",
        "          91.17,\n",
        "          91.53999999999999,\n",
        "          91.84,\n",
        "          91.75999999999999,\n",
        "          91.07,\n",
        "          91.36,\n",
        "          91.22,\n",
        "          91.88,\n",
        "          92.0,\n",
        "          91.97,\n",
        "          91.7,\n",
        "          92.12,\n",
        "          92.28,\n",
        "          92.57,\n",
        "          92.63,\n",
        "          92.55,\n",
        "          92.80000000000001,\n",
        "          92.75999999999999\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          39.050000000000004,\n",
        "          51.85999999999999,\n",
        "          67.30000000000001,\n",
        "          74.29,\n",
        "          74.42999999999999,\n",
        "          80.15,\n",
        "          83.55,\n",
        "          83.58,\n",
        "          86.24000000000001,\n",
        "          87.22999999999999,\n",
        "          87.89,\n",
        "          88.42999999999999,\n",
        "          88.94,\n",
        "          90.06,\n",
        "          89.57000000000001,\n",
        "          90.03999999999999,\n",
        "          90.03999999999999,\n",
        "          91.14,\n",
        "          91.86,\n",
        "          91.79\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          62.99,\n",
        "          75.07000000000001,\n",
        "          75.38,\n",
        "          83.96000000000001,\n",
        "          87.89,\n",
        "          89.62,\n",
        "          89.7,\n",
        "          91.47999999999999,\n",
        "          91.84,\n",
        "          92.49000000000001\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          76.4,\n",
        "          85.66,\n",
        "          90.22,\n",
        "          92.13\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          81.26,\n",
        "          87.98\n",
        "        ]\n",
        "      ]\n",
        "    },\n",
        "    \"RandomSelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          36.01,\n",
        "          43.34,\n",
        "          53.94,\n",
        "          58.02,\n",
        "          60.97,\n",
        "          66.44,\n",
        "          68.63,\n",
        "          70.8,\n",
        "          72.08,\n",
        "          73.58,\n",
        "          73.63,\n",
        "          74.0,\n",
        "          74.2,\n",
        "          75.52,\n",
        "          75.41,\n",
        "          75.81,\n",
        "          75.98,\n",
        "          77.97,\n",
        "          77.5,\n",
        "          80.15,\n",
        "          79.81,\n",
        "          81.13,\n",
        "          80.87,\n",
        "          80.58999999999999,\n",
        "          80.86,\n",
        "          81.26,\n",
        "          82.26,\n",
        "          82.44,\n",
        "          82.75,\n",
        "          82.92,\n",
        "          83.76,\n",
        "          83.50999999999999,\n",
        "          85.05,\n",
        "          85.50999999999999,\n",
        "          85.13,\n",
        "          86.02,\n",
        "          86.02,\n",
        "          86.5,\n",
        "          86.09,\n",
        "          85.83,\n",
        "          86.9,\n",
        "          86.46000000000001,\n",
        "          86.38,\n",
        "          86.88,\n",
        "          87.09,\n",
        "          87.87,\n",
        "          87.47,\n",
        "          87.59,\n",
        "          87.74,\n",
        "          87.78\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          51.64,\n",
        "          60.72,\n",
        "          65.45,\n",
        "          70.28999999999999,\n",
        "          72.94,\n",
        "          76.08,\n",
        "          77.51,\n",
        "          77.78,\n",
        "          79.35,\n",
        "          80.39,\n",
        "          81.6,\n",
        "          81.17,\n",
        "          82.73,\n",
        "          84.28,\n",
        "          84.15,\n",
        "          85.2,\n",
        "          86.13,\n",
        "          86.78,\n",
        "          86.95,\n",
        "          87.59\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          56.86,\n",
        "          69.43,\n",
        "          71.87,\n",
        "          75.68,\n",
        "          80.01,\n",
        "          82.06,\n",
        "          84.5,\n",
        "          85.92,\n",
        "          86.76,\n",
        "          87.32\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          71.5,\n",
        "          82.39,\n",
        "          85.76,\n",
        "          87.56\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          83.19,\n",
        "          88.14999999999999\n",
        "        ]\n",
        "      ]\n",
        "    }\n",
        "  },\n",
        "  \"SvmModel\": {\n",
        "    \"EntropySelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          35.93,\n",
        "          35.97,\n",
        "          40.33,\n",
        "          39.39,\n",
        "          41.349999999999994,\n",
        "          42.99,\n",
        "          46.23,\n",
        "          46.18,\n",
        "          47.260000000000005,\n",
        "          52.5,\n",
        "          52.400000000000006,\n",
        "          51.25999999999999,\n",
        "          51.690000000000005,\n",
        "          51.800000000000004,\n",
        "          53.18000000000001,\n",
        "          53.82,\n",
        "          55.88999999999999,\n",
        "          56.120000000000005,\n",
        "          57.269999999999996,\n",
        "          59.41,\n",
        "          59.95,\n",
        "          62.629999999999995,\n",
        "          61.339999999999996,\n",
        "          63.88,\n",
        "          65.34,\n",
        "          65.77,\n",
        "          66.9,\n",
        "          67.96,\n",
        "          68.27,\n",
        "          67.44,\n",
        "          68.45,\n",
        "          68.63,\n",
        "          68.0,\n",
        "          68.47,\n",
        "          68.77,\n",
        "          68.8,\n",
        "          69.17,\n",
        "          68.97,\n",
        "          69.33,\n",
        "          69.67999999999999,\n",
        "          69.95,\n",
        "          70.34,\n",
        "          70.47,\n",
        "          71.19,\n",
        "          71.97,\n",
        "          72.26,\n",
        "          72.06,\n",
        "          71.98,\n",
        "          72.55,\n",
        "          72.78999999999999\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          50.33,\n",
        "          51.59,\n",
        "          56.599999999999994,\n",
        "          60.24,\n",
        "          61.57,\n",
        "          63.5,\n",
        "          66.74,\n",
        "          68.19,\n",
        "          68.02,\n",
        "          69.8,\n",
        "          75.88000000000001,\n",
        "          77.24,\n",
        "          78.09,\n",
        "          79.38,\n",
        "          80.4,\n",
        "          80.99,\n",
        "          80.28999999999999,\n",
        "          80.12,\n",
        "          79.75999999999999,\n",
        "          80.36999999999999\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          64.55,\n",
        "          68.75,\n",
        "          71.34,\n",
        "          74.11999999999999,\n",
        "          75.96000000000001,\n",
        "          77.03999999999999,\n",
        "          76.85,\n",
        "          79.19,\n",
        "          80.51,\n",
        "          80.99\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          78.4,\n",
        "          78.21000000000001,\n",
        "          80.08,\n",
        "          81.0\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          83.11,\n",
        "          84.53\n",
        "        ]\n",
        "      ]\n",
        "    },\n",
        "    \"MarginSamplingSelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          31.86,\n",
        "          37.6,\n",
        "          46.23,\n",
        "          58.41,\n",
        "          60.34,\n",
        "          65.98,\n",
        "          65.01,\n",
        "          69.86,\n",
        "          72.28999999999999,\n",
        "          74.65,\n",
        "          76.24,\n",
        "          77.37,\n",
        "          77.59,\n",
        "          78.7,\n",
        "          79.06,\n",
        "          80.06,\n",
        "          81.21000000000001,\n",
        "          82.32000000000001,\n",
        "          83.17,\n",
        "          83.78,\n",
        "          84.6,\n",
        "          84.58,\n",
        "          84.47,\n",
        "          85.07000000000001,\n",
        "          85.64,\n",
        "          85.75,\n",
        "          85.7,\n",
        "          86.18,\n",
        "          86.58,\n",
        "          86.50999999999999,\n",
        "          86.71,\n",
        "          87.09,\n",
        "          86.91,\n",
        "          87.13,\n",
        "          87.42999999999999,\n",
        "          87.75,\n",
        "          87.97,\n",
        "          88.23,\n",
        "          88.23,\n",
        "          88.22,\n",
        "          88.16000000000001,\n",
        "          88.03,\n",
        "          88.38000000000001,\n",
        "          88.39,\n",
        "          88.64,\n",
        "          88.98,\n",
        "          89.05999999999999,\n",
        "          89.34,\n",
        "          89.3,\n",
        "          89.52\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          50.160000000000004,\n",
        "          63.73,\n",
        "          70.14,\n",
        "          74.4,\n",
        "          78.99000000000001,\n",
        "          80.36999999999999,\n",
        "          82.76,\n",
        "          84.35000000000001,\n",
        "          85.78,\n",
        "          86.61999999999999,\n",
        "          87.46000000000001,\n",
        "          87.64,\n",
        "          88.08,\n",
        "          88.75,\n",
        "          88.68,\n",
        "          89.02,\n",
        "          89.39,\n",
        "          89.57000000000001,\n",
        "          89.66,\n",
        "          89.8\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          59.099999999999994,\n",
        "          69.91000000000001,\n",
        "          75.66000000000001,\n",
        "          81.41000000000001,\n",
        "          82.69,\n",
        "          85.07000000000001,\n",
        "          85.92,\n",
        "          86.89,\n",
        "          87.8,\n",
        "          87.6\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          79.45,\n",
        "          84.1,\n",
        "          86.36,\n",
        "          88.16000000000001\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          84.58,\n",
        "          87.38\n",
        "        ]\n",
        "      ]\n",
        "    },\n",
        "    \"RandomSelection\": {\n",
        "      \"10\": [\n",
        "        [\n",
        "          31.009999999999998,\n",
        "          33.54,\n",
        "          48.67,\n",
        "          57.34,\n",
        "          61.68,\n",
        "          64.75999999999999,\n",
        "          69.28,\n",
        "          71.97,\n",
        "          73.2,\n",
        "          74.03,\n",
        "          75.08,\n",
        "          76.01,\n",
        "          76.55,\n",
        "          77.42999999999999,\n",
        "          77.75,\n",
        "          79.72,\n",
        "          80.78,\n",
        "          81.62,\n",
        "          81.8,\n",
        "          82.03,\n",
        "          81.82000000000001,\n",
        "          82.72,\n",
        "          82.94,\n",
        "          83.03,\n",
        "          83.72,\n",
        "          83.81,\n",
        "          83.72,\n",
        "          83.95,\n",
        "          84.38,\n",
        "          85.02,\n",
        "          85.36,\n",
        "          85.65,\n",
        "          85.26,\n",
        "          85.37,\n",
        "          85.37,\n",
        "          85.19,\n",
        "          85.18,\n",
        "          85.61999999999999,\n",
        "          85.47,\n",
        "          85.61999999999999,\n",
        "          85.78,\n",
        "          86.00999999999999,\n",
        "          86.05000000000001,\n",
        "          85.96000000000001,\n",
        "          85.96000000000001,\n",
        "          86.0,\n",
        "          86.24000000000001,\n",
        "          86.6,\n",
        "          86.66,\n",
        "          86.81\n",
        "        ]\n",
        "      ],\n",
        "      \"25\": [\n",
        "        [\n",
        "          51.449999999999996,\n",
        "          67.88,\n",
        "          72.25,\n",
        "          77.82,\n",
        "          79.19,\n",
        "          80.32000000000001,\n",
        "          81.19,\n",
        "          81.91000000000001,\n",
        "          82.67999999999999,\n",
        "          82.89,\n",
        "          82.89,\n",
        "          83.05,\n",
        "          83.91999999999999,\n",
        "          84.69,\n",
        "          84.77,\n",
        "          84.66,\n",
        "          85.0,\n",
        "          85.3,\n",
        "          85.79,\n",
        "          86.08\n",
        "        ]\n",
        "      ],\n",
        "      \"50\": [\n",
        "        [\n",
        "          56.38999999999999,\n",
        "          72.92999999999999,\n",
        "          78.44,\n",
        "          81.0,\n",
        "          82.73,\n",
        "          83.52000000000001,\n",
        "          84.35000000000001,\n",
        "          85.17,\n",
        "          86.17,\n",
        "          86.66\n",
        "        ]\n",
        "      ],\n",
        "      \"125\": [\n",
        "        [\n",
        "          73.76,\n",
        "          83.52000000000001,\n",
        "          85.6,\n",
        "          86.44\n",
        "        ]\n",
        "      ],\n",
        "      \"250\": [\n",
        "        [\n",
        "          83.02000000000001,\n",
        "          85.64\n",
        "        ]\n",
        "      ]\n",
        "    }\n",
        "  }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}